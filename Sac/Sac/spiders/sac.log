2017-11-03 10:45:55 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: Sac)
2017-11-03 10:45:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'Sac', 'CONCURRENT_REQUESTS': 32, 'DEPTH_PRIORITY': -1, 'LOG_FILE': 'sac.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Sac.spiders', 'SPIDER_MODULES': ['Sac.spiders']}
2017-11-03 10:45:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-03 10:45:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-03 10:45:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-03 10:45:56 [py.warnings] WARNING: F:\gitwork\pipeline.py:9: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-03 10:45:57 [scrapy.middleware] INFO: Enabled item pipelines:
['Sac.pipelines.SacPipeline']
2017-11-03 10:45:57 [scrapy.core.engine] INFO: Spider opened
2017-11-03 10:45:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-03 10:46:57 [scrapy.extensions.logstats] INFO: Crawled 62 pages (at 62 pages/min), scraped 286 items (at 286 items/min)
2017-11-03 10:48:00 [scrapy.extensions.logstats] INFO: Crawled 139 pages (at 77 pages/min), scraped 363 items (at 77 items/min)
2017-11-03 10:49:03 [scrapy.extensions.logstats] INFO: Crawled 210 pages (at 71 pages/min), scraped 435 items (at 72 items/min)
2017-11-03 10:49:57 [scrapy.extensions.logstats] INFO: Crawled 345 pages (at 135 pages/min), scraped 561 items (at 126 items/min)
2017-11-03 10:50:12 [scrapy.crawler] INFO: Received SIGBREAK, shutting down gracefully. Send again to force 
2017-11-03 10:50:36 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: Sac)
2017-11-03 10:50:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'Sac', 'CONCURRENT_REQUESTS': 32, 'DEPTH_PRIORITY': -1, 'LOG_FILE': 'sac.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Sac.spiders', 'SPIDER_MODULES': ['Sac.spiders']}
2017-11-03 10:50:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-03 10:50:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-03 10:50:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-03 10:50:36 [py.warnings] WARNING: F:\gitwork\pipeline.py:9: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-03 10:50:37 [scrapy.middleware] INFO: Enabled item pipelines:
['Sac.pipelines.SacPipeline']
2017-11-03 10:50:37 [scrapy.core.engine] INFO: Spider opened
2017-11-03 10:50:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-03 10:51:42 [scrapy.extensions.logstats] INFO: Crawled 84 pages (at 84 pages/min), scraped 291 items (at 291 items/min)
2017-11-03 10:52:38 [scrapy.extensions.logstats] INFO: Crawled 143 pages (at 59 pages/min), scraped 339 items (at 48 items/min)
2017-11-03 10:53:38 [scrapy.extensions.logstats] INFO: Crawled 196 pages (at 53 pages/min), scraped 382 items (at 43 items/min)
2017-11-03 10:54:37 [scrapy.extensions.logstats] INFO: Crawled 313 pages (at 117 pages/min), scraped 479 items (at 97 items/min)
2017-11-03 10:55:38 [scrapy.extensions.logstats] INFO: Crawled 517 pages (at 204 pages/min), scraped 651 items (at 172 items/min)
2017-11-03 10:56:38 [scrapy.extensions.logstats] INFO: Crawled 608 pages (at 91 pages/min), scraped 733 items (at 82 items/min)
2017-11-03 10:57:40 [scrapy.extensions.logstats] INFO: Crawled 668 pages (at 60 pages/min), scraped 788 items (at 55 items/min)
2017-11-03 10:58:38 [scrapy.extensions.logstats] INFO: Crawled 747 pages (at 79 pages/min), scraped 848 items (at 60 items/min)
2017-11-03 10:59:38 [scrapy.extensions.logstats] INFO: Crawled 854 pages (at 107 pages/min), scraped 945 items (at 97 items/min)
2017-11-03 11:00:38 [scrapy.extensions.logstats] INFO: Crawled 990 pages (at 136 pages/min), scraped 1066 items (at 121 items/min)
2017-11-03 11:01:38 [scrapy.extensions.logstats] INFO: Crawled 1132 pages (at 142 pages/min), scraped 1187 items (at 121 items/min)
2017-11-03 11:02:37 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 108 pages/min), scraped 1276 items (at 89 items/min)
2017-11-03 11:03:37 [scrapy.extensions.logstats] INFO: Crawled 1345 pages (at 105 pages/min), scraped 1357 items (at 81 items/min)
2017-11-03 11:04:38 [scrapy.extensions.logstats] INFO: Crawled 1470 pages (at 125 pages/min), scraped 1458 items (at 101 items/min)
2017-11-03 11:05:38 [scrapy.extensions.logstats] INFO: Crawled 1635 pages (at 165 pages/min), scraped 1596 items (at 138 items/min)
2017-11-03 11:06:38 [scrapy.extensions.logstats] INFO: Crawled 1745 pages (at 110 pages/min), scraped 1684 items (at 88 items/min)
2017-11-03 11:07:37 [scrapy.extensions.logstats] INFO: Crawled 1852 pages (at 107 pages/min), scraped 1766 items (at 82 items/min)
2017-11-03 11:08:37 [scrapy.extensions.logstats] INFO: Crawled 1911 pages (at 59 pages/min), scraped 1816 items (at 50 items/min)
2017-11-03 11:09:37 [scrapy.extensions.logstats] INFO: Crawled 1994 pages (at 83 pages/min), scraped 1881 items (at 65 items/min)
2017-11-03 11:10:39 [scrapy.extensions.logstats] INFO: Crawled 2119 pages (at 125 pages/min), scraped 1974 items (at 93 items/min)
2017-11-03 11:11:37 [scrapy.extensions.logstats] INFO: Crawled 2242 pages (at 123 pages/min), scraped 2076 items (at 102 items/min)
2017-11-03 11:12:37 [scrapy.extensions.logstats] INFO: Crawled 2363 pages (at 121 pages/min), scraped 2176 items (at 100 items/min)
2017-11-03 11:13:40 [scrapy.extensions.logstats] INFO: Crawled 2420 pages (at 57 pages/min), scraped 2222 items (at 46 items/min)
2017-11-03 11:14:37 [scrapy.extensions.logstats] INFO: Crawled 2533 pages (at 113 pages/min), scraped 2313 items (at 91 items/min)
2017-11-03 11:15:37 [scrapy.extensions.logstats] INFO: Crawled 2666 pages (at 133 pages/min), scraped 2417 items (at 104 items/min)
2017-11-03 11:16:38 [scrapy.extensions.logstats] INFO: Crawled 2760 pages (at 94 pages/min), scraped 2503 items (at 86 items/min)
2017-11-03 11:17:38 [scrapy.extensions.logstats] INFO: Crawled 2833 pages (at 73 pages/min), scraped 2562 items (at 59 items/min)
2017-11-03 11:18:41 [scrapy.extensions.logstats] INFO: Crawled 2896 pages (at 63 pages/min), scraped 2627 items (at 65 items/min)
2017-11-03 11:19:38 [scrapy.extensions.logstats] INFO: Crawled 2949 pages (at 53 pages/min), scraped 2666 items (at 39 items/min)
2017-11-03 11:20:40 [scrapy.extensions.logstats] INFO: Crawled 2992 pages (at 43 pages/min), scraped 2705 items (at 39 items/min)
2017-11-03 11:21:38 [scrapy.extensions.logstats] INFO: Crawled 3035 pages (at 43 pages/min), scraped 2742 items (at 37 items/min)
2017-11-03 11:23:43 [scrapy.extensions.logstats] INFO: Crawled 3038 pages (at 3 pages/min), scraped 2745 items (at 3 items/min)
2017-11-03 11:25:35 [scrapy.extensions.logstats] INFO: Crawled 3043 pages (at 5 pages/min), scraped 2750 items (at 5 items/min)
2017-11-03 11:25:37 [scrapy.extensions.logstats] INFO: Crawled 3048 pages (at 5 pages/min), scraped 2755 items (at 5 items/min)
2017-11-03 11:26:38 [scrapy.extensions.logstats] INFO: Crawled 3209 pages (at 161 pages/min), scraped 2890 items (at 135 items/min)
2017-11-03 11:31:35 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: Sac)
2017-11-03 11:31:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'Sac', 'CONCURRENT_REQUESTS': 32, 'DEPTH_PRIORITY': -1, 'LOG_FILE': 'sac.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Sac.spiders', 'SPIDER_MODULES': ['Sac.spiders']}
2017-11-03 11:31:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-03 11:31:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-03 11:31:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-03 11:31:36 [py.warnings] WARNING: F:\gitwork\pipeline.py:9: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-03 11:31:38 [scrapy.middleware] INFO: Enabled item pipelines:
['Sac.pipelines.SacPipeline']
2017-11-03 11:31:38 [scrapy.core.engine] INFO: Spider opened
2017-11-03 11:31:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-03 11:31:46 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2017-11-03 11:31:46 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-11-03 11:31:46 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2017-11-03 11:31:52 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: Sac)
2017-11-03 11:31:52 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'Sac', 'CONCURRENT_REQUESTS': 32, 'DEPTH_PRIORITY': -1, 'LOG_FILE': 'sac.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Sac.spiders', 'SPIDER_MODULES': ['Sac.spiders']}
2017-11-03 11:31:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-03 11:31:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-03 11:31:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-03 11:31:53 [py.warnings] WARNING: F:\gitwork\pipeline.py:9: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-03 11:31:54 [scrapy.middleware] INFO: Enabled item pipelines:
['Sac.pipelines.SacPipeline']
2017-11-03 11:31:54 [scrapy.core.engine] INFO: Spider opened
2017-11-03 11:31:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-03 11:33:22 [scrapy.extensions.logstats] INFO: Crawled 147 pages (at 147 pages/min), scraped 342 items (at 342 items/min)
2017-11-03 11:34:58 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2017-11-03 11:34:58 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-11-03 11:34:58 [scrapy.extensions.logstats] INFO: Crawled 262 pages (at 115 pages/min), scraped 454 items (at 112 items/min)
2017-11-03 11:34:58 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2017-11-03 11:35:02 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: Sac)
2017-11-03 11:35:02 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'Sac', 'CONCURRENT_REQUESTS': 32, 'DEPTH_PRIORITY': -1, 'LOG_FILE': 'sac.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Sac.spiders', 'SPIDER_MODULES': ['Sac.spiders']}
2017-11-03 11:35:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-03 11:35:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-03 11:35:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-03 11:35:02 [py.warnings] WARNING: F:\gitwork\pipeline.py:9: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-03 11:35:03 [scrapy.middleware] INFO: Enabled item pipelines:
['Sac.pipelines.SacPipeline']
2017-11-03 11:35:03 [scrapy.core.engine] INFO: Spider opened
2017-11-03 11:35:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-03 11:36:03 [scrapy.extensions.logstats] INFO: Crawled 201 pages (at 201 pages/min), scraped 411 items (at 411 items/min)
2017-11-03 11:37:03 [scrapy.extensions.logstats] INFO: Crawled 426 pages (at 225 pages/min), scraped 628 items (at 217 items/min)
2017-11-03 11:38:03 [scrapy.extensions.logstats] INFO: Crawled 657 pages (at 231 pages/min), scraped 851 items (at 223 items/min)
2017-11-03 11:39:03 [scrapy.extensions.logstats] INFO: Crawled 804 pages (at 147 pages/min), scraped 1009 items (at 158 items/min)
2017-11-03 11:40:03 [scrapy.extensions.logstats] INFO: Crawled 1022 pages (at 218 pages/min), scraped 1233 items (at 224 items/min)
2017-11-03 11:41:03 [scrapy.extensions.logstats] INFO: Crawled 1246 pages (at 224 pages/min), scraped 1448 items (at 215 items/min)
2017-11-03 11:42:03 [scrapy.extensions.logstats] INFO: Crawled 1470 pages (at 224 pages/min), scraped 1679 items (at 231 items/min)
2017-11-03 11:43:03 [scrapy.extensions.logstats] INFO: Crawled 1698 pages (at 228 pages/min), scraped 1902 items (at 223 items/min)
2017-11-03 11:44:03 [scrapy.extensions.logstats] INFO: Crawled 1929 pages (at 231 pages/min), scraped 2110 items (at 208 items/min)
2017-11-03 11:45:03 [scrapy.extensions.logstats] INFO: Crawled 2150 pages (at 221 pages/min), scraped 2309 items (at 199 items/min)
2017-11-03 11:46:03 [scrapy.extensions.logstats] INFO: Crawled 2369 pages (at 219 pages/min), scraped 2488 items (at 179 items/min)
2017-11-03 11:47:03 [scrapy.extensions.logstats] INFO: Crawled 2594 pages (at 225 pages/min), scraped 2687 items (at 199 items/min)
2017-11-03 11:48:03 [scrapy.extensions.logstats] INFO: Crawled 2824 pages (at 230 pages/min), scraped 2869 items (at 182 items/min)
2017-11-03 11:49:03 [scrapy.extensions.logstats] INFO: Crawled 3049 pages (at 225 pages/min), scraped 3063 items (at 194 items/min)
2017-11-03 11:50:03 [scrapy.extensions.logstats] INFO: Crawled 3273 pages (at 224 pages/min), scraped 3297 items (at 234 items/min)
2017-11-03 11:51:03 [scrapy.extensions.logstats] INFO: Crawled 3494 pages (at 221 pages/min), scraped 3502 items (at 205 items/min)
2017-11-03 11:52:03 [scrapy.extensions.logstats] INFO: Crawled 3718 pages (at 224 pages/min), scraped 3728 items (at 226 items/min)
2017-11-03 11:53:03 [scrapy.extensions.logstats] INFO: Crawled 3940 pages (at 222 pages/min), scraped 3955 items (at 227 items/min)
2017-11-03 11:54:03 [scrapy.extensions.logstats] INFO: Crawled 4170 pages (at 230 pages/min), scraped 4131 items (at 176 items/min)
2017-11-03 11:55:03 [scrapy.extensions.logstats] INFO: Crawled 4402 pages (at 232 pages/min), scraped 4309 items (at 178 items/min)
2017-11-03 11:56:03 [scrapy.extensions.logstats] INFO: Crawled 4634 pages (at 232 pages/min), scraped 4461 items (at 152 items/min)
2017-11-03 11:57:03 [scrapy.extensions.logstats] INFO: Crawled 4865 pages (at 231 pages/min), scraped 4658 items (at 197 items/min)
2017-11-03 11:58:03 [scrapy.extensions.logstats] INFO: Crawled 5094 pages (at 229 pages/min), scraped 4846 items (at 188 items/min)
2017-11-03 11:59:03 [scrapy.extensions.logstats] INFO: Crawled 5320 pages (at 226 pages/min), scraped 5054 items (at 208 items/min)
2017-11-03 12:00:03 [scrapy.extensions.logstats] INFO: Crawled 5546 pages (at 226 pages/min), scraped 5245 items (at 191 items/min)
2017-11-03 12:01:03 [scrapy.extensions.logstats] INFO: Crawled 5773 pages (at 227 pages/min), scraped 5454 items (at 209 items/min)
2017-11-03 12:02:03 [scrapy.extensions.logstats] INFO: Crawled 6002 pages (at 229 pages/min), scraped 5635 items (at 181 items/min)
2017-11-03 12:03:03 [scrapy.extensions.logstats] INFO: Crawled 6222 pages (at 220 pages/min), scraped 5828 items (at 193 items/min)
2017-11-03 12:04:04 [scrapy.extensions.logstats] INFO: Crawled 6427 pages (at 205 pages/min), scraped 6011 items (at 183 items/min)
2017-11-03 12:05:03 [scrapy.extensions.logstats] INFO: Crawled 6624 pages (at 197 pages/min), scraped 6165 items (at 154 items/min)
2017-11-03 12:06:03 [scrapy.extensions.logstats] INFO: Crawled 6839 pages (at 215 pages/min), scraped 6370 items (at 205 items/min)
2017-11-03 12:07:03 [scrapy.extensions.logstats] INFO: Crawled 7065 pages (at 226 pages/min), scraped 6557 items (at 187 items/min)
2017-11-03 12:08:03 [scrapy.extensions.logstats] INFO: Crawled 7295 pages (at 230 pages/min), scraped 6747 items (at 190 items/min)
2017-11-03 12:09:03 [scrapy.extensions.logstats] INFO: Crawled 7516 pages (at 221 pages/min), scraped 6931 items (at 184 items/min)
2017-11-03 12:10:03 [scrapy.extensions.logstats] INFO: Crawled 7740 pages (at 224 pages/min), scraped 7142 items (at 211 items/min)
2017-11-03 12:11:03 [scrapy.extensions.logstats] INFO: Crawled 7963 pages (at 223 pages/min), scraped 7353 items (at 211 items/min)
2017-11-03 12:12:03 [scrapy.extensions.logstats] INFO: Crawled 8191 pages (at 228 pages/min), scraped 7543 items (at 190 items/min)
2017-11-03 12:13:03 [scrapy.extensions.logstats] INFO: Crawled 8414 pages (at 223 pages/min), scraped 7746 items (at 203 items/min)
2017-11-03 12:14:03 [scrapy.extensions.logstats] INFO: Crawled 8647 pages (at 233 pages/min), scraped 7946 items (at 200 items/min)
2017-11-03 12:15:03 [scrapy.extensions.logstats] INFO: Crawled 8881 pages (at 234 pages/min), scraped 8108 items (at 162 items/min)
2017-11-03 12:16:03 [scrapy.extensions.logstats] INFO: Crawled 9112 pages (at 231 pages/min), scraped 8267 items (at 159 items/min)
2017-11-03 12:17:03 [scrapy.extensions.logstats] INFO: Crawled 9338 pages (at 226 pages/min), scraped 8442 items (at 175 items/min)
2017-11-03 12:18:03 [scrapy.extensions.logstats] INFO: Crawled 9566 pages (at 228 pages/min), scraped 8620 items (at 178 items/min)
2017-11-03 12:19:03 [scrapy.extensions.logstats] INFO: Crawled 9796 pages (at 230 pages/min), scraped 8807 items (at 187 items/min)
2017-11-03 12:19:28 [py.warnings] WARNING: F:\gitwork\Sac\Sac\spiders\sac_person.py:691: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead

2017-11-03 12:19:28 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29966256&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"肖楠","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"中原证券股份有限公司","AOI_ID":"1999073","ADI_ID":"42830","ADI_NAME":"结算托管总部","PTI_NAME":"一般证券业务","CER_NUM":"S0730110030116","OBTAIN_DATE":"2010-03-26","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-03 12:20:03 [scrapy.extensions.logstats] INFO: Crawled 10023 pages (at 227 pages/min), scraped 9000 items (at 193 items/min)
2017-11-03 12:21:03 [scrapy.extensions.logstats] INFO: Crawled 10253 pages (at 230 pages/min), scraped 9187 items (at 187 items/min)
2017-11-03 12:22:03 [scrapy.extensions.logstats] INFO: Crawled 10478 pages (at 225 pages/min), scraped 9377 items (at 190 items/min)
2017-11-03 12:23:03 [scrapy.extensions.logstats] INFO: Crawled 10703 pages (at 225 pages/min), scraped 9569 items (at 192 items/min)
2017-11-03 12:24:03 [scrapy.extensions.logstats] INFO: Crawled 10929 pages (at 226 pages/min), scraped 9753 items (at 184 items/min)
2017-11-03 12:25:03 [scrapy.extensions.logstats] INFO: Crawled 11163 pages (at 234 pages/min), scraped 9938 items (at 185 items/min)
2017-11-03 12:26:03 [scrapy.extensions.logstats] INFO: Crawled 11390 pages (at 227 pages/min), scraped 10130 items (at 192 items/min)
2017-11-03 12:27:03 [scrapy.extensions.logstats] INFO: Crawled 11620 pages (at 230 pages/min), scraped 10309 items (at 179 items/min)
2017-11-03 12:28:03 [scrapy.extensions.logstats] INFO: Crawled 11851 pages (at 231 pages/min), scraped 10487 items (at 178 items/min)
2017-11-03 12:29:03 [scrapy.extensions.logstats] INFO: Crawled 12078 pages (at 227 pages/min), scraped 10687 items (at 200 items/min)
2017-11-03 12:30:03 [scrapy.extensions.logstats] INFO: Crawled 12304 pages (at 226 pages/min), scraped 10868 items (at 181 items/min)
2017-11-03 12:31:03 [scrapy.extensions.logstats] INFO: Crawled 12536 pages (at 232 pages/min), scraped 11071 items (at 203 items/min)
2017-11-03 12:32:03 [scrapy.extensions.logstats] INFO: Crawled 12769 pages (at 233 pages/min), scraped 11289 items (at 218 items/min)
2017-11-03 12:33:03 [scrapy.extensions.logstats] INFO: Crawled 12996 pages (at 227 pages/min), scraped 11482 items (at 193 items/min)
2017-11-03 12:34:03 [scrapy.extensions.logstats] INFO: Crawled 13216 pages (at 220 pages/min), scraped 11710 items (at 228 items/min)
2017-11-03 12:35:03 [scrapy.extensions.logstats] INFO: Crawled 13428 pages (at 212 pages/min), scraped 11965 items (at 255 items/min)
2017-11-03 12:36:03 [scrapy.extensions.logstats] INFO: Crawled 13644 pages (at 216 pages/min), scraped 12163 items (at 198 items/min)
2017-11-03 12:37:03 [scrapy.extensions.logstats] INFO: Crawled 13865 pages (at 221 pages/min), scraped 12326 items (at 163 items/min)
2017-11-03 12:38:03 [scrapy.extensions.logstats] INFO: Crawled 14075 pages (at 210 pages/min), scraped 12521 items (at 195 items/min)
2017-11-03 12:39:03 [scrapy.extensions.logstats] INFO: Crawled 14289 pages (at 214 pages/min), scraped 12724 items (at 203 items/min)
2017-11-03 12:40:03 [scrapy.extensions.logstats] INFO: Crawled 14507 pages (at 218 pages/min), scraped 12929 items (at 205 items/min)
2017-11-03 12:41:03 [scrapy.extensions.logstats] INFO: Crawled 14737 pages (at 230 pages/min), scraped 13143 items (at 214 items/min)
2017-11-03 12:42:03 [scrapy.extensions.logstats] INFO: Crawled 14964 pages (at 227 pages/min), scraped 13367 items (at 224 items/min)
2017-11-03 12:43:03 [scrapy.extensions.logstats] INFO: Crawled 15197 pages (at 233 pages/min), scraped 13584 items (at 217 items/min)
2017-11-03 12:44:03 [scrapy.extensions.logstats] INFO: Crawled 15424 pages (at 227 pages/min), scraped 13809 items (at 225 items/min)
2017-11-03 12:45:03 [scrapy.extensions.logstats] INFO: Crawled 15649 pages (at 225 pages/min), scraped 14017 items (at 208 items/min)
2017-11-03 12:46:03 [scrapy.extensions.logstats] INFO: Crawled 15877 pages (at 228 pages/min), scraped 14245 items (at 228 items/min)
2017-11-03 12:47:03 [scrapy.extensions.logstats] INFO: Crawled 16103 pages (at 226 pages/min), scraped 14450 items (at 205 items/min)
2017-11-03 12:48:03 [scrapy.extensions.logstats] INFO: Crawled 16322 pages (at 219 pages/min), scraped 14658 items (at 208 items/min)
2017-11-03 12:49:03 [scrapy.extensions.logstats] INFO: Crawled 16550 pages (at 228 pages/min), scraped 14865 items (at 207 items/min)
2017-11-03 12:50:03 [scrapy.extensions.logstats] INFO: Crawled 16777 pages (at 227 pages/min), scraped 15073 items (at 208 items/min)
2017-11-03 12:51:03 [scrapy.extensions.logstats] INFO: Crawled 17009 pages (at 232 pages/min), scraped 15286 items (at 213 items/min)
2017-11-03 12:52:03 [scrapy.extensions.logstats] INFO: Crawled 17237 pages (at 228 pages/min), scraped 15489 items (at 203 items/min)
2017-11-03 12:53:03 [scrapy.extensions.logstats] INFO: Crawled 17469 pages (at 232 pages/min), scraped 15678 items (at 189 items/min)
2017-11-03 12:54:03 [scrapy.extensions.logstats] INFO: Crawled 17699 pages (at 230 pages/min), scraped 15871 items (at 193 items/min)
2017-11-03 12:55:03 [scrapy.extensions.logstats] INFO: Crawled 17926 pages (at 227 pages/min), scraped 16071 items (at 200 items/min)
2017-11-03 12:56:03 [scrapy.extensions.logstats] INFO: Crawled 18154 pages (at 228 pages/min), scraped 16263 items (at 192 items/min)
2017-11-03 12:57:03 [scrapy.extensions.logstats] INFO: Crawled 18382 pages (at 228 pages/min), scraped 16452 items (at 189 items/min)
2017-11-03 12:58:03 [scrapy.extensions.logstats] INFO: Crawled 18607 pages (at 225 pages/min), scraped 16658 items (at 206 items/min)
2017-11-03 12:59:03 [scrapy.extensions.logstats] INFO: Crawled 18835 pages (at 228 pages/min), scraped 16867 items (at 209 items/min)
2017-11-03 13:00:03 [scrapy.extensions.logstats] INFO: Crawled 19066 pages (at 231 pages/min), scraped 17019 items (at 152 items/min)
2017-11-03 13:01:03 [scrapy.extensions.logstats] INFO: Crawled 19296 pages (at 230 pages/min), scraped 17175 items (at 156 items/min)
2017-11-03 13:02:03 [scrapy.extensions.logstats] INFO: Crawled 19527 pages (at 231 pages/min), scraped 17345 items (at 170 items/min)
2017-11-03 13:03:03 [scrapy.extensions.logstats] INFO: Crawled 19762 pages (at 235 pages/min), scraped 17519 items (at 174 items/min)
2017-11-03 13:04:03 [scrapy.extensions.logstats] INFO: Crawled 19988 pages (at 226 pages/min), scraped 17702 items (at 183 items/min)
2017-11-03 13:05:03 [scrapy.extensions.logstats] INFO: Crawled 20217 pages (at 229 pages/min), scraped 17902 items (at 200 items/min)
2017-11-03 13:06:03 [scrapy.extensions.logstats] INFO: Crawled 20446 pages (at 229 pages/min), scraped 18069 items (at 167 items/min)
2017-11-03 13:07:03 [scrapy.extensions.logstats] INFO: Crawled 20679 pages (at 233 pages/min), scraped 18254 items (at 185 items/min)
2017-11-03 13:08:03 [scrapy.extensions.logstats] INFO: Crawled 20906 pages (at 227 pages/min), scraped 18431 items (at 177 items/min)
2017-11-03 13:09:03 [scrapy.extensions.logstats] INFO: Crawled 21124 pages (at 218 pages/min), scraped 18603 items (at 172 items/min)
2017-11-03 13:10:03 [scrapy.extensions.logstats] INFO: Crawled 21345 pages (at 221 pages/min), scraped 18778 items (at 175 items/min)
2017-11-03 13:11:03 [scrapy.extensions.logstats] INFO: Crawled 21565 pages (at 220 pages/min), scraped 18955 items (at 177 items/min)
2017-11-03 13:12:03 [scrapy.extensions.logstats] INFO: Crawled 21793 pages (at 228 pages/min), scraped 19138 items (at 183 items/min)
2017-11-03 13:13:03 [scrapy.extensions.logstats] INFO: Crawled 22018 pages (at 225 pages/min), scraped 19336 items (at 198 items/min)
2017-11-03 13:14:03 [scrapy.extensions.logstats] INFO: Crawled 22243 pages (at 225 pages/min), scraped 19545 items (at 209 items/min)
2017-11-03 13:15:03 [scrapy.extensions.logstats] INFO: Crawled 22470 pages (at 227 pages/min), scraped 19760 items (at 215 items/min)
2017-11-03 13:16:03 [scrapy.extensions.logstats] INFO: Crawled 22700 pages (at 230 pages/min), scraped 19952 items (at 192 items/min)
2017-11-03 13:17:03 [scrapy.extensions.logstats] INFO: Crawled 22930 pages (at 230 pages/min), scraped 20147 items (at 195 items/min)
2017-11-03 13:18:03 [scrapy.extensions.logstats] INFO: Crawled 23155 pages (at 225 pages/min), scraped 20349 items (at 202 items/min)
2017-11-03 13:19:03 [scrapy.extensions.logstats] INFO: Crawled 23380 pages (at 225 pages/min), scraped 20569 items (at 220 items/min)
2017-11-03 13:20:03 [scrapy.extensions.logstats] INFO: Crawled 23600 pages (at 220 pages/min), scraped 20813 items (at 244 items/min)
2017-11-03 13:21:03 [scrapy.extensions.logstats] INFO: Crawled 23829 pages (at 229 pages/min), scraped 21010 items (at 197 items/min)
2017-11-03 13:22:03 [scrapy.extensions.logstats] INFO: Crawled 24057 pages (at 228 pages/min), scraped 21203 items (at 193 items/min)
2017-11-03 13:23:03 [scrapy.extensions.logstats] INFO: Crawled 24284 pages (at 227 pages/min), scraped 21396 items (at 193 items/min)
2017-11-03 13:24:03 [scrapy.extensions.logstats] INFO: Crawled 24511 pages (at 227 pages/min), scraped 21612 items (at 216 items/min)
2017-11-03 13:25:03 [scrapy.extensions.logstats] INFO: Crawled 24737 pages (at 226 pages/min), scraped 21832 items (at 220 items/min)
2017-11-03 13:26:03 [scrapy.extensions.logstats] INFO: Crawled 24968 pages (at 231 pages/min), scraped 22073 items (at 241 items/min)
2017-11-03 13:27:03 [scrapy.extensions.logstats] INFO: Crawled 25196 pages (at 228 pages/min), scraped 22302 items (at 229 items/min)
2017-11-03 13:28:03 [scrapy.extensions.logstats] INFO: Crawled 25416 pages (at 220 pages/min), scraped 22538 items (at 236 items/min)
2017-11-03 13:29:03 [scrapy.extensions.logstats] INFO: Crawled 25643 pages (at 227 pages/min), scraped 22757 items (at 219 items/min)
2017-11-03 13:30:03 [scrapy.extensions.logstats] INFO: Crawled 25868 pages (at 225 pages/min), scraped 22981 items (at 224 items/min)
2017-11-03 13:31:03 [scrapy.extensions.logstats] INFO: Crawled 26089 pages (at 221 pages/min), scraped 23172 items (at 191 items/min)
2017-11-03 13:32:03 [scrapy.extensions.logstats] INFO: Crawled 26313 pages (at 224 pages/min), scraped 23360 items (at 188 items/min)
2017-11-03 13:33:03 [scrapy.extensions.logstats] INFO: Crawled 26535 pages (at 222 pages/min), scraped 23552 items (at 192 items/min)
2017-11-03 13:34:03 [scrapy.extensions.logstats] INFO: Crawled 26759 pages (at 224 pages/min), scraped 23710 items (at 158 items/min)
2017-11-03 13:35:07 [scrapy.extensions.logstats] INFO: Crawled 26948 pages (at 189 pages/min), scraped 23868 items (at 158 items/min)
2017-11-03 13:36:03 [scrapy.extensions.logstats] INFO: Crawled 27078 pages (at 130 pages/min), scraped 23973 items (at 105 items/min)
2017-11-03 13:37:03 [scrapy.extensions.logstats] INFO: Crawled 27291 pages (at 213 pages/min), scraped 24137 items (at 164 items/min)
2017-11-03 13:38:03 [scrapy.extensions.logstats] INFO: Crawled 27515 pages (at 224 pages/min), scraped 24313 items (at 176 items/min)
2017-11-03 13:39:03 [scrapy.extensions.logstats] INFO: Crawled 27735 pages (at 220 pages/min), scraped 24491 items (at 178 items/min)
2017-11-03 13:40:03 [scrapy.extensions.logstats] INFO: Crawled 27968 pages (at 233 pages/min), scraped 24672 items (at 181 items/min)
2017-11-03 13:41:03 [scrapy.extensions.logstats] INFO: Crawled 28197 pages (at 229 pages/min), scraped 24856 items (at 184 items/min)
2017-11-03 13:42:03 [scrapy.extensions.logstats] INFO: Crawled 28423 pages (at 226 pages/min), scraped 25034 items (at 178 items/min)
2017-11-03 13:43:03 [scrapy.extensions.logstats] INFO: Crawled 28650 pages (at 227 pages/min), scraped 25215 items (at 181 items/min)
2017-11-03 13:44:03 [scrapy.extensions.logstats] INFO: Crawled 28868 pages (at 218 pages/min), scraped 25391 items (at 176 items/min)
2017-11-03 13:45:03 [scrapy.extensions.logstats] INFO: Crawled 29077 pages (at 209 pages/min), scraped 25543 items (at 152 items/min)
2017-11-03 13:46:05 [scrapy.extensions.logstats] INFO: Crawled 29202 pages (at 125 pages/min), scraped 25640 items (at 97 items/min)
2017-11-03 13:47:03 [scrapy.extensions.logstats] INFO: Crawled 29422 pages (at 220 pages/min), scraped 25802 items (at 162 items/min)
2017-11-03 13:48:03 [scrapy.extensions.logstats] INFO: Crawled 29640 pages (at 218 pages/min), scraped 25973 items (at 171 items/min)
2017-11-03 13:49:03 [scrapy.extensions.logstats] INFO: Crawled 29865 pages (at 225 pages/min), scraped 26142 items (at 169 items/min)
2017-11-03 13:50:05 [scrapy.extensions.logstats] INFO: Crawled 30030 pages (at 165 pages/min), scraped 26272 items (at 130 items/min)
2017-11-03 13:51:06 [scrapy.extensions.logstats] INFO: Crawled 30137 pages (at 107 pages/min), scraped 26356 items (at 84 items/min)
2017-11-03 13:52:03 [scrapy.extensions.logstats] INFO: Crawled 30256 pages (at 119 pages/min), scraped 26453 items (at 97 items/min)
2017-11-03 13:53:03 [scrapy.extensions.logstats] INFO: Crawled 30347 pages (at 91 pages/min), scraped 26530 items (at 77 items/min)
2017-11-03 13:54:03 [scrapy.extensions.logstats] INFO: Crawled 30466 pages (at 119 pages/min), scraped 26619 items (at 89 items/min)
2017-11-03 13:55:03 [scrapy.extensions.logstats] INFO: Crawled 30601 pages (at 135 pages/min), scraped 26722 items (at 103 items/min)
2017-11-03 13:56:03 [scrapy.extensions.logstats] INFO: Crawled 30741 pages (at 140 pages/min), scraped 26829 items (at 107 items/min)
2017-11-03 13:57:03 [scrapy.extensions.logstats] INFO: Crawled 30956 pages (at 215 pages/min), scraped 27005 items (at 176 items/min)
2017-11-03 13:58:03 [scrapy.extensions.logstats] INFO: Crawled 31177 pages (at 221 pages/min), scraped 27184 items (at 179 items/min)
2017-11-03 13:59:03 [scrapy.extensions.logstats] INFO: Crawled 31403 pages (at 226 pages/min), scraped 27358 items (at 174 items/min)
2017-11-03 14:00:03 [scrapy.extensions.logstats] INFO: Crawled 31570 pages (at 167 pages/min), scraped 27490 items (at 132 items/min)
2017-11-03 14:01:04 [scrapy.extensions.logstats] INFO: Crawled 31667 pages (at 97 pages/min), scraped 27560 items (at 70 items/min)
2017-11-03 14:02:04 [scrapy.extensions.logstats] INFO: Crawled 31757 pages (at 90 pages/min), scraped 27641 items (at 81 items/min)
2017-11-03 14:03:03 [scrapy.extensions.logstats] INFO: Crawled 31877 pages (at 120 pages/min), scraped 27738 items (at 97 items/min)
2017-11-03 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 31984 pages (at 107 pages/min), scraped 27836 items (at 98 items/min)
2017-11-03 14:05:04 [scrapy.extensions.logstats] INFO: Crawled 32112 pages (at 128 pages/min), scraped 27925 items (at 89 items/min)
2017-11-03 14:06:04 [scrapy.extensions.logstats] INFO: Crawled 32160 pages (at 48 pages/min), scraped 27970 items (at 45 items/min)
2017-11-03 14:07:20 [scrapy.extensions.logstats] INFO: Crawled 32167 pages (at 7 pages/min), scraped 27974 items (at 4 items/min)
2017-11-03 14:08:05 [scrapy.extensions.logstats] INFO: Crawled 32169 pages (at 2 pages/min), scraped 27976 items (at 2 items/min)
2017-11-03 14:09:16 [scrapy.extensions.logstats] INFO: Crawled 32172 pages (at 3 pages/min), scraped 27979 items (at 3 items/min)
2017-11-03 14:10:04 [scrapy.extensions.logstats] INFO: Crawled 32175 pages (at 3 pages/min), scraped 27981 items (at 2 items/min)
2017-11-03 14:11:04 [scrapy.extensions.logstats] INFO: Crawled 32224 pages (at 49 pages/min), scraped 28018 items (at 37 items/min)
2017-11-03 14:12:03 [scrapy.extensions.logstats] INFO: Crawled 32340 pages (at 116 pages/min), scraped 28105 items (at 87 items/min)
2017-11-03 14:13:03 [scrapy.extensions.logstats] INFO: Crawled 32421 pages (at 81 pages/min), scraped 28175 items (at 70 items/min)
2017-11-03 14:14:13 [scrapy.extensions.logstats] INFO: Crawled 32519 pages (at 98 pages/min), scraped 28241 items (at 66 items/min)
2017-11-03 14:15:14 [scrapy.extensions.logstats] INFO: Crawled 32524 pages (at 5 pages/min), scraped 28245 items (at 4 items/min)
2017-11-03 14:16:03 [scrapy.extensions.logstats] INFO: Crawled 32600 pages (at 76 pages/min), scraped 28300 items (at 55 items/min)
2017-11-03 14:17:03 [scrapy.extensions.logstats] INFO: Crawled 32829 pages (at 229 pages/min), scraped 28482 items (at 182 items/min)
2017-11-03 14:18:03 [scrapy.extensions.logstats] INFO: Crawled 33061 pages (at 232 pages/min), scraped 28667 items (at 185 items/min)
2017-11-03 14:19:03 [scrapy.extensions.logstats] INFO: Crawled 33292 pages (at 231 pages/min), scraped 28849 items (at 182 items/min)
2017-11-03 14:20:03 [scrapy.extensions.logstats] INFO: Crawled 33527 pages (at 235 pages/min), scraped 29043 items (at 194 items/min)
2017-11-03 14:21:03 [scrapy.extensions.logstats] INFO: Crawled 33756 pages (at 229 pages/min), scraped 29232 items (at 189 items/min)
2017-11-03 14:22:03 [scrapy.extensions.logstats] INFO: Crawled 33978 pages (at 222 pages/min), scraped 29415 items (at 183 items/min)
2017-11-03 14:23:03 [scrapy.extensions.logstats] INFO: Crawled 34201 pages (at 223 pages/min), scraped 29602 items (at 187 items/min)
2017-11-03 14:24:18 [scrapy.extensions.logstats] INFO: Crawled 34373 pages (at 172 pages/min), scraped 29739 items (at 137 items/min)
2017-11-03 14:25:14 [scrapy.extensions.logstats] INFO: Crawled 34378 pages (at 5 pages/min), scraped 29742 items (at 3 items/min)
2017-11-03 14:26:03 [scrapy.extensions.logstats] INFO: Crawled 34446 pages (at 68 pages/min), scraped 29800 items (at 58 items/min)
2017-11-03 14:27:03 [scrapy.extensions.logstats] INFO: Crawled 34673 pages (at 227 pages/min), scraped 29992 items (at 192 items/min)
2017-11-03 14:28:03 [scrapy.extensions.logstats] INFO: Crawled 34900 pages (at 227 pages/min), scraped 30171 items (at 179 items/min)
2017-11-03 14:29:03 [scrapy.extensions.logstats] INFO: Crawled 35123 pages (at 223 pages/min), scraped 30353 items (at 182 items/min)
2017-11-03 14:30:04 [scrapy.extensions.logstats] INFO: Crawled 35291 pages (at 168 pages/min), scraped 30490 items (at 137 items/min)
2017-11-03 14:31:03 [scrapy.extensions.logstats] INFO: Crawled 35439 pages (at 148 pages/min), scraped 30609 items (at 119 items/min)
2017-11-03 14:32:04 [scrapy.extensions.logstats] INFO: Crawled 35660 pages (at 221 pages/min), scraped 30798 items (at 189 items/min)
2017-11-03 14:33:06 [scrapy.extensions.logstats] INFO: Crawled 35747 pages (at 87 pages/min), scraped 30864 items (at 66 items/min)
2017-11-03 14:34:06 [scrapy.extensions.logstats] INFO: Crawled 35793 pages (at 46 pages/min), scraped 30896 items (at 32 items/min)
2017-11-03 14:35:05 [scrapy.extensions.logstats] INFO: Crawled 35821 pages (at 28 pages/min), scraped 30916 items (at 20 items/min)
2017-11-03 14:36:03 [scrapy.extensions.logstats] INFO: Crawled 35885 pages (at 64 pages/min), scraped 30975 items (at 59 items/min)
2017-11-03 14:37:03 [scrapy.extensions.logstats] INFO: Crawled 36106 pages (at 221 pages/min), scraped 31149 items (at 174 items/min)
2017-11-03 14:38:03 [scrapy.extensions.logstats] INFO: Crawled 36333 pages (at 227 pages/min), scraped 31327 items (at 178 items/min)
2017-11-03 14:39:03 [scrapy.extensions.logstats] INFO: Crawled 36565 pages (at 232 pages/min), scraped 31518 items (at 191 items/min)
2017-11-03 14:40:03 [scrapy.extensions.logstats] INFO: Crawled 36787 pages (at 222 pages/min), scraped 31686 items (at 168 items/min)
2017-11-03 14:41:03 [scrapy.extensions.logstats] INFO: Crawled 37010 pages (at 223 pages/min), scraped 31852 items (at 166 items/min)
2017-11-03 14:42:03 [scrapy.extensions.logstats] INFO: Crawled 37239 pages (at 229 pages/min), scraped 32020 items (at 168 items/min)
2017-11-03 14:43:03 [scrapy.extensions.logstats] INFO: Crawled 37469 pages (at 230 pages/min), scraped 32192 items (at 172 items/min)
2017-11-03 14:44:03 [scrapy.extensions.logstats] INFO: Crawled 37692 pages (at 223 pages/min), scraped 32370 items (at 178 items/min)
2017-11-03 14:45:03 [scrapy.extensions.logstats] INFO: Crawled 37875 pages (at 183 pages/min), scraped 32511 items (at 141 items/min)
2017-11-03 14:46:03 [scrapy.extensions.logstats] INFO: Crawled 38034 pages (at 159 pages/min), scraped 32637 items (at 126 items/min)
2017-11-03 14:47:03 [scrapy.extensions.logstats] INFO: Crawled 38265 pages (at 231 pages/min), scraped 32821 items (at 184 items/min)
2017-11-03 14:48:03 [scrapy.extensions.logstats] INFO: Crawled 38481 pages (at 216 pages/min), scraped 32988 items (at 167 items/min)
2017-11-03 14:49:03 [scrapy.extensions.logstats] INFO: Crawled 38710 pages (at 229 pages/min), scraped 33186 items (at 198 items/min)
2017-11-03 14:50:04 [scrapy.extensions.logstats] INFO: Crawled 38875 pages (at 165 pages/min), scraped 33314 items (at 128 items/min)
2017-11-03 14:51:03 [scrapy.extensions.logstats] INFO: Crawled 39014 pages (at 139 pages/min), scraped 33420 items (at 106 items/min)
2017-11-03 14:52:05 [scrapy.extensions.logstats] INFO: Crawled 39194 pages (at 180 pages/min), scraped 33548 items (at 128 items/min)
2017-11-03 14:53:03 [scrapy.extensions.logstats] INFO: Crawled 39308 pages (at 114 pages/min), scraped 33631 items (at 83 items/min)
2017-11-03 14:54:03 [scrapy.extensions.logstats] INFO: Crawled 39425 pages (at 117 pages/min), scraped 33727 items (at 96 items/min)
2017-11-03 14:55:04 [scrapy.extensions.logstats] INFO: Crawled 39520 pages (at 95 pages/min), scraped 33805 items (at 78 items/min)
2017-11-03 14:56:03 [scrapy.extensions.logstats] INFO: Crawled 39665 pages (at 145 pages/min), scraped 33924 items (at 119 items/min)
2017-11-03 14:57:03 [scrapy.extensions.logstats] INFO: Crawled 39897 pages (at 232 pages/min), scraped 34098 items (at 174 items/min)
2017-11-03 14:58:03 [scrapy.extensions.logstats] INFO: Crawled 40128 pages (at 231 pages/min), scraped 34267 items (at 169 items/min)
2017-11-03 14:59:03 [scrapy.extensions.logstats] INFO: Crawled 40355 pages (at 227 pages/min), scraped 34454 items (at 187 items/min)
2017-11-03 15:00:04 [scrapy.extensions.logstats] INFO: Crawled 40544 pages (at 189 pages/min), scraped 34606 items (at 152 items/min)
2017-11-03 15:01:05 [scrapy.extensions.logstats] INFO: Crawled 40615 pages (at 71 pages/min), scraped 34669 items (at 63 items/min)
2017-11-03 15:02:03 [scrapy.extensions.logstats] INFO: Crawled 40766 pages (at 151 pages/min), scraped 34789 items (at 120 items/min)
2017-11-03 15:03:03 [scrapy.extensions.logstats] INFO: Crawled 40981 pages (at 215 pages/min), scraped 34969 items (at 180 items/min)
2017-11-03 15:04:04 [scrapy.extensions.logstats] INFO: Crawled 41195 pages (at 214 pages/min), scraped 35157 items (at 188 items/min)
2017-11-03 15:05:03 [scrapy.extensions.logstats] INFO: Crawled 41377 pages (at 182 pages/min), scraped 35296 items (at 139 items/min)
2017-11-03 15:06:03 [scrapy.extensions.logstats] INFO: Crawled 41507 pages (at 130 pages/min), scraped 35408 items (at 112 items/min)
2017-11-03 15:07:03 [scrapy.extensions.logstats] INFO: Crawled 41733 pages (at 226 pages/min), scraped 35583 items (at 175 items/min)
2017-11-03 15:08:03 [scrapy.extensions.logstats] INFO: Crawled 41961 pages (at 228 pages/min), scraped 35770 items (at 187 items/min)
2017-11-03 15:09:03 [scrapy.extensions.logstats] INFO: Crawled 42179 pages (at 218 pages/min), scraped 35937 items (at 167 items/min)
2017-11-03 15:10:03 [scrapy.extensions.logstats] INFO: Crawled 42397 pages (at 218 pages/min), scraped 36113 items (at 176 items/min)
2017-11-03 15:11:03 [scrapy.extensions.logstats] INFO: Crawled 42590 pages (at 193 pages/min), scraped 36267 items (at 154 items/min)
2017-11-03 15:12:04 [scrapy.extensions.logstats] INFO: Crawled 42728 pages (at 138 pages/min), scraped 36373 items (at 106 items/min)
2017-11-03 15:13:03 [scrapy.extensions.logstats] INFO: Crawled 42861 pages (at 133 pages/min), scraped 36472 items (at 99 items/min)
2017-11-03 15:14:03 [scrapy.extensions.logstats] INFO: Crawled 42979 pages (at 118 pages/min), scraped 36575 items (at 103 items/min)
2017-11-03 15:15:06 [scrapy.extensions.logstats] INFO: Crawled 43085 pages (at 106 pages/min), scraped 36647 items (at 72 items/min)
2017-11-03 15:16:03 [scrapy.extensions.logstats] INFO: Crawled 43219 pages (at 134 pages/min), scraped 36746 items (at 99 items/min)
2017-11-03 15:17:03 [scrapy.extensions.logstats] INFO: Crawled 43440 pages (at 221 pages/min), scraped 36925 items (at 179 items/min)
2017-11-03 15:18:03 [scrapy.extensions.logstats] INFO: Crawled 43671 pages (at 231 pages/min), scraped 37093 items (at 168 items/min)
2017-11-03 15:19:03 [scrapy.extensions.logstats] INFO: Crawled 43889 pages (at 218 pages/min), scraped 37277 items (at 184 items/min)
2017-11-03 15:20:03 [scrapy.extensions.logstats] INFO: Crawled 44088 pages (at 199 pages/min), scraped 37430 items (at 153 items/min)
2017-11-03 15:21:03 [scrapy.extensions.logstats] INFO: Crawled 44226 pages (at 138 pages/min), scraped 37543 items (at 113 items/min)
2017-11-03 15:22:03 [scrapy.extensions.logstats] INFO: Crawled 44414 pages (at 188 pages/min), scraped 37700 items (at 157 items/min)
2017-11-03 15:23:03 [scrapy.extensions.logstats] INFO: Crawled 44536 pages (at 122 pages/min), scraped 37814 items (at 114 items/min)
2017-11-03 15:24:03 [scrapy.extensions.logstats] INFO: Crawled 44654 pages (at 118 pages/min), scraped 37915 items (at 101 items/min)
2017-11-03 15:25:04 [scrapy.extensions.logstats] INFO: Crawled 44784 pages (at 130 pages/min), scraped 38012 items (at 97 items/min)
2017-11-03 15:26:03 [scrapy.extensions.logstats] INFO: Crawled 44930 pages (at 146 pages/min), scraped 38143 items (at 131 items/min)
2017-11-03 15:27:06 [scrapy.extensions.logstats] INFO: Crawled 45102 pages (at 172 pages/min), scraped 38295 items (at 152 items/min)
2017-11-03 15:28:05 [scrapy.extensions.logstats] INFO: Crawled 45144 pages (at 42 pages/min), scraped 38321 items (at 26 items/min)
2017-11-03 15:30:45 [scrapy.extensions.logstats] INFO: Crawled 45159 pages (at 15 pages/min), scraped 38340 items (at 19 items/min)
2017-11-03 15:31:03 [scrapy.extensions.logstats] INFO: Crawled 45225 pages (at 66 pages/min), scraped 38393 items (at 53 items/min)
2017-11-03 15:32:03 [scrapy.extensions.logstats] INFO: Crawled 45454 pages (at 229 pages/min), scraped 38579 items (at 186 items/min)
2017-11-03 15:33:03 [scrapy.extensions.logstats] INFO: Crawled 45671 pages (at 217 pages/min), scraped 38755 items (at 176 items/min)
2017-11-03 15:34:03 [scrapy.extensions.logstats] INFO: Crawled 45888 pages (at 217 pages/min), scraped 38927 items (at 172 items/min)
2017-11-03 15:35:03 [scrapy.extensions.logstats] INFO: Crawled 46086 pages (at 198 pages/min), scraped 39090 items (at 163 items/min)
2017-11-03 15:36:03 [scrapy.extensions.logstats] INFO: Crawled 46193 pages (at 107 pages/min), scraped 39161 items (at 71 items/min)
2017-11-03 15:37:03 [scrapy.extensions.logstats] INFO: Crawled 46421 pages (at 228 pages/min), scraped 39348 items (at 187 items/min)
2017-11-03 15:38:05 [scrapy.extensions.logstats] INFO: Crawled 46623 pages (at 202 pages/min), scraped 39524 items (at 176 items/min)
2017-11-03 15:39:04 [scrapy.extensions.logstats] INFO: Crawled 46685 pages (at 62 pages/min), scraped 39569 items (at 45 items/min)
2017-11-03 15:40:03 [scrapy.extensions.logstats] INFO: Crawled 46736 pages (at 51 pages/min), scraped 39604 items (at 35 items/min)
2017-11-03 15:41:03 [scrapy.extensions.logstats] INFO: Crawled 46806 pages (at 70 pages/min), scraped 39678 items (at 74 items/min)
2017-11-03 15:42:04 [scrapy.extensions.logstats] INFO: Crawled 47019 pages (at 213 pages/min), scraped 39847 items (at 169 items/min)
2017-11-03 15:43:03 [scrapy.extensions.logstats] INFO: Crawled 47088 pages (at 69 pages/min), scraped 39900 items (at 53 items/min)
2017-11-03 15:45:22 [scrapy.extensions.logstats] INFO: Crawled 47111 pages (at 23 pages/min), scraped 39919 items (at 19 items/min)
2017-11-03 15:46:03 [scrapy.extensions.logstats] INFO: Crawled 47181 pages (at 70 pages/min), scraped 39966 items (at 47 items/min)
2017-11-03 15:47:03 [scrapy.extensions.logstats] INFO: Crawled 47397 pages (at 216 pages/min), scraped 40150 items (at 184 items/min)
2017-11-03 15:48:03 [scrapy.extensions.logstats] INFO: Crawled 47625 pages (at 228 pages/min), scraped 40345 items (at 195 items/min)
2017-11-03 15:49:03 [scrapy.extensions.logstats] INFO: Crawled 47846 pages (at 221 pages/min), scraped 40525 items (at 180 items/min)
2017-11-03 15:50:03 [scrapy.extensions.logstats] INFO: Crawled 47961 pages (at 115 pages/min), scraped 40606 items (at 81 items/min)
2017-11-03 15:51:03 [scrapy.extensions.logstats] INFO: Crawled 48092 pages (at 131 pages/min), scraped 40720 items (at 114 items/min)
2017-11-03 15:52:03 [scrapy.extensions.logstats] INFO: Crawled 48321 pages (at 229 pages/min), scraped 40898 items (at 178 items/min)
2017-11-03 15:53:03 [scrapy.extensions.logstats] INFO: Crawled 48548 pages (at 227 pages/min), scraped 41073 items (at 175 items/min)
2017-11-03 15:54:03 [scrapy.extensions.logstats] INFO: Crawled 48779 pages (at 231 pages/min), scraped 41257 items (at 184 items/min)
2017-11-03 15:55:08 [scrapy.extensions.logstats] INFO: Crawled 48992 pages (at 213 pages/min), scraped 41422 items (at 165 items/min)
2017-11-03 15:56:03 [scrapy.extensions.logstats] INFO: Crawled 49166 pages (at 174 pages/min), scraped 41561 items (at 139 items/min)
2017-11-03 15:57:03 [scrapy.extensions.logstats] INFO: Crawled 49382 pages (at 216 pages/min), scraped 41739 items (at 178 items/min)
2017-11-03 15:58:04 [scrapy.extensions.logstats] INFO: Crawled 49528 pages (at 146 pages/min), scraped 41855 items (at 116 items/min)
2017-11-03 15:59:04 [scrapy.extensions.logstats] INFO: Crawled 49637 pages (at 109 pages/min), scraped 41948 items (at 93 items/min)
2017-11-03 16:00:04 [scrapy.extensions.logstats] INFO: Crawled 49751 pages (at 114 pages/min), scraped 42028 items (at 80 items/min)
2017-11-03 16:01:03 [scrapy.extensions.logstats] INFO: Crawled 49898 pages (at 147 pages/min), scraped 42157 items (at 129 items/min)
2017-11-03 16:02:03 [scrapy.extensions.logstats] INFO: Crawled 50119 pages (at 221 pages/min), scraped 42333 items (at 176 items/min)
2017-11-03 16:03:04 [scrapy.extensions.logstats] INFO: Crawled 50279 pages (at 160 pages/min), scraped 42466 items (at 133 items/min)
2017-11-03 16:04:03 [scrapy.extensions.logstats] INFO: Crawled 50391 pages (at 112 pages/min), scraped 42571 items (at 105 items/min)
2017-11-03 16:05:04 [scrapy.extensions.logstats] INFO: Crawled 50495 pages (at 104 pages/min), scraped 42653 items (at 82 items/min)
2017-11-03 16:06:03 [scrapy.extensions.logstats] INFO: Crawled 50589 pages (at 94 pages/min), scraped 42726 items (at 73 items/min)
2017-11-03 16:07:03 [scrapy.extensions.logstats] INFO: Crawled 50816 pages (at 227 pages/min), scraped 42902 items (at 176 items/min)
2017-11-03 16:08:03 [scrapy.extensions.logstats] INFO: Crawled 51051 pages (at 235 pages/min), scraped 43103 items (at 201 items/min)
2017-11-03 16:09:03 [scrapy.extensions.logstats] INFO: Crawled 51275 pages (at 224 pages/min), scraped 43292 items (at 189 items/min)
2017-11-03 16:10:03 [scrapy.extensions.logstats] INFO: Crawled 51403 pages (at 128 pages/min), scraped 43387 items (at 95 items/min)
2017-11-03 16:11:03 [scrapy.extensions.logstats] INFO: Crawled 51627 pages (at 224 pages/min), scraped 43575 items (at 188 items/min)
2017-11-03 16:12:03 [scrapy.extensions.logstats] INFO: Crawled 51853 pages (at 226 pages/min), scraped 43772 items (at 197 items/min)
2017-11-03 16:13:03 [scrapy.extensions.logstats] INFO: Crawled 52087 pages (at 234 pages/min), scraped 43954 items (at 182 items/min)
2017-11-03 16:14:03 [scrapy.extensions.logstats] INFO: Crawled 52316 pages (at 229 pages/min), scraped 44129 items (at 175 items/min)
2017-11-03 16:15:03 [scrapy.extensions.logstats] INFO: Crawled 52548 pages (at 232 pages/min), scraped 44326 items (at 197 items/min)
2017-11-03 16:16:03 [scrapy.extensions.logstats] INFO: Crawled 52777 pages (at 229 pages/min), scraped 44502 items (at 176 items/min)
2017-11-03 16:17:03 [scrapy.extensions.logstats] INFO: Crawled 53004 pages (at 227 pages/min), scraped 44692 items (at 190 items/min)
2017-11-03 16:18:03 [scrapy.extensions.logstats] INFO: Crawled 53227 pages (at 223 pages/min), scraped 44886 items (at 194 items/min)
2017-11-03 16:19:03 [scrapy.extensions.logstats] INFO: Crawled 53458 pages (at 231 pages/min), scraped 45066 items (at 180 items/min)
2017-11-03 16:20:03 [scrapy.extensions.logstats] INFO: Crawled 53692 pages (at 234 pages/min), scraped 45254 items (at 188 items/min)
2017-11-03 16:21:03 [scrapy.extensions.logstats] INFO: Crawled 53916 pages (at 224 pages/min), scraped 45437 items (at 183 items/min)
2017-11-03 16:22:03 [scrapy.extensions.logstats] INFO: Crawled 54142 pages (at 226 pages/min), scraped 45617 items (at 180 items/min)
2017-11-03 16:23:03 [scrapy.extensions.logstats] INFO: Crawled 54373 pages (at 231 pages/min), scraped 45805 items (at 188 items/min)
2017-11-03 16:24:03 [scrapy.extensions.logstats] INFO: Crawled 54597 pages (at 224 pages/min), scraped 45995 items (at 190 items/min)
2017-11-03 16:25:03 [scrapy.extensions.logstats] INFO: Crawled 54825 pages (at 228 pages/min), scraped 46180 items (at 185 items/min)
2017-11-03 16:26:03 [scrapy.extensions.logstats] INFO: Crawled 55054 pages (at 229 pages/min), scraped 46379 items (at 199 items/min)
2017-11-03 16:27:03 [scrapy.extensions.logstats] INFO: Crawled 55276 pages (at 222 pages/min), scraped 46562 items (at 183 items/min)
2017-11-03 16:28:03 [scrapy.extensions.logstats] INFO: Crawled 55502 pages (at 226 pages/min), scraped 46754 items (at 192 items/min)
2017-11-03 16:29:03 [scrapy.extensions.logstats] INFO: Crawled 55723 pages (at 221 pages/min), scraped 46931 items (at 177 items/min)
2017-11-03 16:30:03 [scrapy.extensions.logstats] INFO: Crawled 55953 pages (at 230 pages/min), scraped 47136 items (at 205 items/min)
2017-11-03 16:31:03 [scrapy.extensions.logstats] INFO: Crawled 56177 pages (at 224 pages/min), scraped 47328 items (at 192 items/min)
2017-11-03 16:32:03 [scrapy.extensions.logstats] INFO: Crawled 56407 pages (at 230 pages/min), scraped 47518 items (at 190 items/min)
2017-11-03 16:33:03 [scrapy.extensions.logstats] INFO: Crawled 56635 pages (at 228 pages/min), scraped 47707 items (at 189 items/min)
2017-11-03 16:34:03 [scrapy.extensions.logstats] INFO: Crawled 56862 pages (at 227 pages/min), scraped 47909 items (at 202 items/min)
2017-11-03 16:35:03 [scrapy.extensions.logstats] INFO: Crawled 57085 pages (at 223 pages/min), scraped 48106 items (at 197 items/min)
2017-11-03 16:36:03 [scrapy.extensions.logstats] INFO: Crawled 57311 pages (at 226 pages/min), scraped 48297 items (at 191 items/min)
2017-11-03 16:37:03 [scrapy.extensions.logstats] INFO: Crawled 57540 pages (at 229 pages/min), scraped 48485 items (at 188 items/min)
2017-11-03 16:38:03 [scrapy.extensions.logstats] INFO: Crawled 57768 pages (at 228 pages/min), scraped 48673 items (at 188 items/min)
2017-11-03 16:39:03 [scrapy.extensions.logstats] INFO: Crawled 57994 pages (at 226 pages/min), scraped 48865 items (at 192 items/min)
2017-11-03 16:40:03 [scrapy.extensions.logstats] INFO: Crawled 58216 pages (at 222 pages/min), scraped 49042 items (at 177 items/min)
2017-11-03 16:41:03 [scrapy.extensions.logstats] INFO: Crawled 58446 pages (at 230 pages/min), scraped 49237 items (at 195 items/min)
2017-11-03 16:42:03 [scrapy.extensions.logstats] INFO: Crawled 58669 pages (at 223 pages/min), scraped 49436 items (at 199 items/min)
2017-11-03 16:43:03 [scrapy.extensions.logstats] INFO: Crawled 58901 pages (at 232 pages/min), scraped 49617 items (at 181 items/min)
2017-11-03 16:44:03 [scrapy.extensions.logstats] INFO: Crawled 59130 pages (at 229 pages/min), scraped 49791 items (at 174 items/min)
2017-11-03 16:45:03 [scrapy.extensions.logstats] INFO: Crawled 59360 pages (at 230 pages/min), scraped 49956 items (at 165 items/min)
2017-11-03 16:46:03 [scrapy.extensions.logstats] INFO: Crawled 59586 pages (at 226 pages/min), scraped 50123 items (at 167 items/min)
2017-11-03 16:47:03 [scrapy.extensions.logstats] INFO: Crawled 59812 pages (at 226 pages/min), scraped 50300 items (at 177 items/min)
2017-11-03 16:48:03 [scrapy.extensions.logstats] INFO: Crawled 60039 pages (at 227 pages/min), scraped 50461 items (at 161 items/min)
2017-11-03 16:49:03 [scrapy.extensions.logstats] INFO: Crawled 60268 pages (at 229 pages/min), scraped 50642 items (at 181 items/min)
2017-11-03 16:50:03 [scrapy.extensions.logstats] INFO: Crawled 60502 pages (at 234 pages/min), scraped 50832 items (at 190 items/min)
2017-11-03 16:51:03 [scrapy.extensions.logstats] INFO: Crawled 60724 pages (at 222 pages/min), scraped 51008 items (at 176 items/min)
2017-11-03 16:52:03 [scrapy.extensions.logstats] INFO: Crawled 60957 pages (at 233 pages/min), scraped 51197 items (at 189 items/min)
2017-11-03 16:53:03 [scrapy.extensions.logstats] INFO: Crawled 61183 pages (at 226 pages/min), scraped 51376 items (at 179 items/min)
2017-11-03 16:54:03 [scrapy.extensions.logstats] INFO: Crawled 61410 pages (at 227 pages/min), scraped 51557 items (at 181 items/min)
2017-11-03 16:55:03 [scrapy.extensions.logstats] INFO: Crawled 61632 pages (at 222 pages/min), scraped 51722 items (at 165 items/min)
2017-11-03 16:56:03 [scrapy.extensions.logstats] INFO: Crawled 61867 pages (at 235 pages/min), scraped 51890 items (at 168 items/min)
2017-11-03 16:57:03 [scrapy.extensions.logstats] INFO: Crawled 62095 pages (at 228 pages/min), scraped 52060 items (at 170 items/min)
2017-11-03 16:58:03 [scrapy.extensions.logstats] INFO: Crawled 62317 pages (at 222 pages/min), scraped 52240 items (at 180 items/min)
2017-11-03 16:59:03 [scrapy.extensions.logstats] INFO: Crawled 62543 pages (at 226 pages/min), scraped 52395 items (at 155 items/min)
2017-11-03 17:00:03 [scrapy.extensions.logstats] INFO: Crawled 62770 pages (at 227 pages/min), scraped 52565 items (at 170 items/min)
2017-11-03 17:01:03 [scrapy.extensions.logstats] INFO: Crawled 62991 pages (at 221 pages/min), scraped 52743 items (at 178 items/min)
2017-11-03 17:02:03 [scrapy.extensions.logstats] INFO: Crawled 63220 pages (at 229 pages/min), scraped 52938 items (at 195 items/min)
2017-11-03 17:03:03 [scrapy.extensions.logstats] INFO: Crawled 63450 pages (at 230 pages/min), scraped 53123 items (at 185 items/min)
2017-11-03 17:04:03 [scrapy.extensions.logstats] INFO: Crawled 63675 pages (at 225 pages/min), scraped 53310 items (at 187 items/min)
2017-11-03 17:05:03 [scrapy.extensions.logstats] INFO: Crawled 63900 pages (at 225 pages/min), scraped 53493 items (at 183 items/min)
2017-11-03 17:06:03 [scrapy.extensions.logstats] INFO: Crawled 64120 pages (at 220 pages/min), scraped 53675 items (at 182 items/min)
2017-11-03 17:07:03 [scrapy.extensions.logstats] INFO: Crawled 64348 pages (at 228 pages/min), scraped 53869 items (at 194 items/min)
2017-11-03 17:08:03 [scrapy.extensions.logstats] INFO: Crawled 64567 pages (at 219 pages/min), scraped 54057 items (at 188 items/min)
2017-11-03 17:09:03 [scrapy.extensions.logstats] INFO: Crawled 64790 pages (at 223 pages/min), scraped 54253 items (at 196 items/min)
2017-11-03 17:10:03 [scrapy.extensions.logstats] INFO: Crawled 65012 pages (at 222 pages/min), scraped 54443 items (at 190 items/min)
2017-11-03 17:11:03 [scrapy.extensions.logstats] INFO: Crawled 65232 pages (at 220 pages/min), scraped 54628 items (at 185 items/min)
2017-11-03 17:12:03 [scrapy.extensions.logstats] INFO: Crawled 65458 pages (at 226 pages/min), scraped 54827 items (at 199 items/min)
2017-11-03 17:13:03 [scrapy.extensions.logstats] INFO: Crawled 65686 pages (at 228 pages/min), scraped 55020 items (at 193 items/min)
2017-11-03 17:14:03 [scrapy.extensions.logstats] INFO: Crawled 65912 pages (at 226 pages/min), scraped 55215 items (at 195 items/min)
2017-11-03 17:15:03 [scrapy.extensions.logstats] INFO: Crawled 66121 pages (at 209 pages/min), scraped 55390 items (at 175 items/min)
2017-11-03 17:16:03 [scrapy.extensions.logstats] INFO: Crawled 66302 pages (at 181 pages/min), scraped 55549 items (at 159 items/min)
2017-11-03 17:17:03 [scrapy.extensions.logstats] INFO: Crawled 66516 pages (at 214 pages/min), scraped 55730 items (at 181 items/min)
2017-11-03 17:18:03 [scrapy.extensions.logstats] INFO: Crawled 66736 pages (at 220 pages/min), scraped 55914 items (at 184 items/min)
2017-11-03 17:19:03 [scrapy.extensions.logstats] INFO: Crawled 66950 pages (at 214 pages/min), scraped 56092 items (at 178 items/min)
2017-11-03 17:20:03 [scrapy.extensions.logstats] INFO: Crawled 67167 pages (at 217 pages/min), scraped 56290 items (at 198 items/min)
2017-11-03 17:21:03 [scrapy.extensions.logstats] INFO: Crawled 67384 pages (at 217 pages/min), scraped 56501 items (at 211 items/min)
2017-11-03 17:22:03 [scrapy.extensions.logstats] INFO: Crawled 67615 pages (at 231 pages/min), scraped 56705 items (at 204 items/min)
2017-11-03 17:23:03 [scrapy.extensions.logstats] INFO: Crawled 67835 pages (at 220 pages/min), scraped 56916 items (at 211 items/min)
2017-11-03 17:24:03 [scrapy.extensions.logstats] INFO: Crawled 68047 pages (at 212 pages/min), scraped 57120 items (at 204 items/min)
2017-11-03 17:25:03 [scrapy.extensions.logstats] INFO: Crawled 68250 pages (at 203 pages/min), scraped 57318 items (at 198 items/min)
2017-11-03 17:26:05 [scrapy.extensions.logstats] INFO: Crawled 68421 pages (at 171 pages/min), scraped 57487 items (at 169 items/min)
2017-11-03 17:27:03 [scrapy.extensions.logstats] INFO: Crawled 68622 pages (at 201 pages/min), scraped 57690 items (at 203 items/min)
2017-11-03 17:28:03 [scrapy.extensions.logstats] INFO: Crawled 68839 pages (at 217 pages/min), scraped 57884 items (at 194 items/min)
2017-11-03 17:29:03 [scrapy.extensions.logstats] INFO: Crawled 69044 pages (at 205 pages/min), scraped 58075 items (at 191 items/min)
2017-11-03 17:30:03 [scrapy.extensions.logstats] INFO: Crawled 69254 pages (at 210 pages/min), scraped 58263 items (at 188 items/min)
2017-11-03 17:31:03 [scrapy.extensions.logstats] INFO: Crawled 69404 pages (at 150 pages/min), scraped 58398 items (at 135 items/min)
2017-11-03 17:32:03 [scrapy.extensions.logstats] INFO: Crawled 69606 pages (at 202 pages/min), scraped 58590 items (at 192 items/min)
2017-11-03 17:33:04 [scrapy.extensions.logstats] INFO: Crawled 69702 pages (at 96 pages/min), scraped 58686 items (at 96 items/min)
2017-11-03 17:34:04 [scrapy.extensions.logstats] INFO: Crawled 69789 pages (at 87 pages/min), scraped 58755 items (at 69 items/min)
2017-11-03 17:35:03 [scrapy.extensions.logstats] INFO: Crawled 69880 pages (at 91 pages/min), scraped 58841 items (at 86 items/min)
2017-11-03 17:36:03 [scrapy.extensions.logstats] INFO: Crawled 69984 pages (at 104 pages/min), scraped 58934 items (at 93 items/min)
2017-11-03 17:37:03 [scrapy.extensions.logstats] INFO: Crawled 70190 pages (at 206 pages/min), scraped 59129 items (at 195 items/min)
2017-11-03 17:38:03 [scrapy.extensions.logstats] INFO: Crawled 70417 pages (at 227 pages/min), scraped 59329 items (at 200 items/min)
2017-11-03 17:39:03 [scrapy.extensions.logstats] INFO: Crawled 70642 pages (at 225 pages/min), scraped 59537 items (at 208 items/min)
2017-11-03 17:40:03 [scrapy.extensions.logstats] INFO: Crawled 70867 pages (at 225 pages/min), scraped 59745 items (at 208 items/min)
2017-11-03 17:41:03 [scrapy.extensions.logstats] INFO: Crawled 71089 pages (at 222 pages/min), scraped 59966 items (at 221 items/min)
2017-11-03 17:42:03 [scrapy.extensions.logstats] INFO: Crawled 71315 pages (at 226 pages/min), scraped 60193 items (at 227 items/min)
2017-11-03 17:43:03 [scrapy.extensions.logstats] INFO: Crawled 71530 pages (at 215 pages/min), scraped 60444 items (at 251 items/min)
2017-11-03 17:44:03 [scrapy.extensions.logstats] INFO: Crawled 71747 pages (at 217 pages/min), scraped 60657 items (at 213 items/min)
2017-11-03 17:45:03 [scrapy.extensions.logstats] INFO: Crawled 71958 pages (at 211 pages/min), scraped 60875 items (at 218 items/min)
2017-11-03 17:46:03 [scrapy.extensions.logstats] INFO: Crawled 72159 pages (at 201 pages/min), scraped 61083 items (at 208 items/min)
2017-11-03 17:47:03 [scrapy.extensions.logstats] INFO: Crawled 72378 pages (at 219 pages/min), scraped 61320 items (at 237 items/min)
2017-11-03 17:48:04 [scrapy.extensions.logstats] INFO: Crawled 72604 pages (at 226 pages/min), scraped 61550 items (at 230 items/min)
2017-11-03 17:49:03 [scrapy.extensions.logstats] INFO: Crawled 72823 pages (at 219 pages/min), scraped 61778 items (at 228 items/min)
2017-11-03 17:50:03 [scrapy.extensions.logstats] INFO: Crawled 73043 pages (at 220 pages/min), scraped 62023 items (at 245 items/min)
2017-11-03 17:51:03 [scrapy.extensions.logstats] INFO: Crawled 73263 pages (at 220 pages/min), scraped 62243 items (at 220 items/min)
2017-11-03 17:52:03 [scrapy.extensions.logstats] INFO: Crawled 73486 pages (at 223 pages/min), scraped 62468 items (at 225 items/min)
2017-11-03 17:53:03 [scrapy.extensions.logstats] INFO: Crawled 73706 pages (at 220 pages/min), scraped 62691 items (at 223 items/min)
2017-11-03 17:54:03 [scrapy.extensions.logstats] INFO: Crawled 73925 pages (at 219 pages/min), scraped 62922 items (at 231 items/min)
2017-11-03 17:55:03 [scrapy.extensions.logstats] INFO: Crawled 74150 pages (at 225 pages/min), scraped 63124 items (at 202 items/min)
2017-11-03 17:56:03 [scrapy.extensions.logstats] INFO: Crawled 74377 pages (at 227 pages/min), scraped 63351 items (at 227 items/min)
2017-11-03 17:57:03 [scrapy.extensions.logstats] INFO: Crawled 74600 pages (at 223 pages/min), scraped 63559 items (at 208 items/min)
2017-11-03 17:58:03 [scrapy.extensions.logstats] INFO: Crawled 74829 pages (at 229 pages/min), scraped 63757 items (at 198 items/min)
2017-11-03 17:59:03 [scrapy.extensions.logstats] INFO: Crawled 75047 pages (at 218 pages/min), scraped 63950 items (at 193 items/min)
2017-11-03 18:00:03 [scrapy.extensions.logstats] INFO: Crawled 75259 pages (at 212 pages/min), scraped 64143 items (at 193 items/min)
2017-11-03 18:01:03 [scrapy.extensions.logstats] INFO: Crawled 75466 pages (at 207 pages/min), scraped 64338 items (at 195 items/min)
2017-11-03 18:02:03 [scrapy.extensions.logstats] INFO: Crawled 75679 pages (at 213 pages/min), scraped 64561 items (at 223 items/min)
2017-11-03 18:03:04 [scrapy.extensions.logstats] INFO: Crawled 75878 pages (at 199 pages/min), scraped 64790 items (at 229 items/min)
2017-11-03 18:04:03 [scrapy.extensions.logstats] INFO: Crawled 76090 pages (at 212 pages/min), scraped 64969 items (at 179 items/min)
2017-11-03 18:05:03 [scrapy.extensions.logstats] INFO: Crawled 76298 pages (at 208 pages/min), scraped 65155 items (at 186 items/min)
2017-11-03 18:06:03 [scrapy.extensions.logstats] INFO: Crawled 76492 pages (at 194 pages/min), scraped 65326 items (at 171 items/min)
2017-11-03 18:07:03 [scrapy.extensions.logstats] INFO: Crawled 76691 pages (at 199 pages/min), scraped 65497 items (at 171 items/min)
2017-11-03 18:08:03 [scrapy.extensions.logstats] INFO: Crawled 76900 pages (at 209 pages/min), scraped 65670 items (at 173 items/min)
2017-11-03 18:09:03 [scrapy.extensions.logstats] INFO: Crawled 77035 pages (at 135 pages/min), scraped 65799 items (at 129 items/min)
2017-11-03 18:10:03 [scrapy.extensions.logstats] INFO: Crawled 77160 pages (at 125 pages/min), scraped 65891 items (at 92 items/min)
2017-11-03 18:11:03 [scrapy.extensions.logstats] INFO: Crawled 77288 pages (at 128 pages/min), scraped 65998 items (at 107 items/min)
2017-11-03 18:12:03 [scrapy.extensions.logstats] INFO: Crawled 77461 pages (at 173 pages/min), scraped 66152 items (at 154 items/min)
2017-11-03 18:13:04 [scrapy.extensions.logstats] INFO: Crawled 77576 pages (at 115 pages/min), scraped 66248 items (at 96 items/min)
2017-11-03 18:14:03 [scrapy.extensions.logstats] INFO: Crawled 77700 pages (at 124 pages/min), scraped 66356 items (at 108 items/min)
2017-11-03 18:15:03 [scrapy.extensions.logstats] INFO: Crawled 77806 pages (at 106 pages/min), scraped 66462 items (at 106 items/min)
2017-11-03 18:16:03 [scrapy.extensions.logstats] INFO: Crawled 77992 pages (at 186 pages/min), scraped 66622 items (at 160 items/min)
2017-11-03 18:17:03 [scrapy.extensions.logstats] INFO: Crawled 78217 pages (at 225 pages/min), scraped 66833 items (at 211 items/min)
2017-11-03 18:18:03 [scrapy.extensions.logstats] INFO: Crawled 78445 pages (at 228 pages/min), scraped 67032 items (at 199 items/min)
2017-11-03 18:19:03 [scrapy.extensions.logstats] INFO: Crawled 78668 pages (at 223 pages/min), scraped 67234 items (at 202 items/min)
2017-11-03 18:20:03 [scrapy.extensions.logstats] INFO: Crawled 78887 pages (at 219 pages/min), scraped 67440 items (at 206 items/min)
2017-11-03 18:21:03 [scrapy.extensions.logstats] INFO: Crawled 79116 pages (at 229 pages/min), scraped 67643 items (at 203 items/min)
2017-11-03 18:22:03 [scrapy.extensions.logstats] INFO: Crawled 79341 pages (at 225 pages/min), scraped 67829 items (at 186 items/min)
2017-11-03 18:23:03 [scrapy.extensions.logstats] INFO: Crawled 79572 pages (at 231 pages/min), scraped 67979 items (at 150 items/min)
2017-11-03 18:24:03 [scrapy.extensions.logstats] INFO: Crawled 79801 pages (at 229 pages/min), scraped 68133 items (at 154 items/min)
2017-11-03 18:25:03 [scrapy.extensions.logstats] INFO: Crawled 80029 pages (at 228 pages/min), scraped 68296 items (at 163 items/min)
2017-11-03 18:26:03 [scrapy.extensions.logstats] INFO: Crawled 80265 pages (at 236 pages/min), scraped 68461 items (at 165 items/min)
2017-11-03 18:27:03 [scrapy.extensions.logstats] INFO: Crawled 80494 pages (at 229 pages/min), scraped 68648 items (at 187 items/min)
2017-11-03 18:28:03 [scrapy.extensions.logstats] INFO: Crawled 80718 pages (at 224 pages/min), scraped 68840 items (at 192 items/min)
2017-11-03 18:29:03 [scrapy.extensions.logstats] INFO: Crawled 80946 pages (at 228 pages/min), scraped 69045 items (at 205 items/min)
2017-11-03 18:30:03 [scrapy.extensions.logstats] INFO: Crawled 81176 pages (at 230 pages/min), scraped 69250 items (at 205 items/min)
2017-11-03 18:31:03 [scrapy.extensions.logstats] INFO: Crawled 81407 pages (at 231 pages/min), scraped 69431 items (at 181 items/min)
2017-11-03 18:32:03 [scrapy.extensions.logstats] INFO: Crawled 81632 pages (at 225 pages/min), scraped 69622 items (at 191 items/min)
2017-11-03 18:33:03 [scrapy.extensions.logstats] INFO: Crawled 81859 pages (at 227 pages/min), scraped 69824 items (at 202 items/min)
2017-11-03 18:34:03 [scrapy.extensions.logstats] INFO: Crawled 82085 pages (at 226 pages/min), scraped 70021 items (at 197 items/min)
2017-11-03 18:35:03 [scrapy.extensions.logstats] INFO: Crawled 82316 pages (at 231 pages/min), scraped 70198 items (at 177 items/min)
2017-11-03 18:36:03 [scrapy.extensions.logstats] INFO: Crawled 82544 pages (at 228 pages/min), scraped 70406 items (at 208 items/min)
2017-11-03 18:37:03 [scrapy.extensions.logstats] INFO: Crawled 82771 pages (at 227 pages/min), scraped 70596 items (at 190 items/min)
2017-11-03 18:38:03 [scrapy.extensions.logstats] INFO: Crawled 83008 pages (at 237 pages/min), scraped 70751 items (at 155 items/min)
2017-11-03 18:39:03 [scrapy.extensions.logstats] INFO: Crawled 83243 pages (at 235 pages/min), scraped 70910 items (at 159 items/min)
2017-11-03 18:40:03 [scrapy.extensions.logstats] INFO: Crawled 83467 pages (at 224 pages/min), scraped 71075 items (at 165 items/min)
2017-11-03 18:41:03 [scrapy.extensions.logstats] INFO: Crawled 83696 pages (at 229 pages/min), scraped 71265 items (at 190 items/min)
2017-11-03 18:42:03 [scrapy.extensions.logstats] INFO: Crawled 83918 pages (at 222 pages/min), scraped 71450 items (at 185 items/min)
2017-11-03 18:43:03 [scrapy.extensions.logstats] INFO: Crawled 84149 pages (at 231 pages/min), scraped 71634 items (at 184 items/min)
2017-11-03 18:44:03 [scrapy.extensions.logstats] INFO: Crawled 84380 pages (at 231 pages/min), scraped 71801 items (at 167 items/min)
2017-11-03 18:45:03 [scrapy.extensions.logstats] INFO: Crawled 84610 pages (at 230 pages/min), scraped 71977 items (at 176 items/min)
2017-11-03 18:46:03 [scrapy.extensions.logstats] INFO: Crawled 84837 pages (at 227 pages/min), scraped 72148 items (at 171 items/min)
2017-11-03 18:47:03 [scrapy.extensions.logstats] INFO: Crawled 85069 pages (at 232 pages/min), scraped 72323 items (at 175 items/min)
2017-11-03 18:48:03 [scrapy.extensions.logstats] INFO: Crawled 85300 pages (at 231 pages/min), scraped 72509 items (at 186 items/min)
2017-11-03 18:49:03 [scrapy.extensions.logstats] INFO: Crawled 85531 pages (at 231 pages/min), scraped 72670 items (at 161 items/min)
2017-11-03 18:50:03 [scrapy.extensions.logstats] INFO: Crawled 85760 pages (at 229 pages/min), scraped 72848 items (at 178 items/min)
2017-11-03 18:51:03 [scrapy.extensions.logstats] INFO: Crawled 85986 pages (at 226 pages/min), scraped 73073 items (at 225 items/min)
2017-11-03 18:52:03 [scrapy.extensions.logstats] INFO: Crawled 86212 pages (at 226 pages/min), scraped 73293 items (at 220 items/min)
2017-11-03 18:53:03 [scrapy.extensions.logstats] INFO: Crawled 86439 pages (at 227 pages/min), scraped 73500 items (at 207 items/min)
2017-11-03 18:54:03 [scrapy.extensions.logstats] INFO: Crawled 86666 pages (at 227 pages/min), scraped 73667 items (at 167 items/min)
2017-11-03 18:55:03 [scrapy.extensions.logstats] INFO: Crawled 86894 pages (at 228 pages/min), scraped 73838 items (at 171 items/min)
2017-11-03 18:56:03 [scrapy.extensions.logstats] INFO: Crawled 87120 pages (at 226 pages/min), scraped 74001 items (at 163 items/min)
2017-11-03 18:57:03 [scrapy.extensions.logstats] INFO: Crawled 87352 pages (at 232 pages/min), scraped 74186 items (at 185 items/min)
2017-11-03 18:58:03 [scrapy.extensions.logstats] INFO: Crawled 87591 pages (at 239 pages/min), scraped 74353 items (at 167 items/min)
2017-11-03 18:59:03 [scrapy.extensions.logstats] INFO: Crawled 87825 pages (at 234 pages/min), scraped 74512 items (at 159 items/min)
2017-11-03 19:00:03 [scrapy.extensions.logstats] INFO: Crawled 88064 pages (at 239 pages/min), scraped 74680 items (at 168 items/min)
2017-11-03 19:01:03 [scrapy.extensions.logstats] INFO: Crawled 88297 pages (at 233 pages/min), scraped 74836 items (at 156 items/min)
2017-11-03 19:02:03 [scrapy.extensions.logstats] INFO: Crawled 88534 pages (at 237 pages/min), scraped 74993 items (at 157 items/min)
2017-11-03 19:03:03 [scrapy.extensions.logstats] INFO: Crawled 88769 pages (at 235 pages/min), scraped 75154 items (at 161 items/min)
2017-11-03 19:04:03 [scrapy.extensions.logstats] INFO: Crawled 89002 pages (at 233 pages/min), scraped 75320 items (at 166 items/min)
2017-11-03 19:05:03 [scrapy.extensions.logstats] INFO: Crawled 89237 pages (at 235 pages/min), scraped 75478 items (at 158 items/min)
2017-11-03 19:06:03 [scrapy.extensions.logstats] INFO: Crawled 89473 pages (at 236 pages/min), scraped 75634 items (at 156 items/min)
2017-11-03 19:07:03 [scrapy.extensions.logstats] INFO: Crawled 89708 pages (at 235 pages/min), scraped 75782 items (at 148 items/min)
2017-11-03 19:08:03 [scrapy.extensions.logstats] INFO: Crawled 89938 pages (at 230 pages/min), scraped 75933 items (at 151 items/min)
2017-11-03 19:09:03 [scrapy.extensions.logstats] INFO: Crawled 90172 pages (at 234 pages/min), scraped 76086 items (at 153 items/min)
2017-11-03 19:10:03 [scrapy.extensions.logstats] INFO: Crawled 90405 pages (at 233 pages/min), scraped 76251 items (at 165 items/min)
2017-11-03 19:11:03 [scrapy.extensions.logstats] INFO: Crawled 90642 pages (at 237 pages/min), scraped 76403 items (at 152 items/min)
2017-11-03 19:12:03 [scrapy.extensions.logstats] INFO: Crawled 90877 pages (at 235 pages/min), scraped 76581 items (at 178 items/min)
2017-11-03 19:13:03 [scrapy.extensions.logstats] INFO: Crawled 91101 pages (at 224 pages/min), scraped 76784 items (at 203 items/min)
2017-11-03 19:14:03 [scrapy.extensions.logstats] INFO: Crawled 91325 pages (at 224 pages/min), scraped 77025 items (at 241 items/min)
2017-11-03 19:15:03 [scrapy.extensions.logstats] INFO: Crawled 91559 pages (at 234 pages/min), scraped 77211 items (at 186 items/min)
2017-11-03 19:16:03 [scrapy.extensions.logstats] INFO: Crawled 91792 pages (at 233 pages/min), scraped 77403 items (at 192 items/min)
2017-11-03 19:17:03 [scrapy.extensions.logstats] INFO: Crawled 92018 pages (at 226 pages/min), scraped 77609 items (at 206 items/min)
2017-11-03 19:18:03 [scrapy.extensions.logstats] INFO: Crawled 92254 pages (at 236 pages/min), scraped 77816 items (at 207 items/min)
2017-11-03 19:19:03 [scrapy.extensions.logstats] INFO: Crawled 92487 pages (at 233 pages/min), scraped 77972 items (at 156 items/min)
2017-11-03 19:20:03 [scrapy.extensions.logstats] INFO: Crawled 92715 pages (at 228 pages/min), scraped 78181 items (at 209 items/min)
2017-11-03 19:21:03 [scrapy.extensions.logstats] INFO: Crawled 92941 pages (at 226 pages/min), scraped 78401 items (at 220 items/min)
2017-11-03 19:22:03 [scrapy.extensions.logstats] INFO: Crawled 93166 pages (at 225 pages/min), scraped 78611 items (at 210 items/min)
2017-11-03 19:23:03 [scrapy.extensions.logstats] INFO: Crawled 93391 pages (at 225 pages/min), scraped 78820 items (at 209 items/min)
2017-11-03 19:24:03 [scrapy.extensions.logstats] INFO: Crawled 93615 pages (at 224 pages/min), scraped 79048 items (at 228 items/min)
2017-11-03 19:25:03 [scrapy.extensions.logstats] INFO: Crawled 93836 pages (at 221 pages/min), scraped 79276 items (at 228 items/min)
2017-11-03 19:26:03 [scrapy.extensions.logstats] INFO: Crawled 94061 pages (at 225 pages/min), scraped 79477 items (at 201 items/min)
2017-11-03 19:27:03 [scrapy.extensions.logstats] INFO: Crawled 94286 pages (at 225 pages/min), scraped 79696 items (at 219 items/min)
2017-11-03 19:28:03 [scrapy.extensions.logstats] INFO: Crawled 94516 pages (at 230 pages/min), scraped 79893 items (at 197 items/min)
2017-11-03 19:29:03 [scrapy.extensions.logstats] INFO: Crawled 94745 pages (at 229 pages/min), scraped 80091 items (at 198 items/min)
2017-11-03 19:30:03 [scrapy.extensions.logstats] INFO: Crawled 94972 pages (at 227 pages/min), scraped 80290 items (at 199 items/min)
2017-11-03 19:31:03 [scrapy.extensions.logstats] INFO: Crawled 95203 pages (at 231 pages/min), scraped 80492 items (at 202 items/min)
2017-11-03 19:32:03 [scrapy.extensions.logstats] INFO: Crawled 95436 pages (at 233 pages/min), scraped 80698 items (at 206 items/min)
2017-11-03 19:33:03 [scrapy.extensions.logstats] INFO: Crawled 95666 pages (at 230 pages/min), scraped 80893 items (at 195 items/min)
2017-11-03 19:34:03 [scrapy.extensions.logstats] INFO: Crawled 95898 pages (at 232 pages/min), scraped 81107 items (at 214 items/min)
2017-11-03 19:35:03 [scrapy.extensions.logstats] INFO: Crawled 96126 pages (at 228 pages/min), scraped 81316 items (at 209 items/min)
2017-11-03 19:36:03 [scrapy.extensions.logstats] INFO: Crawled 96353 pages (at 227 pages/min), scraped 81514 items (at 198 items/min)
2017-11-03 19:37:03 [scrapy.extensions.logstats] INFO: Crawled 96581 pages (at 228 pages/min), scraped 81727 items (at 213 items/min)
2017-11-03 19:38:03 [scrapy.extensions.logstats] INFO: Crawled 96810 pages (at 229 pages/min), scraped 81939 items (at 212 items/min)
2017-11-03 19:39:03 [scrapy.extensions.logstats] INFO: Crawled 97043 pages (at 233 pages/min), scraped 82128 items (at 189 items/min)
2017-11-03 19:40:03 [scrapy.extensions.logstats] INFO: Crawled 97261 pages (at 218 pages/min), scraped 82324 items (at 196 items/min)
2017-11-03 19:41:03 [scrapy.extensions.logstats] INFO: Crawled 97492 pages (at 231 pages/min), scraped 82528 items (at 204 items/min)
2017-11-03 19:42:03 [scrapy.extensions.logstats] INFO: Crawled 97719 pages (at 227 pages/min), scraped 82716 items (at 188 items/min)
2017-11-03 19:43:03 [scrapy.extensions.logstats] INFO: Crawled 97948 pages (at 229 pages/min), scraped 82903 items (at 187 items/min)
2017-11-03 19:44:03 [scrapy.extensions.logstats] INFO: Crawled 98180 pages (at 232 pages/min), scraped 83094 items (at 191 items/min)
2017-11-03 19:45:03 [scrapy.extensions.logstats] INFO: Crawled 98410 pages (at 230 pages/min), scraped 83297 items (at 203 items/min)
2017-11-03 19:46:03 [scrapy.extensions.logstats] INFO: Crawled 98633 pages (at 223 pages/min), scraped 83506 items (at 209 items/min)
2017-11-03 19:47:03 [scrapy.extensions.logstats] INFO: Crawled 98861 pages (at 228 pages/min), scraped 83710 items (at 204 items/min)
2017-11-03 19:48:03 [scrapy.extensions.logstats] INFO: Crawled 99094 pages (at 233 pages/min), scraped 83906 items (at 196 items/min)
2017-11-03 19:49:03 [scrapy.extensions.logstats] INFO: Crawled 99317 pages (at 223 pages/min), scraped 84118 items (at 212 items/min)
2017-11-03 19:50:03 [scrapy.extensions.logstats] INFO: Crawled 99544 pages (at 227 pages/min), scraped 84322 items (at 204 items/min)
2017-11-03 19:51:03 [scrapy.extensions.logstats] INFO: Crawled 99775 pages (at 231 pages/min), scraped 84510 items (at 188 items/min)
2017-11-03 19:52:03 [scrapy.extensions.logstats] INFO: Crawled 100004 pages (at 229 pages/min), scraped 84702 items (at 192 items/min)
2017-11-03 19:53:03 [scrapy.extensions.logstats] INFO: Crawled 100237 pages (at 233 pages/min), scraped 84902 items (at 200 items/min)
2017-11-03 19:54:03 [scrapy.extensions.logstats] INFO: Crawled 100467 pages (at 230 pages/min), scraped 85116 items (at 214 items/min)
2017-11-03 19:55:03 [scrapy.extensions.logstats] INFO: Crawled 100688 pages (at 221 pages/min), scraped 85318 items (at 202 items/min)
2017-11-03 19:56:03 [scrapy.extensions.logstats] INFO: Crawled 100925 pages (at 237 pages/min), scraped 85511 items (at 193 items/min)
2017-11-03 19:57:03 [scrapy.extensions.logstats] INFO: Crawled 101150 pages (at 225 pages/min), scraped 85720 items (at 209 items/min)
2017-11-03 19:58:03 [scrapy.extensions.logstats] INFO: Crawled 101381 pages (at 231 pages/min), scraped 85905 items (at 185 items/min)
2017-11-03 19:59:03 [scrapy.extensions.logstats] INFO: Crawled 101612 pages (at 231 pages/min), scraped 86096 items (at 191 items/min)
2017-11-03 20:00:03 [scrapy.extensions.logstats] INFO: Crawled 101842 pages (at 230 pages/min), scraped 86284 items (at 188 items/min)
2017-11-03 20:01:03 [scrapy.extensions.logstats] INFO: Crawled 102065 pages (at 223 pages/min), scraped 86484 items (at 200 items/min)
2017-11-03 20:02:03 [scrapy.extensions.logstats] INFO: Crawled 102299 pages (at 234 pages/min), scraped 86674 items (at 190 items/min)
2017-11-03 20:03:03 [scrapy.extensions.logstats] INFO: Crawled 102526 pages (at 227 pages/min), scraped 86887 items (at 213 items/min)
2017-11-03 20:04:03 [scrapy.extensions.logstats] INFO: Crawled 102752 pages (at 226 pages/min), scraped 87066 items (at 179 items/min)
2017-11-03 20:05:03 [scrapy.extensions.logstats] INFO: Crawled 102984 pages (at 232 pages/min), scraped 87258 items (at 192 items/min)
2017-11-03 20:06:03 [scrapy.extensions.logstats] INFO: Crawled 103212 pages (at 228 pages/min), scraped 87450 items (at 192 items/min)
2017-11-03 20:07:03 [scrapy.extensions.logstats] INFO: Crawled 103441 pages (at 229 pages/min), scraped 87623 items (at 173 items/min)
2017-11-03 20:08:03 [scrapy.extensions.logstats] INFO: Crawled 103673 pages (at 232 pages/min), scraped 87823 items (at 200 items/min)
2017-11-03 20:09:03 [scrapy.extensions.logstats] INFO: Crawled 103909 pages (at 236 pages/min), scraped 88024 items (at 201 items/min)
2017-11-03 20:10:03 [scrapy.extensions.logstats] INFO: Crawled 104138 pages (at 229 pages/min), scraped 88238 items (at 214 items/min)
2017-11-03 20:11:03 [scrapy.extensions.logstats] INFO: Crawled 104369 pages (at 231 pages/min), scraped 88437 items (at 199 items/min)
2017-11-03 20:12:03 [scrapy.extensions.logstats] INFO: Crawled 104597 pages (at 228 pages/min), scraped 88643 items (at 206 items/min)
2017-11-03 20:13:03 [scrapy.extensions.logstats] INFO: Crawled 104829 pages (at 232 pages/min), scraped 88838 items (at 195 items/min)
2017-11-03 20:14:03 [scrapy.extensions.logstats] INFO: Crawled 105058 pages (at 229 pages/min), scraped 89031 items (at 193 items/min)
2017-11-03 20:15:03 [scrapy.extensions.logstats] INFO: Crawled 105285 pages (at 227 pages/min), scraped 89238 items (at 207 items/min)
2017-11-03 20:16:03 [scrapy.extensions.logstats] INFO: Crawled 105515 pages (at 230 pages/min), scraped 89444 items (at 206 items/min)
2017-11-03 20:17:03 [scrapy.extensions.logstats] INFO: Crawled 105740 pages (at 225 pages/min), scraped 89654 items (at 210 items/min)
2017-11-03 20:18:03 [scrapy.extensions.logstats] INFO: Crawled 105974 pages (at 234 pages/min), scraped 89826 items (at 172 items/min)
2017-11-03 20:19:03 [scrapy.extensions.logstats] INFO: Crawled 106207 pages (at 233 pages/min), scraped 89975 items (at 149 items/min)
2017-11-03 20:19:11 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=69954969&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"谢照一","SCO_NAME":"男","ECO_NAME":"大专","AOI_NAME":"中泰证券股份有限公司","AOI_ID":"1999074","ADI_ID":"17634","ADI_NAME":"深圳红荔路银荔大厦证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0740111100035","OBTAIN_DATE":"2011-10-17","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-03 20:20:03 [scrapy.extensions.logstats] INFO: Crawled 106441 pages (at 234 pages/min), scraped 90135 items (at 160 items/min)
2017-11-03 20:21:03 [scrapy.extensions.logstats] INFO: Crawled 106675 pages (at 234 pages/min), scraped 90294 items (at 159 items/min)
2017-11-03 20:22:03 [scrapy.extensions.logstats] INFO: Crawled 106904 pages (at 229 pages/min), scraped 90460 items (at 166 items/min)
2017-11-03 20:23:03 [scrapy.extensions.logstats] INFO: Crawled 107132 pages (at 228 pages/min), scraped 90622 items (at 162 items/min)
2017-11-03 20:24:03 [scrapy.extensions.logstats] INFO: Crawled 107360 pages (at 228 pages/min), scraped 90796 items (at 174 items/min)
2017-11-03 20:25:03 [scrapy.extensions.logstats] INFO: Crawled 107588 pages (at 228 pages/min), scraped 90970 items (at 174 items/min)
2017-11-03 20:26:03 [scrapy.extensions.logstats] INFO: Crawled 107819 pages (at 231 pages/min), scraped 91143 items (at 173 items/min)
2017-11-03 20:27:03 [scrapy.extensions.logstats] INFO: Crawled 108048 pages (at 229 pages/min), scraped 91320 items (at 177 items/min)
2017-11-03 20:28:03 [scrapy.extensions.logstats] INFO: Crawled 108279 pages (at 231 pages/min), scraped 91501 items (at 181 items/min)
2017-11-03 20:29:03 [scrapy.extensions.logstats] INFO: Crawled 108512 pages (at 233 pages/min), scraped 91678 items (at 177 items/min)
2017-11-03 20:30:03 [scrapy.extensions.logstats] INFO: Crawled 108742 pages (at 230 pages/min), scraped 91843 items (at 165 items/min)
2017-11-03 20:31:03 [scrapy.extensions.logstats] INFO: Crawled 108974 pages (at 232 pages/min), scraped 92036 items (at 193 items/min)
2017-11-03 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 109207 pages (at 233 pages/min), scraped 92218 items (at 182 items/min)
2017-11-03 20:33:03 [scrapy.extensions.logstats] INFO: Crawled 109434 pages (at 227 pages/min), scraped 92400 items (at 182 items/min)
2017-11-03 20:34:03 [scrapy.extensions.logstats] INFO: Crawled 109662 pages (at 228 pages/min), scraped 92606 items (at 206 items/min)
2017-11-03 20:35:03 [scrapy.extensions.logstats] INFO: Crawled 109892 pages (at 230 pages/min), scraped 92794 items (at 188 items/min)
2017-11-03 20:36:03 [scrapy.extensions.logstats] INFO: Crawled 110125 pages (at 233 pages/min), scraped 92972 items (at 178 items/min)
2017-11-03 20:37:03 [scrapy.extensions.logstats] INFO: Crawled 110358 pages (at 233 pages/min), scraped 93154 items (at 182 items/min)
2017-11-03 20:38:03 [scrapy.extensions.logstats] INFO: Crawled 110589 pages (at 231 pages/min), scraped 93338 items (at 184 items/min)
2017-11-03 20:39:03 [scrapy.extensions.logstats] INFO: Crawled 110823 pages (at 234 pages/min), scraped 93510 items (at 172 items/min)
2017-11-03 20:40:03 [scrapy.extensions.logstats] INFO: Crawled 111043 pages (at 220 pages/min), scraped 93688 items (at 178 items/min)
2017-11-03 20:41:03 [scrapy.extensions.logstats] INFO: Crawled 111270 pages (at 227 pages/min), scraped 93890 items (at 202 items/min)
2017-11-03 20:42:03 [scrapy.extensions.logstats] INFO: Crawled 111490 pages (at 220 pages/min), scraped 94135 items (at 245 items/min)
2017-11-03 20:43:03 [scrapy.extensions.logstats] INFO: Crawled 111715 pages (at 225 pages/min), scraped 94397 items (at 262 items/min)
2017-11-03 20:44:03 [scrapy.extensions.logstats] INFO: Crawled 111935 pages (at 220 pages/min), scraped 94642 items (at 245 items/min)
2017-11-03 20:45:03 [scrapy.extensions.logstats] INFO: Crawled 112158 pages (at 223 pages/min), scraped 94891 items (at 249 items/min)
2017-11-03 20:46:03 [scrapy.extensions.logstats] INFO: Crawled 112379 pages (at 221 pages/min), scraped 95150 items (at 259 items/min)
2017-11-03 20:47:03 [scrapy.extensions.logstats] INFO: Crawled 112601 pages (at 222 pages/min), scraped 95402 items (at 252 items/min)
2017-11-03 20:48:03 [scrapy.extensions.logstats] INFO: Crawled 112826 pages (at 225 pages/min), scraped 95651 items (at 249 items/min)
2017-11-03 20:49:03 [scrapy.extensions.logstats] INFO: Crawled 113052 pages (at 226 pages/min), scraped 95891 items (at 240 items/min)
2017-11-03 20:50:03 [scrapy.extensions.logstats] INFO: Crawled 113273 pages (at 221 pages/min), scraped 96144 items (at 253 items/min)
2017-11-03 20:51:03 [scrapy.extensions.logstats] INFO: Crawled 113495 pages (at 222 pages/min), scraped 96379 items (at 235 items/min)
2017-11-03 20:52:03 [scrapy.extensions.logstats] INFO: Crawled 113723 pages (at 228 pages/min), scraped 96610 items (at 231 items/min)
2017-11-03 20:53:03 [scrapy.extensions.logstats] INFO: Crawled 113951 pages (at 228 pages/min), scraped 96820 items (at 210 items/min)
2017-11-03 20:54:03 [scrapy.extensions.logstats] INFO: Crawled 114178 pages (at 227 pages/min), scraped 97032 items (at 212 items/min)
2017-11-03 20:55:03 [scrapy.extensions.logstats] INFO: Crawled 114404 pages (at 226 pages/min), scraped 97253 items (at 221 items/min)
2017-11-03 20:56:03 [scrapy.extensions.logstats] INFO: Crawled 114609 pages (at 205 pages/min), scraped 97467 items (at 214 items/min)
2017-11-03 20:57:03 [scrapy.extensions.logstats] INFO: Crawled 114844 pages (at 235 pages/min), scraped 97681 items (at 214 items/min)
2017-11-03 20:58:03 [scrapy.extensions.logstats] INFO: Crawled 115069 pages (at 225 pages/min), scraped 97877 items (at 196 items/min)
2017-11-03 20:59:03 [scrapy.extensions.logstats] INFO: Crawled 115297 pages (at 228 pages/min), scraped 98097 items (at 220 items/min)
2017-11-03 21:00:03 [scrapy.extensions.logstats] INFO: Crawled 115520 pages (at 223 pages/min), scraped 98315 items (at 218 items/min)
2017-11-03 21:01:03 [scrapy.extensions.logstats] INFO: Crawled 115744 pages (at 224 pages/min), scraped 98525 items (at 210 items/min)
2017-11-03 21:02:03 [scrapy.extensions.logstats] INFO: Crawled 115971 pages (at 227 pages/min), scraped 98738 items (at 213 items/min)
2017-11-03 21:03:03 [scrapy.extensions.logstats] INFO: Crawled 116202 pages (at 231 pages/min), scraped 98947 items (at 209 items/min)
2017-11-03 21:04:03 [scrapy.extensions.logstats] INFO: Crawled 116426 pages (at 224 pages/min), scraped 99164 items (at 217 items/min)
2017-11-03 21:05:03 [scrapy.extensions.logstats] INFO: Crawled 116648 pages (at 222 pages/min), scraped 99381 items (at 217 items/min)
2017-11-03 21:06:03 [scrapy.extensions.logstats] INFO: Crawled 116882 pages (at 234 pages/min), scraped 99610 items (at 229 items/min)
2017-11-03 21:07:03 [scrapy.extensions.logstats] INFO: Crawled 117107 pages (at 225 pages/min), scraped 99843 items (at 233 items/min)
2017-11-03 21:08:03 [scrapy.extensions.logstats] INFO: Crawled 117333 pages (at 226 pages/min), scraped 100062 items (at 219 items/min)
2017-11-03 21:09:03 [scrapy.extensions.logstats] INFO: Crawled 117561 pages (at 228 pages/min), scraped 100270 items (at 208 items/min)
2017-11-03 21:10:03 [scrapy.extensions.logstats] INFO: Crawled 117792 pages (at 231 pages/min), scraped 100494 items (at 224 items/min)
2017-11-03 21:11:03 [scrapy.extensions.logstats] INFO: Crawled 118008 pages (at 216 pages/min), scraped 100700 items (at 206 items/min)
2017-11-03 21:12:03 [scrapy.extensions.logstats] INFO: Crawled 118237 pages (at 229 pages/min), scraped 100931 items (at 231 items/min)
2017-11-03 21:13:03 [scrapy.extensions.logstats] INFO: Crawled 118468 pages (at 231 pages/min), scraped 101132 items (at 201 items/min)
2017-11-03 21:14:03 [scrapy.extensions.logstats] INFO: Crawled 118695 pages (at 227 pages/min), scraped 101352 items (at 220 items/min)
2017-11-03 21:15:03 [scrapy.extensions.logstats] INFO: Crawled 118923 pages (at 228 pages/min), scraped 101580 items (at 228 items/min)
2017-11-03 21:16:03 [scrapy.extensions.logstats] INFO: Crawled 119145 pages (at 222 pages/min), scraped 101801 items (at 221 items/min)
2017-11-03 21:17:03 [scrapy.extensions.logstats] INFO: Crawled 119370 pages (at 225 pages/min), scraped 102019 items (at 218 items/min)
2017-11-03 21:18:04 [scrapy.extensions.logstats] INFO: Crawled 119595 pages (at 225 pages/min), scraped 102247 items (at 228 items/min)
2017-11-03 21:19:03 [scrapy.extensions.logstats] INFO: Crawled 119817 pages (at 222 pages/min), scraped 102465 items (at 218 items/min)
2017-11-03 21:20:03 [scrapy.extensions.logstats] INFO: Crawled 120047 pages (at 230 pages/min), scraped 102690 items (at 225 items/min)
2017-11-03 21:21:03 [scrapy.extensions.logstats] INFO: Crawled 120270 pages (at 223 pages/min), scraped 102916 items (at 226 items/min)
2017-11-03 21:22:03 [scrapy.extensions.logstats] INFO: Crawled 120493 pages (at 223 pages/min), scraped 103134 items (at 218 items/min)
2017-11-03 21:23:03 [scrapy.extensions.logstats] INFO: Crawled 120722 pages (at 229 pages/min), scraped 103363 items (at 229 items/min)
2017-11-03 21:24:03 [scrapy.extensions.logstats] INFO: Crawled 120948 pages (at 226 pages/min), scraped 103583 items (at 220 items/min)
2017-11-03 21:25:03 [scrapy.extensions.logstats] INFO: Crawled 121169 pages (at 221 pages/min), scraped 103812 items (at 229 items/min)
2017-11-03 21:26:03 [scrapy.extensions.logstats] INFO: Crawled 121392 pages (at 223 pages/min), scraped 104037 items (at 225 items/min)
2017-11-03 21:27:03 [scrapy.extensions.logstats] INFO: Crawled 121616 pages (at 224 pages/min), scraped 104256 items (at 219 items/min)
2017-11-03 21:28:03 [scrapy.extensions.logstats] INFO: Crawled 121839 pages (at 223 pages/min), scraped 104470 items (at 214 items/min)
2017-11-03 21:29:03 [scrapy.extensions.logstats] INFO: Crawled 122061 pages (at 222 pages/min), scraped 104714 items (at 244 items/min)
2017-11-03 21:30:03 [scrapy.extensions.logstats] INFO: Crawled 122282 pages (at 221 pages/min), scraped 104965 items (at 251 items/min)
2017-11-03 21:31:03 [scrapy.extensions.logstats] INFO: Crawled 122502 pages (at 220 pages/min), scraped 105191 items (at 226 items/min)
2017-11-03 21:32:03 [scrapy.extensions.logstats] INFO: Crawled 122727 pages (at 225 pages/min), scraped 105421 items (at 230 items/min)
2017-11-03 21:33:03 [scrapy.extensions.logstats] INFO: Crawled 122965 pages (at 238 pages/min), scraped 105637 items (at 216 items/min)
2017-11-03 21:34:03 [scrapy.extensions.logstats] INFO: Crawled 123192 pages (at 227 pages/min), scraped 105830 items (at 193 items/min)
2017-11-03 21:35:03 [scrapy.extensions.logstats] INFO: Crawled 123424 pages (at 232 pages/min), scraped 106037 items (at 207 items/min)
2017-11-03 21:36:03 [scrapy.extensions.logstats] INFO: Crawled 123654 pages (at 230 pages/min), scraped 106228 items (at 191 items/min)
2017-11-03 21:37:03 [scrapy.extensions.logstats] INFO: Crawled 123884 pages (at 230 pages/min), scraped 106418 items (at 190 items/min)
2017-11-03 21:38:03 [scrapy.extensions.logstats] INFO: Crawled 124111 pages (at 227 pages/min), scraped 106615 items (at 197 items/min)
2017-11-03 21:39:03 [scrapy.extensions.logstats] INFO: Crawled 124344 pages (at 233 pages/min), scraped 106820 items (at 205 items/min)
2017-11-03 21:40:03 [scrapy.extensions.logstats] INFO: Crawled 124564 pages (at 220 pages/min), scraped 107016 items (at 196 items/min)
2017-11-03 21:41:03 [scrapy.extensions.logstats] INFO: Crawled 124783 pages (at 219 pages/min), scraped 107197 items (at 181 items/min)
2017-11-03 21:42:03 [scrapy.extensions.logstats] INFO: Crawled 125007 pages (at 224 pages/min), scraped 107387 items (at 190 items/min)
2017-11-03 21:43:03 [scrapy.extensions.logstats] INFO: Crawled 125239 pages (at 232 pages/min), scraped 107577 items (at 190 items/min)
2017-11-03 21:44:03 [scrapy.extensions.logstats] INFO: Crawled 125468 pages (at 229 pages/min), scraped 107789 items (at 212 items/min)
2017-11-03 21:45:03 [scrapy.extensions.logstats] INFO: Crawled 125698 pages (at 230 pages/min), scraped 107993 items (at 204 items/min)
2017-11-03 21:46:03 [scrapy.extensions.logstats] INFO: Crawled 125927 pages (at 229 pages/min), scraped 108183 items (at 190 items/min)
2017-11-03 21:47:03 [scrapy.extensions.logstats] INFO: Crawled 126153 pages (at 226 pages/min), scraped 108386 items (at 203 items/min)
2017-11-03 21:48:03 [scrapy.extensions.logstats] INFO: Crawled 126381 pages (at 228 pages/min), scraped 108585 items (at 199 items/min)
2017-11-03 21:49:03 [scrapy.extensions.logstats] INFO: Crawled 126610 pages (at 229 pages/min), scraped 108773 items (at 188 items/min)
2017-11-03 21:50:03 [scrapy.extensions.logstats] INFO: Crawled 126841 pages (at 231 pages/min), scraped 108967 items (at 194 items/min)
2017-11-03 21:51:03 [scrapy.extensions.logstats] INFO: Crawled 127072 pages (at 231 pages/min), scraped 109161 items (at 194 items/min)
2017-11-03 21:52:03 [scrapy.extensions.logstats] INFO: Crawled 127299 pages (at 227 pages/min), scraped 109365 items (at 204 items/min)
2017-11-03 21:53:03 [scrapy.extensions.logstats] INFO: Crawled 127527 pages (at 228 pages/min), scraped 109561 items (at 196 items/min)
2017-11-03 21:54:03 [scrapy.extensions.logstats] INFO: Crawled 127758 pages (at 231 pages/min), scraped 109752 items (at 191 items/min)
2017-11-03 21:55:03 [scrapy.extensions.logstats] INFO: Crawled 127986 pages (at 228 pages/min), scraped 109932 items (at 180 items/min)
2017-11-03 21:56:03 [scrapy.extensions.logstats] INFO: Crawled 128206 pages (at 220 pages/min), scraped 110116 items (at 184 items/min)
2017-11-03 21:57:03 [scrapy.extensions.logstats] INFO: Crawled 128435 pages (at 229 pages/min), scraped 110310 items (at 194 items/min)
2017-11-03 21:58:03 [scrapy.extensions.logstats] INFO: Crawled 128664 pages (at 229 pages/min), scraped 110513 items (at 203 items/min)
2017-11-03 21:59:03 [scrapy.extensions.logstats] INFO: Crawled 128893 pages (at 229 pages/min), scraped 110703 items (at 190 items/min)
2017-11-03 22:00:03 [scrapy.extensions.logstats] INFO: Crawled 129129 pages (at 236 pages/min), scraped 110896 items (at 193 items/min)
2017-11-03 22:01:03 [scrapy.extensions.logstats] INFO: Crawled 129361 pages (at 232 pages/min), scraped 111068 items (at 172 items/min)
2017-11-03 22:02:03 [scrapy.extensions.logstats] INFO: Crawled 129597 pages (at 236 pages/min), scraped 111263 items (at 195 items/min)
2017-11-03 22:03:03 [scrapy.extensions.logstats] INFO: Crawled 129825 pages (at 228 pages/min), scraped 111447 items (at 184 items/min)
2017-11-03 22:04:03 [scrapy.extensions.logstats] INFO: Crawled 130053 pages (at 228 pages/min), scraped 111630 items (at 183 items/min)
2017-11-03 22:05:03 [scrapy.extensions.logstats] INFO: Crawled 130284 pages (at 231 pages/min), scraped 111832 items (at 202 items/min)
2017-11-03 22:06:03 [scrapy.extensions.logstats] INFO: Crawled 130513 pages (at 229 pages/min), scraped 112010 items (at 178 items/min)
2017-11-03 22:07:03 [scrapy.extensions.logstats] INFO: Crawled 130739 pages (at 226 pages/min), scraped 112211 items (at 201 items/min)
2017-11-03 22:08:03 [scrapy.extensions.logstats] INFO: Crawled 130968 pages (at 229 pages/min), scraped 112411 items (at 200 items/min)
2017-11-03 22:09:03 [scrapy.extensions.logstats] INFO: Crawled 131201 pages (at 233 pages/min), scraped 112597 items (at 186 items/min)
2017-11-03 22:10:03 [scrapy.extensions.logstats] INFO: Crawled 131433 pages (at 232 pages/min), scraped 112803 items (at 206 items/min)
2017-11-03 22:11:03 [scrapy.extensions.logstats] INFO: Crawled 131658 pages (at 225 pages/min), scraped 112991 items (at 188 items/min)
2017-11-03 22:12:03 [scrapy.extensions.logstats] INFO: Crawled 131886 pages (at 228 pages/min), scraped 113174 items (at 183 items/min)
2017-11-03 22:13:03 [scrapy.extensions.logstats] INFO: Crawled 132117 pages (at 231 pages/min), scraped 113371 items (at 197 items/min)
2017-11-03 22:14:03 [scrapy.extensions.logstats] INFO: Crawled 132348 pages (at 231 pages/min), scraped 113566 items (at 195 items/min)
2017-11-03 22:15:03 [scrapy.extensions.logstats] INFO: Crawled 132579 pages (at 231 pages/min), scraped 113765 items (at 199 items/min)
2017-11-03 22:16:03 [scrapy.extensions.logstats] INFO: Crawled 132813 pages (at 234 pages/min), scraped 113951 items (at 186 items/min)
2017-11-03 22:17:03 [scrapy.extensions.logstats] INFO: Crawled 133037 pages (at 224 pages/min), scraped 114159 items (at 208 items/min)
2017-11-03 22:18:03 [scrapy.extensions.logstats] INFO: Crawled 133263 pages (at 226 pages/min), scraped 114348 items (at 189 items/min)
2017-11-03 22:19:03 [scrapy.extensions.logstats] INFO: Crawled 133494 pages (at 231 pages/min), scraped 114530 items (at 182 items/min)
2017-11-03 22:20:03 [scrapy.extensions.logstats] INFO: Crawled 133726 pages (at 232 pages/min), scraped 114724 items (at 194 items/min)
2017-11-03 22:21:03 [scrapy.extensions.logstats] INFO: Crawled 133955 pages (at 229 pages/min), scraped 114920 items (at 196 items/min)
2017-11-03 22:22:03 [scrapy.extensions.logstats] INFO: Crawled 134176 pages (at 221 pages/min), scraped 115122 items (at 202 items/min)
2017-11-03 22:23:03 [scrapy.extensions.logstats] INFO: Crawled 134411 pages (at 235 pages/min), scraped 115311 items (at 189 items/min)
2017-11-03 22:24:03 [scrapy.extensions.logstats] INFO: Crawled 134640 pages (at 229 pages/min), scraped 115476 items (at 165 items/min)
2017-11-03 22:25:03 [scrapy.extensions.logstats] INFO: Crawled 134879 pages (at 239 pages/min), scraped 115635 items (at 159 items/min)
2017-11-03 22:26:03 [scrapy.extensions.logstats] INFO: Crawled 135113 pages (at 234 pages/min), scraped 115792 items (at 157 items/min)
2017-11-03 22:27:03 [scrapy.extensions.logstats] INFO: Crawled 135346 pages (at 233 pages/min), scraped 115960 items (at 168 items/min)
2017-11-03 22:28:03 [scrapy.extensions.logstats] INFO: Crawled 135571 pages (at 225 pages/min), scraped 116112 items (at 152 items/min)
2017-11-03 22:29:03 [scrapy.extensions.logstats] INFO: Crawled 135804 pages (at 233 pages/min), scraped 116274 items (at 162 items/min)
2017-11-03 22:30:03 [scrapy.extensions.logstats] INFO: Crawled 136037 pages (at 233 pages/min), scraped 116443 items (at 169 items/min)
2017-11-03 22:31:03 [scrapy.extensions.logstats] INFO: Crawled 136265 pages (at 228 pages/min), scraped 116612 items (at 169 items/min)
2017-11-03 22:32:03 [scrapy.extensions.logstats] INFO: Crawled 136499 pages (at 234 pages/min), scraped 116777 items (at 165 items/min)
2017-11-03 22:33:03 [scrapy.extensions.logstats] INFO: Crawled 136731 pages (at 232 pages/min), scraped 116943 items (at 166 items/min)
2017-11-03 22:34:03 [scrapy.extensions.logstats] INFO: Crawled 136963 pages (at 232 pages/min), scraped 117100 items (at 157 items/min)
2017-11-03 22:35:03 [scrapy.extensions.logstats] INFO: Crawled 137195 pages (at 232 pages/min), scraped 117266 items (at 166 items/min)
2017-11-03 22:35:13 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39901411&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"边洋","SCO_NAME":"男","ECO_NAME":"硕士研究生","AOI_NAME":"中国银河证券股份有限公司","AOI_ID":"1999013","ADI_ID":"44490","ADI_NAME":"投资银行二部","PTI_NAME":"一般证券业务","CER_NUM":"S0130108023412","OBTAIN_DATE":"2008-02-22","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-03 22:36:03 [scrapy.extensions.logstats] INFO: Crawled 137424 pages (at 229 pages/min), scraped 117436 items (at 170 items/min)
2017-11-03 22:37:03 [scrapy.extensions.logstats] INFO: Crawled 137654 pages (at 230 pages/min), scraped 117639 items (at 203 items/min)
2017-11-03 22:38:03 [scrapy.extensions.logstats] INFO: Crawled 137885 pages (at 231 pages/min), scraped 117830 items (at 191 items/min)
2017-11-03 22:39:03 [scrapy.extensions.logstats] INFO: Crawled 138113 pages (at 228 pages/min), scraped 118008 items (at 178 items/min)
2017-11-03 22:40:03 [scrapy.extensions.logstats] INFO: Crawled 138342 pages (at 229 pages/min), scraped 118197 items (at 189 items/min)
2017-11-03 22:41:03 [scrapy.extensions.logstats] INFO: Crawled 138573 pages (at 231 pages/min), scraped 118365 items (at 168 items/min)
2017-11-03 22:42:03 [scrapy.extensions.logstats] INFO: Crawled 138803 pages (at 230 pages/min), scraped 118546 items (at 181 items/min)
2017-11-03 22:43:03 [scrapy.extensions.logstats] INFO: Crawled 139034 pages (at 231 pages/min), scraped 118726 items (at 180 items/min)
2017-11-03 22:44:03 [scrapy.extensions.logstats] INFO: Crawled 139263 pages (at 229 pages/min), scraped 118911 items (at 185 items/min)
2017-11-03 22:45:03 [scrapy.extensions.logstats] INFO: Crawled 139493 pages (at 230 pages/min), scraped 119095 items (at 184 items/min)
2017-11-03 22:46:03 [scrapy.extensions.logstats] INFO: Crawled 139727 pages (at 234 pages/min), scraped 119285 items (at 190 items/min)
2017-11-03 22:47:03 [scrapy.extensions.logstats] INFO: Crawled 139954 pages (at 227 pages/min), scraped 119461 items (at 176 items/min)
2017-11-03 22:48:03 [scrapy.extensions.logstats] INFO: Crawled 140184 pages (at 230 pages/min), scraped 119659 items (at 198 items/min)
2017-11-03 22:49:03 [scrapy.extensions.logstats] INFO: Crawled 140415 pages (at 231 pages/min), scraped 119841 items (at 182 items/min)
2017-11-03 22:50:03 [scrapy.extensions.logstats] INFO: Crawled 140638 pages (at 223 pages/min), scraped 120017 items (at 176 items/min)
2017-11-03 22:51:03 [scrapy.extensions.logstats] INFO: Crawled 140874 pages (at 236 pages/min), scraped 120212 items (at 195 items/min)
2017-11-03 22:52:03 [scrapy.extensions.logstats] INFO: Crawled 141102 pages (at 228 pages/min), scraped 120393 items (at 181 items/min)
2017-11-03 22:53:03 [scrapy.extensions.logstats] INFO: Crawled 141334 pages (at 232 pages/min), scraped 120567 items (at 174 items/min)
2017-11-03 22:54:03 [scrapy.extensions.logstats] INFO: Crawled 141564 pages (at 230 pages/min), scraped 120744 items (at 177 items/min)
2017-11-03 22:55:03 [scrapy.extensions.logstats] INFO: Crawled 141794 pages (at 230 pages/min), scraped 120918 items (at 174 items/min)
2017-11-03 22:56:03 [scrapy.extensions.logstats] INFO: Crawled 142025 pages (at 231 pages/min), scraped 121097 items (at 179 items/min)
2017-11-03 22:57:03 [scrapy.extensions.logstats] INFO: Crawled 142252 pages (at 227 pages/min), scraped 121270 items (at 173 items/min)
2017-11-03 22:58:03 [scrapy.extensions.logstats] INFO: Crawled 142484 pages (at 232 pages/min), scraped 121453 items (at 183 items/min)
2017-11-03 22:59:03 [scrapy.extensions.logstats] INFO: Crawled 142715 pages (at 231 pages/min), scraped 121626 items (at 173 items/min)
2017-11-03 23:00:03 [scrapy.extensions.logstats] INFO: Crawled 142949 pages (at 234 pages/min), scraped 121803 items (at 177 items/min)
2017-11-03 23:01:03 [scrapy.extensions.logstats] INFO: Crawled 143178 pages (at 229 pages/min), scraped 121999 items (at 196 items/min)
2017-11-03 23:02:03 [scrapy.extensions.logstats] INFO: Crawled 143411 pages (at 233 pages/min), scraped 122174 items (at 175 items/min)
2017-11-03 23:03:03 [scrapy.extensions.logstats] INFO: Crawled 143642 pages (at 231 pages/min), scraped 122376 items (at 202 items/min)
2017-11-03 23:04:03 [scrapy.extensions.logstats] INFO: Crawled 143871 pages (at 229 pages/min), scraped 122560 items (at 184 items/min)
2017-11-03 23:05:03 [scrapy.extensions.logstats] INFO: Crawled 144102 pages (at 231 pages/min), scraped 122755 items (at 195 items/min)
2017-11-03 23:06:03 [scrapy.extensions.logstats] INFO: Crawled 144327 pages (at 225 pages/min), scraped 122949 items (at 194 items/min)
2017-11-03 23:07:03 [scrapy.extensions.logstats] INFO: Crawled 144565 pages (at 238 pages/min), scraped 123149 items (at 200 items/min)
2017-11-03 23:08:03 [scrapy.extensions.logstats] INFO: Crawled 144795 pages (at 230 pages/min), scraped 123347 items (at 198 items/min)
2017-11-03 23:09:03 [scrapy.extensions.logstats] INFO: Crawled 145025 pages (at 230 pages/min), scraped 123548 items (at 201 items/min)
2017-11-03 23:10:03 [scrapy.extensions.logstats] INFO: Crawled 145257 pages (at 232 pages/min), scraped 123750 items (at 202 items/min)
2017-11-03 23:11:03 [scrapy.extensions.logstats] INFO: Crawled 145490 pages (at 233 pages/min), scraped 123947 items (at 197 items/min)
2017-11-03 23:12:03 [scrapy.extensions.logstats] INFO: Crawled 145721 pages (at 231 pages/min), scraped 124159 items (at 212 items/min)
2017-11-03 23:13:03 [scrapy.extensions.logstats] INFO: Crawled 145950 pages (at 229 pages/min), scraped 124353 items (at 194 items/min)
2017-11-03 23:14:03 [scrapy.extensions.logstats] INFO: Crawled 146179 pages (at 229 pages/min), scraped 124552 items (at 199 items/min)
2017-11-03 23:15:03 [scrapy.extensions.logstats] INFO: Crawled 146403 pages (at 224 pages/min), scraped 124751 items (at 199 items/min)
2017-11-03 23:16:03 [scrapy.extensions.logstats] INFO: Crawled 146631 pages (at 228 pages/min), scraped 124940 items (at 189 items/min)
2017-11-03 23:17:03 [scrapy.extensions.logstats] INFO: Crawled 146858 pages (at 227 pages/min), scraped 125137 items (at 197 items/min)
2017-11-03 23:18:03 [scrapy.extensions.logstats] INFO: Crawled 147088 pages (at 230 pages/min), scraped 125336 items (at 199 items/min)
2017-11-03 23:19:03 [scrapy.extensions.logstats] INFO: Crawled 147318 pages (at 230 pages/min), scraped 125535 items (at 199 items/min)
2017-11-03 23:20:03 [scrapy.extensions.logstats] INFO: Crawled 147549 pages (at 231 pages/min), scraped 125733 items (at 198 items/min)
2017-11-03 23:21:03 [scrapy.extensions.logstats] INFO: Crawled 147782 pages (at 233 pages/min), scraped 125940 items (at 207 items/min)
2017-11-03 23:22:03 [scrapy.extensions.logstats] INFO: Crawled 148006 pages (at 224 pages/min), scraped 126137 items (at 197 items/min)
2017-11-03 23:23:03 [scrapy.extensions.logstats] INFO: Crawled 148234 pages (at 228 pages/min), scraped 126335 items (at 198 items/min)
2017-11-03 23:24:03 [scrapy.extensions.logstats] INFO: Crawled 148461 pages (at 227 pages/min), scraped 126530 items (at 195 items/min)
2017-11-03 23:25:03 [scrapy.extensions.logstats] INFO: Crawled 148693 pages (at 232 pages/min), scraped 126738 items (at 208 items/min)
2017-11-03 23:26:03 [scrapy.extensions.logstats] INFO: Crawled 148918 pages (at 225 pages/min), scraped 126959 items (at 221 items/min)
2017-11-03 23:27:03 [scrapy.extensions.logstats] INFO: Crawled 149145 pages (at 227 pages/min), scraped 127154 items (at 195 items/min)
2017-11-03 23:28:03 [scrapy.extensions.logstats] INFO: Crawled 149378 pages (at 233 pages/min), scraped 127368 items (at 214 items/min)
2017-11-03 23:29:04 [scrapy.extensions.logstats] INFO: Crawled 149605 pages (at 227 pages/min), scraped 127575 items (at 207 items/min)
2017-11-03 23:30:03 [scrapy.extensions.logstats] INFO: Crawled 149837 pages (at 232 pages/min), scraped 127778 items (at 203 items/min)
2017-11-03 23:31:03 [scrapy.extensions.logstats] INFO: Crawled 150066 pages (at 229 pages/min), scraped 127991 items (at 213 items/min)
2017-11-03 23:32:03 [scrapy.extensions.logstats] INFO: Crawled 150291 pages (at 225 pages/min), scraped 128216 items (at 225 items/min)
2017-11-03 23:33:03 [scrapy.extensions.logstats] INFO: Crawled 150513 pages (at 222 pages/min), scraped 128459 items (at 243 items/min)
2017-11-03 23:34:03 [scrapy.extensions.logstats] INFO: Crawled 150740 pages (at 227 pages/min), scraped 128675 items (at 216 items/min)
2017-11-03 23:35:03 [scrapy.extensions.logstats] INFO: Crawled 150968 pages (at 228 pages/min), scraped 128873 items (at 198 items/min)
2017-11-03 23:36:03 [scrapy.extensions.logstats] INFO: Crawled 151201 pages (at 233 pages/min), scraped 129039 items (at 166 items/min)
2017-11-03 23:37:03 [scrapy.extensions.logstats] INFO: Crawled 151438 pages (at 237 pages/min), scraped 129197 items (at 158 items/min)
2017-11-03 23:38:03 [scrapy.extensions.logstats] INFO: Crawled 151671 pages (at 233 pages/min), scraped 129369 items (at 172 items/min)
2017-11-03 23:39:03 [scrapy.extensions.logstats] INFO: Crawled 151899 pages (at 228 pages/min), scraped 129551 items (at 182 items/min)
2017-11-03 23:40:03 [scrapy.extensions.logstats] INFO: Crawled 152124 pages (at 225 pages/min), scraped 129733 items (at 182 items/min)
2017-11-03 23:41:03 [scrapy.extensions.logstats] INFO: Crawled 152344 pages (at 220 pages/min), scraped 129915 items (at 182 items/min)
2017-11-03 23:42:03 [scrapy.extensions.logstats] INFO: Crawled 152576 pages (at 232 pages/min), scraped 130086 items (at 171 items/min)
2017-11-03 23:43:03 [scrapy.extensions.logstats] INFO: Crawled 152807 pages (at 231 pages/min), scraped 130255 items (at 169 items/min)
2017-11-03 23:44:03 [scrapy.extensions.logstats] INFO: Crawled 153040 pages (at 233 pages/min), scraped 130432 items (at 177 items/min)
2017-11-03 23:45:03 [scrapy.extensions.logstats] INFO: Crawled 153271 pages (at 231 pages/min), scraped 130598 items (at 166 items/min)
2017-11-03 23:46:03 [scrapy.extensions.logstats] INFO: Crawled 153503 pages (at 232 pages/min), scraped 130790 items (at 192 items/min)
2017-11-03 23:47:03 [scrapy.extensions.logstats] INFO: Crawled 153732 pages (at 229 pages/min), scraped 130960 items (at 170 items/min)
2017-11-03 23:48:04 [scrapy.extensions.logstats] INFO: Crawled 153965 pages (at 233 pages/min), scraped 131118 items (at 158 items/min)
2017-11-03 23:49:03 [scrapy.extensions.logstats] INFO: Crawled 154195 pages (at 230 pages/min), scraped 131291 items (at 173 items/min)
2017-11-03 23:50:03 [scrapy.extensions.logstats] INFO: Crawled 154434 pages (at 239 pages/min), scraped 131461 items (at 170 items/min)
2017-11-03 23:51:03 [scrapy.extensions.logstats] INFO: Crawled 154662 pages (at 228 pages/min), scraped 131672 items (at 211 items/min)
2017-11-03 23:52:03 [scrapy.extensions.logstats] INFO: Crawled 154888 pages (at 226 pages/min), scraped 131871 items (at 199 items/min)
2017-11-03 23:53:03 [scrapy.extensions.logstats] INFO: Crawled 155116 pages (at 228 pages/min), scraped 132103 items (at 232 items/min)
2017-11-03 23:54:03 [scrapy.extensions.logstats] INFO: Crawled 155335 pages (at 219 pages/min), scraped 132323 items (at 220 items/min)
2017-11-03 23:55:03 [scrapy.extensions.logstats] INFO: Crawled 155559 pages (at 224 pages/min), scraped 132512 items (at 189 items/min)
2017-11-03 23:56:03 [scrapy.extensions.logstats] INFO: Crawled 155785 pages (at 226 pages/min), scraped 132722 items (at 210 items/min)
2017-11-03 23:57:03 [scrapy.extensions.logstats] INFO: Crawled 156012 pages (at 227 pages/min), scraped 132917 items (at 195 items/min)
2017-11-03 23:58:03 [scrapy.extensions.logstats] INFO: Crawled 156244 pages (at 232 pages/min), scraped 133112 items (at 195 items/min)
2017-11-03 23:59:03 [scrapy.extensions.logstats] INFO: Crawled 156472 pages (at 228 pages/min), scraped 133322 items (at 210 items/min)
2017-11-04 00:00:03 [scrapy.extensions.logstats] INFO: Crawled 156703 pages (at 231 pages/min), scraped 133521 items (at 199 items/min)
2017-11-04 00:01:03 [scrapy.extensions.logstats] INFO: Crawled 156932 pages (at 229 pages/min), scraped 133724 items (at 203 items/min)
2017-11-04 00:02:03 [scrapy.extensions.logstats] INFO: Crawled 157162 pages (at 230 pages/min), scraped 133924 items (at 200 items/min)
2017-11-04 00:03:03 [scrapy.extensions.logstats] INFO: Crawled 157392 pages (at 230 pages/min), scraped 134123 items (at 199 items/min)
2017-11-04 00:04:03 [scrapy.extensions.logstats] INFO: Crawled 157622 pages (at 230 pages/min), scraped 134314 items (at 191 items/min)
2017-11-04 00:05:03 [scrapy.extensions.logstats] INFO: Crawled 157849 pages (at 227 pages/min), scraped 134523 items (at 209 items/min)
2017-11-04 00:06:03 [scrapy.extensions.logstats] INFO: Crawled 158075 pages (at 226 pages/min), scraped 134717 items (at 194 items/min)
2017-11-04 00:07:03 [scrapy.extensions.logstats] INFO: Crawled 158308 pages (at 233 pages/min), scraped 134920 items (at 203 items/min)
2017-11-04 00:08:03 [scrapy.extensions.logstats] INFO: Crawled 158536 pages (at 228 pages/min), scraped 135120 items (at 200 items/min)
2017-11-04 00:09:03 [scrapy.extensions.logstats] INFO: Crawled 158761 pages (at 225 pages/min), scraped 135315 items (at 195 items/min)
2017-11-04 00:10:03 [scrapy.extensions.logstats] INFO: Crawled 158983 pages (at 222 pages/min), scraped 135506 items (at 191 items/min)
2017-11-04 00:11:03 [scrapy.extensions.logstats] INFO: Crawled 159211 pages (at 228 pages/min), scraped 135707 items (at 201 items/min)
2017-11-04 00:12:03 [scrapy.extensions.logstats] INFO: Crawled 159441 pages (at 230 pages/min), scraped 135891 items (at 184 items/min)
2017-11-04 00:13:04 [scrapy.extensions.logstats] INFO: Crawled 159663 pages (at 222 pages/min), scraped 136091 items (at 200 items/min)
2017-11-04 00:14:03 [scrapy.extensions.logstats] INFO: Crawled 159890 pages (at 227 pages/min), scraped 136284 items (at 193 items/min)
2017-11-04 00:15:03 [scrapy.extensions.logstats] INFO: Crawled 160115 pages (at 225 pages/min), scraped 136504 items (at 220 items/min)
2017-11-04 00:16:03 [scrapy.extensions.logstats] INFO: Crawled 160347 pages (at 232 pages/min), scraped 136702 items (at 198 items/min)
2017-11-04 00:17:03 [scrapy.extensions.logstats] INFO: Crawled 160571 pages (at 224 pages/min), scraped 136902 items (at 200 items/min)
2017-11-04 00:18:03 [scrapy.extensions.logstats] INFO: Crawled 160796 pages (at 225 pages/min), scraped 137101 items (at 199 items/min)
2017-11-04 00:19:03 [scrapy.extensions.logstats] INFO: Crawled 161025 pages (at 229 pages/min), scraped 137305 items (at 204 items/min)
2017-11-04 00:20:03 [scrapy.extensions.logstats] INFO: Crawled 161254 pages (at 229 pages/min), scraped 137497 items (at 192 items/min)
2017-11-04 00:21:03 [scrapy.extensions.logstats] INFO: Crawled 161485 pages (at 231 pages/min), scraped 137679 items (at 182 items/min)
2017-11-04 00:22:03 [scrapy.extensions.logstats] INFO: Crawled 161709 pages (at 224 pages/min), scraped 137878 items (at 199 items/min)
2017-11-04 00:23:04 [scrapy.extensions.logstats] INFO: Crawled 161938 pages (at 229 pages/min), scraped 138086 items (at 208 items/min)
2017-11-04 00:24:03 [scrapy.extensions.logstats] INFO: Crawled 162162 pages (at 224 pages/min), scraped 138289 items (at 203 items/min)
2017-11-04 00:25:03 [scrapy.extensions.logstats] INFO: Crawled 162391 pages (at 229 pages/min), scraped 138478 items (at 189 items/min)
2017-11-04 00:26:03 [scrapy.extensions.logstats] INFO: Crawled 162622 pages (at 231 pages/min), scraped 138694 items (at 216 items/min)
2017-11-04 00:27:03 [scrapy.extensions.logstats] INFO: Crawled 162851 pages (at 229 pages/min), scraped 138895 items (at 201 items/min)
2017-11-04 00:28:03 [scrapy.extensions.logstats] INFO: Crawled 163081 pages (at 230 pages/min), scraped 139089 items (at 194 items/min)
2017-11-04 00:29:03 [scrapy.extensions.logstats] INFO: Crawled 163308 pages (at 227 pages/min), scraped 139293 items (at 204 items/min)
2017-11-04 00:30:03 [scrapy.extensions.logstats] INFO: Crawled 163529 pages (at 221 pages/min), scraped 139517 items (at 224 items/min)
2017-11-04 00:31:03 [scrapy.extensions.logstats] INFO: Crawled 163755 pages (at 226 pages/min), scraped 139728 items (at 211 items/min)
2017-11-04 00:32:03 [scrapy.extensions.logstats] INFO: Crawled 163985 pages (at 230 pages/min), scraped 139940 items (at 212 items/min)
2017-11-04 00:33:03 [scrapy.extensions.logstats] INFO: Crawled 164209 pages (at 224 pages/min), scraped 140147 items (at 207 items/min)
2017-11-04 00:34:03 [scrapy.extensions.logstats] INFO: Crawled 164438 pages (at 229 pages/min), scraped 140374 items (at 227 items/min)
2017-11-04 00:35:03 [scrapy.extensions.logstats] INFO: Crawled 164662 pages (at 224 pages/min), scraped 140599 items (at 225 items/min)
2017-11-04 00:36:03 [scrapy.extensions.logstats] INFO: Crawled 164885 pages (at 223 pages/min), scraped 140826 items (at 227 items/min)
2017-11-04 00:37:03 [scrapy.extensions.logstats] INFO: Crawled 165114 pages (at 229 pages/min), scraped 141045 items (at 219 items/min)
2017-11-04 00:38:03 [scrapy.extensions.logstats] INFO: Crawled 165341 pages (at 227 pages/min), scraped 141243 items (at 198 items/min)
2017-11-04 00:39:03 [scrapy.extensions.logstats] INFO: Crawled 165566 pages (at 225 pages/min), scraped 141444 items (at 201 items/min)
2017-11-04 00:40:03 [scrapy.extensions.logstats] INFO: Crawled 165793 pages (at 227 pages/min), scraped 141645 items (at 201 items/min)
2017-11-04 00:41:03 [scrapy.extensions.logstats] INFO: Crawled 166019 pages (at 226 pages/min), scraped 141856 items (at 211 items/min)
2017-11-04 00:42:03 [scrapy.extensions.logstats] INFO: Crawled 166247 pages (at 228 pages/min), scraped 142070 items (at 214 items/min)
2017-11-04 00:43:03 [scrapy.extensions.logstats] INFO: Crawled 166473 pages (at 226 pages/min), scraped 142293 items (at 223 items/min)
2017-11-04 00:44:03 [scrapy.extensions.logstats] INFO: Crawled 166699 pages (at 226 pages/min), scraped 142499 items (at 206 items/min)
2017-11-04 00:45:03 [scrapy.extensions.logstats] INFO: Crawled 166927 pages (at 228 pages/min), scraped 142714 items (at 215 items/min)
2017-11-04 00:46:03 [scrapy.extensions.logstats] INFO: Crawled 167158 pages (at 231 pages/min), scraped 142911 items (at 197 items/min)
2017-11-04 00:47:03 [scrapy.extensions.logstats] INFO: Crawled 167385 pages (at 227 pages/min), scraped 143118 items (at 207 items/min)
2017-11-04 00:48:03 [scrapy.extensions.logstats] INFO: Crawled 167613 pages (at 228 pages/min), scraped 143309 items (at 191 items/min)
2017-11-04 00:49:03 [scrapy.extensions.logstats] INFO: Crawled 167842 pages (at 229 pages/min), scraped 143504 items (at 195 items/min)
2017-11-04 00:50:03 [scrapy.extensions.logstats] INFO: Crawled 168068 pages (at 226 pages/min), scraped 143696 items (at 192 items/min)
2017-11-04 00:51:03 [scrapy.extensions.logstats] INFO: Crawled 168298 pages (at 230 pages/min), scraped 143904 items (at 208 items/min)
2017-11-04 00:52:03 [scrapy.extensions.logstats] INFO: Crawled 168525 pages (at 227 pages/min), scraped 144103 items (at 199 items/min)
2017-11-04 00:53:03 [scrapy.extensions.logstats] INFO: Crawled 168750 pages (at 225 pages/min), scraped 144293 items (at 190 items/min)
2017-11-04 00:54:03 [scrapy.extensions.logstats] INFO: Crawled 168982 pages (at 232 pages/min), scraped 144466 items (at 173 items/min)
2017-11-04 00:55:03 [scrapy.extensions.logstats] INFO: Crawled 169209 pages (at 227 pages/min), scraped 144662 items (at 196 items/min)
2017-11-04 00:56:03 [scrapy.extensions.logstats] INFO: Crawled 169438 pages (at 229 pages/min), scraped 144848 items (at 186 items/min)
2017-11-04 00:57:03 [scrapy.extensions.logstats] INFO: Crawled 169668 pages (at 230 pages/min), scraped 145049 items (at 201 items/min)
2017-11-04 00:58:03 [scrapy.extensions.logstats] INFO: Crawled 169894 pages (at 226 pages/min), scraped 145255 items (at 206 items/min)
2017-11-04 00:59:03 [scrapy.extensions.logstats] INFO: Crawled 170122 pages (at 228 pages/min), scraped 145451 items (at 196 items/min)
2017-11-04 01:00:03 [scrapy.extensions.logstats] INFO: Crawled 170360 pages (at 238 pages/min), scraped 145631 items (at 180 items/min)
2017-11-04 01:01:04 [scrapy.extensions.logstats] INFO: Crawled 170580 pages (at 220 pages/min), scraped 145831 items (at 200 items/min)
2017-11-04 01:02:03 [scrapy.extensions.logstats] INFO: Crawled 170813 pages (at 233 pages/min), scraped 146005 items (at 174 items/min)
2017-11-04 01:03:03 [scrapy.extensions.logstats] INFO: Crawled 171042 pages (at 229 pages/min), scraped 146193 items (at 188 items/min)
2017-11-04 01:04:03 [scrapy.extensions.logstats] INFO: Crawled 171276 pages (at 234 pages/min), scraped 146377 items (at 184 items/min)
2017-11-04 01:05:03 [scrapy.extensions.logstats] INFO: Crawled 171498 pages (at 222 pages/min), scraped 146592 items (at 215 items/min)
2017-11-04 01:06:03 [scrapy.extensions.logstats] INFO: Crawled 171718 pages (at 220 pages/min), scraped 146826 items (at 234 items/min)
2017-11-04 01:07:03 [scrapy.extensions.logstats] INFO: Crawled 171940 pages (at 222 pages/min), scraped 147061 items (at 235 items/min)
2017-11-04 01:08:03 [scrapy.extensions.logstats] INFO: Crawled 172171 pages (at 231 pages/min), scraped 147279 items (at 218 items/min)
2017-11-04 01:09:03 [scrapy.extensions.logstats] INFO: Crawled 172401 pages (at 230 pages/min), scraped 147506 items (at 227 items/min)
2017-11-04 01:10:03 [scrapy.extensions.logstats] INFO: Crawled 172625 pages (at 224 pages/min), scraped 147735 items (at 229 items/min)
2017-11-04 01:11:03 [scrapy.extensions.logstats] INFO: Crawled 172852 pages (at 227 pages/min), scraped 147952 items (at 217 items/min)
2017-11-04 01:12:03 [scrapy.extensions.logstats] INFO: Crawled 173079 pages (at 227 pages/min), scraped 148158 items (at 206 items/min)
2017-11-04 01:13:03 [scrapy.extensions.logstats] INFO: Crawled 173309 pages (at 230 pages/min), scraped 148344 items (at 186 items/min)
2017-11-04 01:14:03 [scrapy.extensions.logstats] INFO: Crawled 173538 pages (at 229 pages/min), scraped 148539 items (at 195 items/min)
2017-11-04 01:15:03 [scrapy.extensions.logstats] INFO: Crawled 173768 pages (at 230 pages/min), scraped 148718 items (at 179 items/min)
2017-11-04 01:16:03 [scrapy.extensions.logstats] INFO: Crawled 173997 pages (at 229 pages/min), scraped 148881 items (at 163 items/min)
2017-11-04 01:17:03 [scrapy.extensions.logstats] INFO: Crawled 174231 pages (at 234 pages/min), scraped 149075 items (at 194 items/min)
2017-11-04 01:18:03 [scrapy.extensions.logstats] INFO: Crawled 174460 pages (at 229 pages/min), scraped 149240 items (at 165 items/min)
2017-11-04 01:19:03 [scrapy.extensions.logstats] INFO: Crawled 174686 pages (at 226 pages/min), scraped 149430 items (at 190 items/min)
2017-11-04 01:20:03 [scrapy.extensions.logstats] INFO: Crawled 174911 pages (at 225 pages/min), scraped 149632 items (at 202 items/min)
2017-11-04 01:21:03 [scrapy.extensions.logstats] INFO: Crawled 175141 pages (at 230 pages/min), scraped 149830 items (at 198 items/min)
2017-11-04 01:22:03 [scrapy.extensions.logstats] INFO: Crawled 175372 pages (at 231 pages/min), scraped 150061 items (at 231 items/min)
2017-11-04 01:23:03 [scrapy.extensions.logstats] INFO: Crawled 175594 pages (at 222 pages/min), scraped 150285 items (at 224 items/min)
2017-11-04 01:24:03 [scrapy.extensions.logstats] INFO: Crawled 175815 pages (at 221 pages/min), scraped 150514 items (at 229 items/min)
2017-11-04 01:25:03 [scrapy.extensions.logstats] INFO: Crawled 176040 pages (at 225 pages/min), scraped 150704 items (at 190 items/min)
2017-11-04 01:26:03 [scrapy.extensions.logstats] INFO: Crawled 176267 pages (at 227 pages/min), scraped 150911 items (at 207 items/min)
2017-11-04 01:27:03 [scrapy.extensions.logstats] INFO: Crawled 176491 pages (at 224 pages/min), scraped 151133 items (at 222 items/min)
2017-11-04 01:28:03 [scrapy.extensions.logstats] INFO: Crawled 176720 pages (at 229 pages/min), scraped 151360 items (at 227 items/min)
2017-11-04 01:29:03 [scrapy.extensions.logstats] INFO: Crawled 176949 pages (at 229 pages/min), scraped 151572 items (at 212 items/min)
2017-11-04 01:30:03 [scrapy.extensions.logstats] INFO: Crawled 177172 pages (at 223 pages/min), scraped 151783 items (at 211 items/min)
2017-11-04 01:31:03 [scrapy.extensions.logstats] INFO: Crawled 177398 pages (at 226 pages/min), scraped 151986 items (at 203 items/min)
2017-11-04 01:32:03 [scrapy.extensions.logstats] INFO: Crawled 177626 pages (at 228 pages/min), scraped 152178 items (at 192 items/min)
2017-11-04 01:33:03 [scrapy.extensions.logstats] INFO: Crawled 177862 pages (at 236 pages/min), scraped 152393 items (at 215 items/min)
2017-11-04 01:34:03 [scrapy.extensions.logstats] INFO: Crawled 178092 pages (at 230 pages/min), scraped 152587 items (at 194 items/min)
2017-11-04 01:35:03 [scrapy.extensions.logstats] INFO: Crawled 178324 pages (at 232 pages/min), scraped 152749 items (at 162 items/min)
2017-11-04 01:36:03 [scrapy.extensions.logstats] INFO: Crawled 178553 pages (at 229 pages/min), scraped 152913 items (at 164 items/min)
2017-11-04 01:37:03 [scrapy.extensions.logstats] INFO: Crawled 178788 pages (at 235 pages/min), scraped 153091 items (at 178 items/min)
2017-11-04 01:38:03 [scrapy.extensions.logstats] INFO: Crawled 179016 pages (at 228 pages/min), scraped 153276 items (at 185 items/min)
2017-11-04 01:39:03 [scrapy.extensions.logstats] INFO: Crawled 179244 pages (at 228 pages/min), scraped 153458 items (at 182 items/min)
2017-11-04 01:40:03 [scrapy.extensions.logstats] INFO: Crawled 179480 pages (at 236 pages/min), scraped 153643 items (at 185 items/min)
2017-11-04 01:41:03 [scrapy.extensions.logstats] INFO: Crawled 179707 pages (at 227 pages/min), scraped 153834 items (at 191 items/min)
2017-11-04 01:42:03 [scrapy.extensions.logstats] INFO: Crawled 179940 pages (at 233 pages/min), scraped 154025 items (at 191 items/min)
2017-11-04 01:43:03 [scrapy.extensions.logstats] INFO: Crawled 180171 pages (at 231 pages/min), scraped 154228 items (at 203 items/min)
2017-11-04 01:44:03 [scrapy.extensions.logstats] INFO: Crawled 180400 pages (at 229 pages/min), scraped 154414 items (at 186 items/min)
2017-11-04 01:45:03 [scrapy.extensions.logstats] INFO: Crawled 180625 pages (at 225 pages/min), scraped 154591 items (at 177 items/min)
2017-11-04 01:46:03 [scrapy.extensions.logstats] INFO: Crawled 180860 pages (at 235 pages/min), scraped 154762 items (at 171 items/min)
2017-11-04 01:47:03 [scrapy.extensions.logstats] INFO: Crawled 181092 pages (at 232 pages/min), scraped 154948 items (at 186 items/min)
2017-11-04 01:48:03 [scrapy.extensions.logstats] INFO: Crawled 181318 pages (at 226 pages/min), scraped 155125 items (at 177 items/min)
2017-11-04 01:49:03 [scrapy.extensions.logstats] INFO: Crawled 181550 pages (at 232 pages/min), scraped 155311 items (at 186 items/min)
2017-11-04 01:50:03 [scrapy.extensions.logstats] INFO: Crawled 181779 pages (at 229 pages/min), scraped 155497 items (at 186 items/min)
2017-11-04 01:51:03 [scrapy.extensions.logstats] INFO: Crawled 182012 pages (at 233 pages/min), scraped 155671 items (at 174 items/min)
2017-11-04 01:52:03 [scrapy.extensions.logstats] INFO: Crawled 182240 pages (at 228 pages/min), scraped 155858 items (at 187 items/min)
2017-11-04 01:53:03 [scrapy.extensions.logstats] INFO: Crawled 182469 pages (at 229 pages/min), scraped 156047 items (at 189 items/min)
2017-11-04 01:54:03 [scrapy.extensions.logstats] INFO: Crawled 182699 pages (at 230 pages/min), scraped 156221 items (at 174 items/min)
2017-11-04 01:55:03 [scrapy.extensions.logstats] INFO: Crawled 182926 pages (at 227 pages/min), scraped 156415 items (at 194 items/min)
2017-11-04 01:56:03 [scrapy.extensions.logstats] INFO: Crawled 183157 pages (at 231 pages/min), scraped 156600 items (at 185 items/min)
2017-11-04 01:57:03 [scrapy.extensions.logstats] INFO: Crawled 183393 pages (at 236 pages/min), scraped 156790 items (at 190 items/min)
2017-11-04 01:58:03 [scrapy.extensions.logstats] INFO: Crawled 183627 pages (at 234 pages/min), scraped 156978 items (at 188 items/min)
2017-11-04 01:59:03 [scrapy.extensions.logstats] INFO: Crawled 183854 pages (at 227 pages/min), scraped 157168 items (at 190 items/min)
2017-11-04 02:00:03 [scrapy.extensions.logstats] INFO: Crawled 184087 pages (at 233 pages/min), scraped 157359 items (at 191 items/min)
2017-11-04 02:01:03 [scrapy.extensions.logstats] INFO: Crawled 184322 pages (at 235 pages/min), scraped 157549 items (at 190 items/min)
2017-11-04 02:02:03 [scrapy.extensions.logstats] INFO: Crawled 184559 pages (at 237 pages/min), scraped 157734 items (at 185 items/min)
2017-11-04 02:03:03 [scrapy.extensions.logstats] INFO: Crawled 184789 pages (at 230 pages/min), scraped 157907 items (at 173 items/min)
2017-11-04 02:04:03 [scrapy.extensions.logstats] INFO: Crawled 185022 pages (at 233 pages/min), scraped 158079 items (at 172 items/min)
2017-11-04 02:05:03 [scrapy.extensions.logstats] INFO: Crawled 185252 pages (at 230 pages/min), scraped 158235 items (at 156 items/min)
2017-11-04 02:06:03 [scrapy.extensions.logstats] INFO: Crawled 185490 pages (at 238 pages/min), scraped 158390 items (at 155 items/min)
2017-11-04 02:07:03 [scrapy.extensions.logstats] INFO: Crawled 185724 pages (at 234 pages/min), scraped 158539 items (at 149 items/min)
2017-11-04 02:08:03 [scrapy.extensions.logstats] INFO: Crawled 185957 pages (at 233 pages/min), scraped 158703 items (at 164 items/min)
2017-11-04 02:08:39 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29985303&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"徐洁","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"中国国际金融股份有限公司","AOI_ID":"1999008","ADI_ID":"29505","ADI_NAME":"运作部","PTI_NAME":"一般证券业务","CER_NUM":"S0080109121593","OBTAIN_DATE":"2009-12-25","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 02:09:03 [scrapy.extensions.logstats] INFO: Crawled 186184 pages (at 227 pages/min), scraped 158890 items (at 187 items/min)
2017-11-04 02:10:03 [scrapy.extensions.logstats] INFO: Crawled 186417 pages (at 233 pages/min), scraped 159076 items (at 186 items/min)
2017-11-04 02:11:03 [scrapy.extensions.logstats] INFO: Crawled 186644 pages (at 227 pages/min), scraped 159270 items (at 194 items/min)
2017-11-04 02:12:03 [scrapy.extensions.logstats] INFO: Crawled 186875 pages (at 231 pages/min), scraped 159474 items (at 204 items/min)
2017-11-04 02:13:03 [scrapy.extensions.logstats] INFO: Crawled 187095 pages (at 220 pages/min), scraped 159720 items (at 246 items/min)
2017-11-04 02:14:03 [scrapy.extensions.logstats] INFO: Crawled 187323 pages (at 228 pages/min), scraped 159910 items (at 190 items/min)
2017-11-04 02:15:03 [scrapy.extensions.logstats] INFO: Crawled 187554 pages (at 231 pages/min), scraped 160103 items (at 193 items/min)
2017-11-04 02:16:03 [scrapy.extensions.logstats] INFO: Crawled 187783 pages (at 229 pages/min), scraped 160288 items (at 185 items/min)
2017-11-04 02:17:03 [scrapy.extensions.logstats] INFO: Crawled 188009 pages (at 226 pages/min), scraped 160486 items (at 198 items/min)
2017-11-04 02:18:03 [scrapy.extensions.logstats] INFO: Crawled 188233 pages (at 224 pages/min), scraped 160677 items (at 191 items/min)
2017-11-04 02:19:03 [scrapy.extensions.logstats] INFO: Crawled 188465 pages (at 232 pages/min), scraped 160881 items (at 204 items/min)
2017-11-04 02:20:03 [scrapy.extensions.logstats] INFO: Crawled 188695 pages (at 230 pages/min), scraped 161077 items (at 196 items/min)
2017-11-04 02:21:03 [scrapy.extensions.logstats] INFO: Crawled 188924 pages (at 229 pages/min), scraped 161268 items (at 191 items/min)
2017-11-04 02:22:03 [scrapy.extensions.logstats] INFO: Crawled 189148 pages (at 224 pages/min), scraped 161492 items (at 224 items/min)
2017-11-04 02:23:03 [scrapy.extensions.logstats] INFO: Crawled 189374 pages (at 226 pages/min), scraped 161682 items (at 190 items/min)
2017-11-04 02:24:03 [scrapy.extensions.logstats] INFO: Crawled 189604 pages (at 230 pages/min), scraped 161868 items (at 186 items/min)
2017-11-04 02:25:03 [scrapy.extensions.logstats] INFO: Crawled 189834 pages (at 230 pages/min), scraped 162055 items (at 187 items/min)
2017-11-04 02:26:03 [scrapy.extensions.logstats] INFO: Crawled 190059 pages (at 225 pages/min), scraped 162234 items (at 179 items/min)
2017-11-04 02:27:03 [scrapy.extensions.logstats] INFO: Crawled 190293 pages (at 234 pages/min), scraped 162429 items (at 195 items/min)
2017-11-04 02:28:03 [scrapy.extensions.logstats] INFO: Crawled 190516 pages (at 223 pages/min), scraped 162613 items (at 184 items/min)
2017-11-04 02:29:03 [scrapy.extensions.logstats] INFO: Crawled 190745 pages (at 229 pages/min), scraped 162803 items (at 190 items/min)
2017-11-04 02:30:03 [scrapy.extensions.logstats] INFO: Crawled 190975 pages (at 230 pages/min), scraped 162992 items (at 189 items/min)
2017-11-04 02:31:03 [scrapy.extensions.logstats] INFO: Crawled 191203 pages (at 228 pages/min), scraped 163189 items (at 197 items/min)
2017-11-04 02:32:03 [scrapy.extensions.logstats] INFO: Crawled 191432 pages (at 229 pages/min), scraped 163381 items (at 192 items/min)
2017-11-04 02:33:03 [scrapy.extensions.logstats] INFO: Crawled 191656 pages (at 224 pages/min), scraped 163584 items (at 203 items/min)
2017-11-04 02:34:03 [scrapy.extensions.logstats] INFO: Crawled 191884 pages (at 228 pages/min), scraped 163781 items (at 197 items/min)
2017-11-04 02:35:03 [scrapy.extensions.logstats] INFO: Crawled 192119 pages (at 235 pages/min), scraped 163944 items (at 163 items/min)
2017-11-04 02:36:03 [scrapy.extensions.logstats] INFO: Crawled 192350 pages (at 231 pages/min), scraped 164099 items (at 155 items/min)
2017-11-04 02:37:03 [scrapy.extensions.logstats] INFO: Crawled 192581 pages (at 231 pages/min), scraped 164266 items (at 167 items/min)
2017-11-04 02:38:03 [scrapy.extensions.logstats] INFO: Crawled 192801 pages (at 220 pages/min), scraped 164431 items (at 165 items/min)
2017-11-04 02:39:03 [scrapy.extensions.logstats] INFO: Crawled 193044 pages (at 243 pages/min), scraped 164457 items (at 26 items/min)
2017-11-04 02:40:03 [scrapy.extensions.logstats] INFO: Crawled 193292 pages (at 248 pages/min), scraped 164457 items (at 0 items/min)
2017-11-04 02:41:03 [scrapy.extensions.logstats] INFO: Crawled 193543 pages (at 251 pages/min), scraped 164457 items (at 0 items/min)
2017-11-04 02:42:03 [scrapy.extensions.logstats] INFO: Crawled 193789 pages (at 246 pages/min), scraped 164457 items (at 0 items/min)
2017-11-04 02:43:03 [scrapy.extensions.logstats] INFO: Crawled 194037 pages (at 248 pages/min), scraped 164457 items (at 0 items/min)
2017-11-04 02:44:03 [scrapy.extensions.logstats] INFO: Crawled 194279 pages (at 242 pages/min), scraped 164457 items (at 0 items/min)
2017-11-04 02:45:03 [scrapy.extensions.logstats] INFO: Crawled 194526 pages (at 247 pages/min), scraped 164457 items (at 0 items/min)
2017-11-04 02:46:03 [scrapy.extensions.logstats] INFO: Crawled 194769 pages (at 243 pages/min), scraped 164478 items (at 21 items/min)
2017-11-04 02:47:03 [scrapy.extensions.logstats] INFO: Crawled 194999 pages (at 230 pages/min), scraped 164710 items (at 232 items/min)
2017-11-04 02:48:03 [scrapy.extensions.logstats] INFO: Crawled 195223 pages (at 224 pages/min), scraped 164935 items (at 225 items/min)
2017-11-04 02:49:03 [scrapy.extensions.logstats] INFO: Crawled 195446 pages (at 223 pages/min), scraped 165145 items (at 210 items/min)
2017-11-04 02:50:03 [scrapy.extensions.logstats] INFO: Crawled 195674 pages (at 228 pages/min), scraped 165366 items (at 221 items/min)
2017-11-04 02:51:03 [scrapy.extensions.logstats] INFO: Crawled 195901 pages (at 227 pages/min), scraped 165601 items (at 235 items/min)
2017-11-04 02:52:03 [scrapy.extensions.logstats] INFO: Crawled 196129 pages (at 228 pages/min), scraped 165807 items (at 206 items/min)
2017-11-04 02:53:03 [scrapy.extensions.logstats] INFO: Crawled 196357 pages (at 228 pages/min), scraped 166019 items (at 212 items/min)
2017-11-04 02:54:03 [scrapy.extensions.logstats] INFO: Crawled 196584 pages (at 227 pages/min), scraped 166238 items (at 219 items/min)
2017-11-04 02:55:03 [scrapy.extensions.logstats] INFO: Crawled 196804 pages (at 220 pages/min), scraped 166448 items (at 210 items/min)
2017-11-04 02:56:03 [scrapy.extensions.logstats] INFO: Crawled 197034 pages (at 230 pages/min), scraped 166676 items (at 228 items/min)
2017-11-04 02:57:03 [scrapy.extensions.logstats] INFO: Crawled 197259 pages (at 225 pages/min), scraped 166890 items (at 214 items/min)
2017-11-04 02:58:03 [scrapy.extensions.logstats] INFO: Crawled 197488 pages (at 229 pages/min), scraped 167101 items (at 211 items/min)
2017-11-04 02:59:03 [scrapy.extensions.logstats] INFO: Crawled 197712 pages (at 224 pages/min), scraped 167314 items (at 213 items/min)
2017-11-04 03:00:03 [scrapy.extensions.logstats] INFO: Crawled 197940 pages (at 228 pages/min), scraped 167528 items (at 214 items/min)
2017-11-04 03:01:03 [scrapy.extensions.logstats] INFO: Crawled 198166 pages (at 226 pages/min), scraped 167741 items (at 213 items/min)
2017-11-04 03:02:03 [scrapy.extensions.logstats] INFO: Crawled 198399 pages (at 233 pages/min), scraped 167951 items (at 210 items/min)
2017-11-04 03:03:03 [scrapy.extensions.logstats] INFO: Crawled 198621 pages (at 222 pages/min), scraped 168157 items (at 206 items/min)
2017-11-04 03:04:03 [scrapy.extensions.logstats] INFO: Crawled 198846 pages (at 225 pages/min), scraped 168373 items (at 216 items/min)
2017-11-04 03:05:03 [scrapy.extensions.logstats] INFO: Crawled 199072 pages (at 226 pages/min), scraped 168575 items (at 202 items/min)
2017-11-04 03:06:03 [scrapy.extensions.logstats] INFO: Crawled 199300 pages (at 228 pages/min), scraped 168791 items (at 216 items/min)
2017-11-04 03:07:03 [scrapy.extensions.logstats] INFO: Crawled 199530 pages (at 230 pages/min), scraped 168998 items (at 207 items/min)
2017-11-04 03:08:03 [scrapy.extensions.logstats] INFO: Crawled 199756 pages (at 226 pages/min), scraped 169225 items (at 227 items/min)
2017-11-04 03:09:04 [scrapy.extensions.logstats] INFO: Crawled 199983 pages (at 227 pages/min), scraped 169449 items (at 224 items/min)
2017-11-04 03:10:03 [scrapy.extensions.logstats] INFO: Crawled 200197 pages (at 214 pages/min), scraped 169686 items (at 237 items/min)
2017-11-04 03:11:03 [scrapy.extensions.logstats] INFO: Crawled 200420 pages (at 223 pages/min), scraped 169890 items (at 204 items/min)
2017-11-04 03:12:03 [scrapy.extensions.logstats] INFO: Crawled 200650 pages (at 230 pages/min), scraped 170099 items (at 209 items/min)
2017-11-04 03:13:03 [scrapy.extensions.logstats] INFO: Crawled 200879 pages (at 229 pages/min), scraped 170289 items (at 190 items/min)
2017-11-04 03:14:03 [scrapy.extensions.logstats] INFO: Crawled 201105 pages (at 226 pages/min), scraped 170494 items (at 205 items/min)
2017-11-04 03:15:03 [scrapy.extensions.logstats] INFO: Crawled 201335 pages (at 230 pages/min), scraped 170691 items (at 197 items/min)
2017-11-04 03:16:03 [scrapy.extensions.logstats] INFO: Crawled 201561 pages (at 226 pages/min), scraped 170892 items (at 201 items/min)
2017-11-04 03:17:03 [scrapy.extensions.logstats] INFO: Crawled 201784 pages (at 223 pages/min), scraped 171099 items (at 207 items/min)
2017-11-04 03:18:03 [scrapy.extensions.logstats] INFO: Crawled 202009 pages (at 225 pages/min), scraped 171312 items (at 213 items/min)
2017-11-04 03:19:03 [scrapy.extensions.logstats] INFO: Crawled 202242 pages (at 233 pages/min), scraped 171540 items (at 228 items/min)
2017-11-04 03:20:03 [scrapy.extensions.logstats] INFO: Crawled 202465 pages (at 223 pages/min), scraped 171737 items (at 197 items/min)
2017-11-04 03:21:03 [scrapy.extensions.logstats] INFO: Crawled 202691 pages (at 226 pages/min), scraped 171949 items (at 212 items/min)
2017-11-04 03:22:03 [scrapy.extensions.logstats] INFO: Crawled 202919 pages (at 228 pages/min), scraped 172158 items (at 209 items/min)
2017-11-04 03:23:03 [scrapy.extensions.logstats] INFO: Crawled 203142 pages (at 223 pages/min), scraped 172384 items (at 226 items/min)
2017-11-04 03:24:03 [scrapy.extensions.logstats] INFO: Crawled 203365 pages (at 223 pages/min), scraped 172621 items (at 237 items/min)
2017-11-04 03:25:03 [scrapy.extensions.logstats] INFO: Crawled 203581 pages (at 216 pages/min), scraped 172826 items (at 205 items/min)
2017-11-04 03:26:03 [scrapy.extensions.logstats] INFO: Crawled 203805 pages (at 224 pages/min), scraped 173058 items (at 232 items/min)
2017-11-04 03:27:03 [scrapy.extensions.logstats] INFO: Crawled 204035 pages (at 230 pages/min), scraped 173298 items (at 240 items/min)
2017-11-04 03:28:03 [scrapy.extensions.logstats] INFO: Crawled 204259 pages (at 224 pages/min), scraped 173525 items (at 227 items/min)
2017-11-04 03:29:03 [scrapy.extensions.logstats] INFO: Crawled 204482 pages (at 223 pages/min), scraped 173757 items (at 232 items/min)
2017-11-04 03:30:03 [scrapy.extensions.logstats] INFO: Crawled 204705 pages (at 223 pages/min), scraped 173984 items (at 227 items/min)
2017-11-04 03:31:03 [scrapy.extensions.logstats] INFO: Crawled 204939 pages (at 234 pages/min), scraped 174215 items (at 231 items/min)
2017-11-04 03:32:03 [scrapy.extensions.logstats] INFO: Crawled 205163 pages (at 224 pages/min), scraped 174433 items (at 218 items/min)
2017-11-04 03:33:04 [scrapy.extensions.logstats] INFO: Crawled 205389 pages (at 226 pages/min), scraped 174657 items (at 224 items/min)
2017-11-04 03:34:03 [scrapy.extensions.logstats] INFO: Crawled 205613 pages (at 224 pages/min), scraped 174888 items (at 231 items/min)
2017-11-04 03:35:03 [scrapy.extensions.logstats] INFO: Crawled 205838 pages (at 225 pages/min), scraped 175102 items (at 214 items/min)
2017-11-04 03:36:03 [scrapy.extensions.logstats] INFO: Crawled 206069 pages (at 231 pages/min), scraped 175253 items (at 151 items/min)
2017-11-04 03:37:03 [scrapy.extensions.logstats] INFO: Crawled 206297 pages (at 228 pages/min), scraped 175419 items (at 166 items/min)
2017-11-04 03:38:03 [scrapy.extensions.logstats] INFO: Crawled 206528 pages (at 231 pages/min), scraped 175585 items (at 166 items/min)
2017-11-04 03:39:03 [scrapy.extensions.logstats] INFO: Crawled 206762 pages (at 234 pages/min), scraped 175760 items (at 175 items/min)
2017-11-04 03:39:10 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=59973974&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"梁倩红","SCO_NAME":"女","ECO_NAME":"大专","AOI_NAME":"招商证券股份有限公司","AOI_ID":"1999109","ADI_ID":"47870","ADI_NAME":"佛山顺德东乐路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S1090111010004","OBTAIN_DATE":"2011-01-07","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 03:40:03 [scrapy.extensions.logstats] INFO: Crawled 206991 pages (at 229 pages/min), scraped 175961 items (at 201 items/min)
2017-11-04 03:41:03 [scrapy.extensions.logstats] INFO: Crawled 207202 pages (at 211 pages/min), scraped 176131 items (at 170 items/min)
2017-11-04 03:42:03 [scrapy.extensions.logstats] INFO: Crawled 207429 pages (at 227 pages/min), scraped 176366 items (at 235 items/min)
2017-11-04 03:43:03 [scrapy.extensions.logstats] INFO: Crawled 207653 pages (at 224 pages/min), scraped 176605 items (at 239 items/min)
2017-11-04 03:44:03 [scrapy.extensions.logstats] INFO: Crawled 207869 pages (at 216 pages/min), scraped 176846 items (at 241 items/min)
2017-11-04 03:45:03 [scrapy.extensions.logstats] INFO: Crawled 208091 pages (at 222 pages/min), scraped 177088 items (at 242 items/min)
2017-11-04 03:46:03 [scrapy.extensions.logstats] INFO: Crawled 208312 pages (at 221 pages/min), scraped 177323 items (at 235 items/min)
2017-11-04 03:47:03 [scrapy.extensions.logstats] INFO: Crawled 208543 pages (at 231 pages/min), scraped 177498 items (at 175 items/min)
2017-11-04 03:48:03 [scrapy.extensions.logstats] INFO: Crawled 208767 pages (at 224 pages/min), scraped 177690 items (at 192 items/min)
2017-11-04 03:48:19 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39900630&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"戚少军","SCO_NAME":"男","ECO_NAME":"硕士研究生","AOI_NAME":"招商证券股份有限公司","AOI_ID":"1999109","ADI_ID":"47927","ADI_NAME":"深圳深南东路证券营业部","PTI_NAME":"证券投资咨询业务(投资顾问)","CER_NUM":"S1090611040022","OBTAIN_DATE":"2011-04-11","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 03:49:03 [scrapy.extensions.logstats] INFO: Crawled 208998 pages (at 231 pages/min), scraped 177895 items (at 205 items/min)
2017-11-04 03:50:03 [scrapy.extensions.logstats] INFO: Crawled 209231 pages (at 233 pages/min), scraped 178061 items (at 166 items/min)
2017-11-04 03:51:03 [scrapy.extensions.logstats] INFO: Crawled 209459 pages (at 228 pages/min), scraped 178255 items (at 194 items/min)
2017-11-04 03:52:03 [scrapy.extensions.logstats] INFO: Crawled 209689 pages (at 230 pages/min), scraped 178454 items (at 199 items/min)
2017-11-04 03:53:03 [scrapy.extensions.logstats] INFO: Crawled 209912 pages (at 223 pages/min), scraped 178656 items (at 202 items/min)
2017-11-04 03:54:03 [scrapy.extensions.logstats] INFO: Crawled 210141 pages (at 229 pages/min), scraped 178851 items (at 195 items/min)
2017-11-04 03:55:03 [scrapy.extensions.logstats] INFO: Crawled 210368 pages (at 227 pages/min), scraped 179054 items (at 203 items/min)
2017-11-04 03:56:03 [scrapy.extensions.logstats] INFO: Crawled 210571 pages (at 203 pages/min), scraped 179280 items (at 226 items/min)
2017-11-04 03:57:03 [scrapy.extensions.logstats] INFO: Crawled 210792 pages (at 221 pages/min), scraped 179518 items (at 238 items/min)
2017-11-04 03:58:03 [scrapy.extensions.logstats] INFO: Crawled 211013 pages (at 221 pages/min), scraped 179779 items (at 261 items/min)
2017-11-04 03:59:03 [scrapy.extensions.logstats] INFO: Crawled 211236 pages (at 223 pages/min), scraped 180020 items (at 241 items/min)
2017-11-04 04:00:03 [scrapy.extensions.logstats] INFO: Crawled 211459 pages (at 223 pages/min), scraped 180223 items (at 203 items/min)
2017-11-04 04:01:03 [scrapy.extensions.logstats] INFO: Crawled 211689 pages (at 230 pages/min), scraped 180426 items (at 203 items/min)
2017-11-04 04:02:03 [scrapy.extensions.logstats] INFO: Crawled 211917 pages (at 228 pages/min), scraped 180598 items (at 172 items/min)
2017-11-04 04:03:03 [scrapy.extensions.logstats] INFO: Crawled 212145 pages (at 228 pages/min), scraped 180785 items (at 187 items/min)
2017-11-04 04:04:03 [scrapy.extensions.logstats] INFO: Crawled 212373 pages (at 228 pages/min), scraped 180990 items (at 205 items/min)
2017-11-04 04:05:03 [scrapy.extensions.logstats] INFO: Crawled 212596 pages (at 223 pages/min), scraped 181213 items (at 223 items/min)
2017-11-04 04:06:03 [scrapy.extensions.logstats] INFO: Crawled 212821 pages (at 225 pages/min), scraped 181429 items (at 216 items/min)
2017-11-04 04:07:03 [scrapy.extensions.logstats] INFO: Crawled 213047 pages (at 226 pages/min), scraped 181619 items (at 190 items/min)
2017-11-04 04:08:03 [scrapy.extensions.logstats] INFO: Crawled 213275 pages (at 228 pages/min), scraped 181820 items (at 201 items/min)
2017-11-04 04:09:03 [scrapy.extensions.logstats] INFO: Crawled 213499 pages (at 224 pages/min), scraped 182019 items (at 199 items/min)
2017-11-04 04:10:03 [scrapy.extensions.logstats] INFO: Crawled 213731 pages (at 232 pages/min), scraped 182184 items (at 165 items/min)
2017-11-04 04:11:03 [scrapy.extensions.logstats] INFO: Crawled 213953 pages (at 222 pages/min), scraped 182345 items (at 161 items/min)
2017-11-04 04:12:03 [scrapy.extensions.logstats] INFO: Crawled 214184 pages (at 231 pages/min), scraped 182507 items (at 162 items/min)
2017-11-04 04:13:03 [scrapy.extensions.logstats] INFO: Crawled 214414 pages (at 230 pages/min), scraped 182670 items (at 163 items/min)
2017-11-04 04:14:03 [scrapy.extensions.logstats] INFO: Crawled 214645 pages (at 231 pages/min), scraped 182838 items (at 168 items/min)
2017-11-04 04:15:03 [scrapy.extensions.logstats] INFO: Crawled 214878 pages (at 233 pages/min), scraped 182992 items (at 154 items/min)
2017-11-04 04:16:03 [scrapy.extensions.logstats] INFO: Crawled 215110 pages (at 232 pages/min), scraped 183153 items (at 161 items/min)
2017-11-04 04:17:03 [scrapy.extensions.logstats] INFO: Crawled 215341 pages (at 231 pages/min), scraped 183327 items (at 174 items/min)
2017-11-04 04:18:03 [scrapy.extensions.logstats] INFO: Crawled 215574 pages (at 233 pages/min), scraped 183487 items (at 160 items/min)
2017-11-04 04:19:03 [scrapy.extensions.logstats] INFO: Crawled 215806 pages (at 232 pages/min), scraped 183650 items (at 163 items/min)
2017-11-04 04:20:03 [scrapy.extensions.logstats] INFO: Crawled 216044 pages (at 238 pages/min), scraped 183814 items (at 164 items/min)
2017-11-04 04:21:03 [scrapy.extensions.logstats] INFO: Crawled 216271 pages (at 227 pages/min), scraped 183975 items (at 161 items/min)
2017-11-04 04:22:03 [scrapy.extensions.logstats] INFO: Crawled 216507 pages (at 236 pages/min), scraped 184135 items (at 160 items/min)
2017-11-04 04:23:03 [scrapy.extensions.logstats] INFO: Crawled 216736 pages (at 229 pages/min), scraped 184299 items (at 164 items/min)
2017-11-04 04:24:03 [scrapy.extensions.logstats] INFO: Crawled 216972 pages (at 236 pages/min), scraped 184457 items (at 158 items/min)
2017-11-04 04:25:03 [scrapy.extensions.logstats] INFO: Crawled 217202 pages (at 230 pages/min), scraped 184623 items (at 166 items/min)
2017-11-04 04:26:03 [scrapy.extensions.logstats] INFO: Crawled 217433 pages (at 231 pages/min), scraped 184781 items (at 158 items/min)
2017-11-04 04:27:03 [scrapy.extensions.logstats] INFO: Crawled 217662 pages (at 229 pages/min), scraped 184945 items (at 164 items/min)
2017-11-04 04:28:03 [scrapy.extensions.logstats] INFO: Crawled 217893 pages (at 231 pages/min), scraped 185113 items (at 168 items/min)
2017-11-04 04:29:03 [scrapy.extensions.logstats] INFO: Crawled 218127 pages (at 234 pages/min), scraped 185262 items (at 149 items/min)
2017-11-04 04:30:03 [scrapy.extensions.logstats] INFO: Crawled 218361 pages (at 234 pages/min), scraped 185427 items (at 165 items/min)
2017-11-04 04:31:03 [scrapy.extensions.logstats] INFO: Crawled 218591 pages (at 230 pages/min), scraped 185584 items (at 157 items/min)
2017-11-04 04:32:03 [scrapy.extensions.logstats] INFO: Crawled 218826 pages (at 235 pages/min), scraped 185744 items (at 160 items/min)
2017-11-04 04:33:03 [scrapy.extensions.logstats] INFO: Crawled 219059 pages (at 233 pages/min), scraped 185913 items (at 169 items/min)
2017-11-04 04:34:03 [scrapy.extensions.logstats] INFO: Crawled 219293 pages (at 234 pages/min), scraped 186070 items (at 157 items/min)
2017-11-04 04:35:03 [scrapy.extensions.logstats] INFO: Crawled 219523 pages (at 230 pages/min), scraped 186243 items (at 173 items/min)
2017-11-04 04:36:03 [scrapy.extensions.logstats] INFO: Crawled 219759 pages (at 236 pages/min), scraped 186424 items (at 181 items/min)
2017-11-04 04:37:03 [scrapy.extensions.logstats] INFO: Crawled 219986 pages (at 227 pages/min), scraped 186629 items (at 205 items/min)
2017-11-04 04:38:03 [scrapy.extensions.logstats] INFO: Crawled 220205 pages (at 219 pages/min), scraped 186911 items (at 282 items/min)
2017-11-04 04:39:03 [scrapy.extensions.logstats] INFO: Crawled 220421 pages (at 216 pages/min), scraped 187191 items (at 280 items/min)
2017-11-04 04:40:03 [scrapy.extensions.logstats] INFO: Crawled 220649 pages (at 228 pages/min), scraped 187348 items (at 157 items/min)
2017-11-04 04:41:03 [scrapy.extensions.logstats] INFO: Crawled 220881 pages (at 232 pages/min), scraped 187505 items (at 157 items/min)
2017-11-04 04:42:03 [scrapy.extensions.logstats] INFO: Crawled 221117 pages (at 236 pages/min), scraped 187667 items (at 162 items/min)
2017-11-04 04:43:03 [scrapy.extensions.logstats] INFO: Crawled 221345 pages (at 228 pages/min), scraped 187828 items (at 161 items/min)
2017-11-04 04:44:03 [scrapy.extensions.logstats] INFO: Crawled 221575 pages (at 230 pages/min), scraped 187992 items (at 164 items/min)
2017-11-04 04:45:03 [scrapy.extensions.logstats] INFO: Crawled 221809 pages (at 234 pages/min), scraped 188151 items (at 159 items/min)
2017-11-04 04:46:03 [scrapy.extensions.logstats] INFO: Crawled 222043 pages (at 234 pages/min), scraped 188319 items (at 168 items/min)
2017-11-04 04:47:03 [scrapy.extensions.logstats] INFO: Crawled 222270 pages (at 227 pages/min), scraped 188528 items (at 209 items/min)
2017-11-04 04:48:03 [scrapy.extensions.logstats] INFO: Crawled 222490 pages (at 220 pages/min), scraped 188755 items (at 227 items/min)
2017-11-04 04:49:03 [scrapy.extensions.logstats] INFO: Crawled 222711 pages (at 221 pages/min), scraped 189012 items (at 257 items/min)
2017-11-04 04:50:03 [scrapy.extensions.logstats] INFO: Crawled 222933 pages (at 222 pages/min), scraped 189232 items (at 220 items/min)
2017-11-04 04:51:03 [scrapy.extensions.logstats] INFO: Crawled 223161 pages (at 228 pages/min), scraped 189452 items (at 220 items/min)
2017-11-04 04:52:03 [scrapy.extensions.logstats] INFO: Crawled 223392 pages (at 231 pages/min), scraped 189671 items (at 219 items/min)
2017-11-04 04:53:03 [scrapy.extensions.logstats] INFO: Crawled 223616 pages (at 224 pages/min), scraped 189909 items (at 238 items/min)
2017-11-04 04:54:03 [scrapy.extensions.logstats] INFO: Crawled 223840 pages (at 224 pages/min), scraped 190150 items (at 241 items/min)
2017-11-04 04:55:03 [scrapy.extensions.logstats] INFO: Crawled 224074 pages (at 234 pages/min), scraped 190330 items (at 180 items/min)
2017-11-04 04:56:03 [scrapy.extensions.logstats] INFO: Crawled 224303 pages (at 229 pages/min), scraped 190508 items (at 178 items/min)
2017-11-04 04:57:03 [scrapy.extensions.logstats] INFO: Crawled 224538 pages (at 235 pages/min), scraped 190674 items (at 166 items/min)
2017-11-04 04:58:03 [scrapy.extensions.logstats] INFO: Crawled 224759 pages (at 221 pages/min), scraped 190863 items (at 189 items/min)
2017-11-04 04:59:03 [scrapy.extensions.logstats] INFO: Crawled 224983 pages (at 224 pages/min), scraped 191070 items (at 207 items/min)
2017-11-04 05:00:03 [scrapy.extensions.logstats] INFO: Crawled 225209 pages (at 226 pages/min), scraped 191266 items (at 196 items/min)
2017-11-04 05:01:03 [scrapy.extensions.logstats] INFO: Crawled 225437 pages (at 228 pages/min), scraped 191459 items (at 193 items/min)
2017-11-04 05:02:03 [scrapy.extensions.logstats] INFO: Crawled 225663 pages (at 226 pages/min), scraped 191640 items (at 181 items/min)
2017-11-04 05:03:03 [scrapy.extensions.logstats] INFO: Crawled 225888 pages (at 225 pages/min), scraped 191843 items (at 203 items/min)
2017-11-04 05:04:03 [scrapy.extensions.logstats] INFO: Crawled 226116 pages (at 228 pages/min), scraped 192076 items (at 233 items/min)
2017-11-04 05:05:03 [scrapy.extensions.logstats] INFO: Crawled 226344 pages (at 228 pages/min), scraped 192302 items (at 226 items/min)
2017-11-04 05:06:03 [scrapy.extensions.logstats] INFO: Crawled 226567 pages (at 223 pages/min), scraped 192524 items (at 222 items/min)
2017-11-04 05:07:03 [scrapy.extensions.logstats] INFO: Crawled 226797 pages (at 230 pages/min), scraped 192741 items (at 217 items/min)
2017-11-04 05:08:03 [scrapy.extensions.logstats] INFO: Crawled 227021 pages (at 224 pages/min), scraped 192932 items (at 191 items/min)
2017-11-04 05:09:03 [scrapy.extensions.logstats] INFO: Crawled 227249 pages (at 228 pages/min), scraped 193138 items (at 206 items/min)
2017-11-04 05:10:03 [scrapy.extensions.logstats] INFO: Crawled 227479 pages (at 230 pages/min), scraped 193330 items (at 192 items/min)
2017-11-04 05:11:03 [scrapy.extensions.logstats] INFO: Crawled 227711 pages (at 232 pages/min), scraped 193533 items (at 203 items/min)
2017-11-04 05:12:03 [scrapy.extensions.logstats] INFO: Crawled 227936 pages (at 225 pages/min), scraped 193742 items (at 209 items/min)
2017-11-04 05:13:03 [scrapy.extensions.logstats] INFO: Crawled 228158 pages (at 222 pages/min), scraped 193952 items (at 210 items/min)
2017-11-04 05:14:03 [scrapy.extensions.logstats] INFO: Crawled 228387 pages (at 229 pages/min), scraped 194144 items (at 192 items/min)
2017-11-04 05:15:03 [scrapy.extensions.logstats] INFO: Crawled 228615 pages (at 228 pages/min), scraped 194342 items (at 198 items/min)
2017-11-04 05:16:03 [scrapy.extensions.logstats] INFO: Crawled 228851 pages (at 236 pages/min), scraped 194546 items (at 204 items/min)
2017-11-04 05:17:03 [scrapy.extensions.logstats] INFO: Crawled 229075 pages (at 224 pages/min), scraped 194731 items (at 185 items/min)
2017-11-04 05:18:03 [scrapy.extensions.logstats] INFO: Crawled 229296 pages (at 221 pages/min), scraped 194927 items (at 196 items/min)
2017-11-04 05:19:03 [scrapy.extensions.logstats] INFO: Crawled 229533 pages (at 237 pages/min), scraped 195121 items (at 194 items/min)
2017-11-04 05:20:03 [scrapy.extensions.logstats] INFO: Crawled 229759 pages (at 226 pages/min), scraped 195327 items (at 206 items/min)
2017-11-04 05:21:03 [scrapy.extensions.logstats] INFO: Crawled 229995 pages (at 236 pages/min), scraped 195512 items (at 185 items/min)
2017-11-04 05:22:03 [scrapy.extensions.logstats] INFO: Crawled 230222 pages (at 227 pages/min), scraped 195705 items (at 193 items/min)
2017-11-04 05:23:03 [scrapy.extensions.logstats] INFO: Crawled 230454 pages (at 232 pages/min), scraped 195893 items (at 188 items/min)
2017-11-04 05:24:03 [scrapy.extensions.logstats] INFO: Crawled 230685 pages (at 231 pages/min), scraped 196089 items (at 196 items/min)
2017-11-04 05:25:03 [scrapy.extensions.logstats] INFO: Crawled 230909 pages (at 224 pages/min), scraped 196285 items (at 196 items/min)
2017-11-04 05:26:03 [scrapy.extensions.logstats] INFO: Crawled 231132 pages (at 223 pages/min), scraped 196493 items (at 208 items/min)
2017-11-04 05:27:03 [scrapy.extensions.logstats] INFO: Crawled 231360 pages (at 228 pages/min), scraped 196697 items (at 204 items/min)
2017-11-04 05:28:03 [scrapy.extensions.logstats] INFO: Crawled 231594 pages (at 234 pages/min), scraped 196896 items (at 199 items/min)
2017-11-04 05:29:03 [scrapy.extensions.logstats] INFO: Crawled 231818 pages (at 224 pages/min), scraped 197096 items (at 200 items/min)
2017-11-04 05:30:03 [scrapy.extensions.logstats] INFO: Crawled 232042 pages (at 224 pages/min), scraped 197304 items (at 208 items/min)
2017-11-04 05:31:03 [scrapy.extensions.logstats] INFO: Crawled 232267 pages (at 225 pages/min), scraped 197512 items (at 208 items/min)
2017-11-04 05:32:03 [scrapy.extensions.logstats] INFO: Crawled 232492 pages (at 225 pages/min), scraped 197716 items (at 204 items/min)
2017-11-04 05:33:03 [scrapy.extensions.logstats] INFO: Crawled 232722 pages (at 230 pages/min), scraped 197903 items (at 187 items/min)
2017-11-04 05:34:03 [scrapy.extensions.logstats] INFO: Crawled 232949 pages (at 227 pages/min), scraped 198106 items (at 203 items/min)
2017-11-04 05:35:03 [scrapy.extensions.logstats] INFO: Crawled 233176 pages (at 227 pages/min), scraped 198322 items (at 216 items/min)
2017-11-04 05:36:03 [scrapy.extensions.logstats] INFO: Crawled 233404 pages (at 228 pages/min), scraped 198520 items (at 198 items/min)
2017-11-04 05:37:03 [scrapy.extensions.logstats] INFO: Crawled 233636 pages (at 232 pages/min), scraped 198720 items (at 200 items/min)
2017-11-04 05:38:03 [scrapy.extensions.logstats] INFO: Crawled 233859 pages (at 223 pages/min), scraped 198930 items (at 210 items/min)
2017-11-04 05:39:03 [scrapy.extensions.logstats] INFO: Crawled 234093 pages (at 234 pages/min), scraped 199129 items (at 199 items/min)
2017-11-04 05:40:03 [scrapy.extensions.logstats] INFO: Crawled 234319 pages (at 226 pages/min), scraped 199306 items (at 177 items/min)
2017-11-04 05:41:03 [scrapy.extensions.logstats] INFO: Crawled 234549 pages (at 230 pages/min), scraped 199500 items (at 194 items/min)
2017-11-04 05:42:03 [scrapy.extensions.logstats] INFO: Crawled 234774 pages (at 225 pages/min), scraped 199703 items (at 203 items/min)
2017-11-04 05:43:03 [scrapy.extensions.logstats] INFO: Crawled 234998 pages (at 224 pages/min), scraped 199893 items (at 190 items/min)
2017-11-04 05:44:03 [scrapy.extensions.logstats] INFO: Crawled 235229 pages (at 231 pages/min), scraped 200043 items (at 150 items/min)
2017-11-04 05:45:03 [scrapy.extensions.logstats] INFO: Crawled 235458 pages (at 229 pages/min), scraped 200224 items (at 181 items/min)
2017-11-04 05:46:03 [scrapy.extensions.logstats] INFO: Crawled 235688 pages (at 230 pages/min), scraped 200405 items (at 181 items/min)
2017-11-04 05:47:03 [scrapy.extensions.logstats] INFO: Crawled 235913 pages (at 225 pages/min), scraped 200593 items (at 188 items/min)
2017-11-04 05:48:03 [scrapy.extensions.logstats] INFO: Crawled 236137 pages (at 224 pages/min), scraped 200794 items (at 201 items/min)
2017-11-04 05:49:03 [scrapy.extensions.logstats] INFO: Crawled 236362 pages (at 225 pages/min), scraped 200997 items (at 203 items/min)
2017-11-04 05:50:03 [scrapy.extensions.logstats] INFO: Crawled 236588 pages (at 226 pages/min), scraped 201195 items (at 198 items/min)
2017-11-04 05:51:03 [scrapy.extensions.logstats] INFO: Crawled 236817 pages (at 229 pages/min), scraped 201378 items (at 183 items/min)
2017-11-04 05:52:03 [scrapy.extensions.logstats] INFO: Crawled 237046 pages (at 229 pages/min), scraped 201579 items (at 201 items/min)
2017-11-04 05:53:03 [scrapy.extensions.logstats] INFO: Crawled 237266 pages (at 220 pages/min), scraped 201804 items (at 225 items/min)
2017-11-04 05:54:03 [scrapy.extensions.logstats] INFO: Crawled 237495 pages (at 229 pages/min), scraped 202008 items (at 204 items/min)
2017-11-04 05:55:03 [scrapy.extensions.logstats] INFO: Crawled 237719 pages (at 224 pages/min), scraped 202221 items (at 213 items/min)
2017-11-04 05:56:03 [scrapy.extensions.logstats] INFO: Crawled 237942 pages (at 223 pages/min), scraped 202434 items (at 213 items/min)
2017-11-04 05:57:03 [scrapy.extensions.logstats] INFO: Crawled 238167 pages (at 225 pages/min), scraped 202630 items (at 196 items/min)
2017-11-04 05:58:03 [scrapy.extensions.logstats] INFO: Crawled 238392 pages (at 225 pages/min), scraped 202824 items (at 194 items/min)
2017-11-04 05:59:03 [scrapy.extensions.logstats] INFO: Crawled 238616 pages (at 224 pages/min), scraped 203034 items (at 210 items/min)
2017-11-04 06:00:03 [scrapy.extensions.logstats] INFO: Crawled 238836 pages (at 220 pages/min), scraped 203285 items (at 251 items/min)
2017-11-04 06:01:03 [scrapy.extensions.logstats] INFO: Crawled 239060 pages (at 224 pages/min), scraped 203487 items (at 202 items/min)
2017-11-04 06:02:03 [scrapy.extensions.logstats] INFO: Crawled 239287 pages (at 227 pages/min), scraped 203708 items (at 221 items/min)
2017-11-04 06:02:42 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:42 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:43 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=174392&sqlkey=registration&sqlval=SELECT_PERSON_INFO>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:43 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=249239&sqlkey=registration&sqlval=SELECT_PERSON_INFO>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=181926&sqlkey=registration&sqlval=SELECT_PERSON_INFO>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=175432&sqlkey=registration&sqlval=SELECT_PERSON_INFO>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:44 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:44 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:44 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:45 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:45 [scrapy.core.scraper] ERROR: Error downloading <GET http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=216475&sqlkey=registration&sqlval=SELECT_PERSON_INFO>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:02:45 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-04 06:03:03 [scrapy.extensions.logstats] INFO: Crawled 239436 pages (at 149 pages/min), scraped 203838 items (at 130 items/min)
2017-11-04 06:04:03 [scrapy.extensions.logstats] INFO: Crawled 239665 pages (at 229 pages/min), scraped 204029 items (at 191 items/min)
2017-11-04 06:05:03 [scrapy.extensions.logstats] INFO: Crawled 239894 pages (at 229 pages/min), scraped 204225 items (at 196 items/min)
2017-11-04 06:06:03 [scrapy.extensions.logstats] INFO: Crawled 240118 pages (at 224 pages/min), scraped 204448 items (at 223 items/min)
2017-11-04 06:07:03 [scrapy.extensions.logstats] INFO: Crawled 240348 pages (at 230 pages/min), scraped 204661 items (at 213 items/min)
2017-11-04 06:08:03 [scrapy.extensions.logstats] INFO: Crawled 240563 pages (at 215 pages/min), scraped 204903 items (at 242 items/min)
2017-11-04 06:09:03 [scrapy.extensions.logstats] INFO: Crawled 240790 pages (at 227 pages/min), scraped 205131 items (at 228 items/min)
2017-11-04 06:10:03 [scrapy.extensions.logstats] INFO: Crawled 241012 pages (at 222 pages/min), scraped 205353 items (at 222 items/min)
2017-11-04 06:11:03 [scrapy.extensions.logstats] INFO: Crawled 241244 pages (at 232 pages/min), scraped 205581 items (at 228 items/min)
2017-11-04 06:12:03 [scrapy.extensions.logstats] INFO: Crawled 241463 pages (at 219 pages/min), scraped 205805 items (at 224 items/min)
2017-11-04 06:13:03 [scrapy.extensions.logstats] INFO: Crawled 241688 pages (at 225 pages/min), scraped 206037 items (at 232 items/min)
2017-11-04 06:14:03 [scrapy.extensions.logstats] INFO: Crawled 241915 pages (at 227 pages/min), scraped 206207 items (at 170 items/min)
2017-11-04 06:15:03 [scrapy.extensions.logstats] INFO: Crawled 242140 pages (at 225 pages/min), scraped 206418 items (at 211 items/min)
2017-11-04 06:16:03 [scrapy.extensions.logstats] INFO: Crawled 242370 pages (at 230 pages/min), scraped 206592 items (at 174 items/min)
2017-11-04 06:17:03 [scrapy.extensions.logstats] INFO: Crawled 242601 pages (at 231 pages/min), scraped 206767 items (at 175 items/min)
2017-11-04 06:18:03 [scrapy.extensions.logstats] INFO: Crawled 242827 pages (at 226 pages/min), scraped 206965 items (at 198 items/min)
2017-11-04 06:19:03 [scrapy.extensions.logstats] INFO: Crawled 243049 pages (at 222 pages/min), scraped 207146 items (at 181 items/min)
2017-11-04 06:20:03 [scrapy.extensions.logstats] INFO: Crawled 243279 pages (at 230 pages/min), scraped 207326 items (at 180 items/min)
2017-11-04 06:21:03 [scrapy.extensions.logstats] INFO: Crawled 243503 pages (at 224 pages/min), scraped 207517 items (at 191 items/min)
2017-11-04 06:22:03 [scrapy.extensions.logstats] INFO: Crawled 243732 pages (at 229 pages/min), scraped 207713 items (at 196 items/min)
2017-11-04 06:23:03 [scrapy.extensions.logstats] INFO: Crawled 243960 pages (at 228 pages/min), scraped 207905 items (at 192 items/min)
2017-11-04 06:24:03 [scrapy.extensions.logstats] INFO: Crawled 244188 pages (at 228 pages/min), scraped 208103 items (at 198 items/min)
2017-11-04 06:25:03 [scrapy.extensions.logstats] INFO: Crawled 244400 pages (at 212 pages/min), scraped 208272 items (at 169 items/min)
2017-11-04 06:26:03 [scrapy.extensions.logstats] INFO: Crawled 244625 pages (at 225 pages/min), scraped 208474 items (at 202 items/min)
2017-11-04 06:27:03 [scrapy.extensions.logstats] INFO: Crawled 244858 pages (at 233 pages/min), scraped 208649 items (at 175 items/min)
2017-11-04 06:28:03 [scrapy.extensions.logstats] INFO: Crawled 245086 pages (at 228 pages/min), scraped 208824 items (at 175 items/min)
2017-11-04 06:29:04 [scrapy.extensions.logstats] INFO: Crawled 245308 pages (at 222 pages/min), scraped 209043 items (at 219 items/min)
2017-11-04 06:30:03 [scrapy.extensions.logstats] INFO: Crawled 245529 pages (at 221 pages/min), scraped 209265 items (at 222 items/min)
2017-11-04 06:31:03 [scrapy.extensions.logstats] INFO: Crawled 245761 pages (at 232 pages/min), scraped 209457 items (at 192 items/min)
2017-11-04 06:32:03 [scrapy.extensions.logstats] INFO: Crawled 245985 pages (at 224 pages/min), scraped 209666 items (at 209 items/min)
2017-11-04 06:33:03 [scrapy.extensions.logstats] INFO: Crawled 246210 pages (at 225 pages/min), scraped 209909 items (at 243 items/min)
2017-11-04 06:34:03 [scrapy.extensions.logstats] INFO: Crawled 246428 pages (at 218 pages/min), scraped 210153 items (at 244 items/min)
2017-11-04 06:35:04 [scrapy.extensions.logstats] INFO: Crawled 246643 pages (at 215 pages/min), scraped 210386 items (at 233 items/min)
2017-11-04 06:36:03 [scrapy.extensions.logstats] INFO: Crawled 246854 pages (at 211 pages/min), scraped 210574 items (at 188 items/min)
2017-11-04 06:37:03 [scrapy.extensions.logstats] INFO: Crawled 247072 pages (at 218 pages/min), scraped 210744 items (at 170 items/min)
2017-11-04 06:38:03 [scrapy.extensions.logstats] INFO: Crawled 247281 pages (at 209 pages/min), scraped 210985 items (at 241 items/min)
2017-11-04 06:39:03 [scrapy.extensions.logstats] INFO: Crawled 247475 pages (at 194 pages/min), scraped 211219 items (at 234 items/min)
2017-11-04 06:40:03 [scrapy.extensions.logstats] INFO: Crawled 247689 pages (at 214 pages/min), scraped 211421 items (at 202 items/min)
2017-11-04 06:41:03 [scrapy.extensions.logstats] INFO: Crawled 247901 pages (at 212 pages/min), scraped 211608 items (at 187 items/min)
2017-11-04 06:42:03 [scrapy.extensions.logstats] INFO: Crawled 248112 pages (at 211 pages/min), scraped 211817 items (at 209 items/min)
2017-11-04 06:43:03 [scrapy.extensions.logstats] INFO: Crawled 248328 pages (at 216 pages/min), scraped 212008 items (at 191 items/min)
2017-11-04 06:44:03 [scrapy.extensions.logstats] INFO: Crawled 248537 pages (at 209 pages/min), scraped 212205 items (at 197 items/min)
2017-11-04 06:45:03 [scrapy.extensions.logstats] INFO: Crawled 248742 pages (at 205 pages/min), scraped 212404 items (at 199 items/min)
2017-11-04 06:46:03 [scrapy.extensions.logstats] INFO: Crawled 248964 pages (at 222 pages/min), scraped 212595 items (at 191 items/min)
2017-11-04 06:47:03 [scrapy.extensions.logstats] INFO: Crawled 249182 pages (at 218 pages/min), scraped 212797 items (at 202 items/min)
2017-11-04 06:48:03 [scrapy.extensions.logstats] INFO: Crawled 249395 pages (at 213 pages/min), scraped 213000 items (at 203 items/min)
2017-11-04 06:49:03 [scrapy.extensions.logstats] INFO: Crawled 249610 pages (at 215 pages/min), scraped 213217 items (at 217 items/min)
2017-11-04 06:50:03 [scrapy.extensions.logstats] INFO: Crawled 249826 pages (at 216 pages/min), scraped 213422 items (at 205 items/min)
2017-11-04 06:51:03 [scrapy.extensions.logstats] INFO: Crawled 250033 pages (at 207 pages/min), scraped 213609 items (at 187 items/min)
2017-11-04 06:52:03 [scrapy.extensions.logstats] INFO: Crawled 250247 pages (at 214 pages/min), scraped 213803 items (at 194 items/min)
2017-11-04 06:53:03 [scrapy.extensions.logstats] INFO: Crawled 250468 pages (at 221 pages/min), scraped 213983 items (at 180 items/min)
2017-11-04 06:54:03 [scrapy.extensions.logstats] INFO: Crawled 250692 pages (at 224 pages/min), scraped 214175 items (at 192 items/min)
2017-11-04 06:55:03 [scrapy.extensions.logstats] INFO: Crawled 250904 pages (at 212 pages/min), scraped 214375 items (at 200 items/min)
2017-11-04 06:56:03 [scrapy.extensions.logstats] INFO: Crawled 251118 pages (at 214 pages/min), scraped 214566 items (at 191 items/min)
2017-11-04 06:57:03 [scrapy.extensions.logstats] INFO: Crawled 251339 pages (at 221 pages/min), scraped 214761 items (at 195 items/min)
2017-11-04 06:58:03 [scrapy.extensions.logstats] INFO: Crawled 251560 pages (at 221 pages/min), scraped 214953 items (at 192 items/min)
2017-11-04 06:59:03 [scrapy.extensions.logstats] INFO: Crawled 251778 pages (at 218 pages/min), scraped 215147 items (at 194 items/min)
2017-11-04 07:00:03 [scrapy.extensions.logstats] INFO: Crawled 251999 pages (at 221 pages/min), scraped 215341 items (at 194 items/min)
2017-11-04 07:01:03 [scrapy.extensions.logstats] INFO: Crawled 252214 pages (at 215 pages/min), scraped 215545 items (at 204 items/min)
2017-11-04 07:02:03 [scrapy.extensions.logstats] INFO: Crawled 252430 pages (at 216 pages/min), scraped 215733 items (at 188 items/min)
2017-11-04 07:03:03 [scrapy.extensions.logstats] INFO: Crawled 252657 pages (at 227 pages/min), scraped 215922 items (at 189 items/min)
2017-11-04 07:04:03 [scrapy.extensions.logstats] INFO: Crawled 252875 pages (at 218 pages/min), scraped 216122 items (at 200 items/min)
2017-11-04 07:05:03 [scrapy.extensions.logstats] INFO: Crawled 253096 pages (at 221 pages/min), scraped 216309 items (at 187 items/min)
2017-11-04 07:06:03 [scrapy.extensions.logstats] INFO: Crawled 253318 pages (at 222 pages/min), scraped 216500 items (at 191 items/min)
2017-11-04 07:07:03 [scrapy.extensions.logstats] INFO: Crawled 253538 pages (at 220 pages/min), scraped 216690 items (at 190 items/min)
2017-11-04 07:08:03 [scrapy.extensions.logstats] INFO: Crawled 253757 pages (at 219 pages/min), scraped 216882 items (at 192 items/min)
2017-11-04 07:09:03 [scrapy.extensions.logstats] INFO: Crawled 253979 pages (at 222 pages/min), scraped 217071 items (at 189 items/min)
2017-11-04 07:10:03 [scrapy.extensions.logstats] INFO: Crawled 254191 pages (at 212 pages/min), scraped 217288 items (at 217 items/min)
2017-11-04 07:11:03 [scrapy.extensions.logstats] INFO: Crawled 254411 pages (at 220 pages/min), scraped 217503 items (at 215 items/min)
2017-11-04 07:12:04 [scrapy.extensions.logstats] INFO: Crawled 254639 pages (at 228 pages/min), scraped 217713 items (at 210 items/min)
2017-11-04 07:13:03 [scrapy.extensions.logstats] INFO: Crawled 254852 pages (at 213 pages/min), scraped 217896 items (at 183 items/min)
2017-11-04 07:14:03 [scrapy.extensions.logstats] INFO: Crawled 255068 pages (at 216 pages/min), scraped 218110 items (at 214 items/min)
2017-11-04 07:15:03 [scrapy.extensions.logstats] INFO: Crawled 255290 pages (at 222 pages/min), scraped 218304 items (at 194 items/min)
2017-11-04 07:16:03 [scrapy.extensions.logstats] INFO: Crawled 255513 pages (at 223 pages/min), scraped 218498 items (at 194 items/min)
2017-11-04 07:17:03 [scrapy.extensions.logstats] INFO: Crawled 255727 pages (at 214 pages/min), scraped 218696 items (at 198 items/min)
2017-11-04 07:18:03 [scrapy.extensions.logstats] INFO: Crawled 255943 pages (at 216 pages/min), scraped 218891 items (at 195 items/min)
2017-11-04 07:19:03 [scrapy.extensions.logstats] INFO: Crawled 256168 pages (at 225 pages/min), scraped 219073 items (at 182 items/min)
2017-11-04 07:20:03 [scrapy.extensions.logstats] INFO: Crawled 256382 pages (at 214 pages/min), scraped 219262 items (at 189 items/min)
2017-11-04 07:21:03 [scrapy.extensions.logstats] INFO: Crawled 256606 pages (at 224 pages/min), scraped 219460 items (at 198 items/min)
2017-11-04 07:22:03 [scrapy.extensions.logstats] INFO: Crawled 256830 pages (at 224 pages/min), scraped 219640 items (at 180 items/min)
2017-11-04 07:23:03 [scrapy.extensions.logstats] INFO: Crawled 257052 pages (at 222 pages/min), scraped 219824 items (at 184 items/min)
2017-11-04 07:24:03 [scrapy.extensions.logstats] INFO: Crawled 257276 pages (at 224 pages/min), scraped 220025 items (at 201 items/min)
2017-11-04 07:25:03 [scrapy.extensions.logstats] INFO: Crawled 257493 pages (at 217 pages/min), scraped 220203 items (at 178 items/min)
2017-11-04 07:26:03 [scrapy.extensions.logstats] INFO: Crawled 257709 pages (at 216 pages/min), scraped 220382 items (at 179 items/min)
2017-11-04 07:27:03 [scrapy.extensions.logstats] INFO: Crawled 257927 pages (at 218 pages/min), scraped 220564 items (at 182 items/min)
2017-11-04 07:28:03 [scrapy.extensions.logstats] INFO: Crawled 258160 pages (at 233 pages/min), scraped 220748 items (at 184 items/min)
2017-11-04 07:29:03 [scrapy.extensions.logstats] INFO: Crawled 258372 pages (at 212 pages/min), scraped 220933 items (at 185 items/min)
2017-11-04 07:30:03 [scrapy.extensions.logstats] INFO: Crawled 258597 pages (at 225 pages/min), scraped 221113 items (at 180 items/min)
2017-11-04 07:31:03 [scrapy.extensions.logstats] INFO: Crawled 258793 pages (at 196 pages/min), scraped 221269 items (at 156 items/min)
2017-11-04 07:32:03 [scrapy.extensions.logstats] INFO: Crawled 258917 pages (at 124 pages/min), scraped 221366 items (at 97 items/min)
2017-11-04 07:33:03 [scrapy.extensions.logstats] INFO: Crawled 259025 pages (at 108 pages/min), scraped 221450 items (at 84 items/min)
2017-11-04 07:34:04 [scrapy.extensions.logstats] INFO: Crawled 259143 pages (at 118 pages/min), scraped 221542 items (at 92 items/min)
2017-11-04 07:35:03 [scrapy.extensions.logstats] INFO: Crawled 259284 pages (at 141 pages/min), scraped 221647 items (at 105 items/min)
2017-11-04 07:36:03 [scrapy.extensions.logstats] INFO: Crawled 259441 pages (at 157 pages/min), scraped 221762 items (at 115 items/min)
2017-11-04 07:37:03 [scrapy.extensions.logstats] INFO: Crawled 259664 pages (at 223 pages/min), scraped 221951 items (at 189 items/min)
2017-11-04 07:38:03 [scrapy.extensions.logstats] INFO: Crawled 259892 pages (at 228 pages/min), scraped 222134 items (at 183 items/min)
2017-11-04 07:39:04 [scrapy.extensions.logstats] INFO: Crawled 260115 pages (at 223 pages/min), scraped 222311 items (at 177 items/min)
2017-11-04 07:40:03 [scrapy.extensions.logstats] INFO: Crawled 260328 pages (at 213 pages/min), scraped 222490 items (at 179 items/min)
2017-11-04 07:41:03 [scrapy.extensions.logstats] INFO: Crawled 260546 pages (at 218 pages/min), scraped 222669 items (at 179 items/min)
2017-11-04 07:42:03 [scrapy.extensions.logstats] INFO: Crawled 260770 pages (at 224 pages/min), scraped 222870 items (at 201 items/min)
2017-11-04 07:43:03 [scrapy.extensions.logstats] INFO: Crawled 260994 pages (at 224 pages/min), scraped 223045 items (at 175 items/min)
2017-11-04 07:44:03 [scrapy.extensions.logstats] INFO: Crawled 261207 pages (at 213 pages/min), scraped 223246 items (at 201 items/min)
2017-11-04 07:45:03 [scrapy.extensions.logstats] INFO: Crawled 261427 pages (at 220 pages/min), scraped 223440 items (at 194 items/min)
2017-11-04 07:46:03 [scrapy.extensions.logstats] INFO: Crawled 261644 pages (at 217 pages/min), scraped 223619 items (at 179 items/min)
2017-11-04 07:47:03 [scrapy.extensions.logstats] INFO: Crawled 261864 pages (at 220 pages/min), scraped 223807 items (at 188 items/min)
2017-11-04 07:48:03 [scrapy.extensions.logstats] INFO: Crawled 262088 pages (at 224 pages/min), scraped 223997 items (at 190 items/min)
2017-11-04 07:49:03 [scrapy.extensions.logstats] INFO: Crawled 262308 pages (at 220 pages/min), scraped 224165 items (at 168 items/min)
2017-11-04 07:50:03 [scrapy.extensions.logstats] INFO: Crawled 262531 pages (at 223 pages/min), scraped 224357 items (at 192 items/min)
2017-11-04 07:51:03 [scrapy.extensions.logstats] INFO: Crawled 262749 pages (at 218 pages/min), scraped 224560 items (at 203 items/min)
2017-11-04 07:52:03 [scrapy.extensions.logstats] INFO: Crawled 262973 pages (at 224 pages/min), scraped 224770 items (at 210 items/min)
2017-11-04 07:53:03 [scrapy.extensions.logstats] INFO: Crawled 263186 pages (at 213 pages/min), scraped 224984 items (at 214 items/min)
2017-11-04 07:54:04 [scrapy.extensions.logstats] INFO: Crawled 263402 pages (at 216 pages/min), scraped 225190 items (at 206 items/min)
2017-11-04 07:55:03 [scrapy.extensions.logstats] INFO: Crawled 263620 pages (at 218 pages/min), scraped 225387 items (at 197 items/min)
2017-11-04 07:56:03 [scrapy.extensions.logstats] INFO: Crawled 263837 pages (at 217 pages/min), scraped 225570 items (at 183 items/min)
2017-11-04 07:56:21 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=081597&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"穆棉","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"新时代证券股份有限公司","AOI_ID":"1999028","ADI_ID":"12663","ADI_NAME":"信阳北京大街证券营业部","PTI_NAME":"证券投资咨询业务(投资顾问)","CER_NUM":"S0280611070004","OBTAIN_DATE":"2011-07-18","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 07:57:03 [scrapy.extensions.logstats] INFO: Crawled 264060 pages (at 223 pages/min), scraped 225794 items (at 224 items/min)
2017-11-04 07:58:03 [scrapy.extensions.logstats] INFO: Crawled 264279 pages (at 219 pages/min), scraped 225995 items (at 201 items/min)
2017-11-04 07:59:03 [scrapy.extensions.logstats] INFO: Crawled 264494 pages (at 215 pages/min), scraped 226206 items (at 211 items/min)
2017-11-04 08:00:03 [scrapy.extensions.logstats] INFO: Crawled 264702 pages (at 208 pages/min), scraped 226431 items (at 225 items/min)
2017-11-04 08:01:03 [scrapy.extensions.logstats] INFO: Crawled 264916 pages (at 214 pages/min), scraped 226624 items (at 193 items/min)
2017-11-04 08:02:03 [scrapy.extensions.logstats] INFO: Crawled 265086 pages (at 170 pages/min), scraped 226770 items (at 146 items/min)
2017-11-04 08:03:03 [scrapy.extensions.logstats] INFO: Crawled 265205 pages (at 119 pages/min), scraped 226882 items (at 112 items/min)
2017-11-04 08:04:04 [scrapy.extensions.logstats] INFO: Crawled 265334 pages (at 129 pages/min), scraped 226992 items (at 110 items/min)
2017-11-04 08:05:04 [scrapy.extensions.logstats] INFO: Crawled 265462 pages (at 128 pages/min), scraped 227101 items (at 109 items/min)
2017-11-04 08:06:03 [scrapy.extensions.logstats] INFO: Crawled 265578 pages (at 116 pages/min), scraped 227215 items (at 114 items/min)
2017-11-04 08:07:03 [scrapy.extensions.logstats] INFO: Crawled 265698 pages (at 120 pages/min), scraped 227355 items (at 140 items/min)
2017-11-04 08:08:04 [scrapy.extensions.logstats] INFO: Crawled 265823 pages (at 125 pages/min), scraped 227508 items (at 153 items/min)
2017-11-04 08:09:04 [scrapy.extensions.logstats] INFO: Crawled 265940 pages (at 117 pages/min), scraped 227662 items (at 154 items/min)
2017-11-04 08:10:07 [scrapy.extensions.logstats] INFO: Crawled 266048 pages (at 108 pages/min), scraped 227792 items (at 130 items/min)
2017-11-04 08:11:04 [scrapy.extensions.logstats] INFO: Crawled 266134 pages (at 86 pages/min), scraped 227914 items (at 122 items/min)
2017-11-04 08:12:03 [scrapy.extensions.logstats] INFO: Crawled 266237 pages (at 103 pages/min), scraped 228046 items (at 132 items/min)
2017-11-04 08:13:04 [scrapy.extensions.logstats] INFO: Crawled 266355 pages (at 118 pages/min), scraped 228194 items (at 148 items/min)
2017-11-04 08:14:03 [scrapy.extensions.logstats] INFO: Crawled 266459 pages (at 104 pages/min), scraped 228327 items (at 133 items/min)
2017-11-04 08:15:03 [scrapy.extensions.logstats] INFO: Crawled 266574 pages (at 115 pages/min), scraped 228466 items (at 139 items/min)
2017-11-04 08:16:04 [scrapy.extensions.logstats] INFO: Crawled 266677 pages (at 103 pages/min), scraped 228607 items (at 141 items/min)
2017-11-04 08:17:03 [scrapy.extensions.logstats] INFO: Crawled 266767 pages (at 90 pages/min), scraped 228720 items (at 113 items/min)
2017-11-04 08:18:04 [scrapy.extensions.logstats] INFO: Crawled 266873 pages (at 106 pages/min), scraped 228859 items (at 139 items/min)
2017-11-04 08:19:03 [scrapy.extensions.logstats] INFO: Crawled 266965 pages (at 92 pages/min), scraped 228985 items (at 126 items/min)
2017-11-04 08:20:04 [scrapy.extensions.logstats] INFO: Crawled 267075 pages (at 110 pages/min), scraped 229122 items (at 137 items/min)
2017-11-04 08:21:03 [scrapy.extensions.logstats] INFO: Crawled 267184 pages (at 109 pages/min), scraped 229265 items (at 143 items/min)
2017-11-04 08:22:04 [scrapy.extensions.logstats] INFO: Crawled 267289 pages (at 105 pages/min), scraped 229355 items (at 90 items/min)
2017-11-04 08:23:03 [scrapy.extensions.logstats] INFO: Crawled 267409 pages (at 120 pages/min), scraped 229465 items (at 110 items/min)
2017-11-04 08:24:03 [scrapy.extensions.logstats] INFO: Crawled 267510 pages (at 101 pages/min), scraped 229550 items (at 85 items/min)
2017-11-04 08:25:03 [scrapy.extensions.logstats] INFO: Crawled 267667 pages (at 157 pages/min), scraped 229687 items (at 137 items/min)
2017-11-04 08:26:04 [scrapy.extensions.logstats] INFO: Crawled 267771 pages (at 104 pages/min), scraped 229794 items (at 107 items/min)
2017-11-04 08:27:04 [scrapy.extensions.logstats] INFO: Crawled 267874 pages (at 103 pages/min), scraped 229893 items (at 99 items/min)
2017-11-04 08:28:04 [scrapy.extensions.logstats] INFO: Crawled 267958 pages (at 84 pages/min), scraped 229976 items (at 83 items/min)
2017-11-04 08:29:04 [scrapy.extensions.logstats] INFO: Crawled 268061 pages (at 103 pages/min), scraped 230064 items (at 88 items/min)
2017-11-04 08:30:04 [scrapy.extensions.logstats] INFO: Crawled 268146 pages (at 85 pages/min), scraped 230142 items (at 78 items/min)
2017-11-04 08:31:04 [scrapy.extensions.logstats] INFO: Crawled 268242 pages (at 96 pages/min), scraped 230233 items (at 91 items/min)
2017-11-04 08:32:04 [scrapy.extensions.logstats] INFO: Crawled 268331 pages (at 89 pages/min), scraped 230321 items (at 88 items/min)
2017-11-04 08:33:04 [scrapy.extensions.logstats] INFO: Crawled 268438 pages (at 107 pages/min), scraped 230426 items (at 105 items/min)
2017-11-04 08:34:04 [scrapy.extensions.logstats] INFO: Crawled 268527 pages (at 89 pages/min), scraped 230525 items (at 99 items/min)
2017-11-04 08:35:04 [scrapy.extensions.logstats] INFO: Crawled 268632 pages (at 105 pages/min), scraped 230626 items (at 101 items/min)
2017-11-04 08:36:03 [scrapy.extensions.logstats] INFO: Crawled 268725 pages (at 93 pages/min), scraped 230727 items (at 101 items/min)
2017-11-04 08:37:05 [scrapy.extensions.logstats] INFO: Crawled 268850 pages (at 125 pages/min), scraped 230846 items (at 119 items/min)
2017-11-04 08:38:05 [scrapy.extensions.logstats] INFO: Crawled 268941 pages (at 91 pages/min), scraped 230947 items (at 101 items/min)
2017-11-04 08:39:04 [scrapy.extensions.logstats] INFO: Crawled 269026 pages (at 85 pages/min), scraped 231038 items (at 91 items/min)
2017-11-04 08:40:04 [scrapy.extensions.logstats] INFO: Crawled 269123 pages (at 97 pages/min), scraped 231111 items (at 73 items/min)
2017-11-04 08:41:03 [scrapy.extensions.logstats] INFO: Crawled 269261 pages (at 138 pages/min), scraped 231285 items (at 174 items/min)
2017-11-04 08:42:03 [scrapy.extensions.logstats] INFO: Crawled 269469 pages (at 208 pages/min), scraped 231558 items (at 273 items/min)
2017-11-04 08:43:03 [scrapy.extensions.logstats] INFO: Crawled 269672 pages (at 203 pages/min), scraped 231805 items (at 247 items/min)
2017-11-04 08:44:03 [scrapy.extensions.logstats] INFO: Crawled 269861 pages (at 189 pages/min), scraped 232107 items (at 302 items/min)
2017-11-04 08:45:03 [scrapy.extensions.logstats] INFO: Crawled 270068 pages (at 207 pages/min), scraped 232334 items (at 227 items/min)
2017-11-04 08:46:03 [scrapy.extensions.logstats] INFO: Crawled 270281 pages (at 213 pages/min), scraped 232551 items (at 217 items/min)
2017-11-04 08:47:03 [scrapy.extensions.logstats] INFO: Crawled 270498 pages (at 217 pages/min), scraped 232741 items (at 190 items/min)
2017-11-04 08:48:03 [scrapy.extensions.logstats] INFO: Crawled 270718 pages (at 220 pages/min), scraped 232933 items (at 192 items/min)
2017-11-04 08:49:03 [scrapy.extensions.logstats] INFO: Crawled 270932 pages (at 214 pages/min), scraped 233142 items (at 209 items/min)
2017-11-04 08:50:03 [scrapy.extensions.logstats] INFO: Crawled 271149 pages (at 217 pages/min), scraped 233331 items (at 189 items/min)
2017-11-04 08:51:04 [scrapy.extensions.logstats] INFO: Crawled 271287 pages (at 138 pages/min), scraped 233455 items (at 124 items/min)
2017-11-04 08:52:03 [scrapy.extensions.logstats] INFO: Crawled 271399 pages (at 112 pages/min), scraped 233568 items (at 113 items/min)
2017-11-04 08:53:03 [scrapy.extensions.logstats] INFO: Crawled 271512 pages (at 113 pages/min), scraped 233679 items (at 111 items/min)
2017-11-04 08:54:03 [scrapy.extensions.logstats] INFO: Crawled 271622 pages (at 110 pages/min), scraped 233792 items (at 113 items/min)
2017-11-04 08:55:04 [scrapy.extensions.logstats] INFO: Crawled 271723 pages (at 101 pages/min), scraped 233889 items (at 97 items/min)
2017-11-04 08:56:04 [scrapy.extensions.logstats] INFO: Crawled 271838 pages (at 115 pages/min), scraped 233997 items (at 108 items/min)
2017-11-04 08:57:04 [scrapy.extensions.logstats] INFO: Crawled 271948 pages (at 110 pages/min), scraped 234092 items (at 95 items/min)
2017-11-04 08:58:04 [scrapy.extensions.logstats] INFO: Crawled 272072 pages (at 124 pages/min), scraped 234209 items (at 117 items/min)
2017-11-04 08:59:04 [scrapy.extensions.logstats] INFO: Crawled 272195 pages (at 123 pages/min), scraped 234317 items (at 108 items/min)
2017-11-04 09:00:03 [scrapy.extensions.logstats] INFO: Crawled 272324 pages (at 129 pages/min), scraped 234433 items (at 116 items/min)
2017-11-04 09:01:03 [scrapy.extensions.logstats] INFO: Crawled 272440 pages (at 116 pages/min), scraped 234530 items (at 97 items/min)
2017-11-04 09:02:03 [scrapy.extensions.logstats] INFO: Crawled 272593 pages (at 153 pages/min), scraped 234677 items (at 147 items/min)
2017-11-04 09:03:03 [scrapy.extensions.logstats] INFO: Crawled 272721 pages (at 128 pages/min), scraped 234800 items (at 123 items/min)
2017-11-04 09:04:03 [scrapy.extensions.logstats] INFO: Crawled 272837 pages (at 116 pages/min), scraped 234928 items (at 128 items/min)
2017-11-04 09:05:05 [scrapy.extensions.logstats] INFO: Crawled 272985 pages (at 148 pages/min), scraped 235064 items (at 136 items/min)
2017-11-04 09:06:04 [scrapy.extensions.logstats] INFO: Crawled 273120 pages (at 135 pages/min), scraped 235187 items (at 123 items/min)
2017-11-04 09:07:04 [scrapy.extensions.logstats] INFO: Crawled 273243 pages (at 123 pages/min), scraped 235321 items (at 134 items/min)
2017-11-04 09:08:03 [scrapy.extensions.logstats] INFO: Crawled 273389 pages (at 146 pages/min), scraped 235452 items (at 131 items/min)
2017-11-04 09:09:04 [scrapy.extensions.logstats] INFO: Crawled 273515 pages (at 126 pages/min), scraped 235560 items (at 108 items/min)
2017-11-04 09:10:03 [scrapy.extensions.logstats] INFO: Crawled 273640 pages (at 125 pages/min), scraped 235655 items (at 95 items/min)
2017-11-04 09:11:03 [scrapy.extensions.logstats] INFO: Crawled 273767 pages (at 127 pages/min), scraped 235785 items (at 130 items/min)
2017-11-04 09:12:04 [scrapy.extensions.logstats] INFO: Crawled 273902 pages (at 135 pages/min), scraped 235926 items (at 141 items/min)
2017-11-04 09:13:03 [scrapy.extensions.logstats] INFO: Crawled 274024 pages (at 122 pages/min), scraped 236039 items (at 113 items/min)
2017-11-04 09:14:03 [scrapy.extensions.logstats] INFO: Crawled 274148 pages (at 124 pages/min), scraped 236166 items (at 127 items/min)
2017-11-04 09:15:04 [scrapy.extensions.logstats] INFO: Crawled 274271 pages (at 123 pages/min), scraped 236274 items (at 108 items/min)
2017-11-04 09:16:04 [scrapy.extensions.logstats] INFO: Crawled 274397 pages (at 126 pages/min), scraped 236399 items (at 125 items/min)
2017-11-04 09:17:03 [scrapy.extensions.logstats] INFO: Crawled 274534 pages (at 137 pages/min), scraped 236517 items (at 118 items/min)
2017-11-04 09:18:03 [scrapy.extensions.logstats] INFO: Crawled 274687 pages (at 153 pages/min), scraped 236659 items (at 142 items/min)
2017-11-04 09:19:03 [scrapy.extensions.logstats] INFO: Crawled 274828 pages (at 141 pages/min), scraped 236778 items (at 119 items/min)
2017-11-04 09:20:03 [scrapy.extensions.logstats] INFO: Crawled 274943 pages (at 115 pages/min), scraped 236896 items (at 118 items/min)
2017-11-04 09:21:03 [scrapy.extensions.logstats] INFO: Crawled 275072 pages (at 129 pages/min), scraped 237020 items (at 124 items/min)
2017-11-04 09:22:03 [scrapy.extensions.logstats] INFO: Crawled 275200 pages (at 128 pages/min), scraped 237140 items (at 120 items/min)
2017-11-04 09:23:03 [scrapy.extensions.logstats] INFO: Crawled 275352 pages (at 152 pages/min), scraped 237275 items (at 135 items/min)
2017-11-04 09:24:03 [scrapy.extensions.logstats] INFO: Crawled 275481 pages (at 129 pages/min), scraped 237411 items (at 136 items/min)
2017-11-04 09:25:03 [scrapy.extensions.logstats] INFO: Crawled 275604 pages (at 123 pages/min), scraped 237522 items (at 111 items/min)
2017-11-04 09:26:04 [scrapy.extensions.logstats] INFO: Crawled 275731 pages (at 127 pages/min), scraped 237646 items (at 124 items/min)
2017-11-04 09:27:05 [scrapy.extensions.logstats] INFO: Crawled 275850 pages (at 119 pages/min), scraped 237757 items (at 111 items/min)
2017-11-04 09:28:03 [scrapy.extensions.logstats] INFO: Crawled 275967 pages (at 117 pages/min), scraped 237865 items (at 108 items/min)
2017-11-04 09:29:03 [scrapy.extensions.logstats] INFO: Crawled 276063 pages (at 96 pages/min), scraped 237959 items (at 94 items/min)
2017-11-04 09:30:04 [scrapy.extensions.logstats] INFO: Crawled 276189 pages (at 126 pages/min), scraped 238060 items (at 101 items/min)
2017-11-04 09:31:04 [scrapy.extensions.logstats] INFO: Crawled 276307 pages (at 118 pages/min), scraped 238181 items (at 121 items/min)
2017-11-04 09:32:04 [scrapy.extensions.logstats] INFO: Crawled 276446 pages (at 139 pages/min), scraped 238310 items (at 129 items/min)
2017-11-04 09:33:04 [scrapy.extensions.logstats] INFO: Crawled 276577 pages (at 131 pages/min), scraped 238436 items (at 126 items/min)
2017-11-04 09:34:04 [scrapy.extensions.logstats] INFO: Crawled 276703 pages (at 126 pages/min), scraped 238559 items (at 123 items/min)
2017-11-04 09:35:04 [scrapy.extensions.logstats] INFO: Crawled 276832 pages (at 129 pages/min), scraped 238674 items (at 115 items/min)
2017-11-04 09:36:06 [scrapy.extensions.logstats] INFO: Crawled 276972 pages (at 140 pages/min), scraped 238801 items (at 127 items/min)
2017-11-04 09:37:03 [scrapy.extensions.logstats] INFO: Crawled 277078 pages (at 106 pages/min), scraped 238886 items (at 85 items/min)
2017-11-04 09:38:04 [scrapy.extensions.logstats] INFO: Crawled 277192 pages (at 114 pages/min), scraped 239001 items (at 115 items/min)
2017-11-04 09:39:04 [scrapy.extensions.logstats] INFO: Crawled 277290 pages (at 98 pages/min), scraped 239106 items (at 105 items/min)
2017-11-04 09:40:03 [scrapy.extensions.logstats] INFO: Crawled 277395 pages (at 105 pages/min), scraped 239188 items (at 82 items/min)
2017-11-04 09:41:04 [scrapy.extensions.logstats] INFO: Crawled 277533 pages (at 138 pages/min), scraped 239298 items (at 110 items/min)
2017-11-04 09:42:03 [scrapy.extensions.logstats] INFO: Crawled 277658 pages (at 125 pages/min), scraped 239405 items (at 107 items/min)
2017-11-04 09:43:04 [scrapy.extensions.logstats] INFO: Crawled 277785 pages (at 127 pages/min), scraped 239502 items (at 97 items/min)
2017-11-04 09:44:04 [scrapy.extensions.logstats] INFO: Crawled 277924 pages (at 139 pages/min), scraped 239616 items (at 114 items/min)
2017-11-04 09:45:05 [scrapy.extensions.logstats] INFO: Crawled 278068 pages (at 144 pages/min), scraped 239732 items (at 116 items/min)
2017-11-04 09:46:03 [scrapy.extensions.logstats] INFO: Crawled 278194 pages (at 126 pages/min), scraped 239832 items (at 100 items/min)
2017-11-04 09:47:03 [scrapy.extensions.logstats] INFO: Crawled 278322 pages (at 128 pages/min), scraped 239963 items (at 131 items/min)
2017-11-04 09:48:03 [scrapy.extensions.logstats] INFO: Crawled 278472 pages (at 150 pages/min), scraped 240086 items (at 123 items/min)
2017-11-04 09:49:04 [scrapy.extensions.logstats] INFO: Crawled 278620 pages (at 148 pages/min), scraped 240214 items (at 128 items/min)
2017-11-04 09:50:04 [scrapy.extensions.logstats] INFO: Crawled 278756 pages (at 136 pages/min), scraped 240334 items (at 120 items/min)
2017-11-04 09:51:03 [scrapy.extensions.logstats] INFO: Crawled 278893 pages (at 137 pages/min), scraped 240463 items (at 129 items/min)
2017-11-04 09:52:04 [scrapy.extensions.logstats] INFO: Crawled 279011 pages (at 118 pages/min), scraped 240577 items (at 114 items/min)
2017-11-04 09:53:04 [scrapy.extensions.logstats] INFO: Crawled 279143 pages (at 132 pages/min), scraped 240694 items (at 117 items/min)
2017-11-04 09:54:04 [scrapy.extensions.logstats] INFO: Crawled 279279 pages (at 136 pages/min), scraped 240817 items (at 123 items/min)
2017-11-04 09:55:04 [scrapy.extensions.logstats] INFO: Crawled 279392 pages (at 113 pages/min), scraped 240923 items (at 106 items/min)
2017-11-04 09:56:04 [scrapy.extensions.logstats] INFO: Crawled 279502 pages (at 110 pages/min), scraped 241025 items (at 102 items/min)
2017-11-04 09:57:05 [scrapy.extensions.logstats] INFO: Crawled 279614 pages (at 112 pages/min), scraped 241141 items (at 116 items/min)
2017-11-04 09:58:04 [scrapy.extensions.logstats] INFO: Crawled 279729 pages (at 115 pages/min), scraped 241245 items (at 104 items/min)
2017-11-04 09:59:03 [scrapy.extensions.logstats] INFO: Crawled 279847 pages (at 118 pages/min), scraped 241363 items (at 118 items/min)
2017-11-04 10:00:03 [scrapy.extensions.logstats] INFO: Crawled 279967 pages (at 120 pages/min), scraped 241474 items (at 111 items/min)
2017-11-04 10:01:04 [scrapy.extensions.logstats] INFO: Crawled 280091 pages (at 124 pages/min), scraped 241588 items (at 114 items/min)
2017-11-04 10:02:03 [scrapy.extensions.logstats] INFO: Crawled 280206 pages (at 115 pages/min), scraped 241697 items (at 109 items/min)
2017-11-04 10:03:04 [scrapy.extensions.logstats] INFO: Crawled 280317 pages (at 111 pages/min), scraped 241802 items (at 105 items/min)
2017-11-04 10:04:03 [scrapy.extensions.logstats] INFO: Crawled 280439 pages (at 122 pages/min), scraped 241914 items (at 112 items/min)
2017-11-04 10:05:04 [scrapy.extensions.logstats] INFO: Crawled 280544 pages (at 105 pages/min), scraped 242013 items (at 99 items/min)
2017-11-04 10:06:03 [scrapy.extensions.logstats] INFO: Crawled 280677 pages (at 133 pages/min), scraped 242127 items (at 114 items/min)
2017-11-04 10:07:03 [scrapy.extensions.logstats] INFO: Crawled 280806 pages (at 129 pages/min), scraped 242242 items (at 115 items/min)
2017-11-04 10:08:04 [scrapy.extensions.logstats] INFO: Crawled 280915 pages (at 109 pages/min), scraped 242348 items (at 106 items/min)
2017-11-04 10:09:03 [scrapy.extensions.logstats] INFO: Crawled 281016 pages (at 101 pages/min), scraped 242442 items (at 94 items/min)
2017-11-04 10:10:04 [scrapy.extensions.logstats] INFO: Crawled 281138 pages (at 122 pages/min), scraped 242557 items (at 115 items/min)
2017-11-04 10:11:04 [scrapy.extensions.logstats] INFO: Crawled 281254 pages (at 116 pages/min), scraped 242674 items (at 117 items/min)
2017-11-04 10:12:04 [scrapy.extensions.logstats] INFO: Crawled 281358 pages (at 104 pages/min), scraped 242773 items (at 99 items/min)
2017-11-04 10:13:05 [scrapy.extensions.logstats] INFO: Crawled 281467 pages (at 109 pages/min), scraped 242883 items (at 110 items/min)
2017-11-04 10:14:04 [scrapy.extensions.logstats] INFO: Crawled 281553 pages (at 86 pages/min), scraped 242986 items (at 103 items/min)
2017-11-04 10:15:04 [scrapy.extensions.logstats] INFO: Crawled 281628 pages (at 75 pages/min), scraped 243074 items (at 88 items/min)
2017-11-04 10:16:04 [scrapy.extensions.logstats] INFO: Crawled 281712 pages (at 84 pages/min), scraped 243161 items (at 87 items/min)
2017-11-04 10:17:04 [scrapy.extensions.logstats] INFO: Crawled 281801 pages (at 89 pages/min), scraped 243248 items (at 87 items/min)
2017-11-04 10:18:04 [scrapy.extensions.logstats] INFO: Crawled 281912 pages (at 111 pages/min), scraped 243364 items (at 116 items/min)
2017-11-04 10:19:04 [scrapy.extensions.logstats] INFO: Crawled 282026 pages (at 114 pages/min), scraped 243472 items (at 108 items/min)
2017-11-04 10:20:03 [scrapy.extensions.logstats] INFO: Crawled 282116 pages (at 90 pages/min), scraped 243569 items (at 97 items/min)
2017-11-04 10:21:04 [scrapy.extensions.logstats] INFO: Crawled 282213 pages (at 97 pages/min), scraped 243666 items (at 97 items/min)
2017-11-04 10:22:05 [scrapy.extensions.logstats] INFO: Crawled 282323 pages (at 110 pages/min), scraped 243776 items (at 110 items/min)
2017-11-04 10:23:03 [scrapy.extensions.logstats] INFO: Crawled 282441 pages (at 118 pages/min), scraped 243890 items (at 114 items/min)
2017-11-04 10:24:04 [scrapy.extensions.logstats] INFO: Crawled 282545 pages (at 104 pages/min), scraped 243989 items (at 99 items/min)
2017-11-04 10:25:04 [scrapy.extensions.logstats] INFO: Crawled 282669 pages (at 124 pages/min), scraped 244098 items (at 109 items/min)
2017-11-04 10:26:03 [scrapy.extensions.logstats] INFO: Crawled 282789 pages (at 120 pages/min), scraped 244218 items (at 120 items/min)
2017-11-04 10:27:05 [scrapy.extensions.logstats] INFO: Crawled 282902 pages (at 113 pages/min), scraped 244329 items (at 111 items/min)
2017-11-04 10:28:04 [scrapy.extensions.logstats] INFO: Crawled 283012 pages (at 110 pages/min), scraped 244431 items (at 102 items/min)
2017-11-04 10:29:04 [scrapy.extensions.logstats] INFO: Crawled 283114 pages (at 102 pages/min), scraped 244532 items (at 101 items/min)
2017-11-04 10:30:04 [scrapy.extensions.logstats] INFO: Crawled 283230 pages (at 116 pages/min), scraped 244651 items (at 119 items/min)
2017-11-04 10:31:04 [scrapy.extensions.logstats] INFO: Crawled 283344 pages (at 114 pages/min), scraped 244757 items (at 106 items/min)
2017-11-04 10:32:03 [scrapy.extensions.logstats] INFO: Crawled 283452 pages (at 108 pages/min), scraped 244861 items (at 104 items/min)
2017-11-04 10:33:03 [scrapy.extensions.logstats] INFO: Crawled 283571 pages (at 119 pages/min), scraped 244983 items (at 122 items/min)
2017-11-04 10:34:03 [scrapy.extensions.logstats] INFO: Crawled 283689 pages (at 118 pages/min), scraped 245085 items (at 102 items/min)
2017-11-04 10:35:03 [scrapy.extensions.logstats] INFO: Crawled 283792 pages (at 103 pages/min), scraped 245202 items (at 117 items/min)
2017-11-04 10:36:03 [scrapy.extensions.logstats] INFO: Crawled 283909 pages (at 117 pages/min), scraped 245315 items (at 113 items/min)
2017-11-04 10:37:04 [scrapy.extensions.logstats] INFO: Crawled 284023 pages (at 114 pages/min), scraped 245422 items (at 107 items/min)
2017-11-04 10:38:04 [scrapy.extensions.logstats] INFO: Crawled 284131 pages (at 108 pages/min), scraped 245528 items (at 106 items/min)
2017-11-04 10:39:04 [scrapy.extensions.logstats] INFO: Crawled 284239 pages (at 108 pages/min), scraped 245628 items (at 100 items/min)
2017-11-04 10:40:03 [scrapy.extensions.logstats] INFO: Crawled 284341 pages (at 102 pages/min), scraped 245721 items (at 93 items/min)
2017-11-04 10:41:04 [scrapy.extensions.logstats] INFO: Crawled 284455 pages (at 114 pages/min), scraped 245833 items (at 112 items/min)
2017-11-04 10:42:03 [scrapy.extensions.logstats] INFO: Crawled 284576 pages (at 121 pages/min), scraped 245950 items (at 117 items/min)
2017-11-04 10:43:03 [scrapy.extensions.logstats] INFO: Crawled 284680 pages (at 104 pages/min), scraped 246037 items (at 87 items/min)
2017-11-04 10:44:03 [scrapy.extensions.logstats] INFO: Crawled 284790 pages (at 110 pages/min), scraped 246151 items (at 114 items/min)
2017-11-04 10:45:03 [scrapy.extensions.logstats] INFO: Crawled 284912 pages (at 122 pages/min), scraped 246280 items (at 129 items/min)
2017-11-04 10:46:04 [scrapy.extensions.logstats] INFO: Crawled 285018 pages (at 106 pages/min), scraped 246393 items (at 113 items/min)
2017-11-04 10:47:05 [scrapy.extensions.logstats] INFO: Crawled 285145 pages (at 127 pages/min), scraped 246517 items (at 124 items/min)
2017-11-04 10:48:04 [scrapy.extensions.logstats] INFO: Crawled 285232 pages (at 87 pages/min), scraped 246610 items (at 93 items/min)
2017-11-04 10:49:05 [scrapy.extensions.logstats] INFO: Crawled 285323 pages (at 91 pages/min), scraped 246725 items (at 115 items/min)
2017-11-04 10:50:03 [scrapy.extensions.logstats] INFO: Crawled 285427 pages (at 104 pages/min), scraped 246818 items (at 93 items/min)
2017-11-04 10:51:03 [scrapy.extensions.logstats] INFO: Crawled 285538 pages (at 111 pages/min), scraped 246932 items (at 114 items/min)
2017-11-04 10:52:04 [scrapy.extensions.logstats] INFO: Crawled 285649 pages (at 111 pages/min), scraped 247030 items (at 98 items/min)
2017-11-04 10:53:04 [scrapy.extensions.logstats] INFO: Crawled 285758 pages (at 109 pages/min), scraped 247135 items (at 105 items/min)
2017-11-04 10:54:03 [scrapy.extensions.logstats] INFO: Crawled 285891 pages (at 133 pages/min), scraped 247261 items (at 126 items/min)
2017-11-04 10:55:03 [scrapy.extensions.logstats] INFO: Crawled 286003 pages (at 112 pages/min), scraped 247364 items (at 103 items/min)
2017-11-04 10:56:04 [scrapy.extensions.logstats] INFO: Crawled 286116 pages (at 113 pages/min), scraped 247458 items (at 94 items/min)
2017-11-04 10:57:04 [scrapy.extensions.logstats] INFO: Crawled 286210 pages (at 94 pages/min), scraped 247552 items (at 94 items/min)
2017-11-04 10:58:04 [scrapy.extensions.logstats] INFO: Crawled 286330 pages (at 120 pages/min), scraped 247649 items (at 97 items/min)
2017-11-04 10:59:04 [scrapy.extensions.logstats] INFO: Crawled 286438 pages (at 108 pages/min), scraped 247751 items (at 102 items/min)
2017-11-04 11:00:04 [scrapy.extensions.logstats] INFO: Crawled 286550 pages (at 112 pages/min), scraped 247855 items (at 104 items/min)
2017-11-04 11:01:04 [scrapy.extensions.logstats] INFO: Crawled 286643 pages (at 93 pages/min), scraped 247938 items (at 83 items/min)
2017-11-04 11:02:05 [scrapy.extensions.logstats] INFO: Crawled 286749 pages (at 106 pages/min), scraped 248035 items (at 97 items/min)
2017-11-04 11:03:04 [scrapy.extensions.logstats] INFO: Crawled 286853 pages (at 104 pages/min), scraped 248138 items (at 103 items/min)
2017-11-04 11:04:04 [scrapy.extensions.logstats] INFO: Crawled 286937 pages (at 84 pages/min), scraped 248205 items (at 67 items/min)
2017-11-04 11:05:04 [scrapy.extensions.logstats] INFO: Crawled 287034 pages (at 97 pages/min), scraped 248297 items (at 92 items/min)
2017-11-04 11:06:04 [scrapy.extensions.logstats] INFO: Crawled 287139 pages (at 105 pages/min), scraped 248388 items (at 91 items/min)
2017-11-04 11:07:03 [scrapy.extensions.logstats] INFO: Crawled 287237 pages (at 98 pages/min), scraped 248477 items (at 89 items/min)
2017-11-04 11:08:03 [scrapy.extensions.logstats] INFO: Crawled 287347 pages (at 110 pages/min), scraped 248586 items (at 109 items/min)
2017-11-04 11:09:03 [scrapy.extensions.logstats] INFO: Crawled 287435 pages (at 88 pages/min), scraped 248669 items (at 83 items/min)
2017-11-04 11:10:04 [scrapy.extensions.logstats] INFO: Crawled 287543 pages (at 108 pages/min), scraped 248776 items (at 107 items/min)
2017-11-04 11:11:04 [scrapy.extensions.logstats] INFO: Crawled 287653 pages (at 110 pages/min), scraped 248875 items (at 99 items/min)
2017-11-04 11:12:05 [scrapy.extensions.logstats] INFO: Crawled 287745 pages (at 92 pages/min), scraped 248959 items (at 84 items/min)
2017-11-04 11:13:03 [scrapy.extensions.logstats] INFO: Crawled 287857 pages (at 112 pages/min), scraped 249068 items (at 109 items/min)
2017-11-04 11:14:03 [scrapy.extensions.logstats] INFO: Crawled 287966 pages (at 109 pages/min), scraped 249174 items (at 106 items/min)
2017-11-04 11:15:06 [scrapy.extensions.logstats] INFO: Crawled 288067 pages (at 101 pages/min), scraped 249259 items (at 85 items/min)
2017-11-04 11:16:03 [scrapy.extensions.logstats] INFO: Crawled 288159 pages (at 92 pages/min), scraped 249351 items (at 92 items/min)
2017-11-04 11:17:04 [scrapy.extensions.logstats] INFO: Crawled 288262 pages (at 103 pages/min), scraped 249442 items (at 91 items/min)
2017-11-04 11:18:04 [scrapy.extensions.logstats] INFO: Crawled 288369 pages (at 107 pages/min), scraped 249551 items (at 109 items/min)
2017-11-04 11:19:03 [scrapy.extensions.logstats] INFO: Crawled 288479 pages (at 110 pages/min), scraped 249659 items (at 108 items/min)
2017-11-04 11:20:03 [scrapy.extensions.logstats] INFO: Crawled 288592 pages (at 113 pages/min), scraped 249761 items (at 102 items/min)
2017-11-04 11:21:03 [scrapy.extensions.logstats] INFO: Crawled 288707 pages (at 115 pages/min), scraped 249880 items (at 119 items/min)
2017-11-04 11:22:04 [scrapy.extensions.logstats] INFO: Crawled 288823 pages (at 116 pages/min), scraped 249975 items (at 95 items/min)
2017-11-04 11:23:04 [scrapy.extensions.logstats] INFO: Crawled 288916 pages (at 93 pages/min), scraped 250059 items (at 84 items/min)
2017-11-04 11:24:04 [scrapy.extensions.logstats] INFO: Crawled 289021 pages (at 105 pages/min), scraped 250161 items (at 102 items/min)
2017-11-04 11:25:05 [scrapy.extensions.logstats] INFO: Crawled 289125 pages (at 104 pages/min), scraped 250252 items (at 91 items/min)
2017-11-04 11:26:04 [scrapy.extensions.logstats] INFO: Crawled 289245 pages (at 120 pages/min), scraped 250376 items (at 124 items/min)
2017-11-04 11:27:06 [scrapy.extensions.logstats] INFO: Crawled 289334 pages (at 89 pages/min), scraped 250474 items (at 98 items/min)
2017-11-04 11:28:03 [scrapy.extensions.logstats] INFO: Crawled 289421 pages (at 87 pages/min), scraped 250562 items (at 88 items/min)
2017-11-04 11:29:04 [scrapy.extensions.logstats] INFO: Crawled 289520 pages (at 99 pages/min), scraped 250652 items (at 90 items/min)
2017-11-04 11:30:06 [scrapy.extensions.logstats] INFO: Crawled 289622 pages (at 102 pages/min), scraped 250745 items (at 93 items/min)
2017-11-04 11:31:06 [scrapy.extensions.logstats] INFO: Crawled 289705 pages (at 83 pages/min), scraped 250822 items (at 77 items/min)
2017-11-04 11:32:03 [scrapy.extensions.logstats] INFO: Crawled 289791 pages (at 86 pages/min), scraped 250905 items (at 83 items/min)
2017-11-04 11:33:04 [scrapy.extensions.logstats] INFO: Crawled 289868 pages (at 77 pages/min), scraped 250984 items (at 79 items/min)
2017-11-04 11:34:03 [scrapy.extensions.logstats] INFO: Crawled 289954 pages (at 86 pages/min), scraped 251079 items (at 95 items/min)
2017-11-04 11:35:03 [scrapy.extensions.logstats] INFO: Crawled 290064 pages (at 110 pages/min), scraped 251172 items (at 93 items/min)
2017-11-04 11:36:04 [scrapy.extensions.logstats] INFO: Crawled 290191 pages (at 127 pages/min), scraped 251296 items (at 124 items/min)
2017-11-04 11:37:03 [scrapy.extensions.logstats] INFO: Crawled 290289 pages (at 98 pages/min), scraped 251410 items (at 114 items/min)
2017-11-04 11:38:03 [scrapy.extensions.logstats] INFO: Crawled 290383 pages (at 94 pages/min), scraped 251497 items (at 87 items/min)
2017-11-04 11:39:04 [scrapy.extensions.logstats] INFO: Crawled 290498 pages (at 115 pages/min), scraped 251611 items (at 114 items/min)
2017-11-04 11:40:03 [scrapy.extensions.logstats] INFO: Crawled 290589 pages (at 91 pages/min), scraped 251707 items (at 96 items/min)
2017-11-04 11:41:03 [scrapy.extensions.logstats] INFO: Crawled 290696 pages (at 107 pages/min), scraped 251815 items (at 108 items/min)
2017-11-04 11:42:04 [scrapy.extensions.logstats] INFO: Crawled 290798 pages (at 102 pages/min), scraped 251918 items (at 103 items/min)
2017-11-04 11:43:04 [scrapy.extensions.logstats] INFO: Crawled 290911 pages (at 113 pages/min), scraped 252026 items (at 108 items/min)
2017-11-04 11:44:04 [scrapy.extensions.logstats] INFO: Crawled 291002 pages (at 91 pages/min), scraped 252118 items (at 92 items/min)
2017-11-04 11:45:04 [scrapy.extensions.logstats] INFO: Crawled 291115 pages (at 113 pages/min), scraped 252232 items (at 114 items/min)
2017-11-04 11:46:03 [scrapy.extensions.logstats] INFO: Crawled 291236 pages (at 121 pages/min), scraped 252338 items (at 106 items/min)
2017-11-04 11:47:04 [scrapy.extensions.logstats] INFO: Crawled 291353 pages (at 117 pages/min), scraped 252438 items (at 100 items/min)
2017-11-04 11:48:04 [scrapy.extensions.logstats] INFO: Crawled 291463 pages (at 110 pages/min), scraped 252533 items (at 95 items/min)
2017-11-04 11:49:04 [scrapy.extensions.logstats] INFO: Crawled 291556 pages (at 93 pages/min), scraped 252632 items (at 99 items/min)
2017-11-04 11:50:03 [scrapy.extensions.logstats] INFO: Crawled 291645 pages (at 89 pages/min), scraped 252720 items (at 88 items/min)
2017-11-04 11:51:03 [scrapy.extensions.logstats] INFO: Crawled 291750 pages (at 105 pages/min), scraped 252821 items (at 101 items/min)
2017-11-04 11:52:03 [scrapy.extensions.logstats] INFO: Crawled 291854 pages (at 104 pages/min), scraped 252899 items (at 78 items/min)
2017-11-04 11:53:04 [scrapy.extensions.logstats] INFO: Crawled 291968 pages (at 114 pages/min), scraped 253022 items (at 123 items/min)
2017-11-04 11:54:03 [scrapy.extensions.logstats] INFO: Crawled 292066 pages (at 98 pages/min), scraped 253096 items (at 74 items/min)
2017-11-04 11:55:03 [scrapy.extensions.logstats] INFO: Crawled 292244 pages (at 178 pages/min), scraped 253267 items (at 171 items/min)
2017-11-04 11:56:03 [scrapy.extensions.logstats] INFO: Crawled 292466 pages (at 222 pages/min), scraped 253463 items (at 196 items/min)
2017-11-04 11:57:03 [scrapy.extensions.logstats] INFO: Crawled 292686 pages (at 220 pages/min), scraped 253653 items (at 190 items/min)
2017-11-04 11:58:04 [scrapy.extensions.logstats] INFO: Crawled 292908 pages (at 222 pages/min), scraped 253815 items (at 162 items/min)
2017-11-04 11:59:03 [scrapy.extensions.logstats] INFO: Crawled 293074 pages (at 166 pages/min), scraped 253945 items (at 130 items/min)
2017-11-04 12:00:03 [scrapy.extensions.logstats] INFO: Crawled 293309 pages (at 235 pages/min), scraped 254124 items (at 179 items/min)
2017-11-04 12:01:03 [scrapy.extensions.logstats] INFO: Crawled 293533 pages (at 224 pages/min), scraped 254331 items (at 207 items/min)
2017-11-04 12:02:03 [scrapy.extensions.logstats] INFO: Crawled 293764 pages (at 231 pages/min), scraped 254513 items (at 182 items/min)
2017-11-04 12:02:47 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39900401&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"雷文军","SCO_NAME":"男","ECO_NAME":"大专","AOI_NAME":"西部证券股份有限公司","AOI_ID":"1999080","ADI_ID":"22707","ADI_NAME":"西安雁塔路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0800107110721","OBTAIN_DATE":"2007-11-29","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 12:03:03 [scrapy.extensions.logstats] INFO: Crawled 293991 pages (at 227 pages/min), scraped 254705 items (at 192 items/min)
2017-11-04 12:04:03 [scrapy.extensions.logstats] INFO: Crawled 294216 pages (at 225 pages/min), scraped 254896 items (at 191 items/min)
2017-11-04 12:05:03 [scrapy.extensions.logstats] INFO: Crawled 294439 pages (at 223 pages/min), scraped 255088 items (at 192 items/min)
2017-11-04 12:06:03 [scrapy.extensions.logstats] INFO: Crawled 294665 pages (at 226 pages/min), scraped 255284 items (at 196 items/min)
2017-11-04 12:07:03 [scrapy.extensions.logstats] INFO: Crawled 294895 pages (at 230 pages/min), scraped 255472 items (at 188 items/min)
2017-11-04 12:08:03 [scrapy.extensions.logstats] INFO: Crawled 295120 pages (at 225 pages/min), scraped 255701 items (at 229 items/min)
2017-11-04 12:09:03 [scrapy.extensions.logstats] INFO: Crawled 295345 pages (at 225 pages/min), scraped 255894 items (at 193 items/min)
2017-11-04 12:10:03 [scrapy.extensions.logstats] INFO: Crawled 295575 pages (at 230 pages/min), scraped 256092 items (at 198 items/min)
2017-11-04 12:11:03 [scrapy.extensions.logstats] INFO: Crawled 295804 pages (at 229 pages/min), scraped 256293 items (at 201 items/min)
2017-11-04 12:12:03 [scrapy.extensions.logstats] INFO: Crawled 296035 pages (at 231 pages/min), scraped 256509 items (at 216 items/min)
2017-11-04 12:13:03 [scrapy.extensions.logstats] INFO: Crawled 296261 pages (at 226 pages/min), scraped 256706 items (at 197 items/min)
2017-11-04 12:14:03 [scrapy.extensions.logstats] INFO: Crawled 296485 pages (at 224 pages/min), scraped 256934 items (at 228 items/min)
2017-11-04 12:15:03 [scrapy.extensions.logstats] INFO: Crawled 296711 pages (at 226 pages/min), scraped 257133 items (at 199 items/min)
2017-11-04 12:16:03 [scrapy.extensions.logstats] INFO: Crawled 296948 pages (at 237 pages/min), scraped 257336 items (at 203 items/min)
2017-11-04 12:17:03 [scrapy.extensions.logstats] INFO: Crawled 297170 pages (at 222 pages/min), scraped 257548 items (at 212 items/min)
2017-11-04 12:18:03 [scrapy.extensions.logstats] INFO: Crawled 297396 pages (at 226 pages/min), scraped 257770 items (at 222 items/min)
2017-11-04 12:19:03 [scrapy.extensions.logstats] INFO: Crawled 297621 pages (at 225 pages/min), scraped 257987 items (at 217 items/min)
2017-11-04 12:20:03 [scrapy.extensions.logstats] INFO: Crawled 297850 pages (at 229 pages/min), scraped 258197 items (at 210 items/min)
2017-11-04 12:21:03 [scrapy.extensions.logstats] INFO: Crawled 298076 pages (at 226 pages/min), scraped 258421 items (at 224 items/min)
2017-11-04 12:22:03 [scrapy.extensions.logstats] INFO: Crawled 298305 pages (at 229 pages/min), scraped 258629 items (at 208 items/min)
2017-11-04 12:23:03 [scrapy.extensions.logstats] INFO: Crawled 298528 pages (at 223 pages/min), scraped 258835 items (at 206 items/min)
2017-11-04 12:24:03 [scrapy.extensions.logstats] INFO: Crawled 298759 pages (at 231 pages/min), scraped 259007 items (at 172 items/min)
2017-11-04 12:25:03 [scrapy.extensions.logstats] INFO: Crawled 298987 pages (at 228 pages/min), scraped 259188 items (at 181 items/min)
2017-11-04 12:26:03 [scrapy.extensions.logstats] INFO: Crawled 299217 pages (at 230 pages/min), scraped 259390 items (at 202 items/min)
2017-11-04 12:27:03 [scrapy.extensions.logstats] INFO: Crawled 299444 pages (at 227 pages/min), scraped 259603 items (at 213 items/min)
2017-11-04 12:28:03 [scrapy.extensions.logstats] INFO: Crawled 299673 pages (at 229 pages/min), scraped 259811 items (at 208 items/min)
2017-11-04 12:29:03 [scrapy.extensions.logstats] INFO: Crawled 299898 pages (at 225 pages/min), scraped 260021 items (at 210 items/min)
2017-11-04 12:30:03 [scrapy.extensions.logstats] INFO: Crawled 300125 pages (at 227 pages/min), scraped 260236 items (at 215 items/min)
2017-11-04 12:31:03 [scrapy.extensions.logstats] INFO: Crawled 300346 pages (at 221 pages/min), scraped 260446 items (at 210 items/min)
2017-11-04 12:32:03 [scrapy.extensions.logstats] INFO: Crawled 300566 pages (at 220 pages/min), scraped 260678 items (at 232 items/min)
2017-11-04 12:33:03 [scrapy.extensions.logstats] INFO: Crawled 300786 pages (at 220 pages/min), scraped 260881 items (at 203 items/min)
2017-11-04 12:34:03 [scrapy.extensions.logstats] INFO: Crawled 301003 pages (at 217 pages/min), scraped 261086 items (at 205 items/min)
2017-11-04 12:35:03 [scrapy.extensions.logstats] INFO: Crawled 301216 pages (at 213 pages/min), scraped 261290 items (at 204 items/min)
2017-11-04 12:36:03 [scrapy.extensions.logstats] INFO: Crawled 301432 pages (at 216 pages/min), scraped 261495 items (at 205 items/min)
2017-11-04 12:37:03 [scrapy.extensions.logstats] INFO: Crawled 301650 pages (at 218 pages/min), scraped 261677 items (at 182 items/min)
2017-11-04 12:38:03 [scrapy.extensions.logstats] INFO: Crawled 301868 pages (at 218 pages/min), scraped 261888 items (at 211 items/min)
2017-11-04 12:39:03 [scrapy.extensions.logstats] INFO: Crawled 302090 pages (at 222 pages/min), scraped 262116 items (at 228 items/min)
2017-11-04 12:40:03 [scrapy.extensions.logstats] INFO: Crawled 302317 pages (at 227 pages/min), scraped 262317 items (at 201 items/min)
2017-11-04 12:41:03 [scrapy.extensions.logstats] INFO: Crawled 302544 pages (at 227 pages/min), scraped 262537 items (at 220 items/min)
2017-11-04 12:42:03 [scrapy.extensions.logstats] INFO: Crawled 302774 pages (at 230 pages/min), scraped 262737 items (at 200 items/min)
2017-11-04 12:43:03 [scrapy.extensions.logstats] INFO: Crawled 302999 pages (at 225 pages/min), scraped 262947 items (at 210 items/min)
2017-11-04 12:44:03 [scrapy.extensions.logstats] INFO: Crawled 303220 pages (at 221 pages/min), scraped 263164 items (at 217 items/min)
2017-11-04 12:45:03 [scrapy.extensions.logstats] INFO: Crawled 303446 pages (at 226 pages/min), scraped 263358 items (at 194 items/min)
2017-11-04 12:46:03 [scrapy.extensions.logstats] INFO: Crawled 303678 pages (at 232 pages/min), scraped 263573 items (at 215 items/min)
2017-11-04 12:47:03 [scrapy.extensions.logstats] INFO: Crawled 303897 pages (at 219 pages/min), scraped 263777 items (at 204 items/min)
2017-11-04 12:48:03 [scrapy.extensions.logstats] INFO: Crawled 304125 pages (at 228 pages/min), scraped 263995 items (at 218 items/min)
2017-11-04 12:49:03 [scrapy.extensions.logstats] INFO: Crawled 304352 pages (at 227 pages/min), scraped 264217 items (at 222 items/min)
2017-11-04 12:50:03 [scrapy.extensions.logstats] INFO: Crawled 304572 pages (at 220 pages/min), scraped 264404 items (at 187 items/min)
2017-11-04 12:51:03 [scrapy.extensions.logstats] INFO: Crawled 304793 pages (at 221 pages/min), scraped 264613 items (at 209 items/min)
2017-11-04 12:52:03 [scrapy.extensions.logstats] INFO: Crawled 305023 pages (at 230 pages/min), scraped 264830 items (at 217 items/min)
2017-11-04 12:53:03 [scrapy.extensions.logstats] INFO: Crawled 305249 pages (at 226 pages/min), scraped 265033 items (at 203 items/min)
2017-11-04 12:54:03 [scrapy.extensions.logstats] INFO: Crawled 305471 pages (at 222 pages/min), scraped 265232 items (at 199 items/min)
2017-11-04 12:55:03 [scrapy.extensions.logstats] INFO: Crawled 305700 pages (at 229 pages/min), scraped 265424 items (at 192 items/min)
2017-11-04 12:56:03 [scrapy.extensions.logstats] INFO: Crawled 305928 pages (at 228 pages/min), scraped 265602 items (at 178 items/min)
2017-11-04 12:57:03 [scrapy.extensions.logstats] INFO: Crawled 306152 pages (at 224 pages/min), scraped 265801 items (at 199 items/min)
2017-11-04 12:57:51 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39900139&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"汪娜","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"西藏东方财富证券股份有限公司","AOI_ID":"1999116","ADI_ID":"18496","ADI_NAME":"成都东大街证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S1160109020164","OBTAIN_DATE":"2009-02-12","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 12:58:03 [scrapy.extensions.logstats] INFO: Crawled 306379 pages (at 227 pages/min), scraped 266000 items (at 199 items/min)
2017-11-04 12:59:03 [scrapy.extensions.logstats] INFO: Crawled 306609 pages (at 230 pages/min), scraped 266170 items (at 170 items/min)
2017-11-04 13:00:03 [scrapy.extensions.logstats] INFO: Crawled 306834 pages (at 225 pages/min), scraped 266393 items (at 223 items/min)
2017-11-04 13:01:03 [scrapy.extensions.logstats] INFO: Crawled 307056 pages (at 222 pages/min), scraped 266608 items (at 215 items/min)
2017-11-04 13:02:03 [scrapy.extensions.logstats] INFO: Crawled 307283 pages (at 227 pages/min), scraped 266843 items (at 235 items/min)
2017-11-04 13:03:03 [scrapy.extensions.logstats] INFO: Crawled 307509 pages (at 226 pages/min), scraped 267045 items (at 202 items/min)
2017-11-04 13:04:03 [scrapy.extensions.logstats] INFO: Crawled 307736 pages (at 227 pages/min), scraped 267237 items (at 192 items/min)
2017-11-04 13:05:03 [scrapy.extensions.logstats] INFO: Crawled 307965 pages (at 229 pages/min), scraped 267433 items (at 196 items/min)
2017-11-04 13:06:03 [scrapy.extensions.logstats] INFO: Crawled 308191 pages (at 226 pages/min), scraped 267642 items (at 209 items/min)
2017-11-04 13:07:03 [scrapy.extensions.logstats] INFO: Crawled 308424 pages (at 233 pages/min), scraped 267837 items (at 195 items/min)
2017-11-04 13:08:03 [scrapy.extensions.logstats] INFO: Crawled 308648 pages (at 224 pages/min), scraped 268037 items (at 200 items/min)
2017-11-04 13:09:03 [scrapy.extensions.logstats] INFO: Crawled 308869 pages (at 221 pages/min), scraped 268236 items (at 199 items/min)
2017-11-04 13:10:03 [scrapy.extensions.logstats] INFO: Crawled 309094 pages (at 225 pages/min), scraped 268426 items (at 190 items/min)
2017-11-04 13:11:03 [scrapy.extensions.logstats] INFO: Crawled 309323 pages (at 229 pages/min), scraped 268627 items (at 201 items/min)
2017-11-04 13:12:04 [scrapy.extensions.logstats] INFO: Crawled 309548 pages (at 225 pages/min), scraped 268833 items (at 206 items/min)
2017-11-04 13:13:03 [scrapy.extensions.logstats] INFO: Crawled 309775 pages (at 227 pages/min), scraped 269031 items (at 198 items/min)
2017-11-04 13:14:03 [scrapy.extensions.logstats] INFO: Crawled 310001 pages (at 226 pages/min), scraped 269215 items (at 184 items/min)
2017-11-04 13:15:03 [scrapy.extensions.logstats] INFO: Crawled 310229 pages (at 228 pages/min), scraped 269417 items (at 202 items/min)
2017-11-04 13:16:03 [scrapy.extensions.logstats] INFO: Crawled 310451 pages (at 222 pages/min), scraped 269622 items (at 205 items/min)
2017-11-04 13:17:03 [scrapy.extensions.logstats] INFO: Crawled 310676 pages (at 225 pages/min), scraped 269833 items (at 211 items/min)
2017-11-04 13:18:03 [scrapy.extensions.logstats] INFO: Crawled 310903 pages (at 227 pages/min), scraped 270027 items (at 194 items/min)
2017-11-04 13:19:03 [scrapy.extensions.logstats] INFO: Crawled 311132 pages (at 229 pages/min), scraped 270211 items (at 184 items/min)
2017-11-04 13:20:03 [scrapy.extensions.logstats] INFO: Crawled 311358 pages (at 226 pages/min), scraped 270411 items (at 200 items/min)
2017-11-04 13:21:03 [scrapy.extensions.logstats] INFO: Crawled 311585 pages (at 227 pages/min), scraped 270627 items (at 216 items/min)
2017-11-04 13:22:03 [scrapy.extensions.logstats] INFO: Crawled 311810 pages (at 225 pages/min), scraped 270828 items (at 201 items/min)
2017-11-04 13:23:03 [scrapy.extensions.logstats] INFO: Crawled 312041 pages (at 231 pages/min), scraped 271018 items (at 190 items/min)
2017-11-04 13:24:03 [scrapy.extensions.logstats] INFO: Crawled 312269 pages (at 228 pages/min), scraped 271215 items (at 197 items/min)
2017-11-04 13:25:03 [scrapy.extensions.logstats] INFO: Crawled 312494 pages (at 225 pages/min), scraped 271422 items (at 207 items/min)
2017-11-04 13:26:03 [scrapy.extensions.logstats] INFO: Crawled 312717 pages (at 223 pages/min), scraped 271635 items (at 213 items/min)
2017-11-04 13:27:03 [scrapy.extensions.logstats] INFO: Crawled 312940 pages (at 223 pages/min), scraped 271831 items (at 196 items/min)
2017-11-04 13:28:03 [scrapy.extensions.logstats] INFO: Crawled 313163 pages (at 223 pages/min), scraped 272022 items (at 191 items/min)
2017-11-04 13:29:03 [scrapy.extensions.logstats] INFO: Crawled 313391 pages (at 228 pages/min), scraped 272196 items (at 174 items/min)
2017-11-04 13:30:03 [scrapy.extensions.logstats] INFO: Crawled 313623 pages (at 232 pages/min), scraped 272348 items (at 152 items/min)
2017-11-04 13:31:03 [scrapy.extensions.logstats] INFO: Crawled 313852 pages (at 229 pages/min), scraped 272527 items (at 179 items/min)
2017-11-04 13:32:03 [scrapy.extensions.logstats] INFO: Crawled 314082 pages (at 230 pages/min), scraped 272700 items (at 173 items/min)
2017-11-04 13:33:03 [scrapy.extensions.logstats] INFO: Crawled 314308 pages (at 226 pages/min), scraped 272886 items (at 186 items/min)
2017-11-04 13:34:03 [scrapy.extensions.logstats] INFO: Crawled 314532 pages (at 224 pages/min), scraped 273077 items (at 191 items/min)
2017-11-04 13:35:03 [scrapy.extensions.logstats] INFO: Crawled 314760 pages (at 228 pages/min), scraped 273284 items (at 207 items/min)
2017-11-04 13:36:03 [scrapy.extensions.logstats] INFO: Crawled 314981 pages (at 221 pages/min), scraped 273487 items (at 203 items/min)
2017-11-04 13:37:03 [scrapy.extensions.logstats] INFO: Crawled 315203 pages (at 222 pages/min), scraped 273685 items (at 198 items/min)
2017-11-04 13:38:03 [scrapy.extensions.logstats] INFO: Crawled 315421 pages (at 218 pages/min), scraped 273884 items (at 199 items/min)
2017-11-04 13:39:03 [scrapy.extensions.logstats] INFO: Crawled 315647 pages (at 226 pages/min), scraped 274104 items (at 220 items/min)
2017-11-04 13:40:03 [scrapy.extensions.logstats] INFO: Crawled 315866 pages (at 219 pages/min), scraped 274314 items (at 210 items/min)
2017-11-04 13:41:03 [scrapy.extensions.logstats] INFO: Crawled 316091 pages (at 225 pages/min), scraped 274526 items (at 212 items/min)
2017-11-04 13:42:03 [scrapy.extensions.logstats] INFO: Crawled 316315 pages (at 224 pages/min), scraped 274750 items (at 224 items/min)
2017-11-04 13:43:03 [scrapy.extensions.logstats] INFO: Crawled 316536 pages (at 221 pages/min), scraped 274975 items (at 225 items/min)
2017-11-04 13:44:03 [scrapy.extensions.logstats] INFO: Crawled 316755 pages (at 219 pages/min), scraped 275203 items (at 228 items/min)
2017-11-04 13:45:03 [scrapy.extensions.logstats] INFO: Crawled 316977 pages (at 222 pages/min), scraped 275404 items (at 201 items/min)
2017-11-04 13:46:03 [scrapy.extensions.logstats] INFO: Crawled 317195 pages (at 218 pages/min), scraped 275634 items (at 230 items/min)
2017-11-04 13:47:03 [scrapy.extensions.logstats] INFO: Crawled 317424 pages (at 229 pages/min), scraped 275849 items (at 215 items/min)
2017-11-04 13:48:03 [scrapy.extensions.logstats] INFO: Crawled 317649 pages (at 225 pages/min), scraped 276079 items (at 230 items/min)
2017-11-04 13:49:03 [scrapy.extensions.logstats] INFO: Crawled 317870 pages (at 221 pages/min), scraped 276273 items (at 194 items/min)
2017-11-04 13:50:03 [scrapy.extensions.logstats] INFO: Crawled 318097 pages (at 227 pages/min), scraped 276452 items (at 179 items/min)
2017-11-04 13:51:03 [scrapy.extensions.logstats] INFO: Crawled 318325 pages (at 228 pages/min), scraped 276632 items (at 180 items/min)
2017-11-04 13:52:03 [scrapy.extensions.logstats] INFO: Crawled 318553 pages (at 228 pages/min), scraped 276818 items (at 186 items/min)
2017-11-04 13:53:03 [scrapy.extensions.logstats] INFO: Crawled 318774 pages (at 221 pages/min), scraped 276994 items (at 176 items/min)
2017-11-04 13:54:03 [scrapy.extensions.logstats] INFO: Crawled 318999 pages (at 225 pages/min), scraped 277199 items (at 205 items/min)
2017-11-04 13:55:03 [scrapy.extensions.logstats] INFO: Crawled 319232 pages (at 233 pages/min), scraped 277380 items (at 181 items/min)
2017-11-04 13:56:03 [scrapy.extensions.logstats] INFO: Crawled 319459 pages (at 227 pages/min), scraped 277572 items (at 192 items/min)
2017-11-04 13:57:03 [scrapy.extensions.logstats] INFO: Crawled 319692 pages (at 233 pages/min), scraped 277777 items (at 205 items/min)
2017-11-04 13:58:03 [scrapy.extensions.logstats] INFO: Crawled 319918 pages (at 226 pages/min), scraped 277957 items (at 180 items/min)
2017-11-04 13:59:03 [scrapy.extensions.logstats] INFO: Crawled 320141 pages (at 223 pages/min), scraped 278128 items (at 171 items/min)
2017-11-04 14:00:03 [scrapy.extensions.logstats] INFO: Crawled 320365 pages (at 224 pages/min), scraped 278325 items (at 197 items/min)
2017-11-04 14:01:03 [scrapy.extensions.logstats] INFO: Crawled 320591 pages (at 226 pages/min), scraped 278530 items (at 205 items/min)
2017-11-04 14:02:03 [scrapy.extensions.logstats] INFO: Crawled 320821 pages (at 230 pages/min), scraped 278735 items (at 205 items/min)
2017-11-04 14:03:03 [scrapy.extensions.logstats] INFO: Crawled 321045 pages (at 224 pages/min), scraped 278958 items (at 223 items/min)
2017-11-04 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 321274 pages (at 229 pages/min), scraped 279146 items (at 188 items/min)
2017-11-04 14:05:03 [scrapy.extensions.logstats] INFO: Crawled 321495 pages (at 221 pages/min), scraped 279348 items (at 202 items/min)
2017-11-04 14:06:03 [scrapy.extensions.logstats] INFO: Crawled 321725 pages (at 230 pages/min), scraped 279531 items (at 183 items/min)
2017-11-04 14:07:03 [scrapy.extensions.logstats] INFO: Crawled 321952 pages (at 227 pages/min), scraped 279727 items (at 196 items/min)
2017-11-04 14:08:03 [scrapy.extensions.logstats] INFO: Crawled 322179 pages (at 227 pages/min), scraped 279919 items (at 192 items/min)
2017-11-04 14:09:03 [scrapy.extensions.logstats] INFO: Crawled 322410 pages (at 231 pages/min), scraped 280104 items (at 185 items/min)
2017-11-04 14:10:03 [scrapy.extensions.logstats] INFO: Crawled 322638 pages (at 228 pages/min), scraped 280308 items (at 204 items/min)
2017-11-04 14:11:03 [scrapy.extensions.logstats] INFO: Crawled 322863 pages (at 225 pages/min), scraped 280515 items (at 207 items/min)
2017-11-04 14:12:03 [scrapy.extensions.logstats] INFO: Crawled 323093 pages (at 230 pages/min), scraped 280719 items (at 204 items/min)
2017-11-04 14:13:03 [scrapy.extensions.logstats] INFO: Crawled 323323 pages (at 230 pages/min), scraped 280889 items (at 170 items/min)
2017-11-04 14:14:03 [scrapy.extensions.logstats] INFO: Crawled 323555 pages (at 232 pages/min), scraped 281071 items (at 182 items/min)
2017-11-04 14:15:03 [scrapy.extensions.logstats] INFO: Crawled 323784 pages (at 229 pages/min), scraped 281271 items (at 200 items/min)
2017-11-04 14:16:03 [scrapy.extensions.logstats] INFO: Crawled 324010 pages (at 226 pages/min), scraped 281494 items (at 223 items/min)
2017-11-04 14:17:03 [scrapy.extensions.logstats] INFO: Crawled 324235 pages (at 225 pages/min), scraped 281691 items (at 197 items/min)
2017-11-04 14:18:03 [scrapy.extensions.logstats] INFO: Crawled 324467 pages (at 232 pages/min), scraped 281894 items (at 203 items/min)
2017-11-04 14:19:03 [scrapy.extensions.logstats] INFO: Crawled 324692 pages (at 225 pages/min), scraped 282113 items (at 219 items/min)
2017-11-04 14:20:03 [scrapy.extensions.logstats] INFO: Crawled 324918 pages (at 226 pages/min), scraped 282311 items (at 198 items/min)
2017-11-04 14:21:03 [scrapy.extensions.logstats] INFO: Crawled 325146 pages (at 228 pages/min), scraped 282500 items (at 189 items/min)
2017-11-04 14:22:03 [scrapy.extensions.logstats] INFO: Crawled 325369 pages (at 223 pages/min), scraped 282710 items (at 210 items/min)
2017-11-04 14:23:03 [scrapy.extensions.logstats] INFO: Crawled 325586 pages (at 217 pages/min), scraped 282907 items (at 197 items/min)
2017-11-04 14:24:03 [scrapy.extensions.logstats] INFO: Crawled 325803 pages (at 217 pages/min), scraped 283110 items (at 203 items/min)
2017-11-04 14:25:03 [scrapy.extensions.logstats] INFO: Crawled 326029 pages (at 226 pages/min), scraped 283307 items (at 197 items/min)
2017-11-04 14:26:03 [scrapy.extensions.logstats] INFO: Crawled 326258 pages (at 229 pages/min), scraped 283501 items (at 194 items/min)
2017-11-04 14:27:03 [scrapy.extensions.logstats] INFO: Crawled 326483 pages (at 225 pages/min), scraped 283738 items (at 237 items/min)
2017-11-04 14:28:03 [scrapy.extensions.logstats] INFO: Crawled 326710 pages (at 227 pages/min), scraped 283935 items (at 197 items/min)
2017-11-04 14:29:03 [scrapy.extensions.logstats] INFO: Crawled 326938 pages (at 228 pages/min), scraped 284132 items (at 197 items/min)
2017-11-04 14:30:03 [scrapy.extensions.logstats] INFO: Crawled 327163 pages (at 225 pages/min), scraped 284319 items (at 187 items/min)
2017-11-04 14:31:03 [scrapy.extensions.logstats] INFO: Crawled 327394 pages (at 231 pages/min), scraped 284512 items (at 193 items/min)
2017-11-04 14:32:03 [scrapy.extensions.logstats] INFO: Crawled 327616 pages (at 222 pages/min), scraped 284711 items (at 199 items/min)
2017-11-04 14:33:03 [scrapy.extensions.logstats] INFO: Crawled 327838 pages (at 222 pages/min), scraped 284913 items (at 202 items/min)
2017-11-04 14:34:03 [scrapy.extensions.logstats] INFO: Crawled 328057 pages (at 219 pages/min), scraped 285094 items (at 181 items/min)
2017-11-04 14:35:03 [scrapy.extensions.logstats] INFO: Crawled 328279 pages (at 222 pages/min), scraped 285306 items (at 212 items/min)
2017-11-04 14:36:03 [scrapy.extensions.logstats] INFO: Crawled 328497 pages (at 218 pages/min), scraped 285507 items (at 201 items/min)
2017-11-04 14:37:03 [scrapy.extensions.logstats] INFO: Crawled 328723 pages (at 226 pages/min), scraped 285670 items (at 163 items/min)
2017-11-04 14:38:03 [scrapy.extensions.logstats] INFO: Crawled 328947 pages (at 224 pages/min), scraped 285836 items (at 166 items/min)
2017-11-04 14:39:03 [scrapy.extensions.logstats] INFO: Crawled 329172 pages (at 225 pages/min), scraped 286013 items (at 177 items/min)
2017-11-04 14:40:04 [scrapy.extensions.logstats] INFO: Crawled 329398 pages (at 226 pages/min), scraped 286199 items (at 186 items/min)
2017-11-04 14:41:03 [scrapy.extensions.logstats] INFO: Crawled 329617 pages (at 219 pages/min), scraped 286418 items (at 219 items/min)
2017-11-04 14:42:03 [scrapy.extensions.logstats] INFO: Crawled 329839 pages (at 222 pages/min), scraped 286613 items (at 195 items/min)
2017-11-04 14:43:03 [scrapy.extensions.logstats] INFO: Crawled 330063 pages (at 224 pages/min), scraped 286817 items (at 204 items/min)
2017-11-04 14:44:03 [scrapy.extensions.logstats] INFO: Crawled 330286 pages (at 223 pages/min), scraped 287014 items (at 197 items/min)
2017-11-04 14:45:03 [scrapy.extensions.logstats] INFO: Crawled 330502 pages (at 216 pages/min), scraped 287216 items (at 202 items/min)
2017-11-04 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 330720 pages (at 218 pages/min), scraped 287403 items (at 187 items/min)
2017-11-04 14:47:03 [scrapy.extensions.logstats] INFO: Crawled 330942 pages (at 222 pages/min), scraped 287606 items (at 203 items/min)
2017-11-04 14:48:03 [scrapy.extensions.logstats] INFO: Crawled 331155 pages (at 213 pages/min), scraped 287823 items (at 217 items/min)
2017-11-04 14:49:03 [scrapy.extensions.logstats] INFO: Crawled 331370 pages (at 215 pages/min), scraped 288051 items (at 228 items/min)
2017-11-04 14:50:03 [scrapy.extensions.logstats] INFO: Crawled 331589 pages (at 219 pages/min), scraped 288265 items (at 214 items/min)
2017-11-04 14:51:03 [scrapy.extensions.logstats] INFO: Crawled 331811 pages (at 222 pages/min), scraped 288477 items (at 212 items/min)
2017-11-04 14:52:03 [scrapy.extensions.logstats] INFO: Crawled 332030 pages (at 219 pages/min), scraped 288690 items (at 213 items/min)
2017-11-04 14:53:03 [scrapy.extensions.logstats] INFO: Crawled 332251 pages (at 221 pages/min), scraped 288896 items (at 206 items/min)
2017-11-04 14:54:03 [scrapy.extensions.logstats] INFO: Crawled 332468 pages (at 217 pages/min), scraped 289106 items (at 210 items/min)
2017-11-04 14:55:03 [scrapy.extensions.logstats] INFO: Crawled 332683 pages (at 215 pages/min), scraped 289311 items (at 205 items/min)
2017-11-04 14:56:03 [scrapy.extensions.logstats] INFO: Crawled 332905 pages (at 222 pages/min), scraped 289495 items (at 184 items/min)
2017-11-04 14:57:03 [scrapy.extensions.logstats] INFO: Crawled 333122 pages (at 217 pages/min), scraped 289678 items (at 183 items/min)
2017-11-04 14:58:03 [scrapy.extensions.logstats] INFO: Crawled 333339 pages (at 217 pages/min), scraped 289875 items (at 197 items/min)
2017-11-04 14:59:03 [scrapy.extensions.logstats] INFO: Crawled 333555 pages (at 216 pages/min), scraped 290084 items (at 209 items/min)
2017-11-04 15:00:03 [scrapy.extensions.logstats] INFO: Crawled 333776 pages (at 221 pages/min), scraped 290278 items (at 194 items/min)
2017-11-04 15:01:03 [scrapy.extensions.logstats] INFO: Crawled 333994 pages (at 218 pages/min), scraped 290476 items (at 198 items/min)
2017-11-04 15:02:03 [scrapy.extensions.logstats] INFO: Crawled 334210 pages (at 216 pages/min), scraped 290660 items (at 184 items/min)
2017-11-04 15:03:03 [scrapy.extensions.logstats] INFO: Crawled 334431 pages (at 221 pages/min), scraped 290846 items (at 186 items/min)
2017-11-04 15:04:03 [scrapy.extensions.logstats] INFO: Crawled 334648 pages (at 217 pages/min), scraped 291040 items (at 194 items/min)
2017-11-04 15:05:03 [scrapy.extensions.logstats] INFO: Crawled 334867 pages (at 219 pages/min), scraped 291239 items (at 199 items/min)
2017-11-04 15:06:03 [scrapy.extensions.logstats] INFO: Crawled 335082 pages (at 215 pages/min), scraped 291453 items (at 214 items/min)
2017-11-04 15:07:03 [scrapy.extensions.logstats] INFO: Crawled 335302 pages (at 220 pages/min), scraped 291660 items (at 207 items/min)
2017-11-04 15:08:03 [scrapy.extensions.logstats] INFO: Crawled 335531 pages (at 229 pages/min), scraped 291821 items (at 161 items/min)
2017-11-04 15:09:03 [scrapy.extensions.logstats] INFO: Crawled 335759 pages (at 228 pages/min), scraped 291971 items (at 150 items/min)
2017-11-04 15:10:03 [scrapy.extensions.logstats] INFO: Crawled 335986 pages (at 227 pages/min), scraped 292121 items (at 150 items/min)
2017-11-04 15:11:03 [scrapy.extensions.logstats] INFO: Crawled 336215 pages (at 229 pages/min), scraped 292286 items (at 165 items/min)
2017-11-04 15:12:03 [scrapy.extensions.logstats] INFO: Crawled 336444 pages (at 229 pages/min), scraped 292446 items (at 160 items/min)
2017-11-04 15:13:03 [scrapy.extensions.logstats] INFO: Crawled 336667 pages (at 223 pages/min), scraped 292672 items (at 226 items/min)
2017-11-04 15:14:03 [scrapy.extensions.logstats] INFO: Crawled 336901 pages (at 234 pages/min), scraped 292834 items (at 162 items/min)
2017-11-04 15:15:03 [scrapy.extensions.logstats] INFO: Crawled 337120 pages (at 219 pages/min), scraped 293037 items (at 203 items/min)
2017-11-04 15:16:03 [scrapy.extensions.logstats] INFO: Crawled 337341 pages (at 221 pages/min), scraped 293231 items (at 194 items/min)
2017-11-04 15:17:03 [scrapy.extensions.logstats] INFO: Crawled 337570 pages (at 229 pages/min), scraped 293417 items (at 186 items/min)
2017-11-04 15:18:03 [scrapy.extensions.logstats] INFO: Crawled 337788 pages (at 218 pages/min), scraped 293602 items (at 185 items/min)
2017-11-04 15:19:03 [scrapy.extensions.logstats] INFO: Crawled 338005 pages (at 217 pages/min), scraped 293788 items (at 186 items/min)
2017-11-04 15:20:03 [scrapy.extensions.logstats] INFO: Crawled 338219 pages (at 214 pages/min), scraped 293983 items (at 195 items/min)
2017-11-04 15:21:03 [scrapy.extensions.logstats] INFO: Crawled 338444 pages (at 225 pages/min), scraped 294173 items (at 190 items/min)
2017-11-04 15:22:03 [scrapy.extensions.logstats] INFO: Crawled 338661 pages (at 217 pages/min), scraped 294363 items (at 190 items/min)
2017-11-04 15:23:03 [scrapy.extensions.logstats] INFO: Crawled 338882 pages (at 221 pages/min), scraped 294559 items (at 196 items/min)
2017-11-04 15:24:03 [scrapy.extensions.logstats] INFO: Crawled 339103 pages (at 221 pages/min), scraped 294761 items (at 202 items/min)
2017-11-04 15:25:03 [scrapy.extensions.logstats] INFO: Crawled 339320 pages (at 217 pages/min), scraped 294946 items (at 185 items/min)
2017-11-04 15:26:03 [scrapy.extensions.logstats] INFO: Crawled 339541 pages (at 221 pages/min), scraped 295148 items (at 202 items/min)
2017-11-04 15:27:03 [scrapy.extensions.logstats] INFO: Crawled 339762 pages (at 221 pages/min), scraped 295335 items (at 187 items/min)
2017-11-04 15:28:03 [scrapy.extensions.logstats] INFO: Crawled 339982 pages (at 220 pages/min), scraped 295554 items (at 219 items/min)
2017-11-04 15:29:03 [scrapy.extensions.logstats] INFO: Crawled 340204 pages (at 222 pages/min), scraped 295735 items (at 181 items/min)
2017-11-04 15:30:03 [scrapy.extensions.logstats] INFO: Crawled 340425 pages (at 221 pages/min), scraped 295929 items (at 194 items/min)
2017-11-04 15:31:03 [scrapy.extensions.logstats] INFO: Crawled 340650 pages (at 225 pages/min), scraped 296144 items (at 215 items/min)
2017-11-04 15:32:03 [scrapy.extensions.logstats] INFO: Crawled 340859 pages (at 209 pages/min), scraped 296351 items (at 207 items/min)
2017-11-04 15:33:03 [scrapy.extensions.logstats] INFO: Crawled 341087 pages (at 228 pages/min), scraped 296555 items (at 204 items/min)
2017-11-04 15:34:03 [scrapy.extensions.logstats] INFO: Crawled 341303 pages (at 216 pages/min), scraped 296777 items (at 222 items/min)
2017-11-04 15:35:03 [scrapy.extensions.logstats] INFO: Crawled 341519 pages (at 216 pages/min), scraped 296977 items (at 200 items/min)
2017-11-04 15:36:03 [scrapy.extensions.logstats] INFO: Crawled 341740 pages (at 221 pages/min), scraped 297180 items (at 203 items/min)
2017-11-04 15:37:03 [scrapy.extensions.logstats] INFO: Crawled 341965 pages (at 225 pages/min), scraped 297366 items (at 186 items/min)
2017-11-04 15:38:03 [scrapy.extensions.logstats] INFO: Crawled 342187 pages (at 222 pages/min), scraped 297509 items (at 143 items/min)
2017-11-04 15:38:29 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39909479&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"刘峻","SCO_NAME":"男","ECO_NAME":"高中","AOI_NAME":"世纪证券有限责任公司","AOI_ID":"1999103","ADI_ID":"7912","ADI_NAME":"上海威海路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S1030113010003","OBTAIN_DATE":"2013-01-24","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 15:38:39 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39910421&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"刘琴","SCO_NAME":"女","ECO_NAME":"大专","AOI_NAME":"世纪证券有限责任公司","AOI_ID":"1999103","ADI_ID":"29119","ADI_NAME":"南昌北京西路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S1030111080004","OBTAIN_DATE":"2011-08-02","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 15:39:03 [scrapy.extensions.logstats] INFO: Crawled 342411 pages (at 224 pages/min), scraped 297673 items (at 164 items/min)
2017-11-04 15:40:03 [scrapy.extensions.logstats] INFO: Crawled 342638 pages (at 227 pages/min), scraped 297839 items (at 166 items/min)
2017-11-04 15:41:03 [scrapy.extensions.logstats] INFO: Crawled 342858 pages (at 220 pages/min), scraped 298036 items (at 197 items/min)
2017-11-04 15:42:03 [scrapy.extensions.logstats] INFO: Crawled 343081 pages (at 223 pages/min), scraped 298251 items (at 215 items/min)
2017-11-04 15:43:03 [scrapy.extensions.logstats] INFO: Crawled 343304 pages (at 223 pages/min), scraped 298447 items (at 196 items/min)
2017-11-04 15:44:03 [scrapy.extensions.logstats] INFO: Crawled 343522 pages (at 218 pages/min), scraped 298654 items (at 207 items/min)
2017-11-04 15:45:03 [scrapy.extensions.logstats] INFO: Crawled 343738 pages (at 216 pages/min), scraped 298864 items (at 210 items/min)
2017-11-04 15:46:03 [scrapy.extensions.logstats] INFO: Crawled 343955 pages (at 217 pages/min), scraped 299070 items (at 206 items/min)
2017-11-04 15:47:03 [scrapy.extensions.logstats] INFO: Crawled 344175 pages (at 220 pages/min), scraped 299284 items (at 214 items/min)
2017-11-04 15:48:03 [scrapy.extensions.logstats] INFO: Crawled 344395 pages (at 220 pages/min), scraped 299492 items (at 208 items/min)
2017-11-04 15:49:03 [scrapy.extensions.logstats] INFO: Crawled 344611 pages (at 216 pages/min), scraped 299712 items (at 220 items/min)
2017-11-04 15:50:03 [scrapy.extensions.logstats] INFO: Crawled 344828 pages (at 217 pages/min), scraped 299907 items (at 195 items/min)
2017-11-04 15:51:03 [scrapy.extensions.logstats] INFO: Crawled 345069 pages (at 241 pages/min), scraped 300140 items (at 233 items/min)
2017-11-04 15:52:03 [scrapy.extensions.logstats] INFO: Crawled 345311 pages (at 242 pages/min), scraped 300369 items (at 229 items/min)
2017-11-04 15:53:03 [scrapy.extensions.logstats] INFO: Crawled 345557 pages (at 246 pages/min), scraped 300666 items (at 297 items/min)
2017-11-04 15:54:03 [scrapy.extensions.logstats] INFO: Crawled 345795 pages (at 238 pages/min), scraped 300874 items (at 208 items/min)
2017-11-04 15:55:03 [scrapy.extensions.logstats] INFO: Crawled 346033 pages (at 238 pages/min), scraped 301074 items (at 200 items/min)
2017-11-04 15:56:04 [scrapy.extensions.logstats] INFO: Crawled 346251 pages (at 218 pages/min), scraped 301283 items (at 209 items/min)
2017-11-04 15:57:03 [scrapy.extensions.logstats] INFO: Crawled 346465 pages (at 214 pages/min), scraped 301478 items (at 195 items/min)
2017-11-04 15:58:03 [scrapy.extensions.logstats] INFO: Crawled 346684 pages (at 219 pages/min), scraped 301686 items (at 208 items/min)
2017-11-04 15:59:03 [scrapy.extensions.logstats] INFO: Crawled 346895 pages (at 211 pages/min), scraped 301896 items (at 210 items/min)
2017-11-04 16:00:03 [scrapy.extensions.logstats] INFO: Crawled 347119 pages (at 224 pages/min), scraped 302089 items (at 193 items/min)
2017-11-04 16:01:03 [scrapy.extensions.logstats] INFO: Crawled 347340 pages (at 221 pages/min), scraped 302280 items (at 191 items/min)
2017-11-04 16:02:03 [scrapy.extensions.logstats] INFO: Crawled 347558 pages (at 218 pages/min), scraped 302466 items (at 186 items/min)
2017-11-04 16:03:03 [scrapy.extensions.logstats] INFO: Crawled 347774 pages (at 216 pages/min), scraped 302671 items (at 205 items/min)
2017-11-04 16:04:03 [scrapy.extensions.logstats] INFO: Crawled 347993 pages (at 219 pages/min), scraped 302863 items (at 192 items/min)
2017-11-04 16:05:03 [scrapy.extensions.logstats] INFO: Crawled 348214 pages (at 221 pages/min), scraped 303045 items (at 182 items/min)
2017-11-04 16:06:03 [scrapy.extensions.logstats] INFO: Crawled 348430 pages (at 216 pages/min), scraped 303235 items (at 190 items/min)
2017-11-04 16:07:03 [scrapy.extensions.logstats] INFO: Crawled 348650 pages (at 220 pages/min), scraped 303421 items (at 186 items/min)
2017-11-04 16:08:03 [scrapy.extensions.logstats] INFO: Crawled 348864 pages (at 214 pages/min), scraped 303616 items (at 195 items/min)
2017-11-04 16:09:03 [scrapy.extensions.logstats] INFO: Crawled 349084 pages (at 220 pages/min), scraped 303813 items (at 197 items/min)
2017-11-04 16:10:03 [scrapy.extensions.logstats] INFO: Crawled 349306 pages (at 222 pages/min), scraped 304005 items (at 192 items/min)
2017-11-04 16:11:03 [scrapy.extensions.logstats] INFO: Crawled 349524 pages (at 218 pages/min), scraped 304214 items (at 209 items/min)
2017-11-04 16:12:03 [scrapy.extensions.logstats] INFO: Crawled 349742 pages (at 218 pages/min), scraped 304425 items (at 211 items/min)
2017-11-04 16:13:03 [scrapy.extensions.logstats] INFO: Crawled 349964 pages (at 222 pages/min), scraped 304630 items (at 205 items/min)
2017-11-04 16:14:04 [scrapy.extensions.logstats] INFO: Crawled 350185 pages (at 221 pages/min), scraped 304821 items (at 191 items/min)
2017-11-04 16:15:04 [scrapy.extensions.logstats] INFO: Crawled 350406 pages (at 221 pages/min), scraped 305007 items (at 186 items/min)
2017-11-04 16:16:03 [scrapy.extensions.logstats] INFO: Crawled 350622 pages (at 216 pages/min), scraped 305192 items (at 185 items/min)
2017-11-04 16:17:03 [scrapy.extensions.logstats] INFO: Crawled 350840 pages (at 218 pages/min), scraped 305381 items (at 189 items/min)
2017-11-04 16:18:03 [scrapy.extensions.logstats] INFO: Crawled 351058 pages (at 218 pages/min), scraped 305583 items (at 202 items/min)
2017-11-04 16:19:03 [scrapy.extensions.logstats] INFO: Crawled 351281 pages (at 223 pages/min), scraped 305778 items (at 195 items/min)
2017-11-04 16:20:03 [scrapy.extensions.logstats] INFO: Crawled 351504 pages (at 223 pages/min), scraped 305984 items (at 206 items/min)
2017-11-04 16:21:03 [scrapy.extensions.logstats] INFO: Crawled 351720 pages (at 216 pages/min), scraped 306154 items (at 170 items/min)
2017-11-04 16:22:03 [scrapy.extensions.logstats] INFO: Crawled 351935 pages (at 215 pages/min), scraped 306367 items (at 213 items/min)
2017-11-04 16:23:03 [scrapy.extensions.logstats] INFO: Crawled 352148 pages (at 213 pages/min), scraped 306570 items (at 203 items/min)
2017-11-04 16:24:03 [scrapy.extensions.logstats] INFO: Crawled 352360 pages (at 212 pages/min), scraped 306791 items (at 221 items/min)
2017-11-04 16:25:03 [scrapy.extensions.logstats] INFO: Crawled 352580 pages (at 220 pages/min), scraped 307003 items (at 212 items/min)
2017-11-04 16:26:03 [scrapy.extensions.logstats] INFO: Crawled 352797 pages (at 217 pages/min), scraped 307215 items (at 212 items/min)
2017-11-04 16:27:03 [scrapy.extensions.logstats] INFO: Crawled 353010 pages (at 213 pages/min), scraped 307444 items (at 229 items/min)
2017-11-04 16:28:03 [scrapy.extensions.logstats] INFO: Crawled 353226 pages (at 216 pages/min), scraped 307655 items (at 211 items/min)
2017-11-04 16:29:03 [scrapy.extensions.logstats] INFO: Crawled 353438 pages (at 212 pages/min), scraped 307867 items (at 212 items/min)
2017-11-04 16:30:03 [scrapy.extensions.logstats] INFO: Crawled 353666 pages (at 228 pages/min), scraped 308074 items (at 207 items/min)
2017-11-04 16:31:03 [scrapy.extensions.logstats] INFO: Crawled 353887 pages (at 221 pages/min), scraped 308272 items (at 198 items/min)
2017-11-04 16:32:03 [scrapy.extensions.logstats] INFO: Crawled 354110 pages (at 223 pages/min), scraped 308504 items (at 232 items/min)
2017-11-04 16:33:03 [scrapy.extensions.logstats] INFO: Crawled 354341 pages (at 231 pages/min), scraped 308719 items (at 215 items/min)
2017-11-04 16:34:03 [scrapy.extensions.logstats] INFO: Crawled 354570 pages (at 229 pages/min), scraped 308928 items (at 209 items/min)
2017-11-04 16:35:03 [scrapy.extensions.logstats] INFO: Crawled 354796 pages (at 226 pages/min), scraped 309122 items (at 194 items/min)
2017-11-04 16:36:03 [scrapy.extensions.logstats] INFO: Crawled 355028 pages (at 232 pages/min), scraped 309312 items (at 190 items/min)
2017-11-04 16:37:03 [scrapy.extensions.logstats] INFO: Crawled 355255 pages (at 227 pages/min), scraped 309508 items (at 196 items/min)
2017-11-04 16:38:03 [scrapy.extensions.logstats] INFO: Crawled 355481 pages (at 226 pages/min), scraped 309695 items (at 187 items/min)
2017-11-04 16:39:04 [scrapy.extensions.logstats] INFO: Crawled 355618 pages (at 137 pages/min), scraped 309802 items (at 107 items/min)
2017-11-04 16:40:05 [scrapy.extensions.logstats] INFO: Crawled 355749 pages (at 131 pages/min), scraped 309905 items (at 103 items/min)
2017-11-04 16:41:03 [scrapy.extensions.logstats] INFO: Crawled 355916 pages (at 167 pages/min), scraped 310046 items (at 141 items/min)
2017-11-04 16:42:03 [scrapy.extensions.logstats] INFO: Crawled 356148 pages (at 232 pages/min), scraped 310264 items (at 218 items/min)
2017-11-04 16:43:03 [scrapy.extensions.logstats] INFO: Crawled 356379 pages (at 231 pages/min), scraped 310467 items (at 203 items/min)
2017-11-04 16:44:03 [scrapy.extensions.logstats] INFO: Crawled 356605 pages (at 226 pages/min), scraped 310684 items (at 217 items/min)
2017-11-04 16:45:03 [scrapy.extensions.logstats] INFO: Crawled 356835 pages (at 230 pages/min), scraped 310892 items (at 208 items/min)
2017-11-04 16:46:03 [scrapy.extensions.logstats] INFO: Crawled 357062 pages (at 227 pages/min), scraped 311088 items (at 196 items/min)
2017-11-04 16:47:03 [scrapy.extensions.logstats] INFO: Crawled 357285 pages (at 223 pages/min), scraped 311274 items (at 186 items/min)
2017-11-04 16:48:03 [scrapy.extensions.logstats] INFO: Crawled 357510 pages (at 225 pages/min), scraped 311455 items (at 181 items/min)
2017-11-04 16:49:03 [scrapy.extensions.logstats] INFO: Crawled 357732 pages (at 222 pages/min), scraped 311628 items (at 173 items/min)
2017-11-04 16:50:03 [scrapy.extensions.logstats] INFO: Crawled 357953 pages (at 221 pages/min), scraped 311807 items (at 179 items/min)
2017-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 358093 pages (at 140 pages/min), scraped 311925 items (at 118 items/min)
2017-11-04 16:52:05 [scrapy.extensions.logstats] INFO: Crawled 358207 pages (at 114 pages/min), scraped 312006 items (at 81 items/min)
2017-11-04 16:53:05 [scrapy.extensions.logstats] INFO: Crawled 358317 pages (at 110 pages/min), scraped 312092 items (at 86 items/min)
2017-11-04 16:54:04 [scrapy.extensions.logstats] INFO: Crawled 358420 pages (at 103 pages/min), scraped 312164 items (at 72 items/min)
2017-11-04 16:55:03 [scrapy.extensions.logstats] INFO: Crawled 358548 pages (at 128 pages/min), scraped 312262 items (at 98 items/min)
2017-11-04 16:56:03 [scrapy.extensions.logstats] INFO: Crawled 358676 pages (at 128 pages/min), scraped 312358 items (at 96 items/min)
2017-11-04 16:57:03 [scrapy.extensions.logstats] INFO: Crawled 358793 pages (at 117 pages/min), scraped 312457 items (at 99 items/min)
2017-11-04 16:58:03 [scrapy.extensions.logstats] INFO: Crawled 358921 pages (at 128 pages/min), scraped 312554 items (at 97 items/min)
2017-11-04 16:59:03 [scrapy.extensions.logstats] INFO: Crawled 359041 pages (at 120 pages/min), scraped 312668 items (at 114 items/min)
2017-11-04 17:00:04 [scrapy.extensions.logstats] INFO: Crawled 359163 pages (at 122 pages/min), scraped 312755 items (at 87 items/min)
2017-11-04 17:01:04 [scrapy.extensions.logstats] INFO: Crawled 359286 pages (at 123 pages/min), scraped 312858 items (at 103 items/min)
2017-11-04 17:02:04 [scrapy.extensions.logstats] INFO: Crawled 359423 pages (at 137 pages/min), scraped 312966 items (at 108 items/min)
2017-11-04 17:03:03 [scrapy.extensions.logstats] INFO: Crawled 359535 pages (at 112 pages/min), scraped 313066 items (at 100 items/min)
2017-11-04 17:03:12 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39900615&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"路明","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"申万宏源证券有限公司","AOI_ID":"1999090","ADI_ID":"20494","ADI_NAME":"计划财务管理总部","PTI_NAME":"一般证券业务","CER_NUM":"S1180108101125","OBTAIN_DATE":"2008-10-21","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 17:04:04 [scrapy.extensions.logstats] INFO: Crawled 359692 pages (at 157 pages/min), scraped 313220 items (at 154 items/min)
2017-11-04 17:05:03 [scrapy.extensions.logstats] INFO: Crawled 359801 pages (at 109 pages/min), scraped 313305 items (at 85 items/min)
2017-11-04 17:06:03 [scrapy.extensions.logstats] INFO: Crawled 359944 pages (at 143 pages/min), scraped 313454 items (at 149 items/min)
2017-11-04 17:07:03 [scrapy.extensions.logstats] INFO: Crawled 360066 pages (at 122 pages/min), scraped 313566 items (at 112 items/min)
2017-11-04 17:08:03 [scrapy.extensions.logstats] INFO: Crawled 360195 pages (at 129 pages/min), scraped 313680 items (at 114 items/min)
2017-11-04 17:09:03 [scrapy.extensions.logstats] INFO: Crawled 360343 pages (at 148 pages/min), scraped 313815 items (at 135 items/min)
2017-11-04 17:10:03 [scrapy.extensions.logstats] INFO: Crawled 360463 pages (at 120 pages/min), scraped 313917 items (at 102 items/min)
2017-11-04 17:11:03 [scrapy.extensions.logstats] INFO: Crawled 360582 pages (at 119 pages/min), scraped 314038 items (at 121 items/min)
2017-11-04 17:12:03 [scrapy.extensions.logstats] INFO: Crawled 360721 pages (at 139 pages/min), scraped 314149 items (at 111 items/min)
2017-11-04 17:13:03 [scrapy.extensions.logstats] INFO: Crawled 360837 pages (at 116 pages/min), scraped 314245 items (at 96 items/min)
2017-11-04 17:14:03 [scrapy.extensions.logstats] INFO: Crawled 360961 pages (at 124 pages/min), scraped 314342 items (at 97 items/min)
2017-11-04 17:15:03 [scrapy.extensions.logstats] INFO: Crawled 361075 pages (at 114 pages/min), scraped 314447 items (at 105 items/min)
2017-11-04 17:16:05 [scrapy.extensions.logstats] INFO: Crawled 361209 pages (at 134 pages/min), scraped 314560 items (at 113 items/min)
2017-11-04 17:17:06 [scrapy.extensions.logstats] INFO: Crawled 361319 pages (at 110 pages/min), scraped 314645 items (at 85 items/min)
2017-11-04 17:18:04 [scrapy.extensions.logstats] INFO: Crawled 361433 pages (at 114 pages/min), scraped 314733 items (at 88 items/min)
2017-11-04 17:19:03 [scrapy.extensions.logstats] INFO: Crawled 361542 pages (at 109 pages/min), scraped 314844 items (at 111 items/min)
2017-11-04 17:20:03 [scrapy.extensions.logstats] INFO: Crawled 361671 pages (at 129 pages/min), scraped 314937 items (at 93 items/min)
2017-11-04 17:21:03 [scrapy.extensions.logstats] INFO: Crawled 361800 pages (at 129 pages/min), scraped 315049 items (at 112 items/min)
2017-11-04 17:22:03 [scrapy.extensions.logstats] INFO: Crawled 361919 pages (at 119 pages/min), scraped 315152 items (at 103 items/min)
2017-11-04 17:23:03 [scrapy.extensions.logstats] INFO: Crawled 362051 pages (at 132 pages/min), scraped 315261 items (at 109 items/min)
2017-11-04 17:24:03 [scrapy.extensions.logstats] INFO: Crawled 362160 pages (at 109 pages/min), scraped 315356 items (at 95 items/min)
2017-11-04 17:25:03 [scrapy.extensions.logstats] INFO: Crawled 362264 pages (at 104 pages/min), scraped 315450 items (at 94 items/min)
2017-11-04 17:26:03 [scrapy.extensions.logstats] INFO: Crawled 362395 pages (at 131 pages/min), scraped 315551 items (at 101 items/min)
2017-11-04 17:27:03 [scrapy.extensions.logstats] INFO: Crawled 362531 pages (at 136 pages/min), scraped 315668 items (at 117 items/min)
2017-11-04 17:28:03 [scrapy.extensions.logstats] INFO: Crawled 362654 pages (at 123 pages/min), scraped 315765 items (at 97 items/min)
2017-11-04 17:29:03 [scrapy.extensions.logstats] INFO: Crawled 362791 pages (at 137 pages/min), scraped 315871 items (at 106 items/min)
2017-11-04 17:30:03 [scrapy.extensions.logstats] INFO: Crawled 362904 pages (at 113 pages/min), scraped 315975 items (at 104 items/min)
2017-11-04 17:31:03 [scrapy.extensions.logstats] INFO: Crawled 363022 pages (at 118 pages/min), scraped 316076 items (at 101 items/min)
2017-11-04 17:32:03 [scrapy.extensions.logstats] INFO: Crawled 363155 pages (at 133 pages/min), scraped 316192 items (at 116 items/min)
2017-11-04 17:33:03 [scrapy.extensions.logstats] INFO: Crawled 363275 pages (at 120 pages/min), scraped 316292 items (at 100 items/min)
2017-11-04 17:34:04 [scrapy.extensions.logstats] INFO: Crawled 363397 pages (at 122 pages/min), scraped 316393 items (at 101 items/min)
2017-11-04 17:35:05 [scrapy.extensions.logstats] INFO: Crawled 363507 pages (at 110 pages/min), scraped 316494 items (at 101 items/min)
2017-11-04 17:36:03 [scrapy.extensions.logstats] INFO: Crawled 363600 pages (at 93 pages/min), scraped 316575 items (at 81 items/min)
2017-11-04 17:37:04 [scrapy.extensions.logstats] INFO: Crawled 363726 pages (at 126 pages/min), scraped 316668 items (at 93 items/min)
2017-11-04 17:38:03 [scrapy.extensions.logstats] INFO: Crawled 363814 pages (at 88 pages/min), scraped 316751 items (at 83 items/min)
2017-11-04 17:39:05 [scrapy.extensions.logstats] INFO: Crawled 363918 pages (at 104 pages/min), scraped 316837 items (at 86 items/min)
2017-11-04 17:40:03 [scrapy.extensions.logstats] INFO: Crawled 364021 pages (at 103 pages/min), scraped 316913 items (at 76 items/min)
2017-11-04 17:41:03 [scrapy.extensions.logstats] INFO: Crawled 364191 pages (at 170 pages/min), scraped 317056 items (at 143 items/min)
2017-11-04 17:42:03 [scrapy.extensions.logstats] INFO: Crawled 364432 pages (at 241 pages/min), scraped 317279 items (at 223 items/min)
2017-11-04 17:43:03 [scrapy.extensions.logstats] INFO: Crawled 364674 pages (at 242 pages/min), scraped 317494 items (at 215 items/min)
2017-11-04 17:44:03 [scrapy.extensions.logstats] INFO: Crawled 364831 pages (at 157 pages/min), scraped 317637 items (at 143 items/min)
2017-11-04 17:45:03 [scrapy.extensions.logstats] INFO: Crawled 364944 pages (at 113 pages/min), scraped 317734 items (at 97 items/min)
2017-11-04 17:46:03 [scrapy.extensions.logstats] INFO: Crawled 365056 pages (at 112 pages/min), scraped 317841 items (at 107 items/min)
2017-11-04 17:47:04 [scrapy.extensions.logstats] INFO: Crawled 365140 pages (at 84 pages/min), scraped 317920 items (at 79 items/min)
2017-11-04 17:48:03 [scrapy.extensions.logstats] INFO: Crawled 365253 pages (at 113 pages/min), scraped 318029 items (at 109 items/min)
2017-11-04 17:49:03 [scrapy.extensions.logstats] INFO: Crawled 365359 pages (at 106 pages/min), scraped 318131 items (at 102 items/min)
2017-11-04 17:50:04 [scrapy.extensions.logstats] INFO: Crawled 365450 pages (at 91 pages/min), scraped 318226 items (at 95 items/min)
2017-11-04 17:51:04 [scrapy.extensions.logstats] INFO: Crawled 365556 pages (at 106 pages/min), scraped 318310 items (at 84 items/min)
2017-11-04 17:52:04 [scrapy.extensions.logstats] INFO: Crawled 365666 pages (at 110 pages/min), scraped 318402 items (at 92 items/min)
2017-11-04 17:53:05 [scrapy.extensions.logstats] INFO: Crawled 365771 pages (at 105 pages/min), scraped 318508 items (at 106 items/min)
2017-11-04 17:54:04 [scrapy.extensions.logstats] INFO: Crawled 365882 pages (at 111 pages/min), scraped 318609 items (at 101 items/min)
2017-11-04 17:55:06 [scrapy.extensions.logstats] INFO: Crawled 365994 pages (at 112 pages/min), scraped 318708 items (at 99 items/min)
2017-11-04 17:56:03 [scrapy.extensions.logstats] INFO: Crawled 366133 pages (at 139 pages/min), scraped 318847 items (at 139 items/min)
2017-11-04 17:57:03 [scrapy.extensions.logstats] INFO: Crawled 366255 pages (at 122 pages/min), scraped 318959 items (at 112 items/min)
2017-11-04 17:58:04 [scrapy.extensions.logstats] INFO: Crawled 366346 pages (at 91 pages/min), scraped 319027 items (at 68 items/min)
2017-11-04 17:59:04 [scrapy.extensions.logstats] INFO: Crawled 366461 pages (at 115 pages/min), scraped 319133 items (at 106 items/min)
2017-11-04 18:00:03 [scrapy.extensions.logstats] INFO: Crawled 366565 pages (at 104 pages/min), scraped 319221 items (at 88 items/min)
2017-11-04 18:01:04 [scrapy.extensions.logstats] INFO: Crawled 366671 pages (at 106 pages/min), scraped 319313 items (at 92 items/min)
2017-11-04 18:02:03 [scrapy.extensions.logstats] INFO: Crawled 366789 pages (at 118 pages/min), scraped 319423 items (at 110 items/min)
2017-11-04 18:03:04 [scrapy.extensions.logstats] INFO: Crawled 366902 pages (at 113 pages/min), scraped 319528 items (at 105 items/min)
2017-11-04 18:04:04 [scrapy.extensions.logstats] INFO: Crawled 367001 pages (at 99 pages/min), scraped 319610 items (at 82 items/min)
2017-11-04 18:05:04 [scrapy.extensions.logstats] INFO: Crawled 367114 pages (at 113 pages/min), scraped 319699 items (at 89 items/min)
2017-11-04 18:06:03 [scrapy.extensions.logstats] INFO: Crawled 367222 pages (at 108 pages/min), scraped 319781 items (at 82 items/min)
2017-11-04 18:07:03 [scrapy.extensions.logstats] INFO: Crawled 367332 pages (at 110 pages/min), scraped 319871 items (at 90 items/min)
2017-11-04 18:08:03 [scrapy.extensions.logstats] INFO: Crawled 367439 pages (at 107 pages/min), scraped 319968 items (at 97 items/min)
2017-11-04 18:09:03 [scrapy.extensions.logstats] INFO: Crawled 367556 pages (at 117 pages/min), scraped 320081 items (at 113 items/min)
2017-11-04 18:10:04 [scrapy.extensions.logstats] INFO: Crawled 367657 pages (at 101 pages/min), scraped 320164 items (at 83 items/min)
2017-11-04 18:11:04 [scrapy.extensions.logstats] INFO: Crawled 367765 pages (at 108 pages/min), scraped 320247 items (at 83 items/min)
2017-11-04 18:12:03 [scrapy.extensions.logstats] INFO: Crawled 367874 pages (at 109 pages/min), scraped 320342 items (at 95 items/min)
2017-11-04 18:13:04 [scrapy.extensions.logstats] INFO: Crawled 367994 pages (at 120 pages/min), scraped 320440 items (at 98 items/min)
2017-11-04 18:14:03 [scrapy.extensions.logstats] INFO: Crawled 368105 pages (at 111 pages/min), scraped 320537 items (at 97 items/min)
2017-11-04 18:15:04 [scrapy.extensions.logstats] INFO: Crawled 368230 pages (at 125 pages/min), scraped 320628 items (at 91 items/min)
2017-11-04 18:16:03 [scrapy.extensions.logstats] INFO: Crawled 368338 pages (at 108 pages/min), scraped 320730 items (at 102 items/min)
2017-11-04 18:17:05 [scrapy.extensions.logstats] INFO: Crawled 368449 pages (at 111 pages/min), scraped 320824 items (at 94 items/min)
2017-11-04 18:18:03 [scrapy.extensions.logstats] INFO: Crawled 368561 pages (at 112 pages/min), scraped 320944 items (at 120 items/min)
2017-11-04 18:19:04 [scrapy.extensions.logstats] INFO: Crawled 368651 pages (at 90 pages/min), scraped 321015 items (at 71 items/min)
2017-11-04 18:20:04 [scrapy.extensions.logstats] INFO: Crawled 368762 pages (at 111 pages/min), scraped 321127 items (at 112 items/min)
2017-11-04 18:21:04 [scrapy.extensions.logstats] INFO: Crawled 368890 pages (at 128 pages/min), scraped 321213 items (at 86 items/min)
2017-11-04 18:22:04 [scrapy.extensions.logstats] INFO: Crawled 368988 pages (at 98 pages/min), scraped 321338 items (at 125 items/min)
2017-11-04 18:23:03 [scrapy.extensions.logstats] INFO: Crawled 369112 pages (at 124 pages/min), scraped 321432 items (at 94 items/min)
2017-11-04 18:24:04 [scrapy.extensions.logstats] INFO: Crawled 369221 pages (at 109 pages/min), scraped 321535 items (at 103 items/min)
2017-11-04 18:25:03 [scrapy.extensions.logstats] INFO: Crawled 369333 pages (at 112 pages/min), scraped 321621 items (at 86 items/min)
2017-11-04 18:26:03 [scrapy.extensions.logstats] INFO: Crawled 369446 pages (at 113 pages/min), scraped 321736 items (at 115 items/min)
2017-11-04 18:27:04 [scrapy.extensions.logstats] INFO: Crawled 369553 pages (at 107 pages/min), scraped 321809 items (at 73 items/min)
2017-11-04 18:28:04 [scrapy.extensions.logstats] INFO: Crawled 369664 pages (at 111 pages/min), scraped 321901 items (at 92 items/min)
2017-11-04 18:29:04 [scrapy.extensions.logstats] INFO: Crawled 369776 pages (at 112 pages/min), scraped 322004 items (at 103 items/min)
2017-11-04 18:30:04 [scrapy.extensions.logstats] INFO: Crawled 369883 pages (at 107 pages/min), scraped 322100 items (at 96 items/min)
2017-11-04 18:31:04 [scrapy.extensions.logstats] INFO: Crawled 369992 pages (at 109 pages/min), scraped 322201 items (at 101 items/min)
2017-11-04 18:32:04 [scrapy.extensions.logstats] INFO: Crawled 370105 pages (at 113 pages/min), scraped 322301 items (at 100 items/min)
2017-11-04 18:33:04 [scrapy.extensions.logstats] INFO: Crawled 370218 pages (at 113 pages/min), scraped 322406 items (at 105 items/min)
2017-11-04 18:34:04 [scrapy.extensions.logstats] INFO: Crawled 370321 pages (at 103 pages/min), scraped 322498 items (at 92 items/min)
2017-11-04 18:35:04 [scrapy.extensions.logstats] INFO: Crawled 370432 pages (at 111 pages/min), scraped 322615 items (at 117 items/min)
2017-11-04 18:36:04 [scrapy.extensions.logstats] INFO: Crawled 370540 pages (at 108 pages/min), scraped 322712 items (at 97 items/min)
2017-11-04 18:37:03 [scrapy.extensions.logstats] INFO: Crawled 370638 pages (at 98 pages/min), scraped 322840 items (at 128 items/min)
2017-11-04 18:38:03 [scrapy.extensions.logstats] INFO: Crawled 370755 pages (at 117 pages/min), scraped 322927 items (at 87 items/min)
2017-11-04 18:39:06 [scrapy.extensions.logstats] INFO: Crawled 370868 pages (at 113 pages/min), scraped 323051 items (at 124 items/min)
2017-11-04 18:40:04 [scrapy.extensions.logstats] INFO: Crawled 370960 pages (at 92 pages/min), scraped 323121 items (at 70 items/min)
2017-11-04 18:41:04 [scrapy.extensions.logstats] INFO: Crawled 371095 pages (at 135 pages/min), scraped 323272 items (at 151 items/min)
2017-11-04 18:42:04 [scrapy.extensions.logstats] INFO: Crawled 371182 pages (at 87 pages/min), scraped 323343 items (at 71 items/min)
2017-11-04 18:43:04 [scrapy.extensions.logstats] INFO: Crawled 371287 pages (at 105 pages/min), scraped 323467 items (at 124 items/min)
2017-11-04 18:44:03 [scrapy.extensions.logstats] INFO: Crawled 371396 pages (at 109 pages/min), scraped 323555 items (at 88 items/min)
2017-11-04 18:45:04 [scrapy.extensions.logstats] INFO: Crawled 371501 pages (at 105 pages/min), scraped 323670 items (at 115 items/min)
2017-11-04 18:46:05 [scrapy.extensions.logstats] INFO: Crawled 371592 pages (at 91 pages/min), scraped 323751 items (at 81 items/min)
2017-11-04 18:47:04 [scrapy.extensions.logstats] INFO: Crawled 371699 pages (at 107 pages/min), scraped 323847 items (at 96 items/min)
2017-11-04 18:48:05 [scrapy.extensions.logstats] INFO: Crawled 371807 pages (at 108 pages/min), scraped 323960 items (at 113 items/min)
2017-11-04 18:49:03 [scrapy.extensions.logstats] INFO: Crawled 371914 pages (at 107 pages/min), scraped 324078 items (at 118 items/min)
2017-11-04 18:50:05 [scrapy.extensions.logstats] INFO: Crawled 372033 pages (at 119 pages/min), scraped 324184 items (at 106 items/min)
2017-11-04 18:51:03 [scrapy.extensions.logstats] INFO: Crawled 372130 pages (at 97 pages/min), scraped 324279 items (at 95 items/min)
2017-11-04 18:52:03 [scrapy.extensions.logstats] INFO: Crawled 372229 pages (at 99 pages/min), scraped 324355 items (at 76 items/min)
2017-11-04 18:53:03 [scrapy.extensions.logstats] INFO: Crawled 372320 pages (at 91 pages/min), scraped 324460 items (at 105 items/min)
2017-11-04 18:54:05 [scrapy.extensions.logstats] INFO: Crawled 372424 pages (at 104 pages/min), scraped 324529 items (at 69 items/min)
2017-11-04 18:55:03 [scrapy.extensions.logstats] INFO: Crawled 372518 pages (at 94 pages/min), scraped 324633 items (at 104 items/min)
2017-11-04 18:56:04 [scrapy.extensions.logstats] INFO: Crawled 372640 pages (at 122 pages/min), scraped 324738 items (at 105 items/min)
2017-11-04 18:57:04 [scrapy.extensions.logstats] INFO: Crawled 372744 pages (at 104 pages/min), scraped 324825 items (at 87 items/min)
2017-11-04 18:58:03 [scrapy.extensions.logstats] INFO: Crawled 372854 pages (at 110 pages/min), scraped 324924 items (at 99 items/min)
2017-11-04 18:59:03 [scrapy.extensions.logstats] INFO: Crawled 372961 pages (at 107 pages/min), scraped 325025 items (at 101 items/min)
2017-11-04 19:00:04 [scrapy.extensions.logstats] INFO: Crawled 373062 pages (at 101 pages/min), scraped 325098 items (at 73 items/min)
2017-11-04 19:01:04 [scrapy.extensions.logstats] INFO: Crawled 373176 pages (at 114 pages/min), scraped 325200 items (at 102 items/min)
2017-11-04 19:02:06 [scrapy.extensions.logstats] INFO: Crawled 373302 pages (at 126 pages/min), scraped 325294 items (at 94 items/min)
2017-11-04 19:03:03 [scrapy.extensions.logstats] INFO: Crawled 373406 pages (at 104 pages/min), scraped 325400 items (at 106 items/min)
2017-11-04 19:04:05 [scrapy.extensions.logstats] INFO: Crawled 373512 pages (at 106 pages/min), scraped 325474 items (at 74 items/min)
2017-11-04 19:05:04 [scrapy.extensions.logstats] INFO: Crawled 373618 pages (at 106 pages/min), scraped 325573 items (at 99 items/min)
2017-11-04 19:06:03 [scrapy.extensions.logstats] INFO: Crawled 373712 pages (at 94 pages/min), scraped 325658 items (at 85 items/min)
2017-11-04 19:07:03 [scrapy.extensions.logstats] INFO: Crawled 373807 pages (at 95 pages/min), scraped 325755 items (at 97 items/min)
2017-11-04 19:08:03 [scrapy.extensions.logstats] INFO: Crawled 373923 pages (at 116 pages/min), scraped 325873 items (at 118 items/min)
2017-11-04 19:09:03 [scrapy.extensions.logstats] INFO: Crawled 374048 pages (at 125 pages/min), scraped 326029 items (at 156 items/min)
2017-11-04 19:10:03 [scrapy.extensions.logstats] INFO: Crawled 374155 pages (at 107 pages/min), scraped 326133 items (at 104 items/min)
2017-11-04 19:11:03 [scrapy.extensions.logstats] INFO: Crawled 374267 pages (at 112 pages/min), scraped 326292 items (at 159 items/min)
2017-11-04 19:12:03 [scrapy.extensions.logstats] INFO: Crawled 374374 pages (at 107 pages/min), scraped 326424 items (at 132 items/min)
2017-11-04 19:13:03 [scrapy.extensions.logstats] INFO: Crawled 374488 pages (at 114 pages/min), scraped 326573 items (at 149 items/min)
2017-11-04 19:14:04 [scrapy.extensions.logstats] INFO: Crawled 374584 pages (at 96 pages/min), scraped 326691 items (at 118 items/min)
2017-11-04 19:15:03 [scrapy.extensions.logstats] INFO: Crawled 374693 pages (at 109 pages/min), scraped 326815 items (at 124 items/min)
2017-11-04 19:16:03 [scrapy.extensions.logstats] INFO: Crawled 374800 pages (at 107 pages/min), scraped 326929 items (at 114 items/min)
2017-11-04 19:17:04 [scrapy.extensions.logstats] INFO: Crawled 374891 pages (at 91 pages/min), scraped 327066 items (at 137 items/min)
2017-11-04 19:18:04 [scrapy.extensions.logstats] INFO: Crawled 375000 pages (at 109 pages/min), scraped 327225 items (at 159 items/min)
2017-11-04 19:19:04 [scrapy.extensions.logstats] INFO: Crawled 375103 pages (at 103 pages/min), scraped 327357 items (at 132 items/min)
2017-11-04 19:20:03 [scrapy.extensions.logstats] INFO: Crawled 375233 pages (at 130 pages/min), scraped 327565 items (at 208 items/min)
2017-11-04 19:21:06 [scrapy.extensions.logstats] INFO: Crawled 375350 pages (at 117 pages/min), scraped 327723 items (at 158 items/min)
2017-11-04 19:22:03 [scrapy.extensions.logstats] INFO: Crawled 375460 pages (at 110 pages/min), scraped 327889 items (at 166 items/min)
2017-11-04 19:23:04 [scrapy.extensions.logstats] INFO: Crawled 375570 pages (at 110 pages/min), scraped 328016 items (at 127 items/min)
2017-11-04 19:24:03 [scrapy.extensions.logstats] INFO: Crawled 375683 pages (at 113 pages/min), scraped 328160 items (at 144 items/min)
2017-11-04 19:25:03 [scrapy.extensions.logstats] INFO: Crawled 375792 pages (at 109 pages/min), scraped 328279 items (at 119 items/min)
2017-11-04 19:26:03 [scrapy.extensions.logstats] INFO: Crawled 375902 pages (at 110 pages/min), scraped 328434 items (at 155 items/min)
2017-11-04 19:27:03 [scrapy.extensions.logstats] INFO: Crawled 376015 pages (at 113 pages/min), scraped 328546 items (at 112 items/min)
2017-11-04 19:28:04 [scrapy.extensions.logstats] INFO: Crawled 376122 pages (at 107 pages/min), scraped 328701 items (at 155 items/min)
2017-11-04 19:29:03 [scrapy.extensions.logstats] INFO: Crawled 376233 pages (at 111 pages/min), scraped 328802 items (at 101 items/min)
2017-11-04 19:30:03 [scrapy.extensions.logstats] INFO: Crawled 376329 pages (at 96 pages/min), scraped 328970 items (at 168 items/min)
2017-11-04 19:31:04 [scrapy.extensions.logstats] INFO: Crawled 376430 pages (at 101 pages/min), scraped 329048 items (at 78 items/min)
2017-11-04 19:32:06 [scrapy.extensions.logstats] INFO: Crawled 376550 pages (at 120 pages/min), scraped 329154 items (at 106 items/min)
2017-11-04 19:33:03 [scrapy.extensions.logstats] INFO: Crawled 376656 pages (at 106 pages/min), scraped 329228 items (at 74 items/min)
2017-11-04 19:34:05 [scrapy.extensions.logstats] INFO: Crawled 376758 pages (at 102 pages/min), scraped 329321 items (at 93 items/min)
2017-11-04 19:35:03 [scrapy.extensions.logstats] INFO: Crawled 376853 pages (at 95 pages/min), scraped 329405 items (at 84 items/min)
2017-11-04 19:36:03 [scrapy.extensions.logstats] INFO: Crawled 376953 pages (at 100 pages/min), scraped 329480 items (at 75 items/min)
2017-11-04 19:37:03 [scrapy.extensions.logstats] INFO: Crawled 377054 pages (at 101 pages/min), scraped 329574 items (at 94 items/min)
2017-11-04 19:38:05 [scrapy.extensions.logstats] INFO: Crawled 377151 pages (at 97 pages/min), scraped 329644 items (at 70 items/min)
2017-11-04 19:39:03 [scrapy.extensions.logstats] INFO: Crawled 377261 pages (at 110 pages/min), scraped 329739 items (at 95 items/min)
2017-11-04 19:40:06 [scrapy.extensions.logstats] INFO: Crawled 377370 pages (at 109 pages/min), scraped 329827 items (at 88 items/min)
2017-11-04 19:41:03 [scrapy.extensions.logstats] INFO: Crawled 377479 pages (at 109 pages/min), scraped 329924 items (at 97 items/min)
2017-11-04 19:42:03 [scrapy.extensions.logstats] INFO: Crawled 377582 pages (at 103 pages/min), scraped 330016 items (at 92 items/min)
2017-11-04 19:43:04 [scrapy.extensions.logstats] INFO: Crawled 377689 pages (at 107 pages/min), scraped 330105 items (at 89 items/min)
2017-11-04 19:44:05 [scrapy.extensions.logstats] INFO: Crawled 377788 pages (at 99 pages/min), scraped 330193 items (at 88 items/min)
2017-11-04 19:45:04 [scrapy.extensions.logstats] INFO: Crawled 377881 pages (at 93 pages/min), scraped 330283 items (at 90 items/min)
2017-11-04 19:46:04 [scrapy.extensions.logstats] INFO: Crawled 377972 pages (at 91 pages/min), scraped 330400 items (at 117 items/min)
2017-11-04 19:47:03 [scrapy.extensions.logstats] INFO: Crawled 378077 pages (at 105 pages/min), scraped 330515 items (at 115 items/min)
2017-11-04 19:48:04 [scrapy.extensions.logstats] INFO: Crawled 378186 pages (at 109 pages/min), scraped 330628 items (at 113 items/min)
2017-11-04 19:49:04 [scrapy.extensions.logstats] INFO: Crawled 378295 pages (at 109 pages/min), scraped 330751 items (at 123 items/min)
2017-11-04 19:50:03 [scrapy.extensions.logstats] INFO: Crawled 378404 pages (at 109 pages/min), scraped 330863 items (at 112 items/min)
2017-11-04 19:51:04 [scrapy.extensions.logstats] INFO: Crawled 378511 pages (at 107 pages/min), scraped 330977 items (at 114 items/min)
2017-11-04 19:52:03 [scrapy.extensions.logstats] INFO: Crawled 378623 pages (at 112 pages/min), scraped 331098 items (at 121 items/min)
2017-11-04 19:53:03 [scrapy.extensions.logstats] INFO: Crawled 378741 pages (at 118 pages/min), scraped 331233 items (at 135 items/min)
2017-11-04 19:54:03 [scrapy.extensions.logstats] INFO: Crawled 378861 pages (at 120 pages/min), scraped 331363 items (at 130 items/min)
2017-11-04 19:55:04 [scrapy.extensions.logstats] INFO: Crawled 378974 pages (at 113 pages/min), scraped 331496 items (at 133 items/min)
2017-11-04 19:56:04 [scrapy.extensions.logstats] INFO: Crawled 379067 pages (at 93 pages/min), scraped 331593 items (at 97 items/min)
2017-11-04 19:57:03 [scrapy.extensions.logstats] INFO: Crawled 379163 pages (at 96 pages/min), scraped 331690 items (at 97 items/min)
2017-11-04 19:58:03 [scrapy.extensions.logstats] INFO: Crawled 379268 pages (at 105 pages/min), scraped 331758 items (at 68 items/min)
2017-11-04 19:59:04 [scrapy.extensions.logstats] INFO: Crawled 379366 pages (at 98 pages/min), scraped 331822 items (at 64 items/min)
2017-11-04 20:00:04 [scrapy.extensions.logstats] INFO: Crawled 379466 pages (at 100 pages/min), scraped 331901 items (at 79 items/min)
2017-11-04 20:01:03 [scrapy.extensions.logstats] INFO: Crawled 379579 pages (at 113 pages/min), scraped 332013 items (at 112 items/min)
2017-11-04 20:02:04 [scrapy.extensions.logstats] INFO: Crawled 379692 pages (at 113 pages/min), scraped 332121 items (at 108 items/min)
2017-11-04 20:03:04 [scrapy.extensions.logstats] INFO: Crawled 379801 pages (at 109 pages/min), scraped 332229 items (at 108 items/min)
2017-11-04 20:04:04 [scrapy.extensions.logstats] INFO: Crawled 379909 pages (at 108 pages/min), scraped 332336 items (at 107 items/min)
2017-11-04 20:05:04 [scrapy.extensions.logstats] INFO: Crawled 380030 pages (at 121 pages/min), scraped 332430 items (at 94 items/min)
2017-11-04 20:06:03 [scrapy.extensions.logstats] INFO: Crawled 380122 pages (at 92 pages/min), scraped 332504 items (at 74 items/min)
2017-11-04 20:07:03 [scrapy.extensions.logstats] INFO: Crawled 380233 pages (at 111 pages/min), scraped 332589 items (at 85 items/min)
2017-11-04 20:08:04 [scrapy.extensions.logstats] INFO: Crawled 380352 pages (at 119 pages/min), scraped 332685 items (at 96 items/min)
2017-11-04 20:09:04 [scrapy.extensions.logstats] INFO: Crawled 380458 pages (at 106 pages/min), scraped 332772 items (at 87 items/min)
2017-11-04 20:10:04 [scrapy.extensions.logstats] INFO: Crawled 380590 pages (at 132 pages/min), scraped 332877 items (at 105 items/min)
2017-11-04 20:11:03 [scrapy.extensions.logstats] INFO: Crawled 380693 pages (at 103 pages/min), scraped 332949 items (at 72 items/min)
2017-11-04 20:12:04 [scrapy.extensions.logstats] INFO: Crawled 380784 pages (at 91 pages/min), scraped 333036 items (at 87 items/min)
2017-11-04 20:13:03 [scrapy.extensions.logstats] INFO: Crawled 380894 pages (at 110 pages/min), scraped 333122 items (at 86 items/min)
2017-11-04 20:14:04 [scrapy.extensions.logstats] INFO: Crawled 381018 pages (at 124 pages/min), scraped 333228 items (at 106 items/min)
2017-11-04 20:15:03 [scrapy.extensions.logstats] INFO: Crawled 381112 pages (at 94 pages/min), scraped 333316 items (at 88 items/min)
2017-11-04 20:16:03 [scrapy.extensions.logstats] INFO: Crawled 381225 pages (at 113 pages/min), scraped 333406 items (at 90 items/min)
2017-11-04 20:17:03 [scrapy.extensions.logstats] INFO: Crawled 381341 pages (at 116 pages/min), scraped 333486 items (at 80 items/min)
2017-11-04 20:18:04 [scrapy.extensions.logstats] INFO: Crawled 381469 pages (at 128 pages/min), scraped 333584 items (at 98 items/min)
2017-11-04 20:19:03 [scrapy.extensions.logstats] INFO: Crawled 381578 pages (at 109 pages/min), scraped 333663 items (at 79 items/min)
2017-11-04 20:20:04 [scrapy.extensions.logstats] INFO: Crawled 381692 pages (at 114 pages/min), scraped 333744 items (at 81 items/min)
2017-11-04 20:21:05 [scrapy.extensions.logstats] INFO: Crawled 381798 pages (at 106 pages/min), scraped 333828 items (at 84 items/min)
2017-11-04 20:22:04 [scrapy.extensions.logstats] INFO: Crawled 381912 pages (at 114 pages/min), scraped 333906 items (at 78 items/min)
2017-11-04 20:23:03 [scrapy.extensions.logstats] INFO: Crawled 382010 pages (at 98 pages/min), scraped 333988 items (at 82 items/min)
2017-11-04 20:24:04 [scrapy.extensions.logstats] INFO: Crawled 382110 pages (at 100 pages/min), scraped 334074 items (at 86 items/min)
2017-11-04 20:25:03 [scrapy.extensions.logstats] INFO: Crawled 382235 pages (at 125 pages/min), scraped 334180 items (at 106 items/min)
2017-11-04 20:26:04 [scrapy.extensions.logstats] INFO: Crawled 382357 pages (at 122 pages/min), scraped 334300 items (at 120 items/min)
2017-11-04 20:27:04 [scrapy.extensions.logstats] INFO: Crawled 382461 pages (at 104 pages/min), scraped 334414 items (at 114 items/min)
2017-11-04 20:28:04 [scrapy.extensions.logstats] INFO: Crawled 382565 pages (at 104 pages/min), scraped 334534 items (at 120 items/min)
2017-11-04 20:29:03 [scrapy.extensions.logstats] INFO: Crawled 382660 pages (at 95 pages/min), scraped 334645 items (at 111 items/min)
2017-11-04 20:30:04 [scrapy.extensions.logstats] INFO: Crawled 382762 pages (at 102 pages/min), scraped 334719 items (at 74 items/min)
2017-11-04 20:31:03 [scrapy.extensions.logstats] INFO: Crawled 382862 pages (at 100 pages/min), scraped 334796 items (at 77 items/min)
2017-11-04 20:32:04 [scrapy.extensions.logstats] INFO: Crawled 382965 pages (at 103 pages/min), scraped 334885 items (at 89 items/min)
2017-11-04 20:33:04 [scrapy.extensions.logstats] INFO: Crawled 383066 pages (at 101 pages/min), scraped 334969 items (at 84 items/min)
2017-11-04 20:34:03 [scrapy.extensions.logstats] INFO: Crawled 383177 pages (at 111 pages/min), scraped 335071 items (at 102 items/min)
2017-11-04 20:35:03 [scrapy.extensions.logstats] INFO: Crawled 383295 pages (at 118 pages/min), scraped 335196 items (at 125 items/min)
2017-11-04 20:36:03 [scrapy.extensions.logstats] INFO: Crawled 383396 pages (at 101 pages/min), scraped 335272 items (at 76 items/min)
2017-11-04 20:37:04 [scrapy.extensions.logstats] INFO: Crawled 383499 pages (at 103 pages/min), scraped 335371 items (at 99 items/min)
2017-11-04 20:38:05 [scrapy.extensions.logstats] INFO: Crawled 383579 pages (at 80 pages/min), scraped 335437 items (at 66 items/min)
2017-11-04 20:39:04 [scrapy.extensions.logstats] INFO: Crawled 383670 pages (at 91 pages/min), scraped 335519 items (at 82 items/min)
2017-11-04 20:40:03 [scrapy.extensions.logstats] INFO: Crawled 383783 pages (at 113 pages/min), scraped 335625 items (at 106 items/min)
2017-11-04 20:41:03 [scrapy.extensions.logstats] INFO: Crawled 383899 pages (at 116 pages/min), scraped 335741 items (at 116 items/min)
2017-11-04 20:42:03 [scrapy.extensions.logstats] INFO: Crawled 384017 pages (at 118 pages/min), scraped 335857 items (at 116 items/min)
2017-11-04 20:43:04 [scrapy.extensions.logstats] INFO: Crawled 384121 pages (at 104 pages/min), scraped 335949 items (at 92 items/min)
2017-11-04 20:44:05 [scrapy.extensions.logstats] INFO: Crawled 384230 pages (at 109 pages/min), scraped 336050 items (at 101 items/min)
2017-11-04 20:45:03 [scrapy.extensions.logstats] INFO: Crawled 384339 pages (at 109 pages/min), scraped 336132 items (at 82 items/min)
2017-11-04 20:46:03 [scrapy.extensions.logstats] INFO: Crawled 384439 pages (at 100 pages/min), scraped 336211 items (at 79 items/min)
2017-11-04 20:47:03 [scrapy.extensions.logstats] INFO: Crawled 384555 pages (at 116 pages/min), scraped 336291 items (at 80 items/min)
2017-11-04 20:48:04 [scrapy.extensions.logstats] INFO: Crawled 384657 pages (at 102 pages/min), scraped 336370 items (at 79 items/min)
2017-11-04 20:49:03 [scrapy.extensions.logstats] INFO: Crawled 384751 pages (at 94 pages/min), scraped 336444 items (at 74 items/min)
2017-11-04 20:50:03 [scrapy.extensions.logstats] INFO: Crawled 384867 pages (at 116 pages/min), scraped 336547 items (at 103 items/min)
2017-11-04 20:51:04 [scrapy.extensions.logstats] INFO: Crawled 384970 pages (at 103 pages/min), scraped 336634 items (at 87 items/min)
2017-11-04 20:52:03 [scrapy.extensions.logstats] INFO: Crawled 385068 pages (at 98 pages/min), scraped 336728 items (at 94 items/min)
2017-11-04 20:53:03 [scrapy.extensions.logstats] INFO: Crawled 385175 pages (at 107 pages/min), scraped 336856 items (at 128 items/min)
2017-11-04 20:54:04 [scrapy.extensions.logstats] INFO: Crawled 385294 pages (at 119 pages/min), scraped 336951 items (at 95 items/min)
2017-11-04 20:55:04 [scrapy.extensions.logstats] INFO: Crawled 385414 pages (at 120 pages/min), scraped 337042 items (at 91 items/min)
2017-11-04 20:56:03 [scrapy.extensions.logstats] INFO: Crawled 385521 pages (at 107 pages/min), scraped 337126 items (at 84 items/min)
2017-11-04 20:57:03 [scrapy.extensions.logstats] INFO: Crawled 385627 pages (at 106 pages/min), scraped 337205 items (at 79 items/min)
2017-11-04 20:58:03 [scrapy.extensions.logstats] INFO: Crawled 385738 pages (at 111 pages/min), scraped 337314 items (at 109 items/min)
2017-11-04 20:59:07 [scrapy.extensions.logstats] INFO: Crawled 385849 pages (at 111 pages/min), scraped 337411 items (at 97 items/min)
2017-11-04 21:00:04 [scrapy.extensions.logstats] INFO: Crawled 385955 pages (at 106 pages/min), scraped 337533 items (at 122 items/min)
2017-11-04 21:01:03 [scrapy.extensions.logstats] INFO: Crawled 386055 pages (at 100 pages/min), scraped 337612 items (at 79 items/min)
2017-11-04 21:02:04 [scrapy.extensions.logstats] INFO: Crawled 386172 pages (at 117 pages/min), scraped 337697 items (at 85 items/min)
2017-11-04 21:03:03 [scrapy.extensions.logstats] INFO: Crawled 386264 pages (at 92 pages/min), scraped 337771 items (at 74 items/min)
2017-11-04 21:04:03 [scrapy.extensions.logstats] INFO: Crawled 386386 pages (at 122 pages/min), scraped 337845 items (at 74 items/min)
2017-11-04 21:05:04 [scrapy.extensions.logstats] INFO: Crawled 386496 pages (at 110 pages/min), scraped 337933 items (at 88 items/min)
2017-11-04 21:06:03 [scrapy.extensions.logstats] INFO: Crawled 386607 pages (at 111 pages/min), scraped 338008 items (at 75 items/min)
2017-11-04 21:07:04 [scrapy.extensions.logstats] INFO: Crawled 386720 pages (at 113 pages/min), scraped 338095 items (at 87 items/min)
2017-11-04 21:08:04 [scrapy.extensions.logstats] INFO: Crawled 386834 pages (at 114 pages/min), scraped 338194 items (at 99 items/min)
2017-11-04 21:09:04 [scrapy.extensions.logstats] INFO: Crawled 386943 pages (at 109 pages/min), scraped 338298 items (at 104 items/min)
2017-11-04 21:10:04 [scrapy.extensions.logstats] INFO: Crawled 387043 pages (at 100 pages/min), scraped 338389 items (at 91 items/min)
2017-11-04 21:11:04 [scrapy.extensions.logstats] INFO: Crawled 387150 pages (at 107 pages/min), scraped 338492 items (at 103 items/min)
2017-11-04 21:12:05 [scrapy.extensions.logstats] INFO: Crawled 387242 pages (at 92 pages/min), scraped 338584 items (at 92 items/min)
2017-11-04 21:13:03 [scrapy.extensions.logstats] INFO: Crawled 387357 pages (at 115 pages/min), scraped 338688 items (at 104 items/min)
2017-11-04 21:14:03 [scrapy.extensions.logstats] INFO: Crawled 387464 pages (at 107 pages/min), scraped 338782 items (at 94 items/min)
2017-11-04 21:15:06 [scrapy.extensions.logstats] INFO: Crawled 387566 pages (at 102 pages/min), scraped 338868 items (at 86 items/min)
2017-11-04 21:16:04 [scrapy.extensions.logstats] INFO: Crawled 387677 pages (at 111 pages/min), scraped 338976 items (at 108 items/min)
2017-11-04 21:17:04 [scrapy.extensions.logstats] INFO: Crawled 387803 pages (at 126 pages/min), scraped 339122 items (at 146 items/min)
2017-11-04 21:18:03 [scrapy.extensions.logstats] INFO: Crawled 387895 pages (at 92 pages/min), scraped 339261 items (at 139 items/min)
2017-11-04 21:19:05 [scrapy.extensions.logstats] INFO: Crawled 388002 pages (at 107 pages/min), scraped 339388 items (at 127 items/min)
2017-11-04 21:20:03 [scrapy.extensions.logstats] INFO: Crawled 388109 pages (at 107 pages/min), scraped 339543 items (at 155 items/min)
2017-11-04 21:21:03 [scrapy.extensions.logstats] INFO: Crawled 388201 pages (at 92 pages/min), scraped 339703 items (at 160 items/min)
2017-11-04 21:22:05 [scrapy.extensions.logstats] INFO: Crawled 388324 pages (at 123 pages/min), scraped 339883 items (at 180 items/min)
2017-11-04 21:23:04 [scrapy.extensions.logstats] INFO: Crawled 388419 pages (at 95 pages/min), scraped 339976 items (at 93 items/min)
2017-11-04 21:24:03 [scrapy.extensions.logstats] INFO: Crawled 388531 pages (at 112 pages/min), scraped 340121 items (at 145 items/min)
2017-11-04 21:25:03 [scrapy.extensions.logstats] INFO: Crawled 388643 pages (at 112 pages/min), scraped 340234 items (at 113 items/min)
2017-11-04 21:26:04 [scrapy.extensions.logstats] INFO: Crawled 388761 pages (at 118 pages/min), scraped 340338 items (at 104 items/min)
2017-11-04 21:27:03 [scrapy.extensions.logstats] INFO: Crawled 388877 pages (at 116 pages/min), scraped 340448 items (at 110 items/min)
2017-11-04 21:28:04 [scrapy.extensions.logstats] INFO: Crawled 388991 pages (at 114 pages/min), scraped 340561 items (at 113 items/min)
2017-11-04 21:29:03 [scrapy.extensions.logstats] INFO: Crawled 389099 pages (at 108 pages/min), scraped 340657 items (at 96 items/min)
2017-11-04 21:30:04 [scrapy.extensions.logstats] INFO: Crawled 389203 pages (at 104 pages/min), scraped 340754 items (at 97 items/min)
2017-11-04 21:31:04 [scrapy.extensions.logstats] INFO: Crawled 389311 pages (at 108 pages/min), scraped 340861 items (at 107 items/min)
2017-11-04 21:32:04 [scrapy.extensions.logstats] INFO: Crawled 389427 pages (at 116 pages/min), scraped 340982 items (at 121 items/min)
2017-11-04 21:33:04 [scrapy.extensions.logstats] INFO: Crawled 389538 pages (at 111 pages/min), scraped 341098 items (at 116 items/min)
2017-11-04 21:34:03 [scrapy.extensions.logstats] INFO: Crawled 389638 pages (at 100 pages/min), scraped 341206 items (at 108 items/min)
2017-11-04 21:35:04 [scrapy.extensions.logstats] INFO: Crawled 389760 pages (at 122 pages/min), scraped 341311 items (at 105 items/min)
2017-11-04 21:36:04 [scrapy.extensions.logstats] INFO: Crawled 389865 pages (at 105 pages/min), scraped 341388 items (at 77 items/min)
2017-11-04 21:37:04 [scrapy.extensions.logstats] INFO: Crawled 389989 pages (at 124 pages/min), scraped 341499 items (at 111 items/min)
2017-11-04 21:38:06 [scrapy.extensions.logstats] INFO: Crawled 390107 pages (at 118 pages/min), scraped 341608 items (at 109 items/min)
2017-11-04 21:39:03 [scrapy.extensions.logstats] INFO: Crawled 390200 pages (at 93 pages/min), scraped 341691 items (at 83 items/min)
2017-11-04 21:40:03 [scrapy.extensions.logstats] INFO: Crawled 390311 pages (at 111 pages/min), scraped 341771 items (at 80 items/min)
2017-11-04 21:41:03 [scrapy.extensions.logstats] INFO: Crawled 390437 pages (at 126 pages/min), scraped 341866 items (at 95 items/min)
2017-11-04 21:42:04 [scrapy.extensions.logstats] INFO: Crawled 390545 pages (at 108 pages/min), scraped 341949 items (at 83 items/min)
2017-11-04 21:43:04 [scrapy.extensions.logstats] INFO: Crawled 390652 pages (at 107 pages/min), scraped 342059 items (at 110 items/min)
2017-11-04 21:44:03 [scrapy.extensions.logstats] INFO: Crawled 390760 pages (at 108 pages/min), scraped 342168 items (at 109 items/min)
2017-11-04 21:45:03 [scrapy.extensions.logstats] INFO: Crawled 390866 pages (at 106 pages/min), scraped 342267 items (at 99 items/min)
2017-11-04 21:46:04 [scrapy.extensions.logstats] INFO: Crawled 390986 pages (at 120 pages/min), scraped 342359 items (at 92 items/min)
2017-11-04 21:47:03 [scrapy.extensions.logstats] INFO: Crawled 391099 pages (at 113 pages/min), scraped 342431 items (at 72 items/min)
2017-11-04 21:48:03 [scrapy.extensions.logstats] INFO: Crawled 391203 pages (at 104 pages/min), scraped 342502 items (at 71 items/min)
2017-11-04 21:49:04 [scrapy.extensions.logstats] INFO: Crawled 391306 pages (at 103 pages/min), scraped 342604 items (at 102 items/min)
2017-11-04 21:50:04 [scrapy.extensions.logstats] INFO: Crawled 391405 pages (at 99 pages/min), scraped 342729 items (at 125 items/min)
2017-11-04 21:51:03 [scrapy.extensions.logstats] INFO: Crawled 391526 pages (at 121 pages/min), scraped 342882 items (at 153 items/min)
2017-11-04 21:52:04 [scrapy.extensions.logstats] INFO: Crawled 391650 pages (at 124 pages/min), scraped 342986 items (at 104 items/min)
2017-11-04 21:53:04 [scrapy.extensions.logstats] INFO: Crawled 391750 pages (at 100 pages/min), scraped 343045 items (at 59 items/min)
2017-11-04 21:54:03 [scrapy.extensions.logstats] INFO: Crawled 391847 pages (at 97 pages/min), scraped 343113 items (at 68 items/min)
2017-11-04 21:55:03 [scrapy.extensions.logstats] INFO: Crawled 391955 pages (at 108 pages/min), scraped 343196 items (at 83 items/min)
2017-11-04 21:56:03 [scrapy.extensions.logstats] INFO: Crawled 392054 pages (at 99 pages/min), scraped 343269 items (at 73 items/min)
2017-11-04 21:57:04 [scrapy.extensions.logstats] INFO: Crawled 392177 pages (at 123 pages/min), scraped 343378 items (at 109 items/min)
2017-11-04 21:58:04 [scrapy.extensions.logstats] INFO: Crawled 392288 pages (at 111 pages/min), scraped 343468 items (at 90 items/min)
2017-11-04 21:59:03 [scrapy.extensions.logstats] INFO: Crawled 392397 pages (at 109 pages/min), scraped 343559 items (at 91 items/min)
2017-11-04 22:00:03 [scrapy.extensions.logstats] INFO: Crawled 392494 pages (at 97 pages/min), scraped 343640 items (at 81 items/min)
2017-11-04 22:01:03 [scrapy.extensions.logstats] INFO: Crawled 392595 pages (at 101 pages/min), scraped 343725 items (at 85 items/min)
2017-11-04 22:02:03 [scrapy.extensions.logstats] INFO: Crawled 392711 pages (at 116 pages/min), scraped 343820 items (at 95 items/min)
2017-11-04 22:03:03 [scrapy.extensions.logstats] INFO: Crawled 392842 pages (at 131 pages/min), scraped 343918 items (at 98 items/min)
2017-11-04 22:04:03 [scrapy.extensions.logstats] INFO: Crawled 392946 pages (at 104 pages/min), scraped 343994 items (at 76 items/min)
2017-11-04 22:05:03 [scrapy.extensions.logstats] INFO: Crawled 393064 pages (at 118 pages/min), scraped 344073 items (at 79 items/min)
2017-11-04 22:06:03 [scrapy.extensions.logstats] INFO: Crawled 393178 pages (at 114 pages/min), scraped 344165 items (at 92 items/min)
2017-11-04 22:07:03 [scrapy.extensions.logstats] INFO: Crawled 393284 pages (at 106 pages/min), scraped 344252 items (at 87 items/min)
2017-11-04 22:08:04 [scrapy.extensions.logstats] INFO: Crawled 393389 pages (at 105 pages/min), scraped 344330 items (at 78 items/min)
2017-11-04 22:09:03 [scrapy.extensions.logstats] INFO: Crawled 393505 pages (at 116 pages/min), scraped 344425 items (at 95 items/min)
2017-11-04 22:10:03 [scrapy.extensions.logstats] INFO: Crawled 393621 pages (at 116 pages/min), scraped 344531 items (at 106 items/min)
2017-11-04 22:11:03 [scrapy.extensions.logstats] INFO: Crawled 393735 pages (at 114 pages/min), scraped 344688 items (at 157 items/min)
2017-11-04 22:12:03 [scrapy.extensions.logstats] INFO: Crawled 393853 pages (at 118 pages/min), scraped 344804 items (at 116 items/min)
2017-11-04 22:13:04 [scrapy.extensions.logstats] INFO: Crawled 393950 pages (at 97 pages/min), scraped 344883 items (at 79 items/min)
2017-11-04 22:14:04 [scrapy.extensions.logstats] INFO: Crawled 394054 pages (at 104 pages/min), scraped 344976 items (at 93 items/min)
2017-11-04 22:15:03 [scrapy.extensions.logstats] INFO: Crawled 394155 pages (at 101 pages/min), scraped 345069 items (at 93 items/min)
2017-11-04 22:16:03 [scrapy.extensions.logstats] INFO: Crawled 394266 pages (at 111 pages/min), scraped 345187 items (at 118 items/min)
2017-11-04 22:17:04 [scrapy.extensions.logstats] INFO: Crawled 394374 pages (at 108 pages/min), scraped 345325 items (at 138 items/min)
2017-11-04 22:18:03 [scrapy.extensions.logstats] INFO: Crawled 394476 pages (at 102 pages/min), scraped 345398 items (at 73 items/min)
2017-11-04 22:19:03 [scrapy.extensions.logstats] INFO: Crawled 394578 pages (at 102 pages/min), scraped 345465 items (at 67 items/min)
2017-11-04 22:20:03 [scrapy.extensions.logstats] INFO: Crawled 394674 pages (at 96 pages/min), scraped 345546 items (at 81 items/min)
2017-11-04 22:21:03 [scrapy.extensions.logstats] INFO: Crawled 394785 pages (at 111 pages/min), scraped 345662 items (at 116 items/min)
2017-11-04 22:22:03 [scrapy.extensions.logstats] INFO: Crawled 394892 pages (at 107 pages/min), scraped 345756 items (at 94 items/min)
2017-11-04 22:23:04 [scrapy.extensions.logstats] INFO: Crawled 395004 pages (at 112 pages/min), scraped 345850 items (at 94 items/min)
2017-11-04 22:24:04 [scrapy.extensions.logstats] INFO: Crawled 395115 pages (at 111 pages/min), scraped 345933 items (at 83 items/min)
2017-11-04 22:25:03 [scrapy.extensions.logstats] INFO: Crawled 395237 pages (at 122 pages/min), scraped 346045 items (at 112 items/min)
2017-11-04 22:26:03 [scrapy.extensions.logstats] INFO: Crawled 395337 pages (at 100 pages/min), scraped 346161 items (at 116 items/min)
2017-11-04 22:27:03 [scrapy.extensions.logstats] INFO: Crawled 395447 pages (at 110 pages/min), scraped 346264 items (at 103 items/min)
2017-11-04 22:28:03 [scrapy.extensions.logstats] INFO: Crawled 395569 pages (at 122 pages/min), scraped 346356 items (at 92 items/min)
2017-11-04 22:29:04 [scrapy.extensions.logstats] INFO: Crawled 395678 pages (at 109 pages/min), scraped 346432 items (at 76 items/min)
2017-11-04 22:30:04 [scrapy.extensions.logstats] INFO: Crawled 395786 pages (at 108 pages/min), scraped 346517 items (at 85 items/min)
2017-11-04 22:31:04 [scrapy.extensions.logstats] INFO: Crawled 395881 pages (at 95 pages/min), scraped 346589 items (at 72 items/min)
2017-11-04 22:32:03 [scrapy.extensions.logstats] INFO: Crawled 395988 pages (at 107 pages/min), scraped 346682 items (at 93 items/min)
2017-11-04 22:33:04 [scrapy.extensions.logstats] INFO: Crawled 396101 pages (at 113 pages/min), scraped 346774 items (at 92 items/min)
2017-11-04 22:34:04 [scrapy.extensions.logstats] INFO: Crawled 396194 pages (at 93 pages/min), scraped 346872 items (at 98 items/min)
2017-11-04 22:35:04 [scrapy.extensions.logstats] INFO: Crawled 396297 pages (at 103 pages/min), scraped 346960 items (at 88 items/min)
2017-11-04 22:36:03 [scrapy.extensions.logstats] INFO: Crawled 396401 pages (at 104 pages/min), scraped 347032 items (at 72 items/min)
2017-11-04 22:37:04 [scrapy.extensions.logstats] INFO: Crawled 396495 pages (at 94 pages/min), scraped 347119 items (at 87 items/min)
2017-11-04 22:38:03 [scrapy.extensions.logstats] INFO: Crawled 396592 pages (at 97 pages/min), scraped 347228 items (at 109 items/min)
2017-11-04 22:39:03 [scrapy.extensions.logstats] INFO: Crawled 396709 pages (at 117 pages/min), scraped 347331 items (at 103 items/min)
2017-11-04 22:40:04 [scrapy.extensions.logstats] INFO: Crawled 396822 pages (at 113 pages/min), scraped 347444 items (at 113 items/min)
2017-11-04 22:41:04 [scrapy.extensions.logstats] INFO: Crawled 396923 pages (at 101 pages/min), scraped 347538 items (at 94 items/min)
2017-11-04 22:42:04 [scrapy.extensions.logstats] INFO: Crawled 397020 pages (at 97 pages/min), scraped 347628 items (at 90 items/min)
2017-11-04 22:43:04 [scrapy.extensions.logstats] INFO: Crawled 397124 pages (at 104 pages/min), scraped 347720 items (at 92 items/min)
2017-11-04 22:44:04 [scrapy.extensions.logstats] INFO: Crawled 397233 pages (at 109 pages/min), scraped 347827 items (at 107 items/min)
2017-11-04 22:45:03 [scrapy.extensions.logstats] INFO: Crawled 397343 pages (at 110 pages/min), scraped 347918 items (at 91 items/min)
2017-11-04 22:46:04 [scrapy.extensions.logstats] INFO: Crawled 397447 pages (at 104 pages/min), scraped 348013 items (at 95 items/min)
2017-11-04 22:47:03 [scrapy.extensions.logstats] INFO: Crawled 397543 pages (at 96 pages/min), scraped 348092 items (at 79 items/min)
2017-11-04 22:48:03 [scrapy.extensions.logstats] INFO: Crawled 397646 pages (at 103 pages/min), scraped 348188 items (at 96 items/min)
2017-11-04 22:49:03 [scrapy.extensions.logstats] INFO: Crawled 397743 pages (at 97 pages/min), scraped 348286 items (at 98 items/min)
2017-11-04 22:50:03 [scrapy.extensions.logstats] INFO: Crawled 397843 pages (at 100 pages/min), scraped 348370 items (at 84 items/min)
2017-11-04 22:51:03 [scrapy.extensions.logstats] INFO: Crawled 397945 pages (at 102 pages/min), scraped 348450 items (at 80 items/min)
2017-11-04 22:52:03 [scrapy.extensions.logstats] INFO: Crawled 398057 pages (at 112 pages/min), scraped 348558 items (at 108 items/min)
2017-11-04 22:53:03 [scrapy.extensions.logstats] INFO: Crawled 398166 pages (at 109 pages/min), scraped 348640 items (at 82 items/min)
2017-11-04 22:54:05 [scrapy.extensions.logstats] INFO: Crawled 398275 pages (at 109 pages/min), scraped 348737 items (at 97 items/min)
2017-11-04 22:55:04 [scrapy.extensions.logstats] INFO: Crawled 398383 pages (at 108 pages/min), scraped 348822 items (at 85 items/min)
2017-11-04 22:56:03 [scrapy.extensions.logstats] INFO: Crawled 398499 pages (at 116 pages/min), scraped 348928 items (at 106 items/min)
2017-11-04 22:57:04 [scrapy.extensions.logstats] INFO: Crawled 398600 pages (at 101 pages/min), scraped 349023 items (at 95 items/min)
2017-11-04 22:58:04 [scrapy.extensions.logstats] INFO: Crawled 398709 pages (at 109 pages/min), scraped 349123 items (at 100 items/min)
2017-11-04 22:59:04 [scrapy.extensions.logstats] INFO: Crawled 398812 pages (at 103 pages/min), scraped 349230 items (at 107 items/min)
2017-11-04 23:00:03 [scrapy.extensions.logstats] INFO: Crawled 398913 pages (at 101 pages/min), scraped 349324 items (at 94 items/min)
2017-11-04 23:01:03 [scrapy.extensions.logstats] INFO: Crawled 399023 pages (at 110 pages/min), scraped 349404 items (at 80 items/min)
2017-11-04 23:02:03 [scrapy.extensions.logstats] INFO: Crawled 399142 pages (at 119 pages/min), scraped 349483 items (at 79 items/min)
2017-11-04 23:03:03 [scrapy.extensions.logstats] INFO: Crawled 399239 pages (at 97 pages/min), scraped 349557 items (at 74 items/min)
2017-11-04 23:03:54 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39944283&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"李丹","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"山西证券股份有限公司","AOI_ID":"1999076","ADI_ID":"46427","ADI_NAME":"计划财务部","PTI_NAME":"一般证券业务","CER_NUM":"S0760112040049","OBTAIN_DATE":"2012-04-12","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 23:04:03 [scrapy.extensions.logstats] INFO: Crawled 399349 pages (at 110 pages/min), scraped 349630 items (at 73 items/min)
2017-11-04 23:05:03 [scrapy.extensions.logstats] INFO: Crawled 399464 pages (at 115 pages/min), scraped 349706 items (at 76 items/min)
2017-11-04 23:05:21 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39904917&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"张红兵","SCO_NAME":"男","ECO_NAME":"硕士研究生","AOI_NAME":"山西证券股份有限公司","AOI_ID":"1999076","ADI_ID":"46435","ADI_NAME":"研究所","PTI_NAME":"证券投资咨询业务(分析师)","CER_NUM":"S0760511010023","OBTAIN_DATE":"2011-01-12","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 23:06:03 [scrapy.extensions.logstats] INFO: Crawled 399561 pages (at 97 pages/min), scraped 349789 items (at 83 items/min)
2017-11-04 23:07:03 [scrapy.extensions.logstats] INFO: Crawled 399677 pages (at 116 pages/min), scraped 349871 items (at 82 items/min)
2017-11-04 23:08:03 [scrapy.extensions.logstats] INFO: Crawled 399786 pages (at 109 pages/min), scraped 349969 items (at 98 items/min)
2017-11-04 23:09:05 [scrapy.extensions.logstats] INFO: Crawled 399914 pages (at 128 pages/min), scraped 350074 items (at 105 items/min)
2017-11-04 23:10:04 [scrapy.extensions.logstats] INFO: Crawled 400021 pages (at 107 pages/min), scraped 350160 items (at 86 items/min)
2017-11-04 23:11:04 [scrapy.extensions.logstats] INFO: Crawled 400124 pages (at 103 pages/min), scraped 350250 items (at 90 items/min)
2017-11-04 23:12:03 [scrapy.extensions.logstats] INFO: Crawled 400223 pages (at 99 pages/min), scraped 350335 items (at 85 items/min)
2017-11-04 23:13:03 [scrapy.extensions.logstats] INFO: Crawled 400335 pages (at 112 pages/min), scraped 350428 items (at 93 items/min)
2017-11-04 23:14:04 [scrapy.extensions.logstats] INFO: Crawled 400442 pages (at 107 pages/min), scraped 350515 items (at 87 items/min)
2017-11-04 23:15:03 [scrapy.extensions.logstats] INFO: Crawled 400557 pages (at 115 pages/min), scraped 350600 items (at 85 items/min)
2017-11-04 23:16:03 [scrapy.extensions.logstats] INFO: Crawled 400664 pages (at 107 pages/min), scraped 350696 items (at 96 items/min)
2017-11-04 23:17:03 [scrapy.extensions.logstats] INFO: Crawled 400787 pages (at 123 pages/min), scraped 350782 items (at 86 items/min)
2017-11-04 23:18:03 [scrapy.extensions.logstats] INFO: Crawled 400898 pages (at 111 pages/min), scraped 350861 items (at 79 items/min)
2017-11-04 23:19:03 [scrapy.extensions.logstats] INFO: Crawled 400985 pages (at 87 pages/min), scraped 350931 items (at 70 items/min)
2017-11-04 23:19:47 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=010204&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"韩爱萍","SCO_NAME":"女","ECO_NAME":"大专","AOI_NAME":"山西证券股份有限公司","AOI_ID":"1999076","ADI_ID":"46436","ADI_NAME":"风险管理部","PTI_NAME":"一般证券业务","CER_NUM":"S0760100010410","OBTAIN_DATE":"2004-05-14","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 23:20:04 [scrapy.extensions.logstats] INFO: Crawled 401088 pages (at 103 pages/min), scraped 351023 items (at 92 items/min)
2017-11-04 23:21:04 [scrapy.extensions.logstats] INFO: Crawled 401197 pages (at 109 pages/min), scraped 351111 items (at 88 items/min)
2017-11-04 23:22:04 [scrapy.extensions.logstats] INFO: Crawled 401317 pages (at 120 pages/min), scraped 351211 items (at 100 items/min)
2017-11-04 23:23:05 [scrapy.extensions.logstats] INFO: Crawled 401422 pages (at 105 pages/min), scraped 351317 items (at 106 items/min)
2017-11-04 23:24:03 [scrapy.extensions.logstats] INFO: Crawled 401545 pages (at 123 pages/min), scraped 351426 items (at 109 items/min)
2017-11-04 23:25:03 [scrapy.extensions.logstats] INFO: Crawled 401667 pages (at 122 pages/min), scraped 351533 items (at 107 items/min)
2017-11-04 23:26:03 [scrapy.extensions.logstats] INFO: Crawled 401763 pages (at 96 pages/min), scraped 351605 items (at 72 items/min)
2017-11-04 23:27:03 [scrapy.extensions.logstats] INFO: Crawled 401880 pages (at 117 pages/min), scraped 351705 items (at 100 items/min)
2017-11-04 23:28:04 [scrapy.extensions.logstats] INFO: Crawled 402004 pages (at 124 pages/min), scraped 351797 items (at 92 items/min)
2017-11-04 23:29:03 [scrapy.extensions.logstats] INFO: Crawled 402107 pages (at 103 pages/min), scraped 351889 items (at 92 items/min)
2017-11-04 23:30:03 [scrapy.extensions.logstats] INFO: Crawled 402221 pages (at 114 pages/min), scraped 351985 items (at 96 items/min)
2017-11-04 23:31:03 [scrapy.extensions.logstats] INFO: Crawled 402327 pages (at 106 pages/min), scraped 352071 items (at 86 items/min)
2017-11-04 23:32:03 [scrapy.extensions.logstats] INFO: Crawled 402450 pages (at 123 pages/min), scraped 352170 items (at 99 items/min)
2017-11-04 23:33:04 [scrapy.extensions.logstats] INFO: Crawled 402558 pages (at 108 pages/min), scraped 352260 items (at 90 items/min)
2017-11-04 23:34:04 [scrapy.extensions.logstats] INFO: Crawled 402667 pages (at 109 pages/min), scraped 352349 items (at 89 items/min)
2017-11-04 23:35:03 [scrapy.extensions.logstats] INFO: Crawled 402768 pages (at 101 pages/min), scraped 352443 items (at 94 items/min)
2017-11-04 23:36:04 [scrapy.extensions.logstats] INFO: Crawled 402890 pages (at 122 pages/min), scraped 352563 items (at 120 items/min)
2017-11-04 23:37:03 [scrapy.extensions.logstats] INFO: Crawled 402990 pages (at 100 pages/min), scraped 352655 items (at 92 items/min)
2017-11-04 23:38:03 [scrapy.extensions.logstats] INFO: Crawled 403094 pages (at 104 pages/min), scraped 352768 items (at 113 items/min)
2017-11-04 23:38:18 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=79959472&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"王青","SCO_NAME":"女","ECO_NAME":"大专","AOI_NAME":"山西证券股份有限公司","AOI_ID":"1999076","ADI_ID":"45926","ADI_NAME":"晋城黄华街证券营业部","PTI_NAME":"证券经纪人","CER_NUM":"S0760413010010","OBTAIN_DATE":"2013-01-31","ARRIVE_DATE":"2018-01-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-04 23:39:04 [scrapy.extensions.logstats] INFO: Crawled 403222 pages (at 128 pages/min), scraped 352881 items (at 113 items/min)
2017-11-04 23:40:04 [scrapy.extensions.logstats] INFO: Crawled 403330 pages (at 108 pages/min), scraped 353010 items (at 129 items/min)
2017-11-04 23:41:04 [scrapy.extensions.logstats] INFO: Crawled 403440 pages (at 110 pages/min), scraped 353152 items (at 142 items/min)
2017-11-04 23:42:03 [scrapy.extensions.logstats] INFO: Crawled 403546 pages (at 106 pages/min), scraped 353296 items (at 144 items/min)
2017-11-04 23:43:03 [scrapy.extensions.logstats] INFO: Crawled 403674 pages (at 128 pages/min), scraped 353482 items (at 186 items/min)
2017-11-04 23:44:03 [scrapy.extensions.logstats] INFO: Crawled 403773 pages (at 99 pages/min), scraped 353601 items (at 119 items/min)
2017-11-04 23:45:03 [scrapy.extensions.logstats] INFO: Crawled 403890 pages (at 117 pages/min), scraped 353713 items (at 112 items/min)
2017-11-04 23:46:04 [scrapy.extensions.logstats] INFO: Crawled 404025 pages (at 135 pages/min), scraped 353854 items (at 141 items/min)
2017-11-04 23:47:04 [scrapy.extensions.logstats] INFO: Crawled 404132 pages (at 107 pages/min), scraped 353991 items (at 137 items/min)
2017-11-04 23:48:03 [scrapy.extensions.logstats] INFO: Crawled 404249 pages (at 117 pages/min), scraped 354107 items (at 116 items/min)
2017-11-04 23:49:04 [scrapy.extensions.logstats] INFO: Crawled 404362 pages (at 113 pages/min), scraped 354212 items (at 105 items/min)
2017-11-04 23:50:05 [scrapy.extensions.logstats] INFO: Crawled 404472 pages (at 110 pages/min), scraped 354304 items (at 92 items/min)
2017-11-04 23:51:04 [scrapy.extensions.logstats] INFO: Crawled 404594 pages (at 122 pages/min), scraped 354400 items (at 96 items/min)
2017-11-04 23:52:03 [scrapy.extensions.logstats] INFO: Crawled 404716 pages (at 122 pages/min), scraped 354514 items (at 114 items/min)
2017-11-04 23:53:04 [scrapy.extensions.logstats] INFO: Crawled 404816 pages (at 100 pages/min), scraped 354612 items (at 98 items/min)
2017-11-04 23:54:04 [scrapy.extensions.logstats] INFO: Crawled 404877 pages (at 61 pages/min), scraped 354668 items (at 56 items/min)
2017-11-04 23:55:05 [scrapy.extensions.logstats] INFO: Crawled 404918 pages (at 41 pages/min), scraped 354707 items (at 39 items/min)
2017-11-04 23:56:03 [scrapy.extensions.logstats] INFO: Crawled 404986 pages (at 68 pages/min), scraped 354751 items (at 44 items/min)
2017-11-04 23:57:06 [scrapy.extensions.logstats] INFO: Crawled 405053 pages (at 67 pages/min), scraped 354801 items (at 50 items/min)
2017-11-04 23:58:06 [scrapy.extensions.logstats] INFO: Crawled 405100 pages (at 47 pages/min), scraped 354828 items (at 27 items/min)
2017-11-04 23:59:03 [scrapy.extensions.logstats] INFO: Crawled 405156 pages (at 56 pages/min), scraped 354872 items (at 44 items/min)
2017-11-05 00:00:04 [scrapy.extensions.logstats] INFO: Crawled 405210 pages (at 54 pages/min), scraped 354913 items (at 41 items/min)
2017-11-05 00:01:03 [scrapy.extensions.logstats] INFO: Crawled 405263 pages (at 53 pages/min), scraped 354946 items (at 33 items/min)
2017-11-05 00:02:04 [scrapy.extensions.logstats] INFO: Crawled 405318 pages (at 55 pages/min), scraped 354991 items (at 45 items/min)
2017-11-05 00:03:03 [scrapy.extensions.logstats] INFO: Crawled 405392 pages (at 74 pages/min), scraped 355045 items (at 54 items/min)
2017-11-05 00:04:04 [scrapy.extensions.logstats] INFO: Crawled 405430 pages (at 38 pages/min), scraped 355077 items (at 32 items/min)
2017-11-05 00:05:04 [scrapy.extensions.logstats] INFO: Crawled 405500 pages (at 70 pages/min), scraped 355127 items (at 50 items/min)
2017-11-05 00:06:04 [scrapy.extensions.logstats] INFO: Crawled 405582 pages (at 82 pages/min), scraped 355181 items (at 54 items/min)
2017-11-05 00:07:04 [scrapy.extensions.logstats] INFO: Crawled 405645 pages (at 63 pages/min), scraped 355230 items (at 49 items/min)
2017-11-05 00:08:03 [scrapy.extensions.logstats] INFO: Crawled 405715 pages (at 70 pages/min), scraped 355276 items (at 46 items/min)
2017-11-05 00:09:04 [scrapy.extensions.logstats] INFO: Crawled 405800 pages (at 85 pages/min), scraped 355335 items (at 59 items/min)
2017-11-05 00:10:04 [scrapy.extensions.logstats] INFO: Crawled 405860 pages (at 60 pages/min), scraped 355374 items (at 39 items/min)
2017-11-05 00:11:03 [scrapy.extensions.logstats] INFO: Crawled 405918 pages (at 58 pages/min), scraped 355419 items (at 45 items/min)
2017-11-05 00:12:03 [scrapy.extensions.logstats] INFO: Crawled 405985 pages (at 67 pages/min), scraped 355460 items (at 41 items/min)
2017-11-05 00:13:03 [scrapy.extensions.logstats] INFO: Crawled 406045 pages (at 60 pages/min), scraped 355504 items (at 44 items/min)
2017-11-05 00:14:03 [scrapy.extensions.logstats] INFO: Crawled 406108 pages (at 63 pages/min), scraped 355560 items (at 56 items/min)
2017-11-05 00:15:06 [scrapy.extensions.logstats] INFO: Crawled 406180 pages (at 72 pages/min), scraped 355606 items (at 46 items/min)
2017-11-05 00:16:06 [scrapy.extensions.logstats] INFO: Crawled 406211 pages (at 31 pages/min), scraped 355629 items (at 23 items/min)
2017-11-05 00:17:08 [scrapy.extensions.logstats] INFO: Crawled 406259 pages (at 48 pages/min), scraped 355667 items (at 38 items/min)
2017-11-05 00:18:05 [scrapy.extensions.logstats] INFO: Crawled 406296 pages (at 37 pages/min), scraped 355693 items (at 26 items/min)
2017-11-05 00:19:06 [scrapy.extensions.logstats] INFO: Crawled 406330 pages (at 34 pages/min), scraped 355717 items (at 24 items/min)
2017-11-05 00:20:03 [scrapy.extensions.logstats] INFO: Crawled 406372 pages (at 42 pages/min), scraped 355736 items (at 19 items/min)
2017-11-05 00:21:03 [scrapy.extensions.logstats] INFO: Crawled 406427 pages (at 55 pages/min), scraped 355776 items (at 40 items/min)
2017-11-05 00:22:04 [scrapy.extensions.logstats] INFO: Crawled 406487 pages (at 60 pages/min), scraped 355818 items (at 42 items/min)
2017-11-05 00:23:03 [scrapy.extensions.logstats] INFO: Crawled 406574 pages (at 87 pages/min), scraped 355879 items (at 61 items/min)
2017-11-05 00:24:03 [scrapy.extensions.logstats] INFO: Crawled 406675 pages (at 101 pages/min), scraped 355949 items (at 70 items/min)
2017-11-05 00:25:03 [scrapy.extensions.logstats] INFO: Crawled 406785 pages (at 110 pages/min), scraped 356028 items (at 79 items/min)
2017-11-05 00:26:04 [scrapy.extensions.logstats] INFO: Crawled 406892 pages (at 107 pages/min), scraped 356108 items (at 80 items/min)
2017-11-05 00:27:05 [scrapy.extensions.logstats] INFO: Crawled 407006 pages (at 114 pages/min), scraped 356188 items (at 80 items/min)
2017-11-05 00:28:04 [scrapy.extensions.logstats] INFO: Crawled 407120 pages (at 114 pages/min), scraped 356268 items (at 80 items/min)
2017-11-05 00:29:03 [scrapy.extensions.logstats] INFO: Crawled 407232 pages (at 112 pages/min), scraped 356347 items (at 79 items/min)
2017-11-05 00:30:03 [scrapy.extensions.logstats] INFO: Crawled 407340 pages (at 108 pages/min), scraped 356432 items (at 85 items/min)
2017-11-05 00:31:04 [scrapy.extensions.logstats] INFO: Crawled 407448 pages (at 108 pages/min), scraped 356511 items (at 79 items/min)
2017-11-05 00:32:03 [scrapy.extensions.logstats] INFO: Crawled 407540 pages (at 92 pages/min), scraped 356589 items (at 78 items/min)
2017-11-05 00:33:04 [scrapy.extensions.logstats] INFO: Crawled 407647 pages (at 107 pages/min), scraped 356676 items (at 87 items/min)
2017-11-05 00:34:03 [scrapy.extensions.logstats] INFO: Crawled 407754 pages (at 107 pages/min), scraped 356757 items (at 81 items/min)
2017-11-05 00:35:04 [scrapy.extensions.logstats] INFO: Crawled 407859 pages (at 105 pages/min), scraped 356834 items (at 77 items/min)
2017-11-05 00:36:04 [scrapy.extensions.logstats] INFO: Crawled 407969 pages (at 110 pages/min), scraped 356916 items (at 82 items/min)
2017-11-05 00:37:04 [scrapy.extensions.logstats] INFO: Crawled 408081 pages (at 112 pages/min), scraped 357003 items (at 87 items/min)
2017-11-05 00:38:03 [scrapy.extensions.logstats] INFO: Crawled 408195 pages (at 114 pages/min), scraped 357093 items (at 90 items/min)
2017-11-05 00:39:03 [scrapy.extensions.logstats] INFO: Crawled 408293 pages (at 98 pages/min), scraped 357158 items (at 65 items/min)
2017-11-05 00:40:03 [scrapy.extensions.logstats] INFO: Crawled 408392 pages (at 99 pages/min), scraped 357238 items (at 80 items/min)
2017-11-05 00:41:04 [scrapy.extensions.logstats] INFO: Crawled 408489 pages (at 97 pages/min), scraped 357315 items (at 77 items/min)
2017-11-05 00:42:03 [scrapy.extensions.logstats] INFO: Crawled 408586 pages (at 97 pages/min), scraped 357398 items (at 83 items/min)
2017-11-05 00:43:03 [scrapy.extensions.logstats] INFO: Crawled 408701 pages (at 115 pages/min), scraped 357486 items (at 88 items/min)
2017-11-05 00:44:03 [scrapy.extensions.logstats] INFO: Crawled 408807 pages (at 106 pages/min), scraped 357572 items (at 86 items/min)
2017-11-05 00:45:04 [scrapy.extensions.logstats] INFO: Crawled 408904 pages (at 97 pages/min), scraped 357649 items (at 77 items/min)
2017-11-05 00:46:03 [scrapy.extensions.logstats] INFO: Crawled 409012 pages (at 108 pages/min), scraped 357735 items (at 86 items/min)
2017-11-05 00:47:04 [scrapy.extensions.logstats] INFO: Crawled 409122 pages (at 110 pages/min), scraped 357829 items (at 94 items/min)
2017-11-05 00:48:04 [scrapy.extensions.logstats] INFO: Crawled 409234 pages (at 112 pages/min), scraped 357923 items (at 94 items/min)
2017-11-05 00:49:03 [scrapy.extensions.logstats] INFO: Crawled 409347 pages (at 113 pages/min), scraped 358020 items (at 97 items/min)
2017-11-05 00:50:04 [scrapy.extensions.logstats] INFO: Crawled 409468 pages (at 121 pages/min), scraped 358107 items (at 87 items/min)
2017-11-05 00:51:03 [scrapy.extensions.logstats] INFO: Crawled 409567 pages (at 99 pages/min), scraped 358212 items (at 105 items/min)
2017-11-05 00:52:04 [scrapy.extensions.logstats] INFO: Crawled 409662 pages (at 95 pages/min), scraped 358279 items (at 67 items/min)
2017-11-05 00:53:04 [scrapy.extensions.logstats] INFO: Crawled 409775 pages (at 113 pages/min), scraped 358370 items (at 91 items/min)
2017-11-05 00:54:04 [scrapy.extensions.logstats] INFO: Crawled 409891 pages (at 116 pages/min), scraped 358453 items (at 83 items/min)
2017-11-05 00:55:03 [scrapy.extensions.logstats] INFO: Crawled 410002 pages (at 111 pages/min), scraped 358539 items (at 86 items/min)
2017-11-05 00:56:03 [scrapy.extensions.logstats] INFO: Crawled 410118 pages (at 116 pages/min), scraped 358625 items (at 86 items/min)
2017-11-05 00:57:03 [scrapy.extensions.logstats] INFO: Crawled 410231 pages (at 113 pages/min), scraped 358713 items (at 88 items/min)
2017-11-05 00:58:04 [scrapy.extensions.logstats] INFO: Crawled 410320 pages (at 89 pages/min), scraped 358779 items (at 66 items/min)
2017-11-05 00:59:03 [scrapy.extensions.logstats] INFO: Crawled 410421 pages (at 101 pages/min), scraped 358854 items (at 75 items/min)
2017-11-05 01:00:04 [scrapy.extensions.logstats] INFO: Crawled 410511 pages (at 90 pages/min), scraped 358934 items (at 80 items/min)
2017-11-05 01:01:04 [scrapy.extensions.logstats] INFO: Crawled 410624 pages (at 113 pages/min), scraped 359019 items (at 85 items/min)
2017-11-05 01:02:04 [scrapy.extensions.logstats] INFO: Crawled 410715 pages (at 91 pages/min), scraped 359088 items (at 69 items/min)
2017-11-05 01:03:04 [scrapy.extensions.logstats] INFO: Crawled 410817 pages (at 102 pages/min), scraped 359160 items (at 72 items/min)
2017-11-05 01:04:03 [scrapy.extensions.logstats] INFO: Crawled 410913 pages (at 96 pages/min), scraped 359225 items (at 65 items/min)
2017-11-05 01:05:04 [scrapy.extensions.logstats] INFO: Crawled 411021 pages (at 108 pages/min), scraped 359312 items (at 87 items/min)
2017-11-05 01:06:04 [scrapy.extensions.logstats] INFO: Crawled 411120 pages (at 99 pages/min), scraped 359390 items (at 78 items/min)
2017-11-05 01:07:04 [scrapy.extensions.logstats] INFO: Crawled 411230 pages (at 110 pages/min), scraped 359470 items (at 80 items/min)
2017-11-05 01:08:04 [scrapy.extensions.logstats] INFO: Crawled 411343 pages (at 113 pages/min), scraped 359571 items (at 101 items/min)
2017-11-05 01:09:03 [scrapy.extensions.logstats] INFO: Crawled 411451 pages (at 108 pages/min), scraped 359645 items (at 74 items/min)
2017-11-05 01:10:04 [scrapy.extensions.logstats] INFO: Crawled 411558 pages (at 107 pages/min), scraped 359711 items (at 66 items/min)
2017-11-05 01:11:04 [scrapy.extensions.logstats] INFO: Crawled 411666 pages (at 108 pages/min), scraped 359785 items (at 74 items/min)
2017-11-05 01:12:03 [scrapy.extensions.logstats] INFO: Crawled 411793 pages (at 127 pages/min), scraped 359882 items (at 97 items/min)
2017-11-05 01:13:03 [scrapy.extensions.logstats] INFO: Crawled 411913 pages (at 120 pages/min), scraped 359967 items (at 85 items/min)
2017-11-05 01:14:04 [scrapy.extensions.logstats] INFO: Crawled 412043 pages (at 130 pages/min), scraped 360062 items (at 95 items/min)
2017-11-05 01:15:04 [scrapy.extensions.logstats] INFO: Crawled 412161 pages (at 118 pages/min), scraped 360160 items (at 98 items/min)
2017-11-05 01:16:03 [scrapy.extensions.logstats] INFO: Crawled 412289 pages (at 128 pages/min), scraped 360250 items (at 90 items/min)
2017-11-05 01:17:03 [scrapy.extensions.logstats] INFO: Crawled 412393 pages (at 104 pages/min), scraped 360340 items (at 90 items/min)
2017-11-05 01:18:03 [scrapy.extensions.logstats] INFO: Crawled 412505 pages (at 112 pages/min), scraped 360429 items (at 89 items/min)
2017-11-05 01:19:03 [scrapy.extensions.logstats] INFO: Crawled 412621 pages (at 116 pages/min), scraped 360505 items (at 76 items/min)
2017-11-05 01:20:03 [scrapy.extensions.logstats] INFO: Crawled 412735 pages (at 114 pages/min), scraped 360597 items (at 92 items/min)
2017-11-05 01:21:04 [scrapy.extensions.logstats] INFO: Crawled 412839 pages (at 104 pages/min), scraped 360669 items (at 72 items/min)
2017-11-05 01:22:03 [scrapy.extensions.logstats] INFO: Crawled 412954 pages (at 115 pages/min), scraped 360766 items (at 97 items/min)
2017-11-05 01:23:03 [scrapy.extensions.logstats] INFO: Crawled 413044 pages (at 90 pages/min), scraped 360839 items (at 73 items/min)
2017-11-05 01:24:04 [scrapy.extensions.logstats] INFO: Crawled 413165 pages (at 121 pages/min), scraped 360921 items (at 82 items/min)
2017-11-05 01:25:04 [scrapy.extensions.logstats] INFO: Crawled 413282 pages (at 117 pages/min), scraped 361011 items (at 90 items/min)
2017-11-05 01:26:04 [scrapy.extensions.logstats] INFO: Crawled 413395 pages (at 113 pages/min), scraped 361106 items (at 95 items/min)
2017-11-05 01:27:04 [scrapy.extensions.logstats] INFO: Crawled 413501 pages (at 106 pages/min), scraped 361216 items (at 110 items/min)
2017-11-05 01:28:04 [scrapy.extensions.logstats] INFO: Crawled 413606 pages (at 105 pages/min), scraped 361322 items (at 106 items/min)
2017-11-05 01:29:06 [scrapy.extensions.logstats] INFO: Crawled 413709 pages (at 103 pages/min), scraped 361402 items (at 80 items/min)
2017-11-05 01:30:04 [scrapy.extensions.logstats] INFO: Crawled 413800 pages (at 91 pages/min), scraped 361480 items (at 78 items/min)
2017-11-05 01:31:04 [scrapy.extensions.logstats] INFO: Crawled 413902 pages (at 102 pages/min), scraped 361564 items (at 84 items/min)
2017-11-05 01:32:03 [scrapy.extensions.logstats] INFO: Crawled 414010 pages (at 108 pages/min), scraped 361650 items (at 86 items/min)
2017-11-05 01:33:03 [scrapy.extensions.logstats] INFO: Crawled 414122 pages (at 112 pages/min), scraped 361754 items (at 104 items/min)
2017-11-05 01:34:03 [scrapy.extensions.logstats] INFO: Crawled 414216 pages (at 94 pages/min), scraped 361826 items (at 72 items/min)
2017-11-05 01:35:04 [scrapy.extensions.logstats] INFO: Crawled 414321 pages (at 105 pages/min), scraped 361914 items (at 88 items/min)
2017-11-05 01:36:05 [scrapy.extensions.logstats] INFO: Crawled 414424 pages (at 103 pages/min), scraped 361989 items (at 75 items/min)
2017-11-05 01:37:03 [scrapy.extensions.logstats] INFO: Crawled 414537 pages (at 113 pages/min), scraped 362086 items (at 97 items/min)
2017-11-05 01:38:04 [scrapy.extensions.logstats] INFO: Crawled 414646 pages (at 109 pages/min), scraped 362166 items (at 80 items/min)
2017-11-05 01:39:04 [scrapy.extensions.logstats] INFO: Crawled 414760 pages (at 114 pages/min), scraped 362274 items (at 108 items/min)
2017-11-05 01:40:03 [scrapy.extensions.logstats] INFO: Crawled 414885 pages (at 125 pages/min), scraped 362372 items (at 98 items/min)
2017-11-05 01:41:03 [scrapy.extensions.logstats] INFO: Crawled 414993 pages (at 108 pages/min), scraped 362448 items (at 76 items/min)
2017-11-05 01:42:04 [scrapy.extensions.logstats] INFO: Crawled 415106 pages (at 113 pages/min), scraped 362543 items (at 95 items/min)
2017-11-05 01:43:03 [scrapy.extensions.logstats] INFO: Crawled 415201 pages (at 95 pages/min), scraped 362608 items (at 65 items/min)
2017-11-05 01:44:04 [scrapy.extensions.logstats] INFO: Crawled 415307 pages (at 106 pages/min), scraped 362696 items (at 88 items/min)
2017-11-05 01:45:03 [scrapy.extensions.logstats] INFO: Crawled 415412 pages (at 105 pages/min), scraped 362779 items (at 83 items/min)
2017-11-05 01:46:04 [scrapy.extensions.logstats] INFO: Crawled 415529 pages (at 117 pages/min), scraped 362871 items (at 92 items/min)
2017-11-05 01:47:03 [scrapy.extensions.logstats] INFO: Crawled 415648 pages (at 119 pages/min), scraped 362973 items (at 102 items/min)
2017-11-05 01:48:04 [scrapy.extensions.logstats] INFO: Crawled 415770 pages (at 122 pages/min), scraped 363068 items (at 95 items/min)
2017-11-05 01:49:03 [scrapy.extensions.logstats] INFO: Crawled 415885 pages (at 115 pages/min), scraped 363152 items (at 84 items/min)
2017-11-05 01:50:03 [scrapy.extensions.logstats] INFO: Crawled 416012 pages (at 127 pages/min), scraped 363259 items (at 107 items/min)
2017-11-05 01:51:03 [scrapy.extensions.logstats] INFO: Crawled 416131 pages (at 119 pages/min), scraped 363357 items (at 98 items/min)
2017-11-05 01:52:03 [scrapy.extensions.logstats] INFO: Crawled 416239 pages (at 108 pages/min), scraped 363432 items (at 75 items/min)
2017-11-05 01:53:04 [scrapy.extensions.logstats] INFO: Crawled 416341 pages (at 102 pages/min), scraped 363503 items (at 71 items/min)
2017-11-05 01:54:04 [scrapy.extensions.logstats] INFO: Crawled 416448 pages (at 107 pages/min), scraped 363588 items (at 85 items/min)
2017-11-05 01:55:04 [scrapy.extensions.logstats] INFO: Crawled 416541 pages (at 93 pages/min), scraped 363652 items (at 64 items/min)
2017-11-05 01:56:04 [scrapy.extensions.logstats] INFO: Crawled 416647 pages (at 106 pages/min), scraped 363741 items (at 89 items/min)
2017-11-05 01:57:03 [scrapy.extensions.logstats] INFO: Crawled 416739 pages (at 92 pages/min), scraped 363821 items (at 80 items/min)
2017-11-05 01:58:03 [scrapy.extensions.logstats] INFO: Crawled 416848 pages (at 109 pages/min), scraped 363924 items (at 103 items/min)
2017-11-05 01:59:05 [scrapy.extensions.logstats] INFO: Crawled 416946 pages (at 98 pages/min), scraped 363994 items (at 70 items/min)
2017-11-05 02:00:04 [scrapy.extensions.logstats] INFO: Crawled 417050 pages (at 104 pages/min), scraped 364093 items (at 99 items/min)
2017-11-05 02:01:03 [scrapy.extensions.logstats] INFO: Crawled 417146 pages (at 96 pages/min), scraped 364164 items (at 71 items/min)
2017-11-05 02:02:03 [scrapy.extensions.logstats] INFO: Crawled 417259 pages (at 113 pages/min), scraped 364264 items (at 100 items/min)
2017-11-05 02:03:03 [scrapy.extensions.logstats] INFO: Crawled 417363 pages (at 104 pages/min), scraped 364346 items (at 82 items/min)
2017-11-05 02:04:03 [scrapy.extensions.logstats] INFO: Crawled 417473 pages (at 110 pages/min), scraped 364428 items (at 82 items/min)
2017-11-05 02:05:03 [scrapy.extensions.logstats] INFO: Crawled 417581 pages (at 108 pages/min), scraped 364516 items (at 88 items/min)
2017-11-05 02:06:04 [scrapy.extensions.logstats] INFO: Crawled 417684 pages (at 103 pages/min), scraped 364610 items (at 94 items/min)
2017-11-05 02:07:06 [scrapy.extensions.logstats] INFO: Crawled 417791 pages (at 107 pages/min), scraped 364689 items (at 79 items/min)
2017-11-05 02:08:04 [scrapy.extensions.logstats] INFO: Crawled 417886 pages (at 95 pages/min), scraped 364778 items (at 89 items/min)
2017-11-05 02:09:03 [scrapy.extensions.logstats] INFO: Crawled 418000 pages (at 114 pages/min), scraped 364883 items (at 105 items/min)
2017-11-05 02:10:03 [scrapy.extensions.logstats] INFO: Crawled 418104 pages (at 104 pages/min), scraped 364969 items (at 86 items/min)
2017-11-05 02:11:03 [scrapy.extensions.logstats] INFO: Crawled 418210 pages (at 106 pages/min), scraped 365059 items (at 90 items/min)
2017-11-05 02:12:03 [scrapy.extensions.logstats] INFO: Crawled 418319 pages (at 109 pages/min), scraped 365160 items (at 101 items/min)
2017-11-05 02:13:03 [scrapy.extensions.logstats] INFO: Crawled 418431 pages (at 112 pages/min), scraped 365281 items (at 121 items/min)
2017-11-05 02:14:03 [scrapy.extensions.logstats] INFO: Crawled 418543 pages (at 112 pages/min), scraped 365394 items (at 113 items/min)
2017-11-05 02:15:05 [scrapy.extensions.logstats] INFO: Crawled 418653 pages (at 110 pages/min), scraped 365506 items (at 112 items/min)
2017-11-05 02:16:03 [scrapy.extensions.logstats] INFO: Crawled 418767 pages (at 114 pages/min), scraped 365633 items (at 127 items/min)
2017-11-05 02:17:04 [scrapy.extensions.logstats] INFO: Crawled 418870 pages (at 103 pages/min), scraped 365752 items (at 119 items/min)
2017-11-05 02:18:04 [scrapy.extensions.logstats] INFO: Crawled 418975 pages (at 105 pages/min), scraped 365851 items (at 99 items/min)
2017-11-05 02:19:04 [scrapy.extensions.logstats] INFO: Crawled 419087 pages (at 112 pages/min), scraped 365971 items (at 120 items/min)
2017-11-05 02:20:03 [scrapy.extensions.logstats] INFO: Crawled 419194 pages (at 107 pages/min), scraped 366102 items (at 131 items/min)
2017-11-05 02:21:03 [scrapy.extensions.logstats] INFO: Crawled 419283 pages (at 89 pages/min), scraped 366222 items (at 120 items/min)
2017-11-05 02:22:04 [scrapy.extensions.logstats] INFO: Crawled 419382 pages (at 99 pages/min), scraped 366322 items (at 100 items/min)
2017-11-05 02:23:03 [scrapy.extensions.logstats] INFO: Crawled 419494 pages (at 112 pages/min), scraped 366429 items (at 107 items/min)
2017-11-05 02:24:03 [scrapy.extensions.logstats] INFO: Crawled 419599 pages (at 105 pages/min), scraped 366581 items (at 152 items/min)
2017-11-05 02:25:04 [scrapy.extensions.logstats] INFO: Crawled 419705 pages (at 106 pages/min), scraped 366684 items (at 103 items/min)
2017-11-05 02:26:04 [scrapy.extensions.logstats] INFO: Crawled 419814 pages (at 109 pages/min), scraped 366841 items (at 157 items/min)
2017-11-05 02:27:04 [scrapy.extensions.logstats] INFO: Crawled 419902 pages (at 88 pages/min), scraped 366933 items (at 92 items/min)
2017-11-05 02:28:04 [scrapy.extensions.logstats] INFO: Crawled 420010 pages (at 108 pages/min), scraped 367018 items (at 85 items/min)
2017-11-05 02:29:04 [scrapy.extensions.logstats] INFO: Crawled 420112 pages (at 102 pages/min), scraped 367090 items (at 72 items/min)
2017-11-05 02:30:04 [scrapy.extensions.logstats] INFO: Crawled 420220 pages (at 108 pages/min), scraped 367170 items (at 80 items/min)
2017-11-05 02:31:04 [scrapy.extensions.logstats] INFO: Crawled 420305 pages (at 85 pages/min), scraped 367235 items (at 65 items/min)
2017-11-05 02:32:03 [scrapy.extensions.logstats] INFO: Crawled 420417 pages (at 112 pages/min), scraped 367322 items (at 87 items/min)
2017-11-05 02:33:04 [scrapy.extensions.logstats] INFO: Crawled 420523 pages (at 106 pages/min), scraped 367405 items (at 83 items/min)
2017-11-05 02:34:03 [scrapy.extensions.logstats] INFO: Crawled 420619 pages (at 96 pages/min), scraped 367486 items (at 81 items/min)
2017-11-05 02:35:05 [scrapy.extensions.logstats] INFO: Crawled 420721 pages (at 102 pages/min), scraped 367560 items (at 74 items/min)
2017-11-05 02:36:04 [scrapy.extensions.logstats] INFO: Crawled 420831 pages (at 110 pages/min), scraped 367644 items (at 84 items/min)
2017-11-05 02:37:03 [scrapy.extensions.logstats] INFO: Crawled 420950 pages (at 119 pages/min), scraped 367758 items (at 114 items/min)
2017-11-05 02:38:03 [scrapy.extensions.logstats] INFO: Crawled 421081 pages (at 131 pages/min), scraped 367853 items (at 95 items/min)
2017-11-05 02:39:03 [scrapy.extensions.logstats] INFO: Crawled 421266 pages (at 185 pages/min), scraped 367863 items (at 10 items/min)
2017-11-05 02:40:04 [scrapy.extensions.logstats] INFO: Crawled 421445 pages (at 179 pages/min), scraped 367924 items (at 61 items/min)
2017-11-05 02:41:03 [scrapy.extensions.logstats] INFO: Crawled 421559 pages (at 114 pages/min), scraped 368035 items (at 111 items/min)
2017-11-05 02:42:04 [scrapy.extensions.logstats] INFO: Crawled 421662 pages (at 103 pages/min), scraped 368115 items (at 80 items/min)
2017-11-05 02:43:03 [scrapy.extensions.logstats] INFO: Crawled 421791 pages (at 129 pages/min), scraped 368240 items (at 125 items/min)
2017-11-05 02:44:04 [scrapy.extensions.logstats] INFO: Crawled 421902 pages (at 111 pages/min), scraped 368333 items (at 93 items/min)
2017-11-05 02:45:03 [scrapy.extensions.logstats] INFO: Crawled 421996 pages (at 94 pages/min), scraped 368421 items (at 88 items/min)
2017-11-05 02:46:04 [scrapy.extensions.logstats] INFO: Crawled 422101 pages (at 105 pages/min), scraped 368501 items (at 80 items/min)
2017-11-05 02:47:03 [scrapy.extensions.logstats] INFO: Crawled 422213 pages (at 112 pages/min), scraped 368603 items (at 102 items/min)
2017-11-05 02:48:04 [scrapy.extensions.logstats] INFO: Crawled 422314 pages (at 101 pages/min), scraped 368692 items (at 89 items/min)
2017-11-05 02:49:04 [scrapy.extensions.logstats] INFO: Crawled 422420 pages (at 106 pages/min), scraped 368777 items (at 85 items/min)
2017-11-05 02:50:04 [scrapy.extensions.logstats] INFO: Crawled 422529 pages (at 109 pages/min), scraped 368873 items (at 96 items/min)
2017-11-05 02:51:04 [scrapy.extensions.logstats] INFO: Crawled 422640 pages (at 111 pages/min), scraped 368981 items (at 108 items/min)
2017-11-05 02:52:03 [scrapy.extensions.logstats] INFO: Crawled 422761 pages (at 121 pages/min), scraped 369096 items (at 115 items/min)
2017-11-05 02:53:03 [scrapy.extensions.logstats] INFO: Crawled 422873 pages (at 112 pages/min), scraped 369191 items (at 95 items/min)
2017-11-05 02:54:03 [scrapy.extensions.logstats] INFO: Crawled 422989 pages (at 116 pages/min), scraped 369287 items (at 96 items/min)
2017-11-05 02:55:04 [scrapy.extensions.logstats] INFO: Crawled 423082 pages (at 93 pages/min), scraped 369365 items (at 78 items/min)
2017-11-05 02:56:04 [scrapy.extensions.logstats] INFO: Crawled 423193 pages (at 111 pages/min), scraped 369465 items (at 100 items/min)
2017-11-05 02:57:03 [scrapy.extensions.logstats] INFO: Crawled 423292 pages (at 99 pages/min), scraped 369565 items (at 100 items/min)
2017-11-05 02:58:03 [scrapy.extensions.logstats] INFO: Crawled 423397 pages (at 105 pages/min), scraped 369657 items (at 92 items/min)
2017-11-05 02:59:04 [scrapy.extensions.logstats] INFO: Crawled 423499 pages (at 102 pages/min), scraped 369736 items (at 79 items/min)
2017-11-05 03:00:04 [scrapy.extensions.logstats] INFO: Crawled 423601 pages (at 102 pages/min), scraped 369813 items (at 77 items/min)
2017-11-05 03:01:03 [scrapy.extensions.logstats] INFO: Crawled 423694 pages (at 93 pages/min), scraped 369873 items (at 60 items/min)
2017-11-05 03:02:04 [scrapy.extensions.logstats] INFO: Crawled 423796 pages (at 102 pages/min), scraped 369937 items (at 64 items/min)
2017-11-05 03:03:04 [scrapy.extensions.logstats] INFO: Crawled 423905 pages (at 109 pages/min), scraped 370007 items (at 70 items/min)
2017-11-05 03:04:03 [scrapy.extensions.logstats] INFO: Crawled 424001 pages (at 96 pages/min), scraped 370079 items (at 72 items/min)
2017-11-05 03:05:03 [scrapy.extensions.logstats] INFO: Crawled 424117 pages (at 116 pages/min), scraped 370152 items (at 73 items/min)
2017-11-05 03:06:03 [scrapy.extensions.logstats] INFO: Crawled 424235 pages (at 118 pages/min), scraped 370240 items (at 88 items/min)
2017-11-05 03:07:03 [scrapy.extensions.logstats] INFO: Crawled 424331 pages (at 96 pages/min), scraped 370318 items (at 78 items/min)
2017-11-05 03:08:03 [scrapy.extensions.logstats] INFO: Crawled 424450 pages (at 119 pages/min), scraped 370412 items (at 94 items/min)
2017-11-05 03:09:04 [scrapy.extensions.logstats] INFO: Crawled 424540 pages (at 90 pages/min), scraped 370488 items (at 76 items/min)
2017-11-05 03:10:04 [scrapy.extensions.logstats] INFO: Crawled 424646 pages (at 106 pages/min), scraped 370577 items (at 89 items/min)
2017-11-05 03:11:03 [scrapy.extensions.logstats] INFO: Crawled 424734 pages (at 88 pages/min), scraped 370647 items (at 70 items/min)
2017-11-05 03:12:03 [scrapy.extensions.logstats] INFO: Crawled 424850 pages (at 116 pages/min), scraped 370746 items (at 99 items/min)
2017-11-05 03:13:04 [scrapy.extensions.logstats] INFO: Crawled 424954 pages (at 104 pages/min), scraped 370830 items (at 84 items/min)
2017-11-05 03:14:04 [scrapy.extensions.logstats] INFO: Crawled 425055 pages (at 101 pages/min), scraped 370908 items (at 78 items/min)
2017-11-05 03:15:03 [scrapy.extensions.logstats] INFO: Crawled 425169 pages (at 114 pages/min), scraped 371001 items (at 93 items/min)
2017-11-05 03:16:03 [scrapy.extensions.logstats] INFO: Crawled 425278 pages (at 109 pages/min), scraped 371080 items (at 79 items/min)
2017-11-05 03:17:03 [scrapy.extensions.logstats] INFO: Crawled 425384 pages (at 106 pages/min), scraped 371157 items (at 77 items/min)
2017-11-05 03:18:03 [scrapy.extensions.logstats] INFO: Crawled 425497 pages (at 113 pages/min), scraped 371252 items (at 95 items/min)
2017-11-05 03:19:04 [scrapy.extensions.logstats] INFO: Crawled 425611 pages (at 114 pages/min), scraped 371346 items (at 94 items/min)
2017-11-05 03:20:04 [scrapy.extensions.logstats] INFO: Crawled 425710 pages (at 99 pages/min), scraped 371439 items (at 93 items/min)
2017-11-05 03:21:03 [scrapy.extensions.logstats] INFO: Crawled 425808 pages (at 98 pages/min), scraped 371517 items (at 78 items/min)
2017-11-05 03:22:04 [scrapy.extensions.logstats] INFO: Crawled 425895 pages (at 87 pages/min), scraped 371598 items (at 81 items/min)
2017-11-05 03:23:03 [scrapy.extensions.logstats] INFO: Crawled 426008 pages (at 113 pages/min), scraped 371718 items (at 120 items/min)
2017-11-05 03:24:04 [scrapy.extensions.logstats] INFO: Crawled 426139 pages (at 131 pages/min), scraped 371830 items (at 112 items/min)
2017-11-05 03:25:04 [scrapy.extensions.logstats] INFO: Crawled 426272 pages (at 133 pages/min), scraped 371951 items (at 121 items/min)
2017-11-05 03:26:03 [scrapy.extensions.logstats] INFO: Crawled 426387 pages (at 115 pages/min), scraped 372050 items (at 99 items/min)
2017-11-05 03:27:03 [scrapy.extensions.logstats] INFO: Crawled 426495 pages (at 108 pages/min), scraped 372141 items (at 91 items/min)
2017-11-05 03:28:04 [scrapy.extensions.logstats] INFO: Crawled 426590 pages (at 95 pages/min), scraped 372240 items (at 99 items/min)
2017-11-05 03:29:03 [scrapy.extensions.logstats] INFO: Crawled 426697 pages (at 107 pages/min), scraped 372325 items (at 85 items/min)
2017-11-05 03:30:04 [scrapy.extensions.logstats] INFO: Crawled 426807 pages (at 110 pages/min), scraped 372423 items (at 98 items/min)
2017-11-05 03:31:04 [scrapy.extensions.logstats] INFO: Crawled 426900 pages (at 93 pages/min), scraped 372497 items (at 74 items/min)
2017-11-05 03:32:03 [scrapy.extensions.logstats] INFO: Crawled 427027 pages (at 127 pages/min), scraped 372601 items (at 104 items/min)
2017-11-05 03:33:04 [scrapy.extensions.logstats] INFO: Crawled 427140 pages (at 113 pages/min), scraped 372705 items (at 104 items/min)
2017-11-05 03:34:04 [scrapy.extensions.logstats] INFO: Crawled 427226 pages (at 86 pages/min), scraped 372783 items (at 78 items/min)
2017-11-05 03:35:04 [scrapy.extensions.logstats] INFO: Crawled 427324 pages (at 98 pages/min), scraped 372878 items (at 95 items/min)
2017-11-05 03:36:04 [scrapy.extensions.logstats] INFO: Crawled 427420 pages (at 96 pages/min), scraped 372955 items (at 77 items/min)
2017-11-05 03:37:04 [scrapy.extensions.logstats] INFO: Crawled 427516 pages (at 96 pages/min), scraped 373043 items (at 88 items/min)
2017-11-05 03:38:03 [scrapy.extensions.logstats] INFO: Crawled 427620 pages (at 104 pages/min), scraped 373139 items (at 96 items/min)
2017-11-05 03:39:03 [scrapy.extensions.logstats] INFO: Crawled 427751 pages (at 131 pages/min), scraped 373249 items (at 110 items/min)
2017-11-05 03:40:03 [scrapy.extensions.logstats] INFO: Crawled 427862 pages (at 111 pages/min), scraped 373340 items (at 91 items/min)
2017-11-05 03:41:03 [scrapy.extensions.logstats] INFO: Crawled 427963 pages (at 101 pages/min), scraped 373424 items (at 84 items/min)
2017-11-05 03:42:04 [scrapy.extensions.logstats] INFO: Crawled 428073 pages (at 110 pages/min), scraped 373502 items (at 78 items/min)
2017-11-05 03:43:04 [scrapy.extensions.logstats] INFO: Crawled 428182 pages (at 109 pages/min), scraped 373593 items (at 91 items/min)
2017-11-05 03:44:03 [scrapy.extensions.logstats] INFO: Crawled 428274 pages (at 92 pages/min), scraped 373663 items (at 70 items/min)
2017-11-05 03:45:03 [scrapy.extensions.logstats] INFO: Crawled 428381 pages (at 107 pages/min), scraped 373751 items (at 88 items/min)
2017-11-05 03:46:03 [scrapy.extensions.logstats] INFO: Crawled 428480 pages (at 99 pages/min), scraped 373836 items (at 85 items/min)
2017-11-05 03:47:04 [scrapy.extensions.logstats] INFO: Crawled 428587 pages (at 107 pages/min), scraped 373926 items (at 90 items/min)
2017-11-05 03:48:03 [scrapy.extensions.logstats] INFO: Crawled 428694 pages (at 107 pages/min), scraped 374022 items (at 96 items/min)
2017-11-05 03:49:03 [scrapy.extensions.logstats] INFO: Crawled 428802 pages (at 108 pages/min), scraped 374114 items (at 92 items/min)
2017-11-05 03:50:03 [scrapy.extensions.logstats] INFO: Crawled 428910 pages (at 108 pages/min), scraped 374191 items (at 77 items/min)
2017-11-05 03:51:04 [scrapy.extensions.logstats] INFO: Crawled 429016 pages (at 106 pages/min), scraped 374257 items (at 66 items/min)
2017-11-05 03:52:04 [scrapy.extensions.logstats] INFO: Crawled 429113 pages (at 97 pages/min), scraped 374339 items (at 82 items/min)
2017-11-05 03:53:03 [scrapy.extensions.logstats] INFO: Crawled 429217 pages (at 104 pages/min), scraped 374414 items (at 75 items/min)
2017-11-05 03:54:03 [scrapy.extensions.logstats] INFO: Crawled 429327 pages (at 110 pages/min), scraped 374497 items (at 83 items/min)
2017-11-05 03:55:03 [scrapy.extensions.logstats] INFO: Crawled 429435 pages (at 108 pages/min), scraped 374579 items (at 82 items/min)
2017-11-05 03:56:04 [scrapy.extensions.logstats] INFO: Crawled 429548 pages (at 113 pages/min), scraped 374676 items (at 97 items/min)
2017-11-05 03:57:04 [scrapy.extensions.logstats] INFO: Crawled 429667 pages (at 119 pages/min), scraped 374777 items (at 101 items/min)
2017-11-05 03:58:03 [scrapy.extensions.logstats] INFO: Crawled 429777 pages (at 110 pages/min), scraped 374872 items (at 95 items/min)
2017-11-05 03:59:03 [scrapy.extensions.logstats] INFO: Crawled 429884 pages (at 107 pages/min), scraped 374950 items (at 78 items/min)
2017-11-05 04:00:04 [scrapy.extensions.logstats] INFO: Crawled 429986 pages (at 102 pages/min), scraped 375037 items (at 87 items/min)
2017-11-05 04:01:03 [scrapy.extensions.logstats] INFO: Crawled 430082 pages (at 96 pages/min), scraped 375126 items (at 89 items/min)
2017-11-05 04:02:03 [scrapy.extensions.logstats] INFO: Crawled 430183 pages (at 101 pages/min), scraped 375201 items (at 75 items/min)
2017-11-05 04:03:04 [scrapy.extensions.logstats] INFO: Crawled 430268 pages (at 85 pages/min), scraped 375276 items (at 75 items/min)
2017-11-05 04:04:03 [scrapy.extensions.logstats] INFO: Crawled 430364 pages (at 96 pages/min), scraped 375350 items (at 74 items/min)
2017-11-05 04:05:04 [scrapy.extensions.logstats] INFO: Crawled 430463 pages (at 99 pages/min), scraped 375437 items (at 87 items/min)
2017-11-05 04:06:04 [scrapy.extensions.logstats] INFO: Crawled 430567 pages (at 104 pages/min), scraped 375516 items (at 79 items/min)
2017-11-05 04:07:03 [scrapy.extensions.logstats] INFO: Crawled 430671 pages (at 104 pages/min), scraped 375601 items (at 85 items/min)
2017-11-05 04:08:03 [scrapy.extensions.logstats] INFO: Crawled 430778 pages (at 107 pages/min), scraped 375684 items (at 83 items/min)
2017-11-05 04:09:03 [scrapy.extensions.logstats] INFO: Crawled 430876 pages (at 98 pages/min), scraped 375764 items (at 80 items/min)
2017-11-05 04:10:04 [scrapy.extensions.logstats] INFO: Crawled 430981 pages (at 105 pages/min), scraped 375849 items (at 85 items/min)
2017-11-05 04:11:04 [scrapy.extensions.logstats] INFO: Crawled 431087 pages (at 106 pages/min), scraped 375928 items (at 79 items/min)
2017-11-05 04:12:03 [scrapy.extensions.logstats] INFO: Crawled 431174 pages (at 87 pages/min), scraped 376001 items (at 73 items/min)
2017-11-05 04:13:03 [scrapy.extensions.logstats] INFO: Crawled 431253 pages (at 79 pages/min), scraped 376063 items (at 62 items/min)
2017-11-05 04:14:04 [scrapy.extensions.logstats] INFO: Crawled 431358 pages (at 105 pages/min), scraped 376152 items (at 89 items/min)
2017-11-05 04:15:04 [scrapy.extensions.logstats] INFO: Crawled 431465 pages (at 107 pages/min), scraped 376241 items (at 89 items/min)
2017-11-05 04:16:04 [scrapy.extensions.logstats] INFO: Crawled 431559 pages (at 94 pages/min), scraped 376323 items (at 82 items/min)
2017-11-05 04:17:03 [scrapy.extensions.logstats] INFO: Crawled 431665 pages (at 106 pages/min), scraped 376421 items (at 98 items/min)
2017-11-05 04:18:03 [scrapy.extensions.logstats] INFO: Crawled 431773 pages (at 108 pages/min), scraped 376507 items (at 86 items/min)
2017-11-05 04:19:03 [scrapy.extensions.logstats] INFO: Crawled 431879 pages (at 106 pages/min), scraped 376595 items (at 88 items/min)
2017-11-05 04:20:04 [scrapy.extensions.logstats] INFO: Crawled 431980 pages (at 101 pages/min), scraped 376686 items (at 91 items/min)
2017-11-05 04:21:04 [scrapy.extensions.logstats] INFO: Crawled 432077 pages (at 97 pages/min), scraped 376757 items (at 71 items/min)
2017-11-05 04:22:04 [scrapy.extensions.logstats] INFO: Crawled 432170 pages (at 93 pages/min), scraped 376841 items (at 84 items/min)
2017-11-05 04:23:03 [scrapy.extensions.logstats] INFO: Crawled 432280 pages (at 110 pages/min), scraped 376954 items (at 113 items/min)
2017-11-05 04:24:04 [scrapy.extensions.logstats] INFO: Crawled 432391 pages (at 111 pages/min), scraped 377062 items (at 108 items/min)
2017-11-05 04:25:03 [scrapy.extensions.logstats] INFO: Crawled 432499 pages (at 108 pages/min), scraped 377149 items (at 87 items/min)
2017-11-05 04:26:04 [scrapy.extensions.logstats] INFO: Crawled 432607 pages (at 108 pages/min), scraped 377252 items (at 103 items/min)
2017-11-05 04:27:03 [scrapy.extensions.logstats] INFO: Crawled 432709 pages (at 102 pages/min), scraped 377356 items (at 104 items/min)
2017-11-05 04:28:04 [scrapy.extensions.logstats] INFO: Crawled 432819 pages (at 110 pages/min), scraped 377495 items (at 139 items/min)
2017-11-05 04:29:03 [scrapy.extensions.logstats] INFO: Crawled 432918 pages (at 99 pages/min), scraped 377601 items (at 106 items/min)
2017-11-05 04:30:04 [scrapy.extensions.logstats] INFO: Crawled 433018 pages (at 100 pages/min), scraped 377684 items (at 83 items/min)
2017-11-05 04:31:03 [scrapy.extensions.logstats] INFO: Crawled 433109 pages (at 91 pages/min), scraped 377762 items (at 78 items/min)
2017-11-05 04:32:04 [scrapy.extensions.logstats] INFO: Crawled 433213 pages (at 104 pages/min), scraped 377853 items (at 91 items/min)
2017-11-05 04:33:03 [scrapy.extensions.logstats] INFO: Crawled 433320 pages (at 107 pages/min), scraped 377955 items (at 102 items/min)
2017-11-05 04:34:03 [scrapy.extensions.logstats] INFO: Crawled 433417 pages (at 97 pages/min), scraped 378036 items (at 81 items/min)
2017-11-05 04:35:03 [scrapy.extensions.logstats] INFO: Crawled 433522 pages (at 105 pages/min), scraped 378135 items (at 99 items/min)
2017-11-05 04:36:03 [scrapy.extensions.logstats] INFO: Crawled 433617 pages (at 95 pages/min), scraped 378221 items (at 86 items/min)
2017-11-05 04:37:03 [scrapy.extensions.logstats] INFO: Crawled 433725 pages (at 108 pages/min), scraped 378297 items (at 76 items/min)
2017-11-05 04:38:03 [scrapy.extensions.logstats] INFO: Crawled 433828 pages (at 103 pages/min), scraped 378390 items (at 93 items/min)
2017-11-05 04:39:04 [scrapy.extensions.logstats] INFO: Crawled 433923 pages (at 95 pages/min), scraped 378475 items (at 85 items/min)
2017-11-05 04:40:04 [scrapy.extensions.logstats] INFO: Crawled 434031 pages (at 108 pages/min), scraped 378571 items (at 96 items/min)
2017-11-05 04:41:04 [scrapy.extensions.logstats] INFO: Crawled 434138 pages (at 107 pages/min), scraped 378674 items (at 103 items/min)
2017-11-05 04:42:04 [scrapy.extensions.logstats] INFO: Crawled 434245 pages (at 107 pages/min), scraped 378765 items (at 91 items/min)
2017-11-05 04:43:04 [scrapy.extensions.logstats] INFO: Crawled 434359 pages (at 114 pages/min), scraped 378872 items (at 107 items/min)
2017-11-05 04:44:04 [scrapy.extensions.logstats] INFO: Crawled 434467 pages (at 108 pages/min), scraped 378975 items (at 103 items/min)
2017-11-05 04:45:03 [scrapy.extensions.logstats] INFO: Crawled 434584 pages (at 117 pages/min), scraped 379089 items (at 114 items/min)
2017-11-05 04:46:04 [scrapy.extensions.logstats] INFO: Crawled 434700 pages (at 116 pages/min), scraped 379188 items (at 99 items/min)
2017-11-05 04:47:04 [scrapy.extensions.logstats] INFO: Crawled 434806 pages (at 106 pages/min), scraped 379287 items (at 99 items/min)
2017-11-05 04:48:04 [scrapy.extensions.logstats] INFO: Crawled 434896 pages (at 90 pages/min), scraped 379378 items (at 91 items/min)
2017-11-05 04:49:03 [scrapy.extensions.logstats] INFO: Crawled 435005 pages (at 109 pages/min), scraped 379489 items (at 111 items/min)
2017-11-05 04:50:04 [scrapy.extensions.logstats] INFO: Crawled 435105 pages (at 100 pages/min), scraped 379573 items (at 84 items/min)
2017-11-05 04:51:04 [scrapy.extensions.logstats] INFO: Crawled 435213 pages (at 108 pages/min), scraped 379645 items (at 72 items/min)
2017-11-05 04:52:03 [scrapy.extensions.logstats] INFO: Crawled 435311 pages (at 98 pages/min), scraped 379718 items (at 73 items/min)
2017-11-05 04:53:04 [scrapy.extensions.logstats] INFO: Crawled 435427 pages (at 116 pages/min), scraped 379832 items (at 114 items/min)
2017-11-05 04:54:03 [scrapy.extensions.logstats] INFO: Crawled 435530 pages (at 103 pages/min), scraped 379920 items (at 88 items/min)
2017-11-05 04:55:03 [scrapy.extensions.logstats] INFO: Crawled 435640 pages (at 110 pages/min), scraped 380021 items (at 101 items/min)
2017-11-05 04:56:04 [scrapy.extensions.logstats] INFO: Crawled 435746 pages (at 106 pages/min), scraped 380129 items (at 108 items/min)
2017-11-05 04:57:03 [scrapy.extensions.logstats] INFO: Crawled 435831 pages (at 85 pages/min), scraped 380220 items (at 91 items/min)
2017-11-05 04:58:03 [scrapy.extensions.logstats] INFO: Crawled 435937 pages (at 106 pages/min), scraped 380325 items (at 105 items/min)
2017-11-05 04:59:03 [scrapy.extensions.logstats] INFO: Crawled 436036 pages (at 99 pages/min), scraped 380418 items (at 93 items/min)
2017-11-05 05:00:04 [scrapy.extensions.logstats] INFO: Crawled 436140 pages (at 104 pages/min), scraped 380518 items (at 100 items/min)
2017-11-05 05:01:04 [scrapy.extensions.logstats] INFO: Crawled 436244 pages (at 104 pages/min), scraped 380614 items (at 96 items/min)
2017-11-05 05:02:03 [scrapy.extensions.logstats] INFO: Crawled 436349 pages (at 105 pages/min), scraped 380730 items (at 116 items/min)
2017-11-05 05:03:04 [scrapy.extensions.logstats] INFO: Crawled 436448 pages (at 99 pages/min), scraped 380825 items (at 95 items/min)
2017-11-05 05:04:03 [scrapy.extensions.logstats] INFO: Crawled 436549 pages (at 101 pages/min), scraped 380905 items (at 80 items/min)
2017-11-05 05:05:04 [scrapy.extensions.logstats] INFO: Crawled 436664 pages (at 115 pages/min), scraped 381015 items (at 110 items/min)
2017-11-05 05:06:03 [scrapy.extensions.logstats] INFO: Crawled 436764 pages (at 100 pages/min), scraped 381120 items (at 105 items/min)
2017-11-05 05:07:03 [scrapy.extensions.logstats] INFO: Crawled 436865 pages (at 101 pages/min), scraped 381217 items (at 97 items/min)
2017-11-05 05:08:04 [scrapy.extensions.logstats] INFO: Crawled 436970 pages (at 105 pages/min), scraped 381307 items (at 90 items/min)
2017-11-05 05:09:03 [scrapy.extensions.logstats] INFO: Crawled 437072 pages (at 102 pages/min), scraped 381391 items (at 84 items/min)
2017-11-05 05:10:03 [scrapy.extensions.logstats] INFO: Crawled 437163 pages (at 91 pages/min), scraped 381487 items (at 96 items/min)
2017-11-05 05:11:04 [scrapy.extensions.logstats] INFO: Crawled 437272 pages (at 109 pages/min), scraped 381594 items (at 107 items/min)
2017-11-05 05:12:04 [scrapy.extensions.logstats] INFO: Crawled 437371 pages (at 99 pages/min), scraped 381681 items (at 87 items/min)
2017-11-05 05:13:03 [scrapy.extensions.logstats] INFO: Crawled 437468 pages (at 97 pages/min), scraped 381779 items (at 98 items/min)
2017-11-05 05:14:04 [scrapy.extensions.logstats] INFO: Crawled 437571 pages (at 103 pages/min), scraped 381872 items (at 93 items/min)
2017-11-05 05:15:04 [scrapy.extensions.logstats] INFO: Crawled 437678 pages (at 107 pages/min), scraped 381963 items (at 91 items/min)
2017-11-05 05:16:04 [scrapy.extensions.logstats] INFO: Crawled 437787 pages (at 109 pages/min), scraped 382074 items (at 111 items/min)
2017-11-05 05:17:04 [scrapy.extensions.logstats] INFO: Crawled 437880 pages (at 93 pages/min), scraped 382153 items (at 79 items/min)
2017-11-05 05:18:03 [scrapy.extensions.logstats] INFO: Crawled 437968 pages (at 88 pages/min), scraped 382239 items (at 86 items/min)
2017-11-05 05:19:04 [scrapy.extensions.logstats] INFO: Crawled 438068 pages (at 100 pages/min), scraped 382329 items (at 90 items/min)
2017-11-05 05:20:04 [scrapy.extensions.logstats] INFO: Crawled 438157 pages (at 89 pages/min), scraped 382402 items (at 73 items/min)
2017-11-05 05:21:04 [scrapy.extensions.logstats] INFO: Crawled 438248 pages (at 91 pages/min), scraped 382478 items (at 76 items/min)
2017-11-05 05:22:04 [scrapy.extensions.logstats] INFO: Crawled 438350 pages (at 102 pages/min), scraped 382548 items (at 70 items/min)
2017-11-05 05:23:05 [scrapy.extensions.logstats] INFO: Crawled 438448 pages (at 98 pages/min), scraped 382628 items (at 80 items/min)
2017-11-05 05:24:04 [scrapy.extensions.logstats] INFO: Crawled 438543 pages (at 95 pages/min), scraped 382682 items (at 54 items/min)
2017-11-05 05:25:04 [scrapy.extensions.logstats] INFO: Crawled 438629 pages (at 86 pages/min), scraped 382751 items (at 69 items/min)
2017-11-05 05:26:04 [scrapy.extensions.logstats] INFO: Crawled 438741 pages (at 112 pages/min), scraped 382834 items (at 83 items/min)
2017-11-05 05:27:03 [scrapy.extensions.logstats] INFO: Crawled 438851 pages (at 110 pages/min), scraped 382911 items (at 77 items/min)
2017-11-05 05:28:04 [scrapy.extensions.logstats] INFO: Crawled 438954 pages (at 103 pages/min), scraped 382974 items (at 63 items/min)
2017-11-05 05:29:03 [scrapy.extensions.logstats] INFO: Crawled 439054 pages (at 100 pages/min), scraped 383057 items (at 83 items/min)
2017-11-05 05:30:04 [scrapy.extensions.logstats] INFO: Crawled 439146 pages (at 92 pages/min), scraped 383148 items (at 91 items/min)
2017-11-05 05:31:04 [scrapy.extensions.logstats] INFO: Crawled 439234 pages (at 88 pages/min), scraped 383230 items (at 82 items/min)
2017-11-05 05:32:03 [scrapy.extensions.logstats] INFO: Crawled 439320 pages (at 86 pages/min), scraped 383322 items (at 92 items/min)
2017-11-05 05:33:03 [scrapy.extensions.logstats] INFO: Crawled 439425 pages (at 105 pages/min), scraped 383408 items (at 86 items/min)
2017-11-05 05:34:04 [scrapy.extensions.logstats] INFO: Crawled 439518 pages (at 93 pages/min), scraped 383501 items (at 93 items/min)
2017-11-05 05:35:04 [scrapy.extensions.logstats] INFO: Crawled 439629 pages (at 111 pages/min), scraped 383608 items (at 107 items/min)
2017-11-05 05:36:03 [scrapy.extensions.logstats] INFO: Crawled 439727 pages (at 98 pages/min), scraped 383706 items (at 98 items/min)
2017-11-05 05:37:04 [scrapy.extensions.logstats] INFO: Crawled 439829 pages (at 102 pages/min), scraped 383808 items (at 102 items/min)
2017-11-05 05:38:04 [scrapy.extensions.logstats] INFO: Crawled 439934 pages (at 105 pages/min), scraped 383907 items (at 99 items/min)
2017-11-05 05:39:03 [scrapy.extensions.logstats] INFO: Crawled 440038 pages (at 104 pages/min), scraped 384013 items (at 106 items/min)
2017-11-05 05:40:03 [scrapy.extensions.logstats] INFO: Crawled 440144 pages (at 106 pages/min), scraped 384118 items (at 105 items/min)
2017-11-05 05:41:03 [scrapy.extensions.logstats] INFO: Crawled 440254 pages (at 110 pages/min), scraped 384209 items (at 91 items/min)
2017-11-05 05:42:03 [scrapy.extensions.logstats] INFO: Crawled 440356 pages (at 102 pages/min), scraped 384298 items (at 89 items/min)
2017-11-05 05:43:03 [scrapy.extensions.logstats] INFO: Crawled 440469 pages (at 113 pages/min), scraped 384397 items (at 99 items/min)
2017-11-05 05:44:04 [scrapy.extensions.logstats] INFO: Crawled 440579 pages (at 110 pages/min), scraped 384491 items (at 94 items/min)
2017-11-05 05:45:04 [scrapy.extensions.logstats] INFO: Crawled 440687 pages (at 108 pages/min), scraped 384589 items (at 98 items/min)
2017-11-05 05:46:03 [scrapy.extensions.logstats] INFO: Crawled 440801 pages (at 114 pages/min), scraped 384719 items (at 130 items/min)
2017-11-05 05:47:03 [scrapy.extensions.logstats] INFO: Crawled 440907 pages (at 106 pages/min), scraped 384816 items (at 97 items/min)
2017-11-05 05:48:03 [scrapy.extensions.logstats] INFO: Crawled 441016 pages (at 109 pages/min), scraped 384913 items (at 97 items/min)
2017-11-05 05:49:04 [scrapy.extensions.logstats] INFO: Crawled 441138 pages (at 122 pages/min), scraped 385024 items (at 111 items/min)
2017-11-05 05:50:04 [scrapy.extensions.logstats] INFO: Crawled 441247 pages (at 109 pages/min), scraped 385114 items (at 90 items/min)
2017-11-05 05:51:03 [scrapy.extensions.logstats] INFO: Crawled 441341 pages (at 94 pages/min), scraped 385180 items (at 66 items/min)
2017-11-05 05:52:04 [scrapy.extensions.logstats] INFO: Crawled 441457 pages (at 116 pages/min), scraped 385267 items (at 87 items/min)
2017-11-05 05:53:04 [scrapy.extensions.logstats] INFO: Crawled 441572 pages (at 115 pages/min), scraped 385354 items (at 87 items/min)
2017-11-05 05:54:03 [scrapy.extensions.logstats] INFO: Crawled 441681 pages (at 109 pages/min), scraped 385435 items (at 81 items/min)
2017-11-05 05:55:03 [scrapy.extensions.logstats] INFO: Crawled 441796 pages (at 115 pages/min), scraped 385533 items (at 98 items/min)
2017-11-05 05:56:03 [scrapy.extensions.logstats] INFO: Crawled 441910 pages (at 114 pages/min), scraped 385615 items (at 82 items/min)
2017-11-05 05:57:04 [scrapy.extensions.logstats] INFO: Crawled 442014 pages (at 104 pages/min), scraped 385699 items (at 84 items/min)
2017-11-05 05:58:03 [scrapy.extensions.logstats] INFO: Crawled 442131 pages (at 117 pages/min), scraped 385790 items (at 91 items/min)
2017-11-05 05:59:04 [scrapy.extensions.logstats] INFO: Crawled 442229 pages (at 98 pages/min), scraped 385868 items (at 78 items/min)
2017-11-05 05:59:08 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 05:59:08 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 05:59:09 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:00:04 [scrapy.extensions.logstats] INFO: Crawled 442304 pages (at 75 pages/min), scraped 385912 items (at 44 items/min)
2017-11-05 06:01:03 [scrapy.extensions.logstats] INFO: Crawled 442411 pages (at 107 pages/min), scraped 385987 items (at 75 items/min)
2017-11-05 06:02:04 [scrapy.extensions.logstats] INFO: Crawled 442524 pages (at 113 pages/min), scraped 386072 items (at 85 items/min)
2017-11-05 06:02:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=189269&sqlkey=registration&sqlval=SELECT_PERSON_INFO>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:02:32 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:03:05 [scrapy.extensions.logstats] INFO: Crawled 442605 pages (at 81 pages/min), scraped 386132 items (at 60 items/min)
2017-11-05 06:04:04 [scrapy.extensions.logstats] INFO: Crawled 442715 pages (at 110 pages/min), scraped 386228 items (at 96 items/min)
2017-11-05 06:05:03 [scrapy.extensions.logstats] INFO: Crawled 442826 pages (at 111 pages/min), scraped 386328 items (at 100 items/min)
2017-11-05 06:06:03 [scrapy.extensions.logstats] INFO: Crawled 442941 pages (at 115 pages/min), scraped 386422 items (at 94 items/min)
2017-11-05 06:06:53 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:06:54 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:06:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=59964263&sqlkey=registration&sqlval=SELECT_PERSON_INFO>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:06:54 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:06:54 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:06:54 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-05 06:07:03 [scrapy.extensions.logstats] INFO: Crawled 443018 pages (at 77 pages/min), scraped 386483 items (at 61 items/min)
2017-11-05 06:08:04 [scrapy.extensions.logstats] INFO: Crawled 443116 pages (at 98 pages/min), scraped 386552 items (at 69 items/min)
2017-11-05 06:09:03 [scrapy.extensions.logstats] INFO: Crawled 443221 pages (at 105 pages/min), scraped 386626 items (at 74 items/min)
2017-11-05 06:10:04 [scrapy.extensions.logstats] INFO: Crawled 443318 pages (at 97 pages/min), scraped 386691 items (at 65 items/min)
2017-11-05 06:11:03 [scrapy.extensions.logstats] INFO: Crawled 443425 pages (at 107 pages/min), scraped 386782 items (at 91 items/min)
2017-11-05 06:12:03 [scrapy.extensions.logstats] INFO: Crawled 443537 pages (at 112 pages/min), scraped 386865 items (at 83 items/min)
2017-11-05 06:13:04 [scrapy.extensions.logstats] INFO: Crawled 443663 pages (at 126 pages/min), scraped 386955 items (at 90 items/min)
2017-11-05 06:14:04 [scrapy.extensions.logstats] INFO: Crawled 443770 pages (at 107 pages/min), scraped 387037 items (at 82 items/min)
2017-11-05 06:15:04 [scrapy.extensions.logstats] INFO: Crawled 443866 pages (at 96 pages/min), scraped 387118 items (at 81 items/min)
2017-11-05 06:16:03 [scrapy.extensions.logstats] INFO: Crawled 443972 pages (at 106 pages/min), scraped 387209 items (at 91 items/min)
2017-11-05 06:17:03 [scrapy.extensions.logstats] INFO: Crawled 444075 pages (at 103 pages/min), scraped 387283 items (at 74 items/min)
2017-11-05 06:18:04 [scrapy.extensions.logstats] INFO: Crawled 444182 pages (at 107 pages/min), scraped 387356 items (at 73 items/min)
2017-11-05 06:19:04 [scrapy.extensions.logstats] INFO: Crawled 444277 pages (at 95 pages/min), scraped 387435 items (at 79 items/min)
2017-11-05 06:20:03 [scrapy.extensions.logstats] INFO: Crawled 444385 pages (at 108 pages/min), scraped 387511 items (at 76 items/min)
2017-11-05 06:21:04 [scrapy.extensions.logstats] INFO: Crawled 444489 pages (at 104 pages/min), scraped 387589 items (at 78 items/min)
2017-11-05 06:22:03 [scrapy.extensions.logstats] INFO: Crawled 444588 pages (at 99 pages/min), scraped 387690 items (at 101 items/min)
2017-11-05 06:23:03 [scrapy.extensions.logstats] INFO: Crawled 444694 pages (at 106 pages/min), scraped 387767 items (at 77 items/min)
2017-11-05 06:24:03 [scrapy.extensions.logstats] INFO: Crawled 444794 pages (at 100 pages/min), scraped 387840 items (at 73 items/min)
2017-11-05 06:25:03 [scrapy.extensions.logstats] INFO: Crawled 444890 pages (at 96 pages/min), scraped 387919 items (at 79 items/min)
2017-11-05 06:26:03 [scrapy.extensions.logstats] INFO: Crawled 444992 pages (at 102 pages/min), scraped 387985 items (at 66 items/min)
2017-11-05 06:27:04 [scrapy.extensions.logstats] INFO: Crawled 445082 pages (at 90 pages/min), scraped 388049 items (at 64 items/min)
2017-11-05 06:28:04 [scrapy.extensions.logstats] INFO: Crawled 445183 pages (at 101 pages/min), scraped 388113 items (at 64 items/min)
2017-11-05 06:29:05 [scrapy.extensions.logstats] INFO: Crawled 445291 pages (at 108 pages/min), scraped 388209 items (at 96 items/min)
2017-11-05 06:30:03 [scrapy.extensions.logstats] INFO: Crawled 445385 pages (at 94 pages/min), scraped 388287 items (at 78 items/min)
2017-11-05 06:31:04 [scrapy.extensions.logstats] INFO: Crawled 445480 pages (at 95 pages/min), scraped 388347 items (at 60 items/min)
2017-11-05 06:32:04 [scrapy.extensions.logstats] INFO: Crawled 445591 pages (at 111 pages/min), scraped 388438 items (at 91 items/min)
2017-11-05 06:33:03 [scrapy.extensions.logstats] INFO: Crawled 445688 pages (at 97 pages/min), scraped 388524 items (at 86 items/min)
2017-11-05 06:34:03 [scrapy.extensions.logstats] INFO: Crawled 445782 pages (at 94 pages/min), scraped 388591 items (at 67 items/min)
2017-11-05 06:35:04 [scrapy.extensions.logstats] INFO: Crawled 445875 pages (at 93 pages/min), scraped 388666 items (at 75 items/min)
2017-11-05 06:36:04 [scrapy.extensions.logstats] INFO: Crawled 445975 pages (at 100 pages/min), scraped 388740 items (at 74 items/min)
2017-11-05 06:37:03 [scrapy.extensions.logstats] INFO: Crawled 446069 pages (at 94 pages/min), scraped 388817 items (at 77 items/min)
2017-11-05 06:38:04 [scrapy.extensions.logstats] INFO: Crawled 446158 pages (at 89 pages/min), scraped 388880 items (at 63 items/min)
2017-11-05 06:39:03 [scrapy.extensions.logstats] INFO: Crawled 446256 pages (at 98 pages/min), scraped 388949 items (at 69 items/min)
2017-11-05 06:40:03 [scrapy.extensions.logstats] INFO: Crawled 446348 pages (at 92 pages/min), scraped 389028 items (at 79 items/min)
2017-11-05 06:41:04 [scrapy.extensions.logstats] INFO: Crawled 446445 pages (at 97 pages/min), scraped 389096 items (at 68 items/min)
2017-11-05 06:42:04 [scrapy.extensions.logstats] INFO: Crawled 446558 pages (at 113 pages/min), scraped 389185 items (at 89 items/min)
2017-11-05 06:43:03 [scrapy.extensions.logstats] INFO: Crawled 446654 pages (at 96 pages/min), scraped 389270 items (at 85 items/min)
2017-11-05 06:44:04 [scrapy.extensions.logstats] INFO: Crawled 446754 pages (at 100 pages/min), scraped 389344 items (at 74 items/min)
2017-11-05 06:45:03 [scrapy.extensions.logstats] INFO: Crawled 446857 pages (at 103 pages/min), scraped 389432 items (at 88 items/min)
2017-11-05 06:46:04 [scrapy.extensions.logstats] INFO: Crawled 446953 pages (at 96 pages/min), scraped 389509 items (at 77 items/min)
2017-11-05 06:47:04 [scrapy.extensions.logstats] INFO: Crawled 447055 pages (at 102 pages/min), scraped 389586 items (at 77 items/min)
2017-11-05 06:48:03 [scrapy.extensions.logstats] INFO: Crawled 447151 pages (at 96 pages/min), scraped 389663 items (at 77 items/min)
2017-11-05 06:49:03 [scrapy.extensions.logstats] INFO: Crawled 447260 pages (at 109 pages/min), scraped 389740 items (at 77 items/min)
2017-11-05 06:50:04 [scrapy.extensions.logstats] INFO: Crawled 447364 pages (at 104 pages/min), scraped 389818 items (at 78 items/min)
2017-11-05 06:51:04 [scrapy.extensions.logstats] INFO: Crawled 447472 pages (at 108 pages/min), scraped 389899 items (at 81 items/min)
2017-11-05 06:52:03 [scrapy.extensions.logstats] INFO: Crawled 447581 pages (at 109 pages/min), scraped 389986 items (at 87 items/min)
2017-11-05 06:53:04 [scrapy.extensions.logstats] INFO: Crawled 447683 pages (at 102 pages/min), scraped 390061 items (at 75 items/min)
2017-11-05 06:54:03 [scrapy.extensions.logstats] INFO: Crawled 447786 pages (at 103 pages/min), scraped 390150 items (at 89 items/min)
2017-11-05 06:55:03 [scrapy.extensions.logstats] INFO: Crawled 447890 pages (at 104 pages/min), scraped 390233 items (at 83 items/min)
2017-11-05 06:56:03 [scrapy.extensions.logstats] INFO: Crawled 447999 pages (at 109 pages/min), scraped 390323 items (at 90 items/min)
2017-11-05 06:57:04 [scrapy.extensions.logstats] INFO: Crawled 448099 pages (at 100 pages/min), scraped 390407 items (at 84 items/min)
2017-11-05 06:58:04 [scrapy.extensions.logstats] INFO: Crawled 448204 pages (at 105 pages/min), scraped 390480 items (at 73 items/min)
2017-11-05 06:59:04 [scrapy.extensions.logstats] INFO: Crawled 448297 pages (at 93 pages/min), scraped 390565 items (at 85 items/min)
2017-11-05 07:00:04 [scrapy.extensions.logstats] INFO: Crawled 448396 pages (at 99 pages/min), scraped 390651 items (at 86 items/min)
2017-11-05 07:01:04 [scrapy.extensions.logstats] INFO: Crawled 448487 pages (at 91 pages/min), scraped 390724 items (at 73 items/min)
2017-11-05 07:02:04 [scrapy.extensions.logstats] INFO: Crawled 448577 pages (at 90 pages/min), scraped 390794 items (at 70 items/min)
2017-11-05 07:03:04 [scrapy.extensions.logstats] INFO: Crawled 448684 pages (at 107 pages/min), scraped 390877 items (at 83 items/min)
2017-11-05 07:04:03 [scrapy.extensions.logstats] INFO: Crawled 448786 pages (at 102 pages/min), scraped 390951 items (at 74 items/min)
2017-11-05 07:05:04 [scrapy.extensions.logstats] INFO: Crawled 448875 pages (at 89 pages/min), scraped 391016 items (at 65 items/min)
2017-11-05 07:06:05 [scrapy.extensions.logstats] INFO: Crawled 448968 pages (at 93 pages/min), scraped 391090 items (at 74 items/min)
2017-11-05 07:07:03 [scrapy.extensions.logstats] INFO: Crawled 449072 pages (at 104 pages/min), scraped 391170 items (at 80 items/min)
2017-11-05 07:08:03 [scrapy.extensions.logstats] INFO: Crawled 449175 pages (at 103 pages/min), scraped 391241 items (at 71 items/min)
2017-11-05 07:09:03 [scrapy.extensions.logstats] INFO: Crawled 449267 pages (at 92 pages/min), scraped 391327 items (at 86 items/min)
2017-11-05 07:10:03 [scrapy.extensions.logstats] INFO: Crawled 449367 pages (at 100 pages/min), scraped 391400 items (at 73 items/min)
2017-11-05 07:11:03 [scrapy.extensions.logstats] INFO: Crawled 449469 pages (at 102 pages/min), scraped 391492 items (at 92 items/min)
2017-11-05 07:12:03 [scrapy.extensions.logstats] INFO: Crawled 449573 pages (at 104 pages/min), scraped 391576 items (at 84 items/min)
2017-11-05 07:13:03 [scrapy.extensions.logstats] INFO: Crawled 449669 pages (at 96 pages/min), scraped 391642 items (at 66 items/min)
2017-11-05 07:14:04 [scrapy.extensions.logstats] INFO: Crawled 449775 pages (at 106 pages/min), scraped 391733 items (at 91 items/min)
2017-11-05 07:15:03 [scrapy.extensions.logstats] INFO: Crawled 449872 pages (at 97 pages/min), scraped 391810 items (at 77 items/min)
2017-11-05 07:16:03 [scrapy.extensions.logstats] INFO: Crawled 449975 pages (at 103 pages/min), scraped 391883 items (at 73 items/min)
2017-11-05 07:17:04 [scrapy.extensions.logstats] INFO: Crawled 450079 pages (at 104 pages/min), scraped 391957 items (at 74 items/min)
2017-11-05 07:18:04 [scrapy.extensions.logstats] INFO: Crawled 450186 pages (at 107 pages/min), scraped 392043 items (at 86 items/min)
2017-11-05 07:19:04 [scrapy.extensions.logstats] INFO: Crawled 450282 pages (at 96 pages/min), scraped 392133 items (at 90 items/min)
2017-11-05 07:20:05 [scrapy.extensions.logstats] INFO: Crawled 450389 pages (at 107 pages/min), scraped 392216 items (at 83 items/min)
2017-11-05 07:21:03 [scrapy.extensions.logstats] INFO: Crawled 450497 pages (at 108 pages/min), scraped 392290 items (at 74 items/min)
2017-11-05 07:22:04 [scrapy.extensions.logstats] INFO: Crawled 450604 pages (at 107 pages/min), scraped 392365 items (at 75 items/min)
2017-11-05 07:23:03 [scrapy.extensions.logstats] INFO: Crawled 450703 pages (at 99 pages/min), scraped 392448 items (at 83 items/min)
2017-11-05 07:24:04 [scrapy.extensions.logstats] INFO: Crawled 450796 pages (at 93 pages/min), scraped 392525 items (at 77 items/min)
2017-11-05 07:25:04 [scrapy.extensions.logstats] INFO: Crawled 450901 pages (at 105 pages/min), scraped 392612 items (at 87 items/min)
2017-11-05 07:26:04 [scrapy.extensions.logstats] INFO: Crawled 451001 pages (at 100 pages/min), scraped 392689 items (at 77 items/min)
2017-11-05 07:27:03 [scrapy.extensions.logstats] INFO: Crawled 451104 pages (at 103 pages/min), scraped 392755 items (at 66 items/min)
2017-11-05 07:28:04 [scrapy.extensions.logstats] INFO: Crawled 451209 pages (at 105 pages/min), scraped 392833 items (at 78 items/min)
2017-11-05 07:29:03 [scrapy.extensions.logstats] INFO: Crawled 451301 pages (at 92 pages/min), scraped 392909 items (at 76 items/min)
2017-11-05 07:30:04 [scrapy.extensions.logstats] INFO: Crawled 451404 pages (at 103 pages/min), scraped 392991 items (at 82 items/min)
2017-11-05 07:31:04 [scrapy.extensions.logstats] INFO: Crawled 451513 pages (at 109 pages/min), scraped 393070 items (at 79 items/min)
2017-11-05 07:32:04 [scrapy.extensions.logstats] INFO: Crawled 451613 pages (at 100 pages/min), scraped 393152 items (at 82 items/min)
2017-11-05 07:33:03 [scrapy.extensions.logstats] INFO: Crawled 451717 pages (at 104 pages/min), scraped 393222 items (at 70 items/min)
2017-11-05 07:34:03 [scrapy.extensions.logstats] INFO: Crawled 451826 pages (at 109 pages/min), scraped 393307 items (at 85 items/min)
2017-11-05 07:35:03 [scrapy.extensions.logstats] INFO: Crawled 451942 pages (at 116 pages/min), scraped 393392 items (at 85 items/min)
2017-11-05 07:36:05 [scrapy.extensions.logstats] INFO: Crawled 452048 pages (at 106 pages/min), scraped 393473 items (at 81 items/min)
2017-11-05 07:37:04 [scrapy.extensions.logstats] INFO: Crawled 452145 pages (at 97 pages/min), scraped 393542 items (at 69 items/min)
2017-11-05 07:38:03 [scrapy.extensions.logstats] INFO: Crawled 452253 pages (at 108 pages/min), scraped 393634 items (at 92 items/min)
2017-11-05 07:39:04 [scrapy.extensions.logstats] INFO: Crawled 452348 pages (at 95 pages/min), scraped 393704 items (at 70 items/min)
2017-11-05 07:40:03 [scrapy.extensions.logstats] INFO: Crawled 452448 pages (at 100 pages/min), scraped 393793 items (at 89 items/min)
2017-11-05 07:41:04 [scrapy.extensions.logstats] INFO: Crawled 452550 pages (at 102 pages/min), scraped 393877 items (at 84 items/min)
2017-11-05 07:42:03 [scrapy.extensions.logstats] INFO: Crawled 452659 pages (at 109 pages/min), scraped 393968 items (at 91 items/min)
2017-11-05 07:43:03 [scrapy.extensions.logstats] INFO: Crawled 452769 pages (at 110 pages/min), scraped 394067 items (at 99 items/min)
2017-11-05 07:44:03 [scrapy.extensions.logstats] INFO: Crawled 452869 pages (at 100 pages/min), scraped 394148 items (at 81 items/min)
2017-11-05 07:45:04 [scrapy.extensions.logstats] INFO: Crawled 452972 pages (at 103 pages/min), scraped 394248 items (at 100 items/min)
2017-11-05 07:46:04 [scrapy.extensions.logstats] INFO: Crawled 453079 pages (at 107 pages/min), scraped 394324 items (at 76 items/min)
2017-11-05 07:47:04 [scrapy.extensions.logstats] INFO: Crawled 453185 pages (at 106 pages/min), scraped 394413 items (at 89 items/min)
2017-11-05 07:48:03 [scrapy.extensions.logstats] INFO: Crawled 453295 pages (at 110 pages/min), scraped 394497 items (at 84 items/min)
2017-11-05 07:49:03 [scrapy.extensions.logstats] INFO: Crawled 453406 pages (at 111 pages/min), scraped 394579 items (at 82 items/min)
2017-11-05 07:50:04 [scrapy.extensions.logstats] INFO: Crawled 453518 pages (at 112 pages/min), scraped 394670 items (at 91 items/min)
2017-11-05 07:51:03 [scrapy.extensions.logstats] INFO: Crawled 453624 pages (at 106 pages/min), scraped 394748 items (at 78 items/min)
2017-11-05 07:52:04 [scrapy.extensions.logstats] INFO: Crawled 453734 pages (at 110 pages/min), scraped 394831 items (at 83 items/min)
2017-11-05 07:53:04 [scrapy.extensions.logstats] INFO: Crawled 453841 pages (at 107 pages/min), scraped 394914 items (at 83 items/min)
2017-11-05 07:54:04 [scrapy.extensions.logstats] INFO: Crawled 453949 pages (at 108 pages/min), scraped 394997 items (at 83 items/min)
2017-11-05 07:56:31 [scrapy.extensions.logstats] INFO: Crawled 453985 pages (at 36 pages/min), scraped 395021 items (at 24 items/min)
2017-11-05 07:57:54 [scrapy.extensions.logstats] INFO: Crawled 453985 pages (at 0 pages/min), scraped 395025 items (at 4 items/min)
2017-11-05 07:59:00 [scrapy.extensions.logstats] INFO: Crawled 453985 pages (at 0 pages/min), scraped 395027 items (at 2 items/min)
2017-11-05 07:59:33 [scrapy.extensions.logstats] INFO: Crawled 453988 pages (at 3 pages/min), scraped 395028 items (at 1 items/min)
2017-11-05 08:00:08 [scrapy.extensions.logstats] INFO: Crawled 453989 pages (at 1 pages/min), scraped 395029 items (at 1 items/min)
2017-11-05 08:01:54 [scrapy.extensions.logstats] INFO: Crawled 453989 pages (at 0 pages/min), scraped 395032 items (at 3 items/min)
2017-11-05 08:02:09 [scrapy.extensions.logstats] INFO: Crawled 454002 pages (at 13 pages/min), scraped 395034 items (at 2 items/min)
2017-11-05 08:03:13 [scrapy.extensions.logstats] INFO: Crawled 454008 pages (at 6 pages/min), scraped 395040 items (at 6 items/min)
2017-11-05 08:04:28 [scrapy.extensions.logstats] INFO: Crawled 454013 pages (at 5 pages/min), scraped 395045 items (at 5 items/min)
2017-11-05 08:05:05 [scrapy.extensions.logstats] INFO: Crawled 454015 pages (at 2 pages/min), scraped 395048 items (at 3 items/min)
2017-11-05 08:06:08 [scrapy.extensions.logstats] INFO: Crawled 454020 pages (at 5 pages/min), scraped 395053 items (at 5 items/min)
2017-11-05 08:07:06 [scrapy.extensions.logstats] INFO: Crawled 454031 pages (at 11 pages/min), scraped 395058 items (at 5 items/min)
2017-11-05 08:08:05 [scrapy.extensions.logstats] INFO: Crawled 454038 pages (at 7 pages/min), scraped 395064 items (at 6 items/min)
2017-11-05 08:09:10 [scrapy.extensions.logstats] INFO: Crawled 454041 pages (at 3 pages/min), scraped 395070 items (at 6 items/min)
2017-11-05 08:10:32 [scrapy.extensions.logstats] INFO: Crawled 454045 pages (at 4 pages/min), scraped 395077 items (at 7 items/min)
2017-11-05 08:11:09 [scrapy.extensions.logstats] INFO: Crawled 454051 pages (at 6 pages/min), scraped 395080 items (at 3 items/min)
2017-11-05 08:12:15 [scrapy.extensions.logstats] INFO: Crawled 454062 pages (at 11 pages/min), scraped 395087 items (at 7 items/min)
2017-11-05 08:13:12 [scrapy.extensions.logstats] INFO: Crawled 454068 pages (at 6 pages/min), scraped 395093 items (at 6 items/min)
2017-11-05 08:14:12 [scrapy.extensions.logstats] INFO: Crawled 454070 pages (at 2 pages/min), scraped 395098 items (at 5 items/min)
2017-11-05 08:15:12 [scrapy.extensions.logstats] INFO: Crawled 454089 pages (at 19 pages/min), scraped 395105 items (at 7 items/min)
2017-11-05 08:16:08 [scrapy.extensions.logstats] INFO: Crawled 454095 pages (at 6 pages/min), scraped 395110 items (at 5 items/min)
2017-11-05 08:17:11 [scrapy.extensions.logstats] INFO: Crawled 454098 pages (at 3 pages/min), scraped 395114 items (at 4 items/min)
2017-11-05 08:18:08 [scrapy.extensions.logstats] INFO: Crawled 454114 pages (at 16 pages/min), scraped 395122 items (at 8 items/min)
2017-11-05 08:19:04 [scrapy.extensions.logstats] INFO: Crawled 454119 pages (at 5 pages/min), scraped 395128 items (at 6 items/min)
2017-11-05 08:20:10 [scrapy.extensions.logstats] INFO: Crawled 454123 pages (at 4 pages/min), scraped 395134 items (at 6 items/min)
2017-11-05 08:21:04 [scrapy.extensions.logstats] INFO: Crawled 454137 pages (at 14 pages/min), scraped 395139 items (at 5 items/min)
2017-11-05 08:22:07 [scrapy.extensions.logstats] INFO: Crawled 454144 pages (at 7 pages/min), scraped 395147 items (at 8 items/min)
2017-11-05 08:23:06 [scrapy.extensions.logstats] INFO: Crawled 454153 pages (at 9 pages/min), scraped 395153 items (at 6 items/min)
2017-11-05 08:24:07 [scrapy.extensions.logstats] INFO: Crawled 454164 pages (at 11 pages/min), scraped 395161 items (at 8 items/min)
2017-11-05 08:25:11 [scrapy.extensions.logstats] INFO: Crawled 454172 pages (at 8 pages/min), scraped 395168 items (at 7 items/min)
2017-11-05 08:26:04 [scrapy.extensions.logstats] INFO: Crawled 454185 pages (at 13 pages/min), scraped 395174 items (at 6 items/min)
2017-11-05 08:27:14 [scrapy.extensions.logstats] INFO: Crawled 454192 pages (at 7 pages/min), scraped 395182 items (at 8 items/min)
2017-11-05 08:28:11 [scrapy.extensions.logstats] INFO: Crawled 454196 pages (at 4 pages/min), scraped 395188 items (at 6 items/min)
2017-11-05 08:29:03 [scrapy.extensions.logstats] INFO: Crawled 454200 pages (at 4 pages/min), scraped 395192 items (at 4 items/min)
2017-11-05 08:30:09 [scrapy.extensions.logstats] INFO: Crawled 454213 pages (at 13 pages/min), scraped 395199 items (at 7 items/min)
2017-11-05 08:31:03 [scrapy.extensions.logstats] INFO: Crawled 454220 pages (at 7 pages/min), scraped 395206 items (at 7 items/min)
2017-11-05 08:32:05 [scrapy.extensions.logstats] INFO: Crawled 454226 pages (at 6 pages/min), scraped 395212 items (at 6 items/min)
2017-11-05 08:33:05 [scrapy.extensions.logstats] INFO: Crawled 454245 pages (at 19 pages/min), scraped 395221 items (at 9 items/min)
2017-11-05 08:34:05 [scrapy.extensions.logstats] INFO: Crawled 454250 pages (at 5 pages/min), scraped 395227 items (at 6 items/min)
2017-11-05 08:35:12 [scrapy.extensions.logstats] INFO: Crawled 454252 pages (at 2 pages/min), scraped 395232 items (at 5 items/min)
2017-11-05 08:36:10 [scrapy.extensions.logstats] INFO: Crawled 454265 pages (at 13 pages/min), scraped 395238 items (at 6 items/min)
2017-11-05 08:37:05 [scrapy.extensions.logstats] INFO: Crawled 454273 pages (at 8 pages/min), scraped 395245 items (at 7 items/min)
2017-11-05 08:38:09 [scrapy.extensions.logstats] INFO: Crawled 454274 pages (at 1 pages/min), scraped 395251 items (at 6 items/min)
2017-11-05 08:39:06 [scrapy.extensions.logstats] INFO: Crawled 454283 pages (at 9 pages/min), scraped 395256 items (at 5 items/min)
2017-11-05 08:40:12 [scrapy.extensions.logstats] INFO: Crawled 454289 pages (at 6 pages/min), scraped 395262 items (at 6 items/min)
2017-11-05 08:41:14 [scrapy.extensions.logstats] INFO: Crawled 454297 pages (at 8 pages/min), scraped 395269 items (at 7 items/min)
2017-11-05 08:42:10 [scrapy.extensions.logstats] INFO: Crawled 454303 pages (at 6 pages/min), scraped 395275 items (at 6 items/min)
2017-11-05 08:43:03 [scrapy.extensions.logstats] INFO: Crawled 454315 pages (at 12 pages/min), scraped 395281 items (at 6 items/min)
2017-11-05 08:44:12 [scrapy.extensions.logstats] INFO: Crawled 454322 pages (at 7 pages/min), scraped 395289 items (at 8 items/min)
2017-11-05 08:45:05 [scrapy.extensions.logstats] INFO: Crawled 454328 pages (at 6 pages/min), scraped 395295 items (at 6 items/min)
2017-11-05 08:46:14 [scrapy.extensions.logstats] INFO: Crawled 454332 pages (at 4 pages/min), scraped 395301 items (at 6 items/min)
2017-11-05 08:47:08 [scrapy.extensions.logstats] INFO: Crawled 454347 pages (at 15 pages/min), scraped 395308 items (at 7 items/min)
2017-11-05 08:48:23 [scrapy.extensions.logstats] INFO: Crawled 454353 pages (at 6 pages/min), scraped 395316 items (at 8 items/min)
2017-11-05 08:49:18 [scrapy.extensions.logstats] INFO: Crawled 454356 pages (at 3 pages/min), scraped 395321 items (at 5 items/min)
2017-11-05 08:50:05 [scrapy.extensions.logstats] INFO: Crawled 454359 pages (at 3 pages/min), scraped 395325 items (at 4 items/min)
2017-11-05 08:51:08 [scrapy.extensions.logstats] INFO: Crawled 454373 pages (at 14 pages/min), scraped 395334 items (at 9 items/min)
2017-11-05 08:52:14 [scrapy.extensions.logstats] INFO: Crawled 454377 pages (at 4 pages/min), scraped 395340 items (at 6 items/min)
2017-11-05 08:52:14 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2017-11-05 08:53:05 [scrapy.extensions.logstats] INFO: Crawled 454388 pages (at 11 pages/min), scraped 395344 items (at 4 items/min)
2017-11-05 08:54:09 [scrapy.extensions.logstats] INFO: Crawled 454393 pages (at 5 pages/min), scraped 395350 items (at 6 items/min)
2017-11-05 08:55:10 [scrapy.extensions.logstats] INFO: Crawled 454398 pages (at 5 pages/min), scraped 395356 items (at 6 items/min)
2017-11-05 08:56:14 [scrapy.extensions.logstats] INFO: Crawled 454409 pages (at 11 pages/min), scraped 395361 items (at 5 items/min)
2017-11-05 08:57:18 [scrapy.extensions.logstats] INFO: Crawled 454414 pages (at 5 pages/min), scraped 395368 items (at 7 items/min)
2017-11-05 08:58:22 [scrapy.extensions.logstats] INFO: Crawled 454415 pages (at 1 pages/min), scraped 395373 items (at 5 items/min)
2017-11-05 08:59:40 [scrapy.extensions.logstats] INFO: Crawled 454421 pages (at 6 pages/min), scraped 395379 items (at 6 items/min)
2017-11-05 09:00:03 [scrapy.extensions.logstats] INFO: Crawled 454484 pages (at 63 pages/min), scraped 395431 items (at 52 items/min)
2017-11-05 09:01:03 [scrapy.extensions.logstats] INFO: Crawled 454701 pages (at 217 pages/min), scraped 395611 items (at 180 items/min)
2017-11-05 09:02:03 [scrapy.extensions.logstats] INFO: Crawled 454914 pages (at 213 pages/min), scraped 395801 items (at 190 items/min)
2017-11-05 09:03:03 [scrapy.extensions.logstats] INFO: Crawled 455134 pages (at 220 pages/min), scraped 395984 items (at 183 items/min)
2017-11-05 09:04:03 [scrapy.extensions.logstats] INFO: Crawled 455359 pages (at 225 pages/min), scraped 396178 items (at 194 items/min)
2017-11-05 09:05:03 [scrapy.extensions.logstats] INFO: Crawled 455566 pages (at 207 pages/min), scraped 396391 items (at 213 items/min)
2017-11-05 09:06:03 [scrapy.extensions.logstats] INFO: Crawled 455783 pages (at 217 pages/min), scraped 396587 items (at 196 items/min)
2017-11-05 09:07:03 [scrapy.extensions.logstats] INFO: Crawled 456005 pages (at 222 pages/min), scraped 396780 items (at 193 items/min)
2017-11-05 09:08:05 [scrapy.extensions.logstats] INFO: Crawled 456232 pages (at 227 pages/min), scraped 396974 items (at 194 items/min)
2017-11-05 09:09:03 [scrapy.extensions.logstats] INFO: Crawled 456452 pages (at 220 pages/min), scraped 397169 items (at 195 items/min)
2017-11-05 09:10:03 [scrapy.extensions.logstats] INFO: Crawled 456652 pages (at 200 pages/min), scraped 397340 items (at 171 items/min)
2017-11-05 09:11:03 [scrapy.extensions.logstats] INFO: Crawled 456866 pages (at 214 pages/min), scraped 397558 items (at 218 items/min)
2017-11-05 09:12:03 [scrapy.extensions.logstats] INFO: Crawled 457079 pages (at 213 pages/min), scraped 397719 items (at 161 items/min)
2017-11-05 09:13:03 [scrapy.extensions.logstats] INFO: Crawled 457291 pages (at 212 pages/min), scraped 397896 items (at 177 items/min)
2017-11-05 09:14:03 [scrapy.extensions.logstats] INFO: Crawled 457505 pages (at 214 pages/min), scraped 398108 items (at 212 items/min)
2017-11-05 09:15:03 [scrapy.extensions.logstats] INFO: Crawled 457731 pages (at 226 pages/min), scraped 398297 items (at 189 items/min)
2017-11-05 09:16:03 [scrapy.extensions.logstats] INFO: Crawled 457945 pages (at 214 pages/min), scraped 398484 items (at 187 items/min)
2017-11-05 09:17:03 [scrapy.extensions.logstats] INFO: Crawled 458162 pages (at 217 pages/min), scraped 398671 items (at 187 items/min)
2017-11-05 09:18:08 [scrapy.extensions.logstats] INFO: Crawled 458402 pages (at 240 pages/min), scraped 398875 items (at 204 items/min)
2017-11-05 09:19:03 [scrapy.extensions.logstats] INFO: Crawled 458622 pages (at 220 pages/min), scraped 399080 items (at 205 items/min)
2017-11-05 09:20:03 [scrapy.extensions.logstats] INFO: Crawled 458842 pages (at 220 pages/min), scraped 399277 items (at 197 items/min)
2017-11-05 09:21:03 [scrapy.extensions.logstats] INFO: Crawled 459051 pages (at 209 pages/min), scraped 399454 items (at 177 items/min)
2017-11-05 09:22:03 [scrapy.extensions.logstats] INFO: Crawled 459272 pages (at 221 pages/min), scraped 399659 items (at 205 items/min)
2017-11-05 09:23:03 [scrapy.extensions.logstats] INFO: Crawled 459489 pages (at 217 pages/min), scraped 399840 items (at 181 items/min)
2017-11-05 09:24:03 [scrapy.extensions.logstats] INFO: Crawled 459708 pages (at 219 pages/min), scraped 400028 items (at 188 items/min)
2017-11-05 09:25:03 [scrapy.extensions.logstats] INFO: Crawled 459912 pages (at 204 pages/min), scraped 400234 items (at 206 items/min)
2017-11-05 09:26:03 [scrapy.extensions.logstats] INFO: Crawled 460123 pages (at 211 pages/min), scraped 400418 items (at 184 items/min)
2017-11-05 09:27:03 [scrapy.extensions.logstats] INFO: Crawled 460340 pages (at 217 pages/min), scraped 400614 items (at 196 items/min)
2017-11-05 09:28:04 [scrapy.extensions.logstats] INFO: Crawled 460568 pages (at 228 pages/min), scraped 400815 items (at 201 items/min)
2017-11-05 09:29:03 [scrapy.extensions.logstats] INFO: Crawled 460803 pages (at 235 pages/min), scraped 401011 items (at 196 items/min)
2017-11-05 09:30:03 [scrapy.extensions.logstats] INFO: Crawled 461020 pages (at 217 pages/min), scraped 401207 items (at 196 items/min)
2017-11-05 09:31:03 [scrapy.extensions.logstats] INFO: Crawled 461233 pages (at 213 pages/min), scraped 401381 items (at 174 items/min)
2017-11-05 09:32:03 [scrapy.extensions.logstats] INFO: Crawled 461451 pages (at 218 pages/min), scraped 401559 items (at 178 items/min)
2017-11-05 09:33:03 [scrapy.extensions.logstats] INFO: Crawled 461662 pages (at 211 pages/min), scraped 401732 items (at 173 items/min)
2017-11-05 09:34:03 [scrapy.extensions.logstats] INFO: Crawled 461869 pages (at 207 pages/min), scraped 401931 items (at 199 items/min)
2017-11-05 09:35:03 [scrapy.extensions.logstats] INFO: Crawled 462085 pages (at 216 pages/min), scraped 402128 items (at 197 items/min)
2017-11-05 09:36:03 [scrapy.extensions.logstats] INFO: Crawled 462310 pages (at 225 pages/min), scraped 402316 items (at 188 items/min)
2017-11-05 09:37:03 [scrapy.extensions.logstats] INFO: Crawled 462527 pages (at 217 pages/min), scraped 402529 items (at 213 items/min)
2017-11-05 09:38:03 [scrapy.extensions.logstats] INFO: Crawled 462739 pages (at 212 pages/min), scraped 402730 items (at 201 items/min)
2017-11-05 09:39:08 [scrapy.extensions.logstats] INFO: Crawled 462973 pages (at 234 pages/min), scraped 402920 items (at 190 items/min)
2017-11-05 09:40:03 [scrapy.extensions.logstats] INFO: Crawled 463160 pages (at 187 pages/min), scraped 403100 items (at 180 items/min)
2017-11-05 09:41:03 [scrapy.extensions.logstats] INFO: Crawled 463373 pages (at 213 pages/min), scraped 403274 items (at 174 items/min)
2017-11-05 09:42:03 [scrapy.extensions.logstats] INFO: Crawled 463587 pages (at 214 pages/min), scraped 403458 items (at 184 items/min)
2017-11-05 09:43:03 [scrapy.extensions.logstats] INFO: Crawled 463803 pages (at 216 pages/min), scraped 403691 items (at 233 items/min)
2017-11-05 09:44:03 [scrapy.extensions.logstats] INFO: Crawled 464014 pages (at 211 pages/min), scraped 403881 items (at 190 items/min)
2017-11-05 09:45:03 [scrapy.extensions.logstats] INFO: Crawled 464233 pages (at 219 pages/min), scraped 404110 items (at 229 items/min)
2017-11-05 09:46:03 [scrapy.extensions.logstats] INFO: Crawled 464439 pages (at 206 pages/min), scraped 404319 items (at 209 items/min)
2017-11-05 09:47:03 [scrapy.extensions.logstats] INFO: Crawled 464652 pages (at 213 pages/min), scraped 404558 items (at 239 items/min)
2017-11-05 09:48:04 [scrapy.extensions.logstats] INFO: Crawled 464882 pages (at 230 pages/min), scraped 404798 items (at 240 items/min)
2017-11-05 09:49:03 [scrapy.extensions.logstats] INFO: Crawled 465115 pages (at 233 pages/min), scraped 405043 items (at 245 items/min)
2017-11-05 09:50:03 [scrapy.extensions.logstats] INFO: Crawled 465318 pages (at 203 pages/min), scraped 405260 items (at 217 items/min)
2017-11-05 09:51:03 [scrapy.extensions.logstats] INFO: Crawled 465532 pages (at 214 pages/min), scraped 405475 items (at 215 items/min)
2017-11-05 09:52:03 [scrapy.extensions.logstats] INFO: Crawled 465753 pages (at 221 pages/min), scraped 405703 items (at 228 items/min)
2017-11-05 09:53:03 [scrapy.extensions.logstats] INFO: Crawled 465959 pages (at 206 pages/min), scraped 405938 items (at 235 items/min)
2017-11-05 09:54:03 [scrapy.extensions.logstats] INFO: Crawled 466183 pages (at 224 pages/min), scraped 406150 items (at 212 items/min)
2017-11-05 09:55:03 [scrapy.extensions.logstats] INFO: Crawled 466392 pages (at 209 pages/min), scraped 406342 items (at 192 items/min)
2017-11-05 09:56:03 [scrapy.extensions.logstats] INFO: Crawled 466599 pages (at 207 pages/min), scraped 406521 items (at 179 items/min)
2017-11-05 09:57:03 [scrapy.extensions.logstats] INFO: Crawled 466813 pages (at 214 pages/min), scraped 406727 items (at 206 items/min)
2017-11-05 09:58:04 [scrapy.extensions.logstats] INFO: Crawled 467039 pages (at 226 pages/min), scraped 406925 items (at 198 items/min)
2017-11-05 09:59:03 [scrapy.extensions.logstats] INFO: Crawled 467274 pages (at 235 pages/min), scraped 407163 items (at 238 items/min)
2017-11-05 10:00:03 [scrapy.extensions.logstats] INFO: Crawled 467492 pages (at 218 pages/min), scraped 407348 items (at 185 items/min)
2017-11-05 10:01:03 [scrapy.extensions.logstats] INFO: Crawled 467711 pages (at 219 pages/min), scraped 407546 items (at 198 items/min)
2017-11-05 10:02:03 [scrapy.extensions.logstats] INFO: Crawled 467921 pages (at 210 pages/min), scraped 407724 items (at 178 items/min)
2017-11-05 10:03:03 [scrapy.extensions.logstats] INFO: Crawled 468148 pages (at 227 pages/min), scraped 407961 items (at 237 items/min)
2017-11-05 10:04:03 [scrapy.extensions.logstats] INFO: Crawled 468365 pages (at 217 pages/min), scraped 408152 items (at 191 items/min)
2017-11-05 10:05:03 [scrapy.extensions.logstats] INFO: Crawled 468583 pages (at 218 pages/min), scraped 408355 items (at 203 items/min)
2017-11-05 10:06:03 [scrapy.extensions.logstats] INFO: Crawled 468800 pages (at 217 pages/min), scraped 408554 items (at 199 items/min)
2017-11-05 10:07:03 [scrapy.extensions.logstats] INFO: Crawled 469008 pages (at 208 pages/min), scraped 408745 items (at 191 items/min)
2017-11-05 10:08:04 [scrapy.extensions.logstats] INFO: Crawled 469225 pages (at 217 pages/min), scraped 408950 items (at 205 items/min)
2017-11-05 10:09:06 [scrapy.extensions.logstats] INFO: Crawled 469461 pages (at 236 pages/min), scraped 409147 items (at 197 items/min)
2017-11-05 10:10:03 [scrapy.extensions.logstats] INFO: Crawled 469688 pages (at 227 pages/min), scraped 409322 items (at 175 items/min)
2017-11-05 10:11:03 [scrapy.extensions.logstats] INFO: Crawled 469909 pages (at 221 pages/min), scraped 409516 items (at 194 items/min)
2017-11-05 10:12:03 [scrapy.extensions.logstats] INFO: Crawled 470128 pages (at 219 pages/min), scraped 409731 items (at 215 items/min)
2017-11-05 10:13:03 [scrapy.extensions.logstats] INFO: Crawled 470344 pages (at 216 pages/min), scraped 409921 items (at 190 items/min)
2017-11-05 10:14:03 [scrapy.extensions.logstats] INFO: Crawled 470565 pages (at 221 pages/min), scraped 410124 items (at 203 items/min)
2017-11-05 10:15:03 [scrapy.extensions.logstats] INFO: Crawled 470785 pages (at 220 pages/min), scraped 410353 items (at 229 items/min)
2017-11-05 10:16:03 [scrapy.extensions.logstats] INFO: Crawled 471008 pages (at 223 pages/min), scraped 410545 items (at 192 items/min)
2017-11-05 10:17:03 [scrapy.extensions.logstats] INFO: Crawled 471221 pages (at 213 pages/min), scraped 410735 items (at 190 items/min)
2017-11-05 10:18:03 [scrapy.extensions.logstats] INFO: Crawled 471436 pages (at 215 pages/min), scraped 410916 items (at 181 items/min)
2017-11-05 10:19:03 [scrapy.extensions.logstats] INFO: Crawled 471653 pages (at 217 pages/min), scraped 411087 items (at 171 items/min)
2017-11-05 10:20:07 [scrapy.extensions.logstats] INFO: Crawled 471888 pages (at 235 pages/min), scraped 411285 items (at 198 items/min)
2017-11-05 10:21:03 [scrapy.extensions.logstats] INFO: Crawled 472112 pages (at 224 pages/min), scraped 411494 items (at 209 items/min)
2017-11-05 10:22:03 [scrapy.extensions.logstats] INFO: Crawled 472333 pages (at 221 pages/min), scraped 411716 items (at 222 items/min)
2017-11-05 10:23:03 [scrapy.extensions.logstats] INFO: Crawled 472547 pages (at 214 pages/min), scraped 411907 items (at 191 items/min)
2017-11-05 10:24:03 [scrapy.extensions.logstats] INFO: Crawled 472762 pages (at 215 pages/min), scraped 412123 items (at 216 items/min)
2017-11-05 10:25:03 [scrapy.extensions.logstats] INFO: Crawled 472970 pages (at 208 pages/min), scraped 412328 items (at 205 items/min)
2017-11-05 10:26:03 [scrapy.extensions.logstats] INFO: Crawled 473186 pages (at 216 pages/min), scraped 412527 items (at 199 items/min)
2017-11-05 10:27:03 [scrapy.extensions.logstats] INFO: Crawled 473401 pages (at 215 pages/min), scraped 412731 items (at 204 items/min)
2017-11-05 10:28:03 [scrapy.extensions.logstats] INFO: Crawled 473612 pages (at 211 pages/min), scraped 412928 items (at 197 items/min)
2017-11-05 10:29:03 [scrapy.extensions.logstats] INFO: Crawled 473833 pages (at 221 pages/min), scraped 413118 items (at 190 items/min)
2017-11-05 10:30:07 [scrapy.extensions.logstats] INFO: Crawled 474060 pages (at 227 pages/min), scraped 413289 items (at 171 items/min)
2017-11-05 10:31:03 [scrapy.extensions.logstats] INFO: Crawled 474279 pages (at 219 pages/min), scraped 413465 items (at 176 items/min)
2017-11-05 10:32:03 [scrapy.extensions.logstats] INFO: Crawled 474493 pages (at 214 pages/min), scraped 413640 items (at 175 items/min)
2017-11-05 10:33:03 [scrapy.extensions.logstats] INFO: Crawled 474715 pages (at 222 pages/min), scraped 413823 items (at 183 items/min)
2017-11-05 10:34:03 [scrapy.extensions.logstats] INFO: Crawled 474936 pages (at 221 pages/min), scraped 414022 items (at 199 items/min)
2017-11-05 10:35:03 [scrapy.extensions.logstats] INFO: Crawled 475144 pages (at 208 pages/min), scraped 414205 items (at 183 items/min)
2017-11-05 10:36:03 [scrapy.extensions.logstats] INFO: Crawled 475358 pages (at 214 pages/min), scraped 414385 items (at 180 items/min)
2017-11-05 10:37:03 [scrapy.extensions.logstats] INFO: Crawled 475576 pages (at 218 pages/min), scraped 414587 items (at 202 items/min)
2017-11-05 10:38:03 [scrapy.extensions.logstats] INFO: Crawled 475790 pages (at 214 pages/min), scraped 414782 items (at 195 items/min)
2017-11-05 10:39:03 [scrapy.extensions.logstats] INFO: Crawled 476014 pages (at 224 pages/min), scraped 415008 items (at 226 items/min)
2017-11-05 10:40:03 [scrapy.extensions.logstats] INFO: Crawled 476229 pages (at 215 pages/min), scraped 415235 items (at 227 items/min)
2017-11-05 10:41:07 [scrapy.extensions.logstats] INFO: Crawled 476465 pages (at 236 pages/min), scraped 415483 items (at 248 items/min)
2017-11-05 10:42:03 [scrapy.extensions.logstats] INFO: Crawled 476678 pages (at 213 pages/min), scraped 415678 items (at 195 items/min)
2017-11-05 10:43:03 [scrapy.extensions.logstats] INFO: Crawled 476894 pages (at 216 pages/min), scraped 415884 items (at 206 items/min)
2017-11-05 10:44:03 [scrapy.extensions.logstats] INFO: Crawled 477118 pages (at 224 pages/min), scraped 416106 items (at 222 items/min)
2017-11-05 10:45:03 [scrapy.extensions.logstats] INFO: Crawled 477322 pages (at 204 pages/min), scraped 416305 items (at 199 items/min)
2017-11-05 10:46:03 [scrapy.extensions.logstats] INFO: Crawled 477535 pages (at 213 pages/min), scraped 416507 items (at 202 items/min)
2017-11-05 10:47:03 [scrapy.extensions.logstats] INFO: Crawled 477749 pages (at 214 pages/min), scraped 416714 items (at 207 items/min)
2017-11-05 10:48:03 [scrapy.extensions.logstats] INFO: Crawled 477959 pages (at 210 pages/min), scraped 416888 items (at 174 items/min)
2017-11-05 10:49:03 [scrapy.extensions.logstats] INFO: Crawled 478175 pages (at 216 pages/min), scraped 417089 items (at 201 items/min)
2017-11-05 10:50:03 [scrapy.extensions.logstats] INFO: Crawled 478396 pages (at 221 pages/min), scraped 417343 items (at 254 items/min)
2017-11-05 10:51:04 [scrapy.extensions.logstats] INFO: Crawled 478628 pages (at 232 pages/min), scraped 417632 items (at 289 items/min)
2017-11-05 10:52:03 [scrapy.extensions.logstats] INFO: Crawled 478846 pages (at 218 pages/min), scraped 417897 items (at 265 items/min)
2017-11-05 10:53:03 [scrapy.extensions.logstats] INFO: Crawled 479066 pages (at 220 pages/min), scraped 418114 items (at 217 items/min)
2017-11-05 10:54:03 [scrapy.extensions.logstats] INFO: Crawled 479277 pages (at 211 pages/min), scraped 418299 items (at 185 items/min)
2017-11-05 10:55:03 [scrapy.extensions.logstats] INFO: Crawled 479485 pages (at 208 pages/min), scraped 418477 items (at 178 items/min)
2017-11-05 10:56:03 [scrapy.extensions.logstats] INFO: Crawled 479706 pages (at 221 pages/min), scraped 418642 items (at 165 items/min)
2017-11-05 10:57:03 [scrapy.extensions.logstats] INFO: Crawled 479925 pages (at 219 pages/min), scraped 418803 items (at 161 items/min)
2017-11-05 10:58:03 [scrapy.extensions.logstats] INFO: Crawled 480142 pages (at 217 pages/min), scraped 418962 items (at 159 items/min)
2017-11-05 10:59:03 [scrapy.extensions.logstats] INFO: Crawled 480360 pages (at 218 pages/min), scraped 419127 items (at 165 items/min)
2017-11-05 11:00:04 [scrapy.extensions.logstats] INFO: Crawled 480570 pages (at 210 pages/min), scraped 419281 items (at 154 items/min)
2017-11-05 11:01:06 [scrapy.extensions.logstats] INFO: Crawled 480800 pages (at 230 pages/min), scraped 419491 items (at 210 items/min)
2017-11-05 11:02:03 [scrapy.extensions.logstats] INFO: Crawled 481025 pages (at 225 pages/min), scraped 419670 items (at 179 items/min)
2017-11-05 11:03:03 [scrapy.extensions.logstats] INFO: Crawled 481236 pages (at 211 pages/min), scraped 419870 items (at 200 items/min)
2017-11-05 11:04:03 [scrapy.extensions.logstats] INFO: Crawled 481448 pages (at 212 pages/min), scraped 420093 items (at 223 items/min)
2017-11-05 11:05:03 [scrapy.extensions.logstats] INFO: Crawled 481661 pages (at 213 pages/min), scraped 420318 items (at 225 items/min)
2017-11-05 11:06:03 [scrapy.extensions.logstats] INFO: Crawled 481882 pages (at 221 pages/min), scraped 420555 items (at 237 items/min)
2017-11-05 11:07:03 [scrapy.extensions.logstats] INFO: Crawled 482102 pages (at 220 pages/min), scraped 420771 items (at 216 items/min)
2017-11-05 11:08:03 [scrapy.extensions.logstats] INFO: Crawled 482315 pages (at 213 pages/min), scraped 420975 items (at 204 items/min)
2017-11-05 11:09:03 [scrapy.extensions.logstats] INFO: Crawled 482530 pages (at 215 pages/min), scraped 421211 items (at 236 items/min)
2017-11-05 11:10:03 [scrapy.extensions.logstats] INFO: Crawled 482741 pages (at 211 pages/min), scraped 421416 items (at 205 items/min)
2017-11-05 11:11:05 [scrapy.extensions.logstats] INFO: Crawled 482962 pages (at 221 pages/min), scraped 421632 items (at 216 items/min)
2017-11-05 11:12:03 [scrapy.extensions.logstats] INFO: Crawled 483195 pages (at 233 pages/min), scraped 421818 items (at 186 items/min)
2017-11-05 11:13:03 [scrapy.extensions.logstats] INFO: Crawled 483405 pages (at 210 pages/min), scraped 421982 items (at 164 items/min)
2017-11-05 11:14:03 [scrapy.extensions.logstats] INFO: Crawled 483623 pages (at 218 pages/min), scraped 422145 items (at 163 items/min)
2017-11-05 11:15:03 [scrapy.extensions.logstats] INFO: Crawled 483846 pages (at 223 pages/min), scraped 422314 items (at 169 items/min)
2017-11-05 11:16:03 [scrapy.extensions.logstats] INFO: Crawled 484071 pages (at 225 pages/min), scraped 422475 items (at 161 items/min)
2017-11-05 11:17:03 [scrapy.extensions.logstats] INFO: Crawled 484286 pages (at 215 pages/min), scraped 422670 items (at 195 items/min)
2017-11-05 11:18:03 [scrapy.extensions.logstats] INFO: Crawled 484508 pages (at 222 pages/min), scraped 422903 items (at 233 items/min)
2017-11-05 11:19:03 [scrapy.extensions.logstats] INFO: Crawled 484716 pages (at 208 pages/min), scraped 423100 items (at 197 items/min)
2017-11-05 11:20:03 [scrapy.extensions.logstats] INFO: Crawled 484931 pages (at 215 pages/min), scraped 423332 items (at 232 items/min)
2017-11-05 11:21:04 [scrapy.extensions.logstats] INFO: Crawled 485151 pages (at 220 pages/min), scraped 423544 items (at 212 items/min)
2017-11-05 11:22:03 [scrapy.extensions.logstats] INFO: Crawled 485385 pages (at 234 pages/min), scraped 423793 items (at 249 items/min)
2017-11-05 11:23:03 [scrapy.extensions.logstats] INFO: Crawled 485594 pages (at 209 pages/min), scraped 424028 items (at 235 items/min)
2017-11-05 11:24:03 [scrapy.extensions.logstats] INFO: Crawled 485808 pages (at 214 pages/min), scraped 424242 items (at 214 items/min)
2017-11-05 11:25:03 [scrapy.extensions.logstats] INFO: Crawled 486023 pages (at 215 pages/min), scraped 424477 items (at 235 items/min)
2017-11-05 11:26:03 [scrapy.extensions.logstats] INFO: Crawled 486234 pages (at 211 pages/min), scraped 424688 items (at 211 items/min)
2017-11-05 11:27:03 [scrapy.extensions.logstats] INFO: Crawled 486451 pages (at 217 pages/min), scraped 424941 items (at 253 items/min)
2017-11-05 11:28:03 [scrapy.extensions.logstats] INFO: Crawled 486672 pages (at 221 pages/min), scraped 425158 items (at 217 items/min)
2017-11-05 11:29:03 [scrapy.extensions.logstats] INFO: Crawled 486878 pages (at 206 pages/min), scraped 425375 items (at 217 items/min)
2017-11-05 11:30:03 [scrapy.extensions.logstats] INFO: Crawled 487092 pages (at 214 pages/min), scraped 425558 items (at 183 items/min)
2017-11-05 11:31:07 [scrapy.extensions.logstats] INFO: Crawled 487336 pages (at 244 pages/min), scraped 425754 items (at 196 items/min)
2017-11-05 11:32:03 [scrapy.extensions.logstats] INFO: Crawled 487515 pages (at 179 pages/min), scraped 425944 items (at 190 items/min)
2017-11-05 11:33:03 [scrapy.extensions.logstats] INFO: Crawled 487673 pages (at 158 pages/min), scraped 426098 items (at 154 items/min)
2017-11-05 11:34:15 [scrapy.extensions.logstats] INFO: Crawled 487776 pages (at 103 pages/min), scraped 426188 items (at 90 items/min)
2017-11-05 11:35:27 [scrapy.extensions.logstats] INFO: Crawled 487782 pages (at 6 pages/min), scraped 426195 items (at 7 items/min)
2017-11-05 11:36:04 [scrapy.extensions.logstats] INFO: Crawled 487785 pages (at 3 pages/min), scraped 426198 items (at 3 items/min)
2017-11-05 11:37:03 [scrapy.extensions.logstats] INFO: Crawled 487920 pages (at 135 pages/min), scraped 426334 items (at 136 items/min)
2017-11-05 11:38:03 [scrapy.extensions.logstats] INFO: Crawled 488133 pages (at 213 pages/min), scraped 426523 items (at 189 items/min)
2017-11-05 11:39:03 [scrapy.extensions.logstats] INFO: Crawled 488354 pages (at 221 pages/min), scraped 426714 items (at 191 items/min)
2017-11-05 11:40:03 [scrapy.extensions.logstats] INFO: Crawled 488556 pages (at 202 pages/min), scraped 426926 items (at 212 items/min)
2017-11-05 11:41:08 [scrapy.extensions.logstats] INFO: Crawled 488790 pages (at 234 pages/min), scraped 427145 items (at 219 items/min)
2017-11-05 11:42:03 [scrapy.extensions.logstats] INFO: Crawled 489004 pages (at 214 pages/min), scraped 427354 items (at 209 items/min)
2017-11-05 11:43:03 [scrapy.extensions.logstats] INFO: Crawled 489221 pages (at 217 pages/min), scraped 427552 items (at 198 items/min)
2017-11-05 11:44:03 [scrapy.extensions.logstats] INFO: Crawled 489457 pages (at 236 pages/min), scraped 427776 items (at 224 items/min)
2017-11-05 11:45:03 [scrapy.extensions.logstats] INFO: Crawled 489708 pages (at 251 pages/min), scraped 428007 items (at 231 items/min)
2017-11-05 11:46:03 [scrapy.extensions.logstats] INFO: Crawled 489945 pages (at 237 pages/min), scraped 428255 items (at 248 items/min)
2017-11-05 11:47:03 [scrapy.extensions.logstats] INFO: Crawled 490182 pages (at 237 pages/min), scraped 428493 items (at 238 items/min)
2017-11-05 11:48:03 [scrapy.extensions.logstats] INFO: Crawled 490425 pages (at 243 pages/min), scraped 428723 items (at 230 items/min)
2017-11-05 11:49:03 [scrapy.extensions.logstats] INFO: Crawled 490662 pages (at 237 pages/min), scraped 428955 items (at 232 items/min)
2017-11-05 11:50:03 [scrapy.extensions.logstats] INFO: Crawled 490900 pages (at 238 pages/min), scraped 429176 items (at 221 items/min)
2017-11-05 11:51:03 [scrapy.extensions.logstats] INFO: Crawled 491140 pages (at 240 pages/min), scraped 429416 items (at 240 items/min)
2017-11-05 11:52:03 [scrapy.extensions.logstats] INFO: Crawled 491379 pages (at 239 pages/min), scraped 429647 items (at 231 items/min)
2017-11-05 11:53:07 [scrapy.extensions.logstats] INFO: Crawled 491617 pages (at 238 pages/min), scraped 429867 items (at 220 items/min)
2017-11-05 11:54:03 [scrapy.extensions.logstats] INFO: Crawled 491834 pages (at 217 pages/min), scraped 430064 items (at 197 items/min)
2017-11-05 11:55:03 [scrapy.extensions.logstats] INFO: Crawled 491970 pages (at 136 pages/min), scraped 430183 items (at 119 items/min)
2017-11-05 11:56:03 [scrapy.extensions.logstats] INFO: Crawled 492074 pages (at 104 pages/min), scraped 430271 items (at 88 items/min)
2017-11-05 11:57:03 [scrapy.extensions.logstats] INFO: Crawled 492279 pages (at 205 pages/min), scraped 430472 items (at 201 items/min)
2017-11-05 11:58:03 [scrapy.extensions.logstats] INFO: Crawled 492486 pages (at 207 pages/min), scraped 430673 items (at 201 items/min)
2017-11-05 11:59:03 [scrapy.extensions.logstats] INFO: Crawled 492703 pages (at 217 pages/min), scraped 430889 items (at 216 items/min)
2017-11-05 12:00:04 [scrapy.extensions.logstats] INFO: Crawled 492851 pages (at 148 pages/min), scraped 431016 items (at 127 items/min)
2017-11-05 12:01:03 [scrapy.extensions.logstats] INFO: Crawled 492970 pages (at 119 pages/min), scraped 431143 items (at 127 items/min)
2017-11-05 12:02:04 [scrapy.extensions.logstats] INFO: Crawled 493104 pages (at 134 pages/min), scraped 431267 items (at 124 items/min)
2017-11-05 12:03:06 [scrapy.extensions.logstats] INFO: Crawled 493292 pages (at 188 pages/min), scraped 431431 items (at 164 items/min)
2017-11-05 12:04:03 [scrapy.extensions.logstats] INFO: Crawled 493423 pages (at 131 pages/min), scraped 431562 items (at 131 items/min)
2017-11-05 12:05:03 [scrapy.extensions.logstats] INFO: Crawled 493629 pages (at 206 pages/min), scraped 431773 items (at 211 items/min)
2017-11-05 12:06:03 [scrapy.extensions.logstats] INFO: Crawled 493844 pages (at 215 pages/min), scraped 431953 items (at 180 items/min)
2017-11-05 12:07:03 [scrapy.extensions.logstats] INFO: Crawled 494057 pages (at 213 pages/min), scraped 432129 items (at 176 items/min)
2017-11-05 12:08:03 [scrapy.extensions.logstats] INFO: Crawled 494258 pages (at 201 pages/min), scraped 432283 items (at 154 items/min)
2017-11-05 12:09:03 [scrapy.extensions.logstats] INFO: Crawled 494477 pages (at 219 pages/min), scraped 432457 items (at 174 items/min)
2017-11-05 12:10:03 [scrapy.extensions.logstats] INFO: Crawled 494679 pages (at 202 pages/min), scraped 432634 items (at 177 items/min)
2017-11-05 12:11:03 [scrapy.extensions.logstats] INFO: Crawled 494887 pages (at 208 pages/min), scraped 432811 items (at 177 items/min)
2017-11-05 12:12:03 [scrapy.extensions.logstats] INFO: Crawled 495112 pages (at 225 pages/min), scraped 432995 items (at 184 items/min)
2017-11-05 12:13:03 [scrapy.extensions.logstats] INFO: Crawled 495349 pages (at 237 pages/min), scraped 433158 items (at 163 items/min)
2017-11-05 12:14:03 [scrapy.extensions.logstats] INFO: Crawled 495574 pages (at 225 pages/min), scraped 433316 items (at 158 items/min)
2017-11-05 12:15:03 [scrapy.extensions.logstats] INFO: Crawled 495788 pages (at 214 pages/min), scraped 433512 items (at 196 items/min)
2017-11-05 12:16:03 [scrapy.extensions.logstats] INFO: Crawled 496003 pages (at 215 pages/min), scraped 433721 items (at 209 items/min)
2017-11-05 12:17:03 [scrapy.extensions.logstats] INFO: Crawled 496202 pages (at 199 pages/min), scraped 433895 items (at 174 items/min)
2017-11-05 12:18:03 [scrapy.extensions.logstats] INFO: Crawled 496413 pages (at 211 pages/min), scraped 434089 items (at 194 items/min)
2017-11-05 12:19:03 [scrapy.extensions.logstats] INFO: Crawled 496628 pages (at 215 pages/min), scraped 434285 items (at 196 items/min)
2017-11-05 12:20:03 [scrapy.extensions.logstats] INFO: Crawled 496845 pages (at 217 pages/min), scraped 434504 items (at 219 items/min)
2017-11-05 12:21:03 [scrapy.extensions.logstats] INFO: Crawled 497049 pages (at 204 pages/min), scraped 434706 items (at 202 items/min)
2017-11-05 12:22:03 [scrapy.extensions.logstats] INFO: Crawled 497260 pages (at 211 pages/min), scraped 434908 items (at 202 items/min)
2017-11-05 12:23:07 [scrapy.extensions.logstats] INFO: Crawled 497500 pages (at 240 pages/min), scraped 435175 items (at 267 items/min)
2017-11-05 12:24:03 [scrapy.extensions.logstats] INFO: Crawled 497716 pages (at 216 pages/min), scraped 435415 items (at 240 items/min)
2017-11-05 12:25:03 [scrapy.extensions.logstats] INFO: Crawled 497939 pages (at 223 pages/min), scraped 435651 items (at 236 items/min)
2017-11-05 12:26:03 [scrapy.extensions.logstats] INFO: Crawled 498149 pages (at 210 pages/min), scraped 435882 items (at 231 items/min)
2017-11-05 12:27:03 [scrapy.extensions.logstats] INFO: Crawled 498368 pages (at 219 pages/min), scraped 436071 items (at 189 items/min)
2017-11-05 12:28:03 [scrapy.extensions.logstats] INFO: Crawled 498576 pages (at 208 pages/min), scraped 436263 items (at 192 items/min)
2017-11-05 12:29:03 [scrapy.extensions.logstats] INFO: Crawled 498794 pages (at 218 pages/min), scraped 436448 items (at 185 items/min)
2017-11-05 12:30:03 [scrapy.extensions.logstats] INFO: Crawled 499015 pages (at 221 pages/min), scraped 436632 items (at 184 items/min)
2017-11-05 12:31:03 [scrapy.extensions.logstats] INFO: Crawled 499228 pages (at 213 pages/min), scraped 436808 items (at 176 items/min)
2017-11-05 12:32:03 [scrapy.extensions.logstats] INFO: Crawled 499446 pages (at 218 pages/min), scraped 436994 items (at 186 items/min)
2017-11-05 12:33:03 [scrapy.extensions.logstats] INFO: Crawled 499665 pages (at 219 pages/min), scraped 437208 items (at 214 items/min)
2017-11-05 12:34:11 [scrapy.extensions.logstats] INFO: Crawled 499904 pages (at 239 pages/min), scraped 437415 items (at 207 items/min)
2017-11-05 12:35:03 [scrapy.extensions.logstats] INFO: Crawled 500109 pages (at 205 pages/min), scraped 437609 items (at 194 items/min)
2017-11-05 12:36:03 [scrapy.extensions.logstats] INFO: Crawled 500322 pages (at 213 pages/min), scraped 437788 items (at 179 items/min)
2017-11-05 12:37:03 [scrapy.extensions.logstats] INFO: Crawled 500520 pages (at 198 pages/min), scraped 437962 items (at 174 items/min)
2017-11-05 12:38:03 [scrapy.extensions.logstats] INFO: Crawled 500736 pages (at 216 pages/min), scraped 438127 items (at 165 items/min)
2017-11-05 12:39:03 [scrapy.extensions.logstats] INFO: Crawled 500946 pages (at 210 pages/min), scraped 438328 items (at 201 items/min)
2017-11-05 12:40:03 [scrapy.extensions.logstats] INFO: Crawled 501173 pages (at 227 pages/min), scraped 438551 items (at 223 items/min)
2017-11-05 12:41:03 [scrapy.extensions.logstats] INFO: Crawled 501392 pages (at 219 pages/min), scraped 438774 items (at 223 items/min)
2017-11-05 12:42:04 [scrapy.extensions.logstats] INFO: Crawled 501598 pages (at 206 pages/min), scraped 438996 items (at 222 items/min)
2017-11-05 12:43:06 [scrapy.extensions.logstats] INFO: Crawled 501829 pages (at 231 pages/min), scraped 439231 items (at 235 items/min)
2017-11-05 12:44:03 [scrapy.extensions.logstats] INFO: Crawled 502049 pages (at 220 pages/min), scraped 439480 items (at 249 items/min)
2017-11-05 12:45:03 [scrapy.extensions.logstats] INFO: Crawled 502269 pages (at 220 pages/min), scraped 439706 items (at 226 items/min)
2017-11-05 12:46:03 [scrapy.extensions.logstats] INFO: Crawled 502479 pages (at 210 pages/min), scraped 439961 items (at 255 items/min)
2017-11-05 12:47:03 [scrapy.extensions.logstats] INFO: Crawled 502696 pages (at 217 pages/min), scraped 440206 items (at 245 items/min)
2017-11-05 12:48:03 [scrapy.extensions.logstats] INFO: Crawled 502918 pages (at 222 pages/min), scraped 440460 items (at 254 items/min)
2017-11-05 12:49:03 [scrapy.extensions.logstats] INFO: Crawled 503128 pages (at 210 pages/min), scraped 440676 items (at 216 items/min)
2017-11-05 12:50:03 [scrapy.extensions.logstats] INFO: Crawled 503337 pages (at 209 pages/min), scraped 440896 items (at 220 items/min)
2017-11-05 12:51:03 [scrapy.extensions.logstats] INFO: Crawled 503553 pages (at 216 pages/min), scraped 441132 items (at 236 items/min)
2017-11-05 12:52:03 [scrapy.extensions.logstats] INFO: Crawled 503761 pages (at 208 pages/min), scraped 441368 items (at 236 items/min)
2017-11-05 12:53:04 [scrapy.extensions.logstats] INFO: Crawled 503981 pages (at 220 pages/min), scraped 441592 items (at 224 items/min)
2017-11-05 12:54:03 [scrapy.extensions.logstats] INFO: Crawled 504215 pages (at 234 pages/min), scraped 441847 items (at 255 items/min)
2017-11-05 12:55:03 [scrapy.extensions.logstats] INFO: Crawled 504427 pages (at 212 pages/min), scraped 442040 items (at 193 items/min)
2017-11-05 12:56:03 [scrapy.extensions.logstats] INFO: Crawled 504632 pages (at 205 pages/min), scraped 442235 items (at 195 items/min)
2017-11-05 12:57:03 [scrapy.extensions.logstats] INFO: Crawled 504841 pages (at 209 pages/min), scraped 442413 items (at 178 items/min)
2017-11-05 12:58:03 [scrapy.extensions.logstats] INFO: Crawled 505058 pages (at 217 pages/min), scraped 442598 items (at 185 items/min)
2017-11-05 12:59:03 [scrapy.extensions.logstats] INFO: Crawled 505265 pages (at 207 pages/min), scraped 442794 items (at 196 items/min)
2017-11-05 13:00:03 [scrapy.extensions.logstats] INFO: Crawled 505479 pages (at 214 pages/min), scraped 442993 items (at 199 items/min)
2017-11-05 13:01:03 [scrapy.extensions.logstats] INFO: Crawled 505697 pages (at 218 pages/min), scraped 443203 items (at 210 items/min)
2017-11-05 13:02:03 [scrapy.extensions.logstats] INFO: Crawled 505919 pages (at 222 pages/min), scraped 443390 items (at 187 items/min)
2017-11-05 13:03:04 [scrapy.extensions.logstats] INFO: Crawled 506148 pages (at 229 pages/min), scraped 443579 items (at 189 items/min)
2017-11-05 13:04:09 [scrapy.extensions.logstats] INFO: Crawled 506384 pages (at 236 pages/min), scraped 443794 items (at 215 items/min)
2017-11-05 13:05:03 [scrapy.extensions.logstats] INFO: Crawled 506600 pages (at 216 pages/min), scraped 443964 items (at 170 items/min)
2017-11-05 13:06:03 [scrapy.extensions.logstats] INFO: Crawled 506804 pages (at 204 pages/min), scraped 444137 items (at 173 items/min)
2017-11-05 13:07:03 [scrapy.extensions.logstats] INFO: Crawled 507022 pages (at 218 pages/min), scraped 444330 items (at 193 items/min)
2017-11-05 13:08:03 [scrapy.extensions.logstats] INFO: Crawled 507228 pages (at 206 pages/min), scraped 444519 items (at 189 items/min)
2017-11-05 13:09:03 [scrapy.extensions.logstats] INFO: Crawled 507432 pages (at 204 pages/min), scraped 444693 items (at 174 items/min)
2017-11-05 13:10:03 [scrapy.extensions.logstats] INFO: Crawled 507645 pages (at 213 pages/min), scraped 444866 items (at 173 items/min)
2017-11-05 13:11:03 [scrapy.extensions.logstats] INFO: Crawled 507864 pages (at 219 pages/min), scraped 445061 items (at 195 items/min)
2017-11-05 13:12:03 [scrapy.extensions.logstats] INFO: Crawled 508079 pages (at 215 pages/min), scraped 445243 items (at 182 items/min)
2017-11-05 13:13:04 [scrapy.extensions.logstats] INFO: Crawled 508299 pages (at 220 pages/min), scraped 445405 items (at 162 items/min)
2017-11-05 13:14:03 [scrapy.extensions.logstats] INFO: Crawled 508528 pages (at 229 pages/min), scraped 445571 items (at 166 items/min)
2017-11-05 13:15:05 [scrapy.extensions.logstats] INFO: Crawled 508686 pages (at 158 pages/min), scraped 445677 items (at 106 items/min)
2017-11-05 13:16:03 [scrapy.extensions.logstats] INFO: Crawled 508872 pages (at 186 pages/min), scraped 445814 items (at 137 items/min)
2017-11-05 13:17:03 [scrapy.extensions.logstats] INFO: Crawled 509087 pages (at 215 pages/min), scraped 445982 items (at 168 items/min)
2017-11-05 13:18:03 [scrapy.extensions.logstats] INFO: Crawled 509305 pages (at 218 pages/min), scraped 446128 items (at 146 items/min)
2017-11-05 13:19:03 [scrapy.extensions.logstats] INFO: Crawled 509510 pages (at 205 pages/min), scraped 446272 items (at 144 items/min)
2017-11-05 13:20:03 [scrapy.extensions.logstats] INFO: Crawled 509713 pages (at 203 pages/min), scraped 446435 items (at 163 items/min)
2017-11-05 13:21:03 [scrapy.extensions.logstats] INFO: Crawled 509918 pages (at 205 pages/min), scraped 446615 items (at 180 items/min)
2017-11-05 13:22:03 [scrapy.extensions.logstats] INFO: Crawled 510137 pages (at 219 pages/min), scraped 446800 items (at 185 items/min)
2017-11-05 13:23:03 [scrapy.extensions.logstats] INFO: Crawled 510377 pages (at 240 pages/min), scraped 446994 items (at 194 items/min)
2017-11-05 13:24:03 [scrapy.extensions.logstats] INFO: Crawled 510600 pages (at 223 pages/min), scraped 447169 items (at 175 items/min)
2017-11-05 13:25:03 [scrapy.extensions.logstats] INFO: Crawled 510818 pages (at 218 pages/min), scraped 447346 items (at 177 items/min)
2017-11-05 13:26:03 [scrapy.extensions.logstats] INFO: Crawled 511030 pages (at 212 pages/min), scraped 447511 items (at 165 items/min)
2017-11-05 13:27:03 [scrapy.extensions.logstats] INFO: Crawled 511245 pages (at 215 pages/min), scraped 447680 items (at 169 items/min)
2017-11-05 13:28:03 [scrapy.extensions.logstats] INFO: Crawled 511458 pages (at 213 pages/min), scraped 447849 items (at 169 items/min)
2017-11-05 13:29:03 [scrapy.extensions.logstats] INFO: Crawled 511674 pages (at 216 pages/min), scraped 448027 items (at 178 items/min)
2017-11-05 13:30:03 [scrapy.extensions.logstats] INFO: Crawled 511893 pages (at 219 pages/min), scraped 448225 items (at 198 items/min)
2017-11-05 13:31:03 [scrapy.extensions.logstats] INFO: Crawled 512120 pages (at 227 pages/min), scraped 448413 items (at 188 items/min)
2017-11-05 13:32:03 [scrapy.extensions.logstats] INFO: Crawled 512338 pages (at 218 pages/min), scraped 448587 items (at 174 items/min)
2017-11-05 13:33:10 [scrapy.extensions.logstats] INFO: Crawled 512547 pages (at 209 pages/min), scraped 448756 items (at 169 items/min)
2017-11-05 13:34:03 [scrapy.extensions.logstats] INFO: Crawled 512749 pages (at 202 pages/min), scraped 448989 items (at 233 items/min)
2017-11-05 13:35:03 [scrapy.extensions.logstats] INFO: Crawled 512968 pages (at 219 pages/min), scraped 449198 items (at 209 items/min)
2017-11-05 13:36:04 [scrapy.extensions.logstats] INFO: Crawled 513187 pages (at 219 pages/min), scraped 449402 items (at 204 items/min)
2017-11-05 13:37:03 [scrapy.extensions.logstats] INFO: Crawled 513352 pages (at 165 pages/min), scraped 449559 items (at 157 items/min)
2017-11-05 13:38:03 [scrapy.extensions.logstats] INFO: Crawled 513568 pages (at 216 pages/min), scraped 449754 items (at 195 items/min)
2017-11-05 13:39:03 [scrapy.extensions.logstats] INFO: Crawled 513785 pages (at 217 pages/min), scraped 449929 items (at 175 items/min)
2017-11-05 13:40:03 [scrapy.extensions.logstats] INFO: Crawled 514005 pages (at 220 pages/min), scraped 450127 items (at 198 items/min)
2017-11-05 13:41:03 [scrapy.extensions.logstats] INFO: Crawled 514223 pages (at 218 pages/min), scraped 450316 items (at 189 items/min)
2017-11-05 13:42:04 [scrapy.extensions.logstats] INFO: Crawled 514441 pages (at 218 pages/min), scraped 450531 items (at 215 items/min)
2017-11-05 13:43:03 [scrapy.extensions.logstats] INFO: Crawled 514678 pages (at 237 pages/min), scraped 450743 items (at 212 items/min)
2017-11-05 13:44:03 [scrapy.extensions.logstats] INFO: Crawled 514886 pages (at 208 pages/min), scraped 450924 items (at 181 items/min)
2017-11-05 13:45:03 [scrapy.extensions.logstats] INFO: Crawled 515094 pages (at 208 pages/min), scraped 451100 items (at 176 items/min)
2017-11-05 13:46:03 [scrapy.extensions.logstats] INFO: Crawled 515254 pages (at 160 pages/min), scraped 451240 items (at 140 items/min)
2017-11-05 13:47:03 [scrapy.extensions.logstats] INFO: Crawled 515472 pages (at 218 pages/min), scraped 451408 items (at 168 items/min)
2017-11-05 13:48:03 [scrapy.extensions.logstats] INFO: Crawled 515685 pages (at 213 pages/min), scraped 451546 items (at 138 items/min)
2017-11-05 13:49:03 [scrapy.extensions.logstats] INFO: Crawled 515899 pages (at 214 pages/min), scraped 451721 items (at 175 items/min)
2017-11-05 13:50:03 [scrapy.extensions.logstats] INFO: Crawled 516117 pages (at 218 pages/min), scraped 451907 items (at 186 items/min)
2017-11-05 13:51:03 [scrapy.extensions.logstats] INFO: Crawled 516330 pages (at 213 pages/min), scraped 452058 items (at 151 items/min)
2017-11-05 13:52:04 [scrapy.extensions.logstats] INFO: Crawled 516546 pages (at 216 pages/min), scraped 452228 items (at 170 items/min)
2017-11-05 13:53:03 [scrapy.extensions.logstats] INFO: Crawled 516780 pages (at 234 pages/min), scraped 452504 items (at 276 items/min)
2017-11-05 13:54:03 [scrapy.extensions.logstats] INFO: Crawled 516996 pages (at 216 pages/min), scraped 452749 items (at 245 items/min)
2017-11-05 13:55:03 [scrapy.extensions.logstats] INFO: Crawled 517213 pages (at 217 pages/min), scraped 452922 items (at 173 items/min)
2017-11-05 13:56:03 [scrapy.extensions.logstats] INFO: Crawled 517420 pages (at 207 pages/min), scraped 453112 items (at 190 items/min)
2017-11-05 13:57:03 [scrapy.extensions.logstats] INFO: Crawled 517601 pages (at 181 pages/min), scraped 453284 items (at 172 items/min)
2017-11-05 13:58:03 [scrapy.extensions.logstats] INFO: Crawled 517814 pages (at 213 pages/min), scraped 453486 items (at 202 items/min)
2017-11-05 13:59:03 [scrapy.extensions.logstats] INFO: Crawled 518031 pages (at 217 pages/min), scraped 453693 items (at 207 items/min)
2017-11-05 14:00:03 [scrapy.extensions.logstats] INFO: Crawled 518247 pages (at 216 pages/min), scraped 453906 items (at 213 items/min)
2017-11-05 14:01:03 [scrapy.extensions.logstats] INFO: Crawled 518461 pages (at 214 pages/min), scraped 454121 items (at 215 items/min)
2017-11-05 14:02:04 [scrapy.extensions.logstats] INFO: Crawled 518635 pages (at 174 pages/min), scraped 454286 items (at 165 items/min)
2017-11-05 14:03:06 [scrapy.extensions.logstats] INFO: Crawled 518767 pages (at 132 pages/min), scraped 454404 items (at 118 items/min)
2017-11-05 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 518839 pages (at 72 pages/min), scraped 454469 items (at 65 items/min)
2017-11-05 14:05:04 [scrapy.extensions.logstats] INFO: Crawled 518900 pages (at 61 pages/min), scraped 454527 items (at 58 items/min)
2017-11-05 14:06:04 [scrapy.extensions.logstats] INFO: Crawled 518936 pages (at 36 pages/min), scraped 454567 items (at 40 items/min)
2017-11-05 14:07:03 [scrapy.extensions.logstats] INFO: Crawled 519075 pages (at 139 pages/min), scraped 454695 items (at 128 items/min)
2017-11-05 14:08:03 [scrapy.extensions.logstats] INFO: Crawled 519281 pages (at 206 pages/min), scraped 454912 items (at 217 items/min)
2017-11-05 14:09:03 [scrapy.extensions.logstats] INFO: Crawled 519495 pages (at 214 pages/min), scraped 455162 items (at 250 items/min)
2017-11-05 14:10:03 [scrapy.extensions.logstats] INFO: Crawled 519704 pages (at 209 pages/min), scraped 455355 items (at 193 items/min)
2017-11-05 14:11:03 [scrapy.extensions.logstats] INFO: Crawled 519926 pages (at 222 pages/min), scraped 455544 items (at 189 items/min)
2017-11-05 14:12:03 [scrapy.extensions.logstats] INFO: Crawled 520140 pages (at 214 pages/min), scraped 455720 items (at 176 items/min)
2017-11-05 14:13:03 [scrapy.extensions.logstats] INFO: Crawled 520356 pages (at 216 pages/min), scraped 455900 items (at 180 items/min)
2017-11-05 14:14:08 [scrapy.extensions.logstats] INFO: Crawled 520586 pages (at 230 pages/min), scraped 456103 items (at 203 items/min)
2017-11-05 14:15:03 [scrapy.extensions.logstats] INFO: Crawled 520811 pages (at 225 pages/min), scraped 456276 items (at 173 items/min)
2017-11-05 14:16:03 [scrapy.extensions.logstats] INFO: Crawled 521019 pages (at 208 pages/min), scraped 456454 items (at 178 items/min)
2017-11-05 14:17:03 [scrapy.extensions.logstats] INFO: Crawled 521233 pages (at 214 pages/min), scraped 456678 items (at 224 items/min)
2017-11-05 14:18:03 [scrapy.extensions.logstats] INFO: Crawled 521445 pages (at 212 pages/min), scraped 456868 items (at 190 items/min)
2017-11-05 14:19:03 [scrapy.extensions.logstats] INFO: Crawled 521668 pages (at 223 pages/min), scraped 457038 items (at 170 items/min)
2017-11-05 14:20:03 [scrapy.extensions.logstats] INFO: Crawled 521883 pages (at 215 pages/min), scraped 457209 items (at 171 items/min)
2017-11-05 14:21:03 [scrapy.extensions.logstats] INFO: Crawled 522094 pages (at 211 pages/min), scraped 457398 items (at 189 items/min)
2017-11-05 14:22:03 [scrapy.extensions.logstats] INFO: Crawled 522308 pages (at 214 pages/min), scraped 457572 items (at 174 items/min)
2017-11-05 14:23:04 [scrapy.extensions.logstats] INFO: Crawled 522514 pages (at 206 pages/min), scraped 457747 items (at 175 items/min)
2017-11-05 14:24:07 [scrapy.extensions.logstats] INFO: Crawled 522752 pages (at 238 pages/min), scraped 457939 items (at 192 items/min)
2017-11-05 14:25:03 [scrapy.extensions.logstats] INFO: Crawled 522975 pages (at 223 pages/min), scraped 458125 items (at 186 items/min)
2017-11-05 14:26:03 [scrapy.extensions.logstats] INFO: Crawled 523194 pages (at 219 pages/min), scraped 458310 items (at 185 items/min)
2017-11-05 14:27:03 [scrapy.extensions.logstats] INFO: Crawled 523414 pages (at 220 pages/min), scraped 458480 items (at 170 items/min)
2017-11-05 14:28:03 [scrapy.extensions.logstats] INFO: Crawled 523637 pages (at 223 pages/min), scraped 458656 items (at 176 items/min)
2017-11-05 14:29:03 [scrapy.extensions.logstats] INFO: Crawled 523869 pages (at 232 pages/min), scraped 458844 items (at 188 items/min)
2017-11-05 14:30:03 [scrapy.extensions.logstats] INFO: Crawled 524078 pages (at 209 pages/min), scraped 459024 items (at 180 items/min)
2017-11-05 14:31:03 [scrapy.extensions.logstats] INFO: Crawled 524289 pages (at 211 pages/min), scraped 459182 items (at 158 items/min)
2017-11-05 14:32:03 [scrapy.extensions.logstats] INFO: Crawled 524508 pages (at 219 pages/min), scraped 459353 items (at 171 items/min)
2017-11-05 14:33:03 [scrapy.extensions.logstats] INFO: Crawled 524725 pages (at 217 pages/min), scraped 459537 items (at 184 items/min)
2017-11-05 14:34:04 [scrapy.extensions.logstats] INFO: Crawled 524946 pages (at 221 pages/min), scraped 459706 items (at 169 items/min)
2017-11-05 14:35:06 [scrapy.extensions.logstats] INFO: Crawled 525176 pages (at 230 pages/min), scraped 459879 items (at 173 items/min)
2017-11-05 14:35:20 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39902021&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"黄海霖","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"华融证券股份有限公司","AOI_ID":"1999149","ADI_ID":"19100","ADI_NAME":"重庆天星桥正街证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S1490108111128","OBTAIN_DATE":"2008-11-12","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-05 14:36:03 [scrapy.extensions.logstats] INFO: Crawled 525398 pages (at 222 pages/min), scraped 460033 items (at 154 items/min)
2017-11-05 14:37:03 [scrapy.extensions.logstats] INFO: Crawled 525601 pages (at 203 pages/min), scraped 460185 items (at 152 items/min)
2017-11-05 14:38:03 [scrapy.extensions.logstats] INFO: Crawled 525814 pages (at 213 pages/min), scraped 460441 items (at 256 items/min)
2017-11-05 14:39:03 [scrapy.extensions.logstats] INFO: Crawled 526017 pages (at 203 pages/min), scraped 460649 items (at 208 items/min)
2017-11-05 14:40:03 [scrapy.extensions.logstats] INFO: Crawled 526212 pages (at 195 pages/min), scraped 460828 items (at 179 items/min)
2017-11-05 14:41:03 [scrapy.extensions.logstats] INFO: Crawled 526434 pages (at 222 pages/min), scraped 461004 items (at 176 items/min)
2017-11-05 14:42:03 [scrapy.extensions.logstats] INFO: Crawled 526648 pages (at 214 pages/min), scraped 461189 items (at 185 items/min)
2017-11-05 14:43:03 [scrapy.extensions.logstats] INFO: Crawled 526860 pages (at 212 pages/min), scraped 461344 items (at 155 items/min)
2017-11-05 14:44:04 [scrapy.extensions.logstats] INFO: Crawled 527077 pages (at 217 pages/min), scraped 461537 items (at 193 items/min)
2017-11-05 14:45:07 [scrapy.extensions.logstats] INFO: Crawled 527315 pages (at 238 pages/min), scraped 461765 items (at 228 items/min)
2017-11-05 14:46:03 [scrapy.extensions.logstats] INFO: Crawled 527540 pages (at 225 pages/min), scraped 461977 items (at 212 items/min)
2017-11-05 14:47:03 [scrapy.extensions.logstats] INFO: Crawled 527760 pages (at 220 pages/min), scraped 462146 items (at 169 items/min)
2017-11-05 14:48:03 [scrapy.extensions.logstats] INFO: Crawled 527987 pages (at 227 pages/min), scraped 462330 items (at 184 items/min)
2017-11-05 14:49:03 [scrapy.extensions.logstats] INFO: Crawled 528201 pages (at 214 pages/min), scraped 462507 items (at 177 items/min)
2017-11-05 14:50:03 [scrapy.extensions.logstats] INFO: Crawled 528423 pages (at 222 pages/min), scraped 462692 items (at 185 items/min)
2017-11-05 14:51:03 [scrapy.extensions.logstats] INFO: Crawled 528644 pages (at 221 pages/min), scraped 462881 items (at 189 items/min)
2017-11-05 14:52:03 [scrapy.extensions.logstats] INFO: Crawled 528867 pages (at 223 pages/min), scraped 463054 items (at 173 items/min)
2017-11-05 14:53:03 [scrapy.extensions.logstats] INFO: Crawled 529083 pages (at 216 pages/min), scraped 463266 items (at 212 items/min)
2017-11-05 14:54:03 [scrapy.extensions.logstats] INFO: Crawled 529298 pages (at 215 pages/min), scraped 463461 items (at 195 items/min)
2017-11-05 14:55:04 [scrapy.extensions.logstats] INFO: Crawled 529527 pages (at 229 pages/min), scraped 463667 items (at 206 items/min)
2017-11-05 14:56:03 [scrapy.extensions.logstats] INFO: Crawled 529765 pages (at 238 pages/min), scraped 463889 items (at 222 items/min)
2017-11-05 14:57:03 [scrapy.extensions.logstats] INFO: Crawled 529982 pages (at 217 pages/min), scraped 464077 items (at 188 items/min)
2017-11-05 14:58:03 [scrapy.extensions.logstats] INFO: Crawled 530204 pages (at 222 pages/min), scraped 464261 items (at 184 items/min)
2017-11-05 14:59:04 [scrapy.extensions.logstats] INFO: Crawled 530302 pages (at 98 pages/min), scraped 464348 items (at 87 items/min)
2017-11-05 15:00:03 [scrapy.extensions.logstats] INFO: Crawled 530391 pages (at 89 pages/min), scraped 464425 items (at 77 items/min)
2017-11-05 15:01:04 [scrapy.extensions.logstats] INFO: Crawled 530455 pages (at 64 pages/min), scraped 464470 items (at 45 items/min)
2017-11-05 15:02:03 [scrapy.extensions.logstats] INFO: Crawled 530616 pages (at 161 pages/min), scraped 464626 items (at 156 items/min)
2017-11-05 15:03:03 [scrapy.extensions.logstats] INFO: Crawled 530834 pages (at 218 pages/min), scraped 464803 items (at 177 items/min)
2017-11-05 15:04:03 [scrapy.extensions.logstats] INFO: Crawled 531050 pages (at 216 pages/min), scraped 464979 items (at 176 items/min)
2017-11-05 15:05:03 [scrapy.extensions.logstats] INFO: Crawled 531264 pages (at 214 pages/min), scraped 465156 items (at 177 items/min)
2017-11-05 15:06:04 [scrapy.extensions.logstats] INFO: Crawled 531459 pages (at 195 pages/min), scraped 465321 items (at 165 items/min)
2017-11-05 15:07:03 [scrapy.extensions.logstats] INFO: Crawled 531692 pages (at 233 pages/min), scraped 465523 items (at 202 items/min)
2017-11-05 15:08:03 [scrapy.extensions.logstats] INFO: Crawled 531906 pages (at 214 pages/min), scraped 465707 items (at 184 items/min)
2017-11-05 15:09:03 [scrapy.extensions.logstats] INFO: Crawled 532128 pages (at 222 pages/min), scraped 465914 items (at 207 items/min)
2017-11-05 15:09:37 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39903726&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"高璐","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"华龙证券股份有限公司","AOI_ID":"1999023","ADI_ID":"48704","ADI_NAME":"证券投资总部","PTI_NAME":"证券投资咨询业务(投资顾问)","CER_NUM":"S0230610120111","OBTAIN_DATE":"2010-12-31","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-05 15:10:03 [scrapy.extensions.logstats] INFO: Crawled 532332 pages (at 204 pages/min), scraped 466104 items (at 190 items/min)
2017-11-05 15:11:03 [scrapy.extensions.logstats] INFO: Crawled 532544 pages (at 212 pages/min), scraped 466295 items (at 191 items/min)
2017-11-05 15:12:03 [scrapy.extensions.logstats] INFO: Crawled 532759 pages (at 215 pages/min), scraped 466477 items (at 182 items/min)
2017-11-05 15:13:03 [scrapy.extensions.logstats] INFO: Crawled 532967 pages (at 208 pages/min), scraped 466668 items (at 191 items/min)
2017-11-05 15:14:03 [scrapy.extensions.logstats] INFO: Crawled 533178 pages (at 211 pages/min), scraped 466867 items (at 199 items/min)
2017-11-05 15:15:03 [scrapy.extensions.logstats] INFO: Crawled 533397 pages (at 219 pages/min), scraped 467069 items (at 202 items/min)
2017-11-05 15:16:03 [scrapy.extensions.logstats] INFO: Crawled 533618 pages (at 221 pages/min), scraped 467302 items (at 233 items/min)
2017-11-05 15:17:06 [scrapy.extensions.logstats] INFO: Crawled 533845 pages (at 227 pages/min), scraped 467519 items (at 217 items/min)
2017-11-05 15:18:03 [scrapy.extensions.logstats] INFO: Crawled 534072 pages (at 227 pages/min), scraped 467735 items (at 216 items/min)
2017-11-05 15:19:03 [scrapy.extensions.logstats] INFO: Crawled 534286 pages (at 214 pages/min), scraped 467945 items (at 210 items/min)
2017-11-05 15:20:03 [scrapy.extensions.logstats] INFO: Crawled 534501 pages (at 215 pages/min), scraped 468150 items (at 205 items/min)
2017-11-05 15:21:03 [scrapy.extensions.logstats] INFO: Crawled 534717 pages (at 216 pages/min), scraped 468321 items (at 171 items/min)
2017-11-05 15:22:03 [scrapy.extensions.logstats] INFO: Crawled 534928 pages (at 211 pages/min), scraped 468506 items (at 185 items/min)
2017-11-05 15:23:03 [scrapy.extensions.logstats] INFO: Crawled 535140 pages (at 212 pages/min), scraped 468699 items (at 193 items/min)
2017-11-05 15:24:03 [scrapy.extensions.logstats] INFO: Crawled 535347 pages (at 207 pages/min), scraped 468890 items (at 191 items/min)
2017-11-05 15:25:03 [scrapy.extensions.logstats] INFO: Crawled 535555 pages (at 208 pages/min), scraped 469082 items (at 192 items/min)
2017-11-05 15:26:03 [scrapy.extensions.logstats] INFO: Crawled 535769 pages (at 214 pages/min), scraped 469291 items (at 209 items/min)
2017-11-05 15:27:04 [scrapy.extensions.logstats] INFO: Crawled 535991 pages (at 222 pages/min), scraped 469527 items (at 236 items/min)
2017-11-05 15:28:03 [scrapy.extensions.logstats] INFO: Crawled 536223 pages (at 232 pages/min), scraped 469734 items (at 207 items/min)
2017-11-05 15:29:03 [scrapy.extensions.logstats] INFO: Crawled 536427 pages (at 204 pages/min), scraped 469934 items (at 200 items/min)
2017-11-05 15:30:03 [scrapy.extensions.logstats] INFO: Crawled 536640 pages (at 213 pages/min), scraped 470132 items (at 198 items/min)
2017-11-05 15:31:03 [scrapy.extensions.logstats] INFO: Crawled 536841 pages (at 201 pages/min), scraped 470344 items (at 212 items/min)
2017-11-05 15:32:03 [scrapy.extensions.logstats] INFO: Crawled 537048 pages (at 207 pages/min), scraped 470539 items (at 195 items/min)
2017-11-05 15:33:03 [scrapy.extensions.logstats] INFO: Crawled 537262 pages (at 214 pages/min), scraped 470754 items (at 215 items/min)
2017-11-05 15:34:03 [scrapy.extensions.logstats] INFO: Crawled 537472 pages (at 210 pages/min), scraped 470972 items (at 218 items/min)
2017-11-05 15:35:03 [scrapy.extensions.logstats] INFO: Crawled 537686 pages (at 214 pages/min), scraped 471193 items (at 221 items/min)
2017-11-05 15:36:04 [scrapy.extensions.logstats] INFO: Crawled 537913 pages (at 227 pages/min), scraped 471392 items (at 199 items/min)
2017-11-05 15:37:06 [scrapy.extensions.logstats] INFO: Crawled 538140 pages (at 227 pages/min), scraped 471608 items (at 216 items/min)
2017-11-05 15:38:03 [scrapy.extensions.logstats] INFO: Crawled 538359 pages (at 219 pages/min), scraped 471786 items (at 178 items/min)
2017-11-05 15:39:03 [scrapy.extensions.logstats] INFO: Crawled 538563 pages (at 204 pages/min), scraped 471950 items (at 164 items/min)
2017-11-05 15:40:03 [scrapy.extensions.logstats] INFO: Crawled 538769 pages (at 206 pages/min), scraped 472107 items (at 157 items/min)
2017-11-05 15:41:03 [scrapy.extensions.logstats] INFO: Crawled 538985 pages (at 216 pages/min), scraped 472291 items (at 184 items/min)
2017-11-05 15:42:03 [scrapy.extensions.logstats] INFO: Crawled 539203 pages (at 218 pages/min), scraped 472487 items (at 196 items/min)
2017-11-05 15:43:03 [scrapy.extensions.logstats] INFO: Crawled 539411 pages (at 208 pages/min), scraped 472699 items (at 212 items/min)
2017-11-05 15:44:03 [scrapy.extensions.logstats] INFO: Crawled 539621 pages (at 210 pages/min), scraped 472898 items (at 199 items/min)
2017-11-05 15:45:03 [scrapy.extensions.logstats] INFO: Crawled 539839 pages (at 218 pages/min), scraped 473107 items (at 209 items/min)
2017-11-05 15:46:03 [scrapy.extensions.logstats] INFO: Crawled 540066 pages (at 227 pages/min), scraped 473334 items (at 227 items/min)
2017-11-05 15:47:08 [scrapy.extensions.logstats] INFO: Crawled 540301 pages (at 235 pages/min), scraped 473554 items (at 220 items/min)
2017-11-05 15:48:03 [scrapy.extensions.logstats] INFO: Crawled 540520 pages (at 219 pages/min), scraped 473742 items (at 188 items/min)
2017-11-05 15:49:03 [scrapy.extensions.logstats] INFO: Crawled 540719 pages (at 199 pages/min), scraped 473929 items (at 187 items/min)
2017-11-05 15:50:03 [scrapy.extensions.logstats] INFO: Crawled 540938 pages (at 219 pages/min), scraped 474123 items (at 194 items/min)
2017-11-05 15:51:03 [scrapy.extensions.logstats] INFO: Crawled 541155 pages (at 217 pages/min), scraped 474311 items (at 188 items/min)
2017-11-05 15:52:03 [scrapy.extensions.logstats] INFO: Crawled 541353 pages (at 198 pages/min), scraped 474483 items (at 172 items/min)
2017-11-05 15:53:03 [scrapy.extensions.logstats] INFO: Crawled 541561 pages (at 208 pages/min), scraped 474642 items (at 159 items/min)
2017-11-05 15:54:03 [scrapy.extensions.logstats] INFO: Crawled 541777 pages (at 216 pages/min), scraped 474810 items (at 168 items/min)
2017-11-05 15:55:03 [scrapy.extensions.logstats] INFO: Crawled 541981 pages (at 204 pages/min), scraped 474962 items (at 152 items/min)
2017-11-05 15:56:06 [scrapy.extensions.logstats] INFO: Crawled 542203 pages (at 222 pages/min), scraped 475142 items (at 180 items/min)
2017-11-05 15:57:03 [scrapy.extensions.logstats] INFO: Crawled 542430 pages (at 227 pages/min), scraped 475320 items (at 178 items/min)
2017-11-05 15:58:03 [scrapy.extensions.logstats] INFO: Crawled 542647 pages (at 217 pages/min), scraped 475483 items (at 163 items/min)
2017-11-05 15:59:03 [scrapy.extensions.logstats] INFO: Crawled 542861 pages (at 214 pages/min), scraped 475662 items (at 179 items/min)
2017-11-05 16:00:03 [scrapy.extensions.logstats] INFO: Crawled 543087 pages (at 226 pages/min), scraped 475847 items (at 185 items/min)
2017-11-05 16:01:03 [scrapy.extensions.logstats] INFO: Crawled 543297 pages (at 210 pages/min), scraped 476021 items (at 174 items/min)
2017-11-05 16:02:03 [scrapy.extensions.logstats] INFO: Crawled 543528 pages (at 231 pages/min), scraped 476208 items (at 187 items/min)
2017-11-05 16:03:03 [scrapy.extensions.logstats] INFO: Crawled 543749 pages (at 221 pages/min), scraped 476393 items (at 185 items/min)
2017-11-05 16:04:03 [scrapy.extensions.logstats] INFO: Crawled 543969 pages (at 220 pages/min), scraped 476581 items (at 188 items/min)
2017-11-05 16:05:03 [scrapy.extensions.logstats] INFO: Crawled 544189 pages (at 220 pages/min), scraped 476747 items (at 166 items/min)
2017-11-05 16:06:04 [scrapy.extensions.logstats] INFO: Crawled 544420 pages (at 231 pages/min), scraped 476929 items (at 182 items/min)
2017-11-05 16:07:04 [scrapy.extensions.logstats] INFO: Crawled 544655 pages (at 235 pages/min), scraped 477135 items (at 206 items/min)
2017-11-05 16:08:03 [scrapy.extensions.logstats] INFO: Crawled 544870 pages (at 215 pages/min), scraped 477326 items (at 191 items/min)
2017-11-05 16:09:03 [scrapy.extensions.logstats] INFO: Crawled 545084 pages (at 214 pages/min), scraped 477499 items (at 173 items/min)
2017-11-05 16:10:03 [scrapy.extensions.logstats] INFO: Crawled 545287 pages (at 203 pages/min), scraped 477668 items (at 169 items/min)
2017-11-05 16:11:03 [scrapy.extensions.logstats] INFO: Crawled 545507 pages (at 220 pages/min), scraped 477842 items (at 174 items/min)
2017-11-05 16:12:03 [scrapy.extensions.logstats] INFO: Crawled 545731 pages (at 224 pages/min), scraped 478023 items (at 181 items/min)
2017-11-05 16:13:03 [scrapy.extensions.logstats] INFO: Crawled 545950 pages (at 219 pages/min), scraped 478208 items (at 185 items/min)
2017-11-05 16:14:03 [scrapy.extensions.logstats] INFO: Crawled 546170 pages (at 220 pages/min), scraped 478388 items (at 180 items/min)
2017-11-05 16:15:03 [scrapy.extensions.logstats] INFO: Crawled 546380 pages (at 210 pages/min), scraped 478543 items (at 155 items/min)
2017-11-05 16:16:03 [scrapy.extensions.logstats] INFO: Crawled 546594 pages (at 214 pages/min), scraped 478689 items (at 146 items/min)
2017-11-05 16:17:09 [scrapy.extensions.logstats] INFO: Crawled 546831 pages (at 237 pages/min), scraped 478855 items (at 166 items/min)
2017-11-05 16:18:03 [scrapy.extensions.logstats] INFO: Crawled 547045 pages (at 214 pages/min), scraped 479034 items (at 179 items/min)
2017-11-05 16:19:03 [scrapy.extensions.logstats] INFO: Crawled 547261 pages (at 216 pages/min), scraped 479214 items (at 180 items/min)
2017-11-05 16:20:03 [scrapy.extensions.logstats] INFO: Crawled 547460 pages (at 199 pages/min), scraped 479372 items (at 158 items/min)
2017-11-05 16:21:03 [scrapy.extensions.logstats] INFO: Crawled 547682 pages (at 222 pages/min), scraped 479543 items (at 171 items/min)
2017-11-05 16:22:03 [scrapy.extensions.logstats] INFO: Crawled 547897 pages (at 215 pages/min), scraped 479708 items (at 165 items/min)
2017-11-05 16:23:03 [scrapy.extensions.logstats] INFO: Crawled 548117 pages (at 220 pages/min), scraped 479887 items (at 179 items/min)
2017-11-05 16:24:03 [scrapy.extensions.logstats] INFO: Crawled 548332 pages (at 215 pages/min), scraped 480085 items (at 198 items/min)
2017-11-05 16:25:03 [scrapy.extensions.logstats] INFO: Crawled 548551 pages (at 219 pages/min), scraped 480262 items (at 177 items/min)
2017-11-05 16:26:05 [scrapy.extensions.logstats] INFO: Crawled 548766 pages (at 215 pages/min), scraped 480426 items (at 164 items/min)
2017-11-05 16:27:03 [scrapy.extensions.logstats] INFO: Crawled 549002 pages (at 236 pages/min), scraped 480636 items (at 210 items/min)
2017-11-05 16:28:03 [scrapy.extensions.logstats] INFO: Crawled 549244 pages (at 242 pages/min), scraped 480845 items (at 209 items/min)
2017-11-05 16:29:03 [scrapy.extensions.logstats] INFO: Crawled 549467 pages (at 223 pages/min), scraped 481039 items (at 194 items/min)
2017-11-05 16:30:03 [scrapy.extensions.logstats] INFO: Crawled 549710 pages (at 243 pages/min), scraped 481236 items (at 197 items/min)
2017-11-05 16:31:03 [scrapy.extensions.logstats] INFO: Crawled 549916 pages (at 206 pages/min), scraped 481423 items (at 187 items/min)
2017-11-05 16:32:03 [scrapy.extensions.logstats] INFO: Crawled 550128 pages (at 212 pages/min), scraped 481643 items (at 220 items/min)
2017-11-05 16:33:03 [scrapy.extensions.logstats] INFO: Crawled 550340 pages (at 212 pages/min), scraped 481865 items (at 222 items/min)
2017-11-05 16:34:04 [scrapy.extensions.logstats] INFO: Crawled 550505 pages (at 165 pages/min), scraped 482036 items (at 171 items/min)
2017-11-05 16:35:03 [scrapy.extensions.logstats] INFO: Crawled 550639 pages (at 134 pages/min), scraped 482161 items (at 125 items/min)
2017-11-05 16:36:39 [scrapy.extensions.logstats] INFO: Crawled 550695 pages (at 56 pages/min), scraped 482203 items (at 42 items/min)
2017-11-05 16:37:08 [scrapy.extensions.logstats] INFO: Crawled 550756 pages (at 61 pages/min), scraped 482263 items (at 60 items/min)
2017-11-05 16:38:03 [scrapy.extensions.logstats] INFO: Crawled 550940 pages (at 184 pages/min), scraped 482451 items (at 188 items/min)
2017-11-05 16:39:07 [scrapy.extensions.logstats] INFO: Crawled 551033 pages (at 93 pages/min), scraped 482544 items (at 93 items/min)
2017-11-05 16:40:07 [scrapy.extensions.logstats] INFO: Crawled 551045 pages (at 12 pages/min), scraped 482559 items (at 15 items/min)
2017-11-05 16:41:04 [scrapy.extensions.logstats] INFO: Crawled 551060 pages (at 15 pages/min), scraped 482565 items (at 6 items/min)
2017-11-05 16:42:03 [scrapy.extensions.logstats] INFO: Crawled 551220 pages (at 160 pages/min), scraped 482742 items (at 177 items/min)
2017-11-05 16:43:03 [scrapy.extensions.logstats] INFO: Crawled 551443 pages (at 223 pages/min), scraped 482942 items (at 200 items/min)
2017-11-05 16:44:03 [scrapy.extensions.logstats] INFO: Crawled 551653 pages (at 210 pages/min), scraped 483142 items (at 200 items/min)
2017-11-05 16:45:03 [scrapy.extensions.logstats] INFO: Crawled 551855 pages (at 202 pages/min), scraped 483320 items (at 178 items/min)
2017-11-05 16:46:03 [scrapy.extensions.logstats] INFO: Crawled 552066 pages (at 211 pages/min), scraped 483519 items (at 199 items/min)
2017-11-05 16:47:04 [scrapy.extensions.logstats] INFO: Crawled 552278 pages (at 212 pages/min), scraped 483714 items (at 195 items/min)
2017-11-05 16:48:03 [scrapy.extensions.logstats] INFO: Crawled 552517 pages (at 239 pages/min), scraped 483924 items (at 210 items/min)
2017-11-05 16:49:03 [scrapy.extensions.logstats] INFO: Crawled 552735 pages (at 218 pages/min), scraped 484139 items (at 215 items/min)
2017-11-05 16:50:03 [scrapy.extensions.logstats] INFO: Crawled 552947 pages (at 212 pages/min), scraped 484348 items (at 209 items/min)
2017-11-05 16:51:03 [scrapy.extensions.logstats] INFO: Crawled 553164 pages (at 217 pages/min), scraped 484551 items (at 203 items/min)
2017-11-05 16:52:03 [scrapy.extensions.logstats] INFO: Crawled 553376 pages (at 212 pages/min), scraped 484746 items (at 195 items/min)
2017-11-05 16:53:03 [scrapy.extensions.logstats] INFO: Crawled 553600 pages (at 224 pages/min), scraped 484948 items (at 202 items/min)
2017-11-05 16:54:03 [scrapy.extensions.logstats] INFO: Crawled 553819 pages (at 219 pages/min), scraped 485154 items (at 206 items/min)
2017-11-05 16:55:03 [scrapy.extensions.logstats] INFO: Crawled 554019 pages (at 200 pages/min), scraped 485326 items (at 172 items/min)
2017-11-05 16:56:03 [scrapy.extensions.logstats] INFO: Crawled 554231 pages (at 212 pages/min), scraped 485530 items (at 204 items/min)
2017-11-05 16:57:03 [scrapy.extensions.logstats] INFO: Crawled 554445 pages (at 214 pages/min), scraped 485737 items (at 207 items/min)
2017-11-05 16:58:06 [scrapy.extensions.logstats] INFO: Crawled 554677 pages (at 232 pages/min), scraped 485951 items (at 214 items/min)
2017-11-05 16:59:03 [scrapy.extensions.logstats] INFO: Crawled 554894 pages (at 217 pages/min), scraped 486152 items (at 201 items/min)
2017-11-05 17:00:03 [scrapy.extensions.logstats] INFO: Crawled 555105 pages (at 211 pages/min), scraped 486344 items (at 192 items/min)
2017-11-05 17:01:03 [scrapy.extensions.logstats] INFO: Crawled 555320 pages (at 215 pages/min), scraped 486547 items (at 203 items/min)
2017-11-05 17:02:03 [scrapy.extensions.logstats] INFO: Crawled 555527 pages (at 207 pages/min), scraped 486744 items (at 197 items/min)
2017-11-05 17:03:03 [scrapy.extensions.logstats] INFO: Crawled 555738 pages (at 211 pages/min), scraped 486931 items (at 187 items/min)
2017-11-05 17:04:03 [scrapy.extensions.logstats] INFO: Crawled 555938 pages (at 200 pages/min), scraped 487116 items (at 185 items/min)
2017-11-05 17:05:03 [scrapy.extensions.logstats] INFO: Crawled 556143 pages (at 205 pages/min), scraped 487292 items (at 176 items/min)
2017-11-05 17:06:03 [scrapy.extensions.logstats] INFO: Crawled 556336 pages (at 193 pages/min), scraped 487456 items (at 164 items/min)
2017-11-05 17:07:03 [scrapy.extensions.logstats] INFO: Crawled 556546 pages (at 210 pages/min), scraped 487653 items (at 197 items/min)
2017-11-05 17:08:04 [scrapy.extensions.logstats] INFO: Crawled 556776 pages (at 230 pages/min), scraped 487830 items (at 177 items/min)
2017-11-05 17:09:03 [scrapy.extensions.logstats] INFO: Crawled 557005 pages (at 229 pages/min), scraped 488013 items (at 183 items/min)
2017-11-05 17:10:03 [scrapy.extensions.logstats] INFO: Crawled 557214 pages (at 209 pages/min), scraped 488170 items (at 157 items/min)
2017-11-05 17:11:03 [scrapy.extensions.logstats] INFO: Crawled 557425 pages (at 211 pages/min), scraped 488323 items (at 153 items/min)
2017-11-05 17:12:03 [scrapy.extensions.logstats] INFO: Crawled 557633 pages (at 208 pages/min), scraped 488483 items (at 160 items/min)
2017-11-05 17:13:03 [scrapy.extensions.logstats] INFO: Crawled 557842 pages (at 209 pages/min), scraped 488655 items (at 172 items/min)
2017-11-05 17:14:03 [scrapy.extensions.logstats] INFO: Crawled 558050 pages (at 208 pages/min), scraped 488840 items (at 185 items/min)
2017-11-05 17:15:03 [scrapy.extensions.logstats] INFO: Crawled 558235 pages (at 185 pages/min), scraped 488980 items (at 140 items/min)
2017-11-05 17:16:03 [scrapy.extensions.logstats] INFO: Crawled 558343 pages (at 108 pages/min), scraped 489064 items (at 84 items/min)
2017-11-05 17:17:05 [scrapy.extensions.logstats] INFO: Crawled 558486 pages (at 143 pages/min), scraped 489165 items (at 101 items/min)
2017-11-05 17:18:07 [scrapy.extensions.logstats] INFO: Crawled 558721 pages (at 235 pages/min), scraped 489345 items (at 180 items/min)
2017-11-05 17:19:03 [scrapy.extensions.logstats] INFO: Crawled 558934 pages (at 213 pages/min), scraped 489517 items (at 172 items/min)
2017-11-05 17:20:03 [scrapy.extensions.logstats] INFO: Crawled 559147 pages (at 213 pages/min), scraped 489680 items (at 163 items/min)
2017-11-05 17:21:03 [scrapy.extensions.logstats] INFO: Crawled 559368 pages (at 221 pages/min), scraped 489866 items (at 186 items/min)
2017-11-05 17:22:03 [scrapy.extensions.logstats] INFO: Crawled 559577 pages (at 209 pages/min), scraped 490044 items (at 178 items/min)
2017-11-05 17:23:03 [scrapy.extensions.logstats] INFO: Crawled 559785 pages (at 208 pages/min), scraped 490242 items (at 198 items/min)
2017-11-05 17:24:03 [scrapy.extensions.logstats] INFO: Crawled 559992 pages (at 207 pages/min), scraped 490449 items (at 207 items/min)
2017-11-05 17:25:03 [scrapy.extensions.logstats] INFO: Crawled 560204 pages (at 212 pages/min), scraped 490644 items (at 195 items/min)
2017-11-05 17:26:03 [scrapy.extensions.logstats] INFO: Crawled 560412 pages (at 208 pages/min), scraped 490841 items (at 197 items/min)
2017-11-05 17:27:04 [scrapy.extensions.logstats] INFO: Crawled 560628 pages (at 216 pages/min), scraped 491038 items (at 197 items/min)
2017-11-05 17:28:03 [scrapy.extensions.logstats] INFO: Crawled 560857 pages (at 229 pages/min), scraped 491253 items (at 215 items/min)
2017-11-05 17:29:03 [scrapy.extensions.logstats] INFO: Crawled 561072 pages (at 215 pages/min), scraped 491450 items (at 197 items/min)
2017-11-05 17:30:03 [scrapy.extensions.logstats] INFO: Crawled 561283 pages (at 211 pages/min), scraped 491631 items (at 181 items/min)
2017-11-05 17:31:03 [scrapy.extensions.logstats] INFO: Crawled 561494 pages (at 211 pages/min), scraped 491831 items (at 200 items/min)
2017-11-05 17:32:03 [scrapy.extensions.logstats] INFO: Crawled 561626 pages (at 132 pages/min), scraped 491944 items (at 113 items/min)
2017-11-05 17:33:08 [scrapy.extensions.logstats] INFO: Crawled 561784 pages (at 158 pages/min), scraped 492101 items (at 157 items/min)
2017-11-05 17:34:03 [scrapy.extensions.logstats] INFO: Crawled 561838 pages (at 54 pages/min), scraped 492150 items (at 49 items/min)
2017-11-05 17:35:03 [scrapy.extensions.logstats] INFO: Crawled 562041 pages (at 203 pages/min), scraped 492343 items (at 193 items/min)
2017-11-05 17:36:03 [scrapy.extensions.logstats] INFO: Crawled 562245 pages (at 204 pages/min), scraped 492512 items (at 169 items/min)
2017-11-05 17:37:03 [scrapy.extensions.logstats] INFO: Crawled 562445 pages (at 200 pages/min), scraped 492696 items (at 184 items/min)
2017-11-05 17:38:05 [scrapy.extensions.logstats] INFO: Crawled 562599 pages (at 154 pages/min), scraped 492840 items (at 144 items/min)
2017-11-05 17:39:03 [scrapy.extensions.logstats] INFO: Crawled 562827 pages (at 228 pages/min), scraped 493046 items (at 206 items/min)
2017-11-05 17:40:03 [scrapy.extensions.logstats] INFO: Crawled 563012 pages (at 185 pages/min), scraped 493220 items (at 174 items/min)
2017-11-05 17:41:03 [scrapy.extensions.logstats] INFO: Crawled 563220 pages (at 208 pages/min), scraped 493406 items (at 186 items/min)
2017-11-05 17:42:03 [scrapy.extensions.logstats] INFO: Crawled 563429 pages (at 209 pages/min), scraped 493588 items (at 182 items/min)
2017-11-05 17:43:03 [scrapy.extensions.logstats] INFO: Crawled 563646 pages (at 217 pages/min), scraped 493799 items (at 211 items/min)
2017-11-05 17:44:03 [scrapy.extensions.logstats] INFO: Crawled 563857 pages (at 211 pages/min), scraped 493978 items (at 179 items/min)
2017-11-05 17:45:03 [scrapy.extensions.logstats] INFO: Crawled 564077 pages (at 220 pages/min), scraped 494167 items (at 189 items/min)
2017-11-05 17:46:03 [scrapy.extensions.logstats] INFO: Crawled 564278 pages (at 201 pages/min), scraped 494354 items (at 187 items/min)
2017-11-05 17:47:03 [scrapy.extensions.logstats] INFO: Crawled 564423 pages (at 145 pages/min), scraped 494503 items (at 149 items/min)
2017-11-05 17:48:09 [scrapy.extensions.logstats] INFO: Crawled 564654 pages (at 231 pages/min), scraped 494714 items (at 211 items/min)
2017-11-05 17:49:03 [scrapy.extensions.logstats] INFO: Crawled 564869 pages (at 215 pages/min), scraped 494898 items (at 184 items/min)
2017-11-05 17:50:03 [scrapy.extensions.logstats] INFO: Crawled 565068 pages (at 199 pages/min), scraped 495072 items (at 174 items/min)
2017-11-05 17:51:03 [scrapy.extensions.logstats] INFO: Crawled 565272 pages (at 204 pages/min), scraped 495260 items (at 188 items/min)
2017-11-05 17:52:03 [scrapy.extensions.logstats] INFO: Crawled 565475 pages (at 203 pages/min), scraped 495447 items (at 187 items/min)
2017-11-05 17:53:03 [scrapy.extensions.logstats] INFO: Crawled 565691 pages (at 216 pages/min), scraped 495638 items (at 191 items/min)
2017-11-05 17:54:03 [scrapy.extensions.logstats] INFO: Crawled 565895 pages (at 204 pages/min), scraped 495820 items (at 182 items/min)
2017-11-05 17:55:03 [scrapy.extensions.logstats] INFO: Crawled 566070 pages (at 175 pages/min), scraped 495964 items (at 144 items/min)
2017-11-05 17:56:04 [scrapy.extensions.logstats] INFO: Crawled 566177 pages (at 107 pages/min), scraped 496072 items (at 108 items/min)
2017-11-05 17:57:04 [scrapy.extensions.logstats] INFO: Crawled 566230 pages (at 53 pages/min), scraped 496112 items (at 40 items/min)
2017-11-05 17:58:10 [scrapy.extensions.logstats] INFO: Crawled 566309 pages (at 79 pages/min), scraped 496178 items (at 66 items/min)
2017-11-05 17:59:04 [scrapy.extensions.logstats] INFO: Crawled 566361 pages (at 52 pages/min), scraped 496216 items (at 38 items/min)
2017-11-05 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 566380 pages (at 19 pages/min), scraped 496239 items (at 23 items/min)
2017-11-05 18:01:22 [scrapy.extensions.logstats] INFO: Crawled 566390 pages (at 10 pages/min), scraped 496242 items (at 3 items/min)
2017-11-05 18:02:03 [scrapy.extensions.logstats] INFO: Crawled 566546 pages (at 156 pages/min), scraped 496372 items (at 130 items/min)
2017-11-05 18:03:03 [scrapy.extensions.logstats] INFO: Crawled 566749 pages (at 203 pages/min), scraped 496558 items (at 186 items/min)
2017-11-05 18:04:03 [scrapy.extensions.logstats] INFO: Crawled 566961 pages (at 212 pages/min), scraped 496752 items (at 194 items/min)
2017-11-05 18:05:03 [scrapy.extensions.logstats] INFO: Crawled 567175 pages (at 214 pages/min), scraped 496918 items (at 166 items/min)
2017-11-05 18:06:03 [scrapy.extensions.logstats] INFO: Crawled 567379 pages (at 204 pages/min), scraped 497071 items (at 153 items/min)
2017-11-05 18:07:03 [scrapy.extensions.logstats] INFO: Crawled 567583 pages (at 204 pages/min), scraped 497232 items (at 161 items/min)
2017-11-05 18:08:03 [scrapy.extensions.logstats] INFO: Crawled 567823 pages (at 240 pages/min), scraped 497413 items (at 181 items/min)
2017-11-05 18:09:03 [scrapy.extensions.logstats] INFO: Crawled 567989 pages (at 166 pages/min), scraped 497534 items (at 121 items/min)
2017-11-05 18:10:03 [scrapy.extensions.logstats] INFO: Crawled 568135 pages (at 146 pages/min), scraped 497653 items (at 119 items/min)
2017-11-05 18:10:05 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29984242&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"华志伟","SCO_NAME":"男","ECO_NAME":"大专","AOI_NAME":"华宝证券有限责任公司","AOI_ID":"1999089","ADI_ID":"47366","ADI_NAME":"杭州玉古路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0890111040014","OBTAIN_DATE":"2011-04-20","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-05 18:11:03 [scrapy.extensions.logstats] INFO: Crawled 568352 pages (at 217 pages/min), scraped 497829 items (at 176 items/min)
2017-11-05 18:11:06 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29925128&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"杜震宇","SCO_NAME":"男","ECO_NAME":"硕士研究生","AOI_NAME":"华宝证券有限责任公司","AOI_ID":"1999089","ADI_ID":"42316","ADI_NAME":"人力资源部","PTI_NAME":"一般证券业务","CER_NUM":"S0890109030226","OBTAIN_DATE":"2009-03-17","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-05 18:12:03 [scrapy.extensions.logstats] INFO: Crawled 568555 pages (at 203 pages/min), scraped 497989 items (at 160 items/min)
2017-11-05 18:13:03 [scrapy.extensions.logstats] INFO: Crawled 568753 pages (at 198 pages/min), scraped 498184 items (at 195 items/min)
2017-11-05 18:14:03 [scrapy.extensions.logstats] INFO: Crawled 568957 pages (at 204 pages/min), scraped 498359 items (at 175 items/min)
2017-11-05 18:15:03 [scrapy.extensions.logstats] INFO: Crawled 569170 pages (at 213 pages/min), scraped 498539 items (at 180 items/min)
2017-11-05 18:16:03 [scrapy.extensions.logstats] INFO: Crawled 569383 pages (at 213 pages/min), scraped 498715 items (at 176 items/min)
2017-11-05 18:17:05 [scrapy.extensions.logstats] INFO: Crawled 569615 pages (at 232 pages/min), scraped 498923 items (at 208 items/min)
2017-11-05 18:18:03 [scrapy.extensions.logstats] INFO: Crawled 569836 pages (at 221 pages/min), scraped 499127 items (at 204 items/min)
2017-11-05 18:19:03 [scrapy.extensions.logstats] INFO: Crawled 570044 pages (at 208 pages/min), scraped 499344 items (at 217 items/min)
2017-11-05 18:20:03 [scrapy.extensions.logstats] INFO: Crawled 570249 pages (at 205 pages/min), scraped 499525 items (at 181 items/min)
2017-11-05 18:21:03 [scrapy.extensions.logstats] INFO: Crawled 570464 pages (at 215 pages/min), scraped 499719 items (at 194 items/min)
2017-11-05 18:22:03 [scrapy.extensions.logstats] INFO: Crawled 570681 pages (at 217 pages/min), scraped 499901 items (at 182 items/min)
2017-11-05 18:23:03 [scrapy.extensions.logstats] INFO: Crawled 570902 pages (at 221 pages/min), scraped 500095 items (at 194 items/min)
2017-11-05 18:24:03 [scrapy.extensions.logstats] INFO: Crawled 571113 pages (at 211 pages/min), scraped 500276 items (at 181 items/min)
2017-11-05 18:25:03 [scrapy.extensions.logstats] INFO: Crawled 571319 pages (at 206 pages/min), scraped 500475 items (at 199 items/min)
2017-11-05 18:26:03 [scrapy.extensions.logstats] INFO: Crawled 571538 pages (at 219 pages/min), scraped 500689 items (at 214 items/min)
2017-11-05 18:27:08 [scrapy.extensions.logstats] INFO: Crawled 571759 pages (at 221 pages/min), scraped 500894 items (at 205 items/min)
2017-11-05 18:28:03 [scrapy.extensions.logstats] INFO: Crawled 571979 pages (at 220 pages/min), scraped 501108 items (at 214 items/min)
2017-11-05 18:29:03 [scrapy.extensions.logstats] INFO: Crawled 572189 pages (at 210 pages/min), scraped 501326 items (at 218 items/min)
2017-11-05 18:30:03 [scrapy.extensions.logstats] INFO: Crawled 572399 pages (at 210 pages/min), scraped 501492 items (at 166 items/min)
2017-11-05 18:31:03 [scrapy.extensions.logstats] INFO: Crawled 572606 pages (at 207 pages/min), scraped 501656 items (at 164 items/min)
2017-11-05 18:32:03 [scrapy.extensions.logstats] INFO: Crawled 572823 pages (at 217 pages/min), scraped 501846 items (at 190 items/min)
2017-11-05 18:33:03 [scrapy.extensions.logstats] INFO: Crawled 573047 pages (at 224 pages/min), scraped 502014 items (at 168 items/min)
2017-11-05 18:34:03 [scrapy.extensions.logstats] INFO: Crawled 573265 pages (at 218 pages/min), scraped 502165 items (at 151 items/min)
2017-11-05 18:35:03 [scrapy.extensions.logstats] INFO: Crawled 573470 pages (at 205 pages/min), scraped 502341 items (at 176 items/min)
2017-11-05 18:36:04 [scrapy.extensions.logstats] INFO: Crawled 573678 pages (at 208 pages/min), scraped 502501 items (at 160 items/min)
2017-11-05 18:37:03 [scrapy.extensions.logstats] INFO: Crawled 573913 pages (at 235 pages/min), scraped 502694 items (at 193 items/min)
2017-11-05 18:38:03 [scrapy.extensions.logstats] INFO: Crawled 574124 pages (at 211 pages/min), scraped 502867 items (at 173 items/min)
2017-11-05 18:39:03 [scrapy.extensions.logstats] INFO: Crawled 574334 pages (at 210 pages/min), scraped 503059 items (at 192 items/min)
2017-11-05 18:40:03 [scrapy.extensions.logstats] INFO: Crawled 574542 pages (at 208 pages/min), scraped 503250 items (at 191 items/min)
2017-11-05 18:41:03 [scrapy.extensions.logstats] INFO: Crawled 574754 pages (at 212 pages/min), scraped 503411 items (at 161 items/min)
2017-11-05 18:42:03 [scrapy.extensions.logstats] INFO: Crawled 574966 pages (at 212 pages/min), scraped 503616 items (at 205 items/min)
2017-11-05 18:43:03 [scrapy.extensions.logstats] INFO: Crawled 575170 pages (at 204 pages/min), scraped 503807 items (at 191 items/min)
2017-11-05 18:44:03 [scrapy.extensions.logstats] INFO: Crawled 575379 pages (at 209 pages/min), scraped 503999 items (at 192 items/min)
2017-11-05 18:45:03 [scrapy.extensions.logstats] INFO: Crawled 575591 pages (at 212 pages/min), scraped 504182 items (at 183 items/min)
2017-11-05 18:46:03 [scrapy.extensions.logstats] INFO: Crawled 575810 pages (at 219 pages/min), scraped 504353 items (at 171 items/min)
2017-11-05 18:47:03 [scrapy.extensions.logstats] INFO: Crawled 576044 pages (at 234 pages/min), scraped 504548 items (at 195 items/min)
2017-11-05 18:48:03 [scrapy.extensions.logstats] INFO: Crawled 576282 pages (at 238 pages/min), scraped 504733 items (at 185 items/min)
2017-11-05 18:49:03 [scrapy.extensions.logstats] INFO: Crawled 576486 pages (at 204 pages/min), scraped 504874 items (at 141 items/min)
2017-11-05 18:50:03 [scrapy.extensions.logstats] INFO: Crawled 576700 pages (at 214 pages/min), scraped 505056 items (at 182 items/min)
2017-11-05 18:51:03 [scrapy.extensions.logstats] INFO: Crawled 576933 pages (at 233 pages/min), scraped 505261 items (at 205 items/min)
2017-11-05 18:52:03 [scrapy.extensions.logstats] INFO: Crawled 577166 pages (at 233 pages/min), scraped 505491 items (at 230 items/min)
2017-11-05 18:53:03 [scrapy.extensions.logstats] INFO: Crawled 577379 pages (at 213 pages/min), scraped 505695 items (at 204 items/min)
2017-11-05 18:54:03 [scrapy.extensions.logstats] INFO: Crawled 577596 pages (at 217 pages/min), scraped 505918 items (at 223 items/min)
2017-11-05 18:55:03 [scrapy.extensions.logstats] INFO: Crawled 577814 pages (at 218 pages/min), scraped 506134 items (at 216 items/min)
2017-11-05 18:56:03 [scrapy.extensions.logstats] INFO: Crawled 578023 pages (at 209 pages/min), scraped 506345 items (at 211 items/min)
2017-11-05 18:57:03 [scrapy.extensions.logstats] INFO: Crawled 578236 pages (at 213 pages/min), scraped 506547 items (at 202 items/min)
2017-11-05 18:58:03 [scrapy.extensions.logstats] INFO: Crawled 578468 pages (at 232 pages/min), scraped 506757 items (at 210 items/min)
2017-11-05 18:59:03 [scrapy.extensions.logstats] INFO: Crawled 578678 pages (at 210 pages/min), scraped 506958 items (at 201 items/min)
2017-11-05 19:00:03 [scrapy.extensions.logstats] INFO: Crawled 578908 pages (at 230 pages/min), scraped 507190 items (at 232 items/min)
2017-11-05 19:01:03 [scrapy.extensions.logstats] INFO: Crawled 579112 pages (at 204 pages/min), scraped 507426 items (at 236 items/min)
2017-11-05 19:02:03 [scrapy.extensions.logstats] INFO: Crawled 579326 pages (at 214 pages/min), scraped 507597 items (at 171 items/min)
2017-11-05 19:03:03 [scrapy.extensions.logstats] INFO: Crawled 579525 pages (at 199 pages/min), scraped 507787 items (at 190 items/min)
2017-11-05 19:04:03 [scrapy.extensions.logstats] INFO: Crawled 579723 pages (at 198 pages/min), scraped 507984 items (at 197 items/min)
2017-11-05 19:05:03 [scrapy.extensions.logstats] INFO: Crawled 579945 pages (at 222 pages/min), scraped 508198 items (at 214 items/min)
2017-11-05 19:06:03 [scrapy.extensions.logstats] INFO: Crawled 580146 pages (at 201 pages/min), scraped 508352 items (at 154 items/min)
2017-11-05 19:06:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EmpHashID'],
 'result': {'ADI_ID': '12003',
            'ADI_NAME': '运营中心',
            'ChangeInformationCount': '1',
            'CorpFullName': '恒泰证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999067',
            'Education': '本科',
            'EmpFullName': '齐姗姗',
            'EmpHashID': '5D2D51F34D437859E0538850A8C0BDE2',
            'EmpID': '59972742',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S0670110080121',
            'QualificationStartDate': '2010-08-24',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080101/registrationRpInfo/136385764944344200.jpg'}}
Traceback (most recent call last):
  File "pymssql.pyx", line 447, in pymssql.Cursor.execute (pymssql.c:7119)
  File "_mssql.pyx", line 1011, in _mssql.MSSQLConnection.execute_query (_mssql.c:11586)
  File "_mssql.pyx", line 1043, in _mssql.MSSQLConnection.execute_query (_mssql.c:11477)
  File "_mssql.pyx", line 1241, in _mssql.MSSQLConnection.get_result (_mssql.c:13497)
  File "_mssql.pyx", line 1588, in _mssql.check_cancel_and_raise (_mssql.c:16910)
  File "_mssql.pyx", line 1630, in _mssql.maybe_raise_MSSQLDatabaseException (_mssql.c:17524)
_mssql.MSSQLDatabaseException: (8642, b'The query processor could not start the necessary thread resources for parallel query execution.DB-Lib error message 20018, severity 17:\nGeneral SQL Server error: Check messages from the SQL Server\n')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 351, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 340, in main
    error = self.sqlquery(item,item.keys(),self.tablekeys,self.tableName)
  File "F:\gitwork\pipeline.py", line 250, in sqlquery
    result = self.getQueryResult(item,keys,wherekeys,tb,isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 47, in foo
    result = func(self,*args,**kwargs)
  File "F:\gitwork\pipeline.py", line 73, in getQueryResult
    self.cursor.execute(sql)
  File "pymssql.pyx", line 467, in pymssql.Cursor.execute (pymssql.c:7561)
pymssql.OperationalError: (8642, b'The query processor could not start the necessary thread resources for parallel query execution.DB-Lib error message 20018, severity 17:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-05 19:07:04 [scrapy.extensions.logstats] INFO: Crawled 580366 pages (at 220 pages/min), scraped 508504 items (at 152 items/min)
2017-11-05 19:08:03 [scrapy.extensions.logstats] INFO: Crawled 580602 pages (at 236 pages/min), scraped 508689 items (at 185 items/min)
2017-11-05 19:08:48 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39904535&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"闫婷婷","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"恒泰证券股份有限公司","AOI_ID":"1999067","ADI_ID":"32861","ADI_NAME":"南京水西门大街证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0670108040588","OBTAIN_DATE":"2008-04-10","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-05 19:09:03 [scrapy.extensions.logstats] INFO: Crawled 580818 pages (at 216 pages/min), scraped 508842 items (at 153 items/min)
2017-11-05 19:10:03 [scrapy.extensions.logstats] INFO: Crawled 581024 pages (at 206 pages/min), scraped 508996 items (at 154 items/min)
2017-11-05 19:11:03 [scrapy.extensions.logstats] INFO: Crawled 581230 pages (at 206 pages/min), scraped 509173 items (at 177 items/min)
2017-11-05 19:12:03 [scrapy.extensions.logstats] INFO: Crawled 581434 pages (at 204 pages/min), scraped 509335 items (at 162 items/min)
2017-11-05 19:13:03 [scrapy.extensions.logstats] INFO: Crawled 581650 pages (at 216 pages/min), scraped 509513 items (at 178 items/min)
2017-11-05 19:14:03 [scrapy.extensions.logstats] INFO: Crawled 581869 pages (at 219 pages/min), scraped 509712 items (at 199 items/min)
2017-11-05 19:15:03 [scrapy.extensions.logstats] INFO: Crawled 582073 pages (at 204 pages/min), scraped 509894 items (at 182 items/min)
2017-11-05 19:16:03 [scrapy.extensions.logstats] INFO: Crawled 582285 pages (at 212 pages/min), scraped 510110 items (at 216 items/min)
2017-11-05 19:17:03 [scrapy.extensions.logstats] INFO: Crawled 582511 pages (at 226 pages/min), scraped 510322 items (at 212 items/min)
2017-11-05 19:18:07 [scrapy.extensions.logstats] INFO: Crawled 582752 pages (at 241 pages/min), scraped 510572 items (at 250 items/min)
2017-11-05 19:19:03 [scrapy.extensions.logstats] INFO: Crawled 582964 pages (at 212 pages/min), scraped 510798 items (at 226 items/min)
2017-11-05 19:20:03 [scrapy.extensions.logstats] INFO: Crawled 583178 pages (at 214 pages/min), scraped 511000 items (at 202 items/min)
2017-11-05 19:21:03 [scrapy.extensions.logstats] INFO: Crawled 583380 pages (at 202 pages/min), scraped 511206 items (at 206 items/min)
2017-11-05 19:22:03 [scrapy.extensions.logstats] INFO: Crawled 583611 pages (at 231 pages/min), scraped 511423 items (at 217 items/min)
2017-11-05 19:23:03 [scrapy.extensions.logstats] INFO: Crawled 583820 pages (at 209 pages/min), scraped 511621 items (at 198 items/min)
2017-11-05 19:24:03 [scrapy.extensions.logstats] INFO: Crawled 584046 pages (at 226 pages/min), scraped 511808 items (at 187 items/min)
2017-11-05 19:25:03 [scrapy.extensions.logstats] INFO: Crawled 584255 pages (at 209 pages/min), scraped 512013 items (at 205 items/min)
2017-11-05 19:26:03 [scrapy.extensions.logstats] INFO: Crawled 584469 pages (at 214 pages/min), scraped 512208 items (at 195 items/min)
2017-11-05 19:27:04 [scrapy.extensions.logstats] INFO: Crawled 584681 pages (at 212 pages/min), scraped 512422 items (at 214 items/min)
2017-11-05 19:28:04 [scrapy.extensions.logstats] INFO: Crawled 584905 pages (at 224 pages/min), scraped 512630 items (at 208 items/min)
2017-11-05 19:29:03 [scrapy.extensions.logstats] INFO: Crawled 585139 pages (at 234 pages/min), scraped 512866 items (at 236 items/min)
2017-11-05 19:30:03 [scrapy.extensions.logstats] INFO: Crawled 585345 pages (at 206 pages/min), scraped 513051 items (at 185 items/min)
2017-11-05 19:31:03 [scrapy.extensions.logstats] INFO: Crawled 585565 pages (at 220 pages/min), scraped 513250 items (at 199 items/min)
2017-11-05 19:32:03 [scrapy.extensions.logstats] INFO: Crawled 585769 pages (at 204 pages/min), scraped 513455 items (at 205 items/min)
2017-11-05 19:33:03 [scrapy.extensions.logstats] INFO: Crawled 585970 pages (at 201 pages/min), scraped 513658 items (at 203 items/min)
2017-11-05 19:34:03 [scrapy.extensions.logstats] INFO: Crawled 586172 pages (at 202 pages/min), scraped 513831 items (at 173 items/min)
2017-11-05 19:35:03 [scrapy.extensions.logstats] INFO: Crawled 586384 pages (at 212 pages/min), scraped 514057 items (at 226 items/min)
2017-11-05 19:36:03 [scrapy.extensions.logstats] INFO: Crawled 586593 pages (at 209 pages/min), scraped 514247 items (at 190 items/min)
2017-11-05 19:37:03 [scrapy.extensions.logstats] INFO: Crawled 586815 pages (at 222 pages/min), scraped 514451 items (at 204 items/min)
2017-11-05 19:38:04 [scrapy.extensions.logstats] INFO: Crawled 587034 pages (at 219 pages/min), scraped 514644 items (at 193 items/min)
2017-11-05 19:39:03 [scrapy.extensions.logstats] INFO: Crawled 587271 pages (at 237 pages/min), scraped 514858 items (at 214 items/min)
2017-11-05 19:40:03 [scrapy.extensions.logstats] INFO: Crawled 587489 pages (at 218 pages/min), scraped 515079 items (at 221 items/min)
2017-11-05 19:41:03 [scrapy.extensions.logstats] INFO: Crawled 587703 pages (at 214 pages/min), scraped 515279 items (at 200 items/min)
2017-11-05 19:42:03 [scrapy.extensions.logstats] INFO: Crawled 587924 pages (at 221 pages/min), scraped 515463 items (at 184 items/min)
2017-11-05 19:43:03 [scrapy.extensions.logstats] INFO: Crawled 588136 pages (at 212 pages/min), scraped 515650 items (at 187 items/min)
2017-11-05 19:44:03 [scrapy.extensions.logstats] INFO: Crawled 588360 pages (at 224 pages/min), scraped 515826 items (at 176 items/min)
2017-11-05 19:45:03 [scrapy.extensions.logstats] INFO: Crawled 588566 pages (at 206 pages/min), scraped 515997 items (at 171 items/min)
2017-11-05 19:46:03 [scrapy.extensions.logstats] INFO: Crawled 588772 pages (at 206 pages/min), scraped 516200 items (at 203 items/min)
2017-11-05 19:47:03 [scrapy.extensions.logstats] INFO: Crawled 588979 pages (at 207 pages/min), scraped 516377 items (at 177 items/min)
2017-11-05 19:48:03 [scrapy.extensions.logstats] INFO: Crawled 589197 pages (at 218 pages/min), scraped 516566 items (at 189 items/min)
2017-11-05 19:49:03 [scrapy.extensions.logstats] INFO: Crawled 589441 pages (at 244 pages/min), scraped 516799 items (at 233 items/min)
2017-11-05 19:50:03 [scrapy.extensions.logstats] INFO: Crawled 589659 pages (at 218 pages/min), scraped 517008 items (at 209 items/min)
2017-11-05 19:51:03 [scrapy.extensions.logstats] INFO: Crawled 589894 pages (at 235 pages/min), scraped 517241 items (at 233 items/min)
2017-11-05 19:52:03 [scrapy.extensions.logstats] INFO: Crawled 590107 pages (at 213 pages/min), scraped 517433 items (at 192 items/min)
2017-11-05 19:53:03 [scrapy.extensions.logstats] INFO: Crawled 590323 pages (at 216 pages/min), scraped 517653 items (at 220 items/min)
2017-11-05 19:54:03 [scrapy.extensions.logstats] INFO: Crawled 590555 pages (at 232 pages/min), scraped 517874 items (at 221 items/min)
2017-11-05 19:55:03 [scrapy.extensions.logstats] INFO: Crawled 590764 pages (at 209 pages/min), scraped 518070 items (at 196 items/min)
2017-11-05 19:56:03 [scrapy.extensions.logstats] INFO: Crawled 590987 pages (at 223 pages/min), scraped 518277 items (at 207 items/min)
2017-11-05 19:57:03 [scrapy.extensions.logstats] INFO: Crawled 591194 pages (at 207 pages/min), scraped 518467 items (at 190 items/min)
2017-11-05 19:58:03 [scrapy.extensions.logstats] INFO: Crawled 591402 pages (at 208 pages/min), scraped 518682 items (at 215 items/min)
2017-11-05 19:59:06 [scrapy.extensions.logstats] INFO: Crawled 591621 pages (at 219 pages/min), scraped 518893 items (at 211 items/min)
2017-11-05 20:00:03 [scrapy.extensions.logstats] INFO: Crawled 591848 pages (at 227 pages/min), scraped 519115 items (at 222 items/min)
2017-11-05 20:01:03 [scrapy.extensions.logstats] INFO: Crawled 592062 pages (at 214 pages/min), scraped 519284 items (at 169 items/min)
2017-11-05 20:02:03 [scrapy.extensions.logstats] INFO: Crawled 592271 pages (at 209 pages/min), scraped 519460 items (at 176 items/min)
2017-11-05 20:03:03 [scrapy.extensions.logstats] INFO: Crawled 592473 pages (at 202 pages/min), scraped 519656 items (at 196 items/min)
2017-11-05 20:04:03 [scrapy.extensions.logstats] INFO: Crawled 592694 pages (at 221 pages/min), scraped 519831 items (at 175 items/min)
2017-11-05 20:05:03 [scrapy.extensions.logstats] INFO: Crawled 592911 pages (at 217 pages/min), scraped 520014 items (at 183 items/min)
2017-11-05 20:06:03 [scrapy.extensions.logstats] INFO: Crawled 593120 pages (at 209 pages/min), scraped 520195 items (at 181 items/min)
2017-11-05 20:07:03 [scrapy.extensions.logstats] INFO: Crawled 593318 pages (at 198 pages/min), scraped 520370 items (at 175 items/min)
2017-11-05 20:08:03 [scrapy.extensions.logstats] INFO: Crawled 593529 pages (at 211 pages/min), scraped 520558 items (at 188 items/min)
2017-11-05 20:09:07 [scrapy.extensions.logstats] INFO: Crawled 593754 pages (at 225 pages/min), scraped 520758 items (at 200 items/min)
2017-11-05 20:10:03 [scrapy.extensions.logstats] INFO: Crawled 593972 pages (at 218 pages/min), scraped 520952 items (at 194 items/min)
2017-11-05 20:11:03 [scrapy.extensions.logstats] INFO: Crawled 594184 pages (at 212 pages/min), scraped 521134 items (at 182 items/min)
2017-11-05 20:12:03 [scrapy.extensions.logstats] INFO: Crawled 594391 pages (at 207 pages/min), scraped 521327 items (at 193 items/min)
2017-11-05 20:13:03 [scrapy.extensions.logstats] INFO: Crawled 594616 pages (at 225 pages/min), scraped 521521 items (at 194 items/min)
2017-11-05 20:14:03 [scrapy.extensions.logstats] INFO: Crawled 594840 pages (at 224 pages/min), scraped 521721 items (at 200 items/min)
2017-11-05 20:15:03 [scrapy.extensions.logstats] INFO: Crawled 595045 pages (at 205 pages/min), scraped 521907 items (at 186 items/min)
2017-11-05 20:16:03 [scrapy.extensions.logstats] INFO: Crawled 595249 pages (at 204 pages/min), scraped 522105 items (at 198 items/min)
2017-11-05 20:17:03 [scrapy.extensions.logstats] INFO: Crawled 595459 pages (at 210 pages/min), scraped 522302 items (at 197 items/min)
2017-11-05 20:18:03 [scrapy.extensions.logstats] INFO: Crawled 595665 pages (at 206 pages/min), scraped 522483 items (at 181 items/min)
2017-11-05 20:19:04 [scrapy.extensions.logstats] INFO: Crawled 595881 pages (at 216 pages/min), scraped 522692 items (at 209 items/min)
2017-11-05 20:20:03 [scrapy.extensions.logstats] INFO: Crawled 596117 pages (at 236 pages/min), scraped 522894 items (at 202 items/min)
2017-11-05 20:21:03 [scrapy.extensions.logstats] INFO: Crawled 596332 pages (at 215 pages/min), scraped 523079 items (at 185 items/min)
2017-11-05 20:22:03 [scrapy.extensions.logstats] INFO: Crawled 596536 pages (at 204 pages/min), scraped 523248 items (at 169 items/min)
2017-11-05 20:23:03 [scrapy.extensions.logstats] INFO: Crawled 596741 pages (at 205 pages/min), scraped 523431 items (at 183 items/min)
2017-11-05 20:24:03 [scrapy.extensions.logstats] INFO: Crawled 596954 pages (at 213 pages/min), scraped 523637 items (at 206 items/min)
2017-11-05 20:25:03 [scrapy.extensions.logstats] INFO: Crawled 597166 pages (at 212 pages/min), scraped 523824 items (at 187 items/min)
2017-11-05 20:26:03 [scrapy.extensions.logstats] INFO: Crawled 597382 pages (at 216 pages/min), scraped 524019 items (at 195 items/min)
2017-11-05 20:27:03 [scrapy.extensions.logstats] INFO: Crawled 597586 pages (at 204 pages/min), scraped 524219 items (at 200 items/min)
2017-11-05 20:28:03 [scrapy.extensions.logstats] INFO: Crawled 597785 pages (at 199 pages/min), scraped 524399 items (at 180 items/min)
2017-11-05 20:29:04 [scrapy.extensions.logstats] INFO: Crawled 597999 pages (at 214 pages/min), scraped 524629 items (at 230 items/min)
2017-11-05 20:30:03 [scrapy.extensions.logstats] INFO: Crawled 598224 pages (at 225 pages/min), scraped 524869 items (at 240 items/min)
2017-11-05 20:31:03 [scrapy.extensions.logstats] INFO: Crawled 598446 pages (at 222 pages/min), scraped 525093 items (at 224 items/min)
2017-11-05 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 598661 pages (at 215 pages/min), scraped 525269 items (at 176 items/min)
2017-11-05 20:33:03 [scrapy.extensions.logstats] INFO: Crawled 598898 pages (at 237 pages/min), scraped 525476 items (at 207 items/min)
2017-11-05 20:34:03 [scrapy.extensions.logstats] INFO: Crawled 599141 pages (at 243 pages/min), scraped 525697 items (at 221 items/min)
2017-11-05 20:35:03 [scrapy.extensions.logstats] INFO: Crawled 599380 pages (at 239 pages/min), scraped 525910 items (at 213 items/min)
2017-11-05 20:36:03 [scrapy.extensions.logstats] INFO: Crawled 599620 pages (at 240 pages/min), scraped 526101 items (at 191 items/min)
2017-11-05 20:37:03 [scrapy.extensions.logstats] INFO: Crawled 599860 pages (at 240 pages/min), scraped 526288 items (at 187 items/min)
2017-11-05 20:38:03 [scrapy.extensions.logstats] INFO: Crawled 600099 pages (at 239 pages/min), scraped 526497 items (at 209 items/min)
2017-11-05 20:39:03 [scrapy.extensions.logstats] INFO: Crawled 600338 pages (at 239 pages/min), scraped 526695 items (at 198 items/min)
2017-11-05 20:40:03 [scrapy.extensions.logstats] INFO: Crawled 600576 pages (at 238 pages/min), scraped 526894 items (at 199 items/min)
2017-11-05 20:41:03 [scrapy.extensions.logstats] INFO: Crawled 600816 pages (at 240 pages/min), scraped 527088 items (at 194 items/min)
2017-11-05 20:42:03 [scrapy.extensions.logstats] INFO: Crawled 601057 pages (at 241 pages/min), scraped 527281 items (at 193 items/min)
2017-11-05 20:43:03 [scrapy.extensions.logstats] INFO: Crawled 601296 pages (at 239 pages/min), scraped 527519 items (at 238 items/min)
2017-11-05 20:44:03 [scrapy.extensions.logstats] INFO: Crawled 601538 pages (at 242 pages/min), scraped 527739 items (at 220 items/min)
2017-11-05 20:45:03 [scrapy.extensions.logstats] INFO: Crawled 601776 pages (at 238 pages/min), scraped 527946 items (at 207 items/min)
2017-11-05 20:46:03 [scrapy.extensions.logstats] INFO: Crawled 602015 pages (at 239 pages/min), scraped 528160 items (at 214 items/min)
2017-11-05 20:47:03 [scrapy.extensions.logstats] INFO: Crawled 602249 pages (at 234 pages/min), scraped 528364 items (at 204 items/min)
2017-11-05 20:48:03 [scrapy.extensions.logstats] INFO: Crawled 602486 pages (at 237 pages/min), scraped 528612 items (at 248 items/min)
2017-11-05 20:49:03 [scrapy.extensions.logstats] INFO: Crawled 602729 pages (at 243 pages/min), scraped 528820 items (at 208 items/min)
2017-11-05 20:50:03 [scrapy.extensions.logstats] INFO: Crawled 602968 pages (at 239 pages/min), scraped 529035 items (at 215 items/min)
2017-11-05 20:51:03 [scrapy.extensions.logstats] INFO: Crawled 603203 pages (at 235 pages/min), scraped 529246 items (at 211 items/min)
2017-11-05 20:52:03 [scrapy.extensions.logstats] INFO: Crawled 603444 pages (at 241 pages/min), scraped 529469 items (at 223 items/min)
2017-11-05 20:53:03 [scrapy.extensions.logstats] INFO: Crawled 603692 pages (at 248 pages/min), scraped 529694 items (at 225 items/min)
2017-11-05 20:54:03 [scrapy.extensions.logstats] INFO: Crawled 603931 pages (at 239 pages/min), scraped 529912 items (at 218 items/min)
2017-11-05 20:55:03 [scrapy.extensions.logstats] INFO: Crawled 604168 pages (at 237 pages/min), scraped 530132 items (at 220 items/min)
2017-11-05 20:56:03 [scrapy.extensions.logstats] INFO: Crawled 604408 pages (at 240 pages/min), scraped 530347 items (at 215 items/min)
2017-11-05 20:57:03 [scrapy.extensions.logstats] INFO: Crawled 604650 pages (at 242 pages/min), scraped 530544 items (at 197 items/min)
2017-11-05 20:58:03 [scrapy.extensions.logstats] INFO: Crawled 604888 pages (at 238 pages/min), scraped 530745 items (at 201 items/min)
2017-11-05 20:59:03 [scrapy.extensions.logstats] INFO: Crawled 605125 pages (at 237 pages/min), scraped 530953 items (at 208 items/min)
2017-11-05 21:00:03 [scrapy.extensions.logstats] INFO: Crawled 605366 pages (at 241 pages/min), scraped 531157 items (at 204 items/min)
2017-11-05 21:01:03 [scrapy.extensions.logstats] INFO: Crawled 605602 pages (at 236 pages/min), scraped 531357 items (at 200 items/min)
2017-11-05 21:02:03 [scrapy.extensions.logstats] INFO: Crawled 605847 pages (at 245 pages/min), scraped 531559 items (at 202 items/min)
2017-11-05 21:03:03 [scrapy.extensions.logstats] INFO: Crawled 606090 pages (at 243 pages/min), scraped 531750 items (at 191 items/min)
2017-11-05 21:04:03 [scrapy.extensions.logstats] INFO: Crawled 606330 pages (at 240 pages/min), scraped 531940 items (at 190 items/min)
2017-11-05 21:05:03 [scrapy.extensions.logstats] INFO: Crawled 606571 pages (at 241 pages/min), scraped 532125 items (at 185 items/min)
2017-11-05 21:06:03 [scrapy.extensions.logstats] INFO: Crawled 606810 pages (at 239 pages/min), scraped 532317 items (at 192 items/min)
2017-11-05 21:07:03 [scrapy.extensions.logstats] INFO: Crawled 607050 pages (at 240 pages/min), scraped 532509 items (at 192 items/min)
2017-11-05 21:08:03 [scrapy.extensions.logstats] INFO: Crawled 607290 pages (at 240 pages/min), scraped 532690 items (at 181 items/min)
2017-11-05 21:09:03 [scrapy.extensions.logstats] INFO: Crawled 607532 pages (at 242 pages/min), scraped 532882 items (at 192 items/min)
2017-11-05 21:10:03 [scrapy.extensions.logstats] INFO: Crawled 607773 pages (at 241 pages/min), scraped 533076 items (at 194 items/min)
2017-11-05 21:11:03 [scrapy.extensions.logstats] INFO: Crawled 608017 pages (at 244 pages/min), scraped 533259 items (at 183 items/min)
2017-11-05 21:12:03 [scrapy.extensions.logstats] INFO: Crawled 608257 pages (at 240 pages/min), scraped 533448 items (at 189 items/min)
2017-11-05 21:13:03 [scrapy.extensions.logstats] INFO: Crawled 608498 pages (at 241 pages/min), scraped 533630 items (at 182 items/min)
2017-11-05 21:14:03 [scrapy.extensions.logstats] INFO: Crawled 608738 pages (at 240 pages/min), scraped 533818 items (at 188 items/min)
2017-11-05 21:15:03 [scrapy.extensions.logstats] INFO: Crawled 608977 pages (at 239 pages/min), scraped 534058 items (at 240 items/min)
2017-11-05 21:16:03 [scrapy.extensions.logstats] INFO: Crawled 609217 pages (at 240 pages/min), scraped 534251 items (at 193 items/min)
2017-11-05 21:17:03 [scrapy.extensions.logstats] INFO: Crawled 609458 pages (at 241 pages/min), scraped 534449 items (at 198 items/min)
2017-11-05 21:18:03 [scrapy.extensions.logstats] INFO: Crawled 609699 pages (at 241 pages/min), scraped 534655 items (at 206 items/min)
2017-11-05 21:19:03 [scrapy.extensions.logstats] INFO: Crawled 609940 pages (at 241 pages/min), scraped 534851 items (at 196 items/min)
2017-11-05 21:20:03 [scrapy.extensions.logstats] INFO: Crawled 610185 pages (at 245 pages/min), scraped 535050 items (at 199 items/min)
2017-11-05 21:20:23 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39900001&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"曲绍鹏","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"海通证券股份有限公司","AOI_ID":"1999085","ADI_ID":"11726","ADI_NAME":"黑龙江分公司","PTI_NAME":"一般证券业务","CER_NUM":"S0850107122500","OBTAIN_DATE":"2007-12-14","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-05 21:21:03 [scrapy.extensions.logstats] INFO: Crawled 610426 pages (at 241 pages/min), scraped 535249 items (at 199 items/min)
2017-11-05 21:22:03 [scrapy.extensions.logstats] INFO: Crawled 610665 pages (at 239 pages/min), scraped 535467 items (at 218 items/min)
2017-11-05 21:23:03 [scrapy.extensions.logstats] INFO: Crawled 610904 pages (at 239 pages/min), scraped 535669 items (at 202 items/min)
2017-11-05 21:23:06 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29992155&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"刘微","SCO_NAME":"女","ECO_NAME":"硕士研究生","AOI_NAME":"海通证券股份有限公司","AOI_ID":"1999085","ADI_ID":"8469","ADI_NAME":"江苏分公司","PTI_NAME":"一般证券业务","CER_NUM":"S0850110013752","OBTAIN_DATE":"2010-01-28","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-05 21:24:03 [scrapy.extensions.logstats] INFO: Crawled 611152 pages (at 248 pages/min), scraped 535888 items (at 219 items/min)
2017-11-05 21:25:03 [scrapy.extensions.logstats] INFO: Crawled 611394 pages (at 242 pages/min), scraped 536117 items (at 229 items/min)
2017-11-05 21:26:03 [scrapy.extensions.logstats] INFO: Crawled 611634 pages (at 240 pages/min), scraped 536341 items (at 224 items/min)
2017-11-05 21:27:03 [scrapy.extensions.logstats] INFO: Crawled 611870 pages (at 236 pages/min), scraped 536556 items (at 215 items/min)
2017-11-05 21:28:03 [scrapy.extensions.logstats] INFO: Crawled 612110 pages (at 240 pages/min), scraped 536790 items (at 234 items/min)
2017-11-05 21:29:03 [scrapy.extensions.logstats] INFO: Crawled 612347 pages (at 237 pages/min), scraped 537026 items (at 236 items/min)
2017-11-05 21:30:03 [scrapy.extensions.logstats] INFO: Crawled 612583 pages (at 236 pages/min), scraped 537271 items (at 245 items/min)
2017-11-05 21:31:03 [scrapy.extensions.logstats] INFO: Crawled 612816 pages (at 233 pages/min), scraped 537518 items (at 247 items/min)
2017-11-05 21:32:03 [scrapy.extensions.logstats] INFO: Crawled 613049 pages (at 233 pages/min), scraped 537757 items (at 239 items/min)
2017-11-05 21:33:03 [scrapy.extensions.logstats] INFO: Crawled 613284 pages (at 235 pages/min), scraped 538012 items (at 255 items/min)
2017-11-05 21:34:03 [scrapy.extensions.logstats] INFO: Crawled 613516 pages (at 232 pages/min), scraped 538247 items (at 235 items/min)
2017-11-05 21:35:03 [scrapy.extensions.logstats] INFO: Crawled 613755 pages (at 239 pages/min), scraped 538514 items (at 267 items/min)
2017-11-05 21:36:03 [scrapy.extensions.logstats] INFO: Crawled 613994 pages (at 239 pages/min), scraped 538762 items (at 248 items/min)
2017-11-05 21:37:03 [scrapy.extensions.logstats] INFO: Crawled 614232 pages (at 238 pages/min), scraped 539012 items (at 250 items/min)
2017-11-05 21:38:03 [scrapy.extensions.logstats] INFO: Crawled 614466 pages (at 234 pages/min), scraped 539266 items (at 254 items/min)
2017-11-05 21:39:03 [scrapy.extensions.logstats] INFO: Crawled 614704 pages (at 238 pages/min), scraped 539510 items (at 244 items/min)
2017-11-05 21:40:03 [scrapy.extensions.logstats] INFO: Crawled 614931 pages (at 227 pages/min), scraped 539739 items (at 229 items/min)
2017-11-05 21:41:03 [scrapy.extensions.logstats] INFO: Crawled 615163 pages (at 232 pages/min), scraped 539983 items (at 244 items/min)
2017-11-05 21:42:03 [scrapy.extensions.logstats] INFO: Crawled 615408 pages (at 245 pages/min), scraped 540235 items (at 252 items/min)
2017-11-05 21:43:03 [scrapy.extensions.logstats] INFO: Crawled 615649 pages (at 241 pages/min), scraped 540476 items (at 241 items/min)
2017-11-05 21:44:03 [scrapy.extensions.logstats] INFO: Crawled 615886 pages (at 237 pages/min), scraped 540751 items (at 275 items/min)
2017-11-05 21:45:03 [scrapy.extensions.logstats] INFO: Crawled 616121 pages (at 235 pages/min), scraped 541048 items (at 297 items/min)
2017-11-05 21:46:03 [scrapy.extensions.logstats] INFO: Crawled 616356 pages (at 235 pages/min), scraped 541300 items (at 252 items/min)
2017-11-05 21:47:03 [scrapy.extensions.logstats] INFO: Crawled 616591 pages (at 235 pages/min), scraped 541591 items (at 291 items/min)
2017-11-05 21:48:03 [scrapy.extensions.logstats] INFO: Crawled 616828 pages (at 237 pages/min), scraped 541848 items (at 257 items/min)
2017-11-05 21:49:03 [scrapy.extensions.logstats] INFO: Crawled 617064 pages (at 236 pages/min), scraped 542122 items (at 274 items/min)
2017-11-05 21:50:03 [scrapy.extensions.logstats] INFO: Crawled 617305 pages (at 241 pages/min), scraped 542417 items (at 295 items/min)
2017-11-05 21:51:03 [scrapy.extensions.logstats] INFO: Crawled 617539 pages (at 234 pages/min), scraped 542696 items (at 279 items/min)
2017-11-05 21:52:03 [scrapy.extensions.logstats] INFO: Crawled 617773 pages (at 234 pages/min), scraped 542962 items (at 266 items/min)
2017-11-05 21:53:03 [scrapy.extensions.logstats] INFO: Crawled 618010 pages (at 237 pages/min), scraped 543169 items (at 207 items/min)
2017-11-05 21:54:03 [scrapy.extensions.logstats] INFO: Crawled 618249 pages (at 239 pages/min), scraped 543403 items (at 234 items/min)
2017-11-05 21:55:03 [scrapy.extensions.logstats] INFO: Crawled 618479 pages (at 230 pages/min), scraped 543679 items (at 276 items/min)
2017-11-05 21:56:03 [scrapy.extensions.logstats] INFO: Crawled 618719 pages (at 240 pages/min), scraped 543924 items (at 245 items/min)
2017-11-05 21:57:03 [scrapy.extensions.logstats] INFO: Crawled 618961 pages (at 242 pages/min), scraped 544180 items (at 256 items/min)
2017-11-05 21:58:03 [scrapy.extensions.logstats] INFO: Crawled 619194 pages (at 233 pages/min), scraped 544429 items (at 249 items/min)
2017-11-05 21:59:03 [scrapy.extensions.logstats] INFO: Crawled 619433 pages (at 239 pages/min), scraped 544697 items (at 268 items/min)
2017-11-05 22:00:03 [scrapy.extensions.logstats] INFO: Crawled 619677 pages (at 244 pages/min), scraped 544947 items (at 250 items/min)
2017-11-05 22:01:03 [scrapy.extensions.logstats] INFO: Crawled 619916 pages (at 239 pages/min), scraped 545169 items (at 222 items/min)
2017-11-05 22:02:03 [scrapy.extensions.logstats] INFO: Crawled 620152 pages (at 236 pages/min), scraped 545460 items (at 291 items/min)
2017-11-05 22:03:03 [scrapy.extensions.logstats] INFO: Crawled 620389 pages (at 237 pages/min), scraped 545705 items (at 245 items/min)
2017-11-05 22:04:03 [scrapy.extensions.logstats] INFO: Crawled 620631 pages (at 242 pages/min), scraped 545954 items (at 249 items/min)
2017-11-05 22:05:03 [scrapy.extensions.logstats] INFO: Crawled 620868 pages (at 237 pages/min), scraped 546195 items (at 241 items/min)
2017-11-05 22:06:03 [scrapy.extensions.logstats] INFO: Crawled 621101 pages (at 233 pages/min), scraped 546443 items (at 248 items/min)
2017-11-05 22:07:03 [scrapy.extensions.logstats] INFO: Crawled 621338 pages (at 237 pages/min), scraped 546687 items (at 244 items/min)
2017-11-05 22:08:03 [scrapy.extensions.logstats] INFO: Crawled 621577 pages (at 239 pages/min), scraped 546944 items (at 257 items/min)
2017-11-05 22:09:03 [scrapy.extensions.logstats] INFO: Crawled 621818 pages (at 241 pages/min), scraped 547184 items (at 240 items/min)
2017-11-05 22:10:03 [scrapy.extensions.logstats] INFO: Crawled 622042 pages (at 224 pages/min), scraped 547419 items (at 235 items/min)
2017-11-05 22:11:03 [scrapy.extensions.logstats] INFO: Crawled 622283 pages (at 241 pages/min), scraped 547652 items (at 233 items/min)
2017-11-05 22:12:03 [scrapy.extensions.logstats] INFO: Crawled 622523 pages (at 240 pages/min), scraped 547928 items (at 276 items/min)
2017-11-05 22:13:03 [scrapy.extensions.logstats] INFO: Crawled 622758 pages (at 235 pages/min), scraped 548205 items (at 277 items/min)
2017-11-05 22:14:03 [scrapy.extensions.logstats] INFO: Crawled 622999 pages (at 241 pages/min), scraped 548481 items (at 276 items/min)
2017-11-05 22:15:03 [scrapy.extensions.logstats] INFO: Crawled 623238 pages (at 239 pages/min), scraped 548740 items (at 259 items/min)
2017-11-05 22:16:03 [scrapy.extensions.logstats] INFO: Crawled 623475 pages (at 237 pages/min), scraped 549042 items (at 302 items/min)
2017-11-05 22:17:03 [scrapy.extensions.logstats] INFO: Crawled 623717 pages (at 242 pages/min), scraped 549285 items (at 243 items/min)
2017-11-05 22:18:03 [scrapy.extensions.logstats] INFO: Crawled 623958 pages (at 241 pages/min), scraped 549491 items (at 206 items/min)
2017-11-05 22:19:03 [scrapy.extensions.logstats] INFO: Crawled 624200 pages (at 242 pages/min), scraped 549702 items (at 211 items/min)
2017-11-05 22:20:03 [scrapy.extensions.logstats] INFO: Crawled 624438 pages (at 238 pages/min), scraped 549907 items (at 205 items/min)
2017-11-05 22:21:03 [scrapy.extensions.logstats] INFO: Crawled 624676 pages (at 238 pages/min), scraped 550116 items (at 209 items/min)
2017-11-05 22:22:03 [scrapy.extensions.logstats] INFO: Crawled 624914 pages (at 238 pages/min), scraped 550332 items (at 216 items/min)
2017-11-05 22:23:03 [scrapy.extensions.logstats] INFO: Crawled 625158 pages (at 244 pages/min), scraped 550547 items (at 215 items/min)
2017-11-05 22:24:03 [scrapy.extensions.logstats] INFO: Crawled 625396 pages (at 238 pages/min), scraped 550755 items (at 208 items/min)
2017-11-05 22:25:03 [scrapy.extensions.logstats] INFO: Crawled 625635 pages (at 239 pages/min), scraped 550948 items (at 193 items/min)
2017-11-05 22:26:03 [scrapy.extensions.logstats] INFO: Crawled 625877 pages (at 242 pages/min), scraped 551165 items (at 217 items/min)
2017-11-05 22:27:03 [scrapy.extensions.logstats] INFO: Crawled 626122 pages (at 245 pages/min), scraped 551383 items (at 218 items/min)
2017-11-05 22:28:03 [scrapy.extensions.logstats] INFO: Crawled 626363 pages (at 241 pages/min), scraped 551607 items (at 224 items/min)
2017-11-05 22:29:03 [scrapy.extensions.logstats] INFO: Crawled 626606 pages (at 243 pages/min), scraped 551804 items (at 197 items/min)
2017-11-05 22:30:03 [scrapy.extensions.logstats] INFO: Crawled 626849 pages (at 243 pages/min), scraped 551995 items (at 191 items/min)
2017-11-05 22:31:03 [scrapy.extensions.logstats] INFO: Crawled 627091 pages (at 242 pages/min), scraped 552199 items (at 204 items/min)
2017-11-05 22:32:03 [scrapy.extensions.logstats] INFO: Crawled 627326 pages (at 235 pages/min), scraped 552400 items (at 201 items/min)
2017-11-05 22:33:03 [scrapy.extensions.logstats] INFO: Crawled 627563 pages (at 237 pages/min), scraped 552627 items (at 227 items/min)
2017-11-05 22:34:03 [scrapy.extensions.logstats] INFO: Crawled 627808 pages (at 245 pages/min), scraped 552787 items (at 160 items/min)
2017-11-05 22:35:03 [scrapy.extensions.logstats] INFO: Crawled 628052 pages (at 244 pages/min), scraped 552951 items (at 164 items/min)
2017-11-05 22:36:03 [scrapy.extensions.logstats] INFO: Crawled 628293 pages (at 241 pages/min), scraped 553181 items (at 230 items/min)
2017-11-05 22:37:03 [scrapy.extensions.logstats] INFO: Crawled 628533 pages (at 240 pages/min), scraped 553400 items (at 219 items/min)
2017-11-05 22:38:03 [scrapy.extensions.logstats] INFO: Crawled 628766 pages (at 233 pages/min), scraped 553626 items (at 226 items/min)
2017-11-05 22:39:03 [scrapy.extensions.logstats] INFO: Crawled 629005 pages (at 239 pages/min), scraped 553883 items (at 257 items/min)
2017-11-05 22:40:03 [scrapy.extensions.logstats] INFO: Crawled 629242 pages (at 237 pages/min), scraped 554084 items (at 201 items/min)
2017-11-05 22:41:03 [scrapy.extensions.logstats] INFO: Crawled 629482 pages (at 240 pages/min), scraped 554281 items (at 197 items/min)
2017-11-05 22:42:03 [scrapy.extensions.logstats] INFO: Crawled 629724 pages (at 242 pages/min), scraped 554519 items (at 238 items/min)
2017-11-05 22:43:03 [scrapy.extensions.logstats] INFO: Crawled 629965 pages (at 241 pages/min), scraped 554756 items (at 237 items/min)
2017-11-05 22:44:03 [scrapy.extensions.logstats] INFO: Crawled 630203 pages (at 238 pages/min), scraped 554984 items (at 228 items/min)
2017-11-05 22:45:03 [scrapy.extensions.logstats] INFO: Crawled 630440 pages (at 237 pages/min), scraped 555220 items (at 236 items/min)
2017-11-05 22:46:03 [scrapy.extensions.logstats] INFO: Crawled 630680 pages (at 240 pages/min), scraped 555506 items (at 286 items/min)
2017-11-05 22:47:03 [scrapy.extensions.logstats] INFO: Crawled 630919 pages (at 239 pages/min), scraped 555758 items (at 252 items/min)
2017-11-05 22:48:03 [scrapy.extensions.logstats] INFO: Crawled 631149 pages (at 230 pages/min), scraped 556004 items (at 246 items/min)
2017-11-05 22:49:03 [scrapy.extensions.logstats] INFO: Crawled 631387 pages (at 238 pages/min), scraped 556300 items (at 296 items/min)
2017-11-05 22:50:03 [scrapy.extensions.logstats] INFO: Crawled 631616 pages (at 229 pages/min), scraped 556633 items (at 333 items/min)
2017-11-05 22:51:03 [scrapy.extensions.logstats] INFO: Crawled 631850 pages (at 234 pages/min), scraped 556907 items (at 274 items/min)
2017-11-05 22:52:03 [scrapy.extensions.logstats] INFO: Crawled 632080 pages (at 230 pages/min), scraped 557117 items (at 210 items/min)
2017-11-05 22:53:03 [scrapy.extensions.logstats] INFO: Crawled 632317 pages (at 237 pages/min), scraped 557339 items (at 222 items/min)
2017-11-05 22:54:03 [scrapy.extensions.logstats] INFO: Crawled 632559 pages (at 242 pages/min), scraped 557572 items (at 233 items/min)
2017-11-05 22:55:03 [scrapy.extensions.logstats] INFO: Crawled 632791 pages (at 232 pages/min), scraped 557741 items (at 169 items/min)
2017-11-05 22:56:03 [scrapy.extensions.logstats] INFO: Crawled 633019 pages (at 228 pages/min), scraped 557921 items (at 180 items/min)
2017-11-05 22:57:03 [scrapy.extensions.logstats] INFO: Crawled 633259 pages (at 240 pages/min), scraped 558116 items (at 195 items/min)
2017-11-05 22:58:03 [scrapy.extensions.logstats] INFO: Crawled 633501 pages (at 242 pages/min), scraped 558309 items (at 193 items/min)
2017-11-05 22:59:03 [scrapy.extensions.logstats] INFO: Crawled 633742 pages (at 241 pages/min), scraped 558510 items (at 201 items/min)
2017-11-05 23:00:03 [scrapy.extensions.logstats] INFO: Crawled 633982 pages (at 240 pages/min), scraped 558704 items (at 194 items/min)
2017-11-05 23:01:03 [scrapy.extensions.logstats] INFO: Crawled 634221 pages (at 239 pages/min), scraped 558914 items (at 210 items/min)
2017-11-05 23:02:03 [scrapy.extensions.logstats] INFO: Crawled 634463 pages (at 242 pages/min), scraped 559122 items (at 208 items/min)
2017-11-05 23:03:03 [scrapy.extensions.logstats] INFO: Crawled 634700 pages (at 237 pages/min), scraped 559344 items (at 222 items/min)
2017-11-05 23:04:03 [scrapy.extensions.logstats] INFO: Crawled 634939 pages (at 239 pages/min), scraped 559548 items (at 204 items/min)
2017-11-05 23:05:03 [scrapy.extensions.logstats] INFO: Crawled 635180 pages (at 241 pages/min), scraped 559752 items (at 204 items/min)
2017-11-05 23:06:03 [scrapy.extensions.logstats] INFO: Crawled 635423 pages (at 243 pages/min), scraped 559947 items (at 195 items/min)
2017-11-05 23:07:03 [scrapy.extensions.logstats] INFO: Crawled 635662 pages (at 239 pages/min), scraped 560143 items (at 196 items/min)
2017-11-05 23:08:03 [scrapy.extensions.logstats] INFO: Crawled 635902 pages (at 240 pages/min), scraped 560340 items (at 197 items/min)
2017-11-05 23:09:03 [scrapy.extensions.logstats] INFO: Crawled 636136 pages (at 234 pages/min), scraped 560535 items (at 195 items/min)
2017-11-05 23:10:03 [scrapy.extensions.logstats] INFO: Crawled 636375 pages (at 239 pages/min), scraped 560747 items (at 212 items/min)
2017-11-05 23:11:03 [scrapy.extensions.logstats] INFO: Crawled 636616 pages (at 241 pages/min), scraped 560962 items (at 215 items/min)
2017-11-05 23:12:03 [scrapy.extensions.logstats] INFO: Crawled 636858 pages (at 242 pages/min), scraped 561165 items (at 203 items/min)
2017-11-05 23:13:03 [scrapy.extensions.logstats] INFO: Crawled 637101 pages (at 243 pages/min), scraped 561353 items (at 188 items/min)
2017-11-05 23:14:03 [scrapy.extensions.logstats] INFO: Crawled 637337 pages (at 236 pages/min), scraped 561553 items (at 200 items/min)
2017-11-05 23:15:03 [scrapy.extensions.logstats] INFO: Crawled 637580 pages (at 243 pages/min), scraped 561745 items (at 192 items/min)
2017-11-05 23:16:03 [scrapy.extensions.logstats] INFO: Crawled 637826 pages (at 246 pages/min), scraped 561947 items (at 202 items/min)
2017-11-05 23:17:03 [scrapy.extensions.logstats] INFO: Crawled 638066 pages (at 240 pages/min), scraped 562144 items (at 197 items/min)
2017-11-05 23:18:03 [scrapy.extensions.logstats] INFO: Crawled 638303 pages (at 237 pages/min), scraped 562349 items (at 205 items/min)
2017-11-05 23:19:03 [scrapy.extensions.logstats] INFO: Crawled 638542 pages (at 239 pages/min), scraped 562538 items (at 189 items/min)
2017-11-05 23:20:03 [scrapy.extensions.logstats] INFO: Crawled 638785 pages (at 243 pages/min), scraped 562753 items (at 215 items/min)
2017-11-05 23:21:03 [scrapy.extensions.logstats] INFO: Crawled 639023 pages (at 238 pages/min), scraped 562948 items (at 195 items/min)
2017-11-05 23:22:03 [scrapy.extensions.logstats] INFO: Crawled 639262 pages (at 239 pages/min), scraped 563154 items (at 206 items/min)
2017-11-05 23:23:03 [scrapy.extensions.logstats] INFO: Crawled 639496 pages (at 234 pages/min), scraped 563361 items (at 207 items/min)
2017-11-05 23:24:03 [scrapy.extensions.logstats] INFO: Crawled 639737 pages (at 241 pages/min), scraped 563556 items (at 195 items/min)
2017-11-05 23:25:03 [scrapy.extensions.logstats] INFO: Crawled 639976 pages (at 239 pages/min), scraped 563756 items (at 200 items/min)
2017-11-05 23:26:03 [scrapy.extensions.logstats] INFO: Crawled 640213 pages (at 237 pages/min), scraped 563958 items (at 202 items/min)
2017-11-05 23:27:03 [scrapy.extensions.logstats] INFO: Crawled 640453 pages (at 240 pages/min), scraped 564150 items (at 192 items/min)
2017-11-05 23:28:03 [scrapy.extensions.logstats] INFO: Crawled 640694 pages (at 241 pages/min), scraped 564341 items (at 191 items/min)
2017-11-05 23:29:03 [scrapy.extensions.logstats] INFO: Crawled 640935 pages (at 241 pages/min), scraped 564538 items (at 197 items/min)
2017-11-05 23:30:03 [scrapy.extensions.logstats] INFO: Crawled 641178 pages (at 243 pages/min), scraped 564729 items (at 191 items/min)
2017-11-05 23:31:03 [scrapy.extensions.logstats] INFO: Crawled 641420 pages (at 242 pages/min), scraped 564931 items (at 202 items/min)
2017-11-05 23:32:03 [scrapy.extensions.logstats] INFO: Crawled 641662 pages (at 242 pages/min), scraped 565131 items (at 200 items/min)
2017-11-05 23:33:03 [scrapy.extensions.logstats] INFO: Crawled 641899 pages (at 237 pages/min), scraped 565337 items (at 206 items/min)
2017-11-05 23:34:03 [scrapy.extensions.logstats] INFO: Crawled 642142 pages (at 243 pages/min), scraped 565527 items (at 190 items/min)
2017-11-05 23:35:03 [scrapy.extensions.logstats] INFO: Crawled 642387 pages (at 245 pages/min), scraped 565727 items (at 200 items/min)
2017-11-05 23:36:03 [scrapy.extensions.logstats] INFO: Crawled 642624 pages (at 237 pages/min), scraped 565918 items (at 191 items/min)
2017-11-05 23:37:03 [scrapy.extensions.logstats] INFO: Crawled 642862 pages (at 238 pages/min), scraped 566122 items (at 204 items/min)
2017-11-05 23:38:03 [scrapy.extensions.logstats] INFO: Crawled 643103 pages (at 241 pages/min), scraped 566324 items (at 202 items/min)
2017-11-05 23:39:03 [scrapy.extensions.logstats] INFO: Crawled 643342 pages (at 239 pages/min), scraped 566523 items (at 199 items/min)
2017-11-05 23:40:03 [scrapy.extensions.logstats] INFO: Crawled 643582 pages (at 240 pages/min), scraped 566722 items (at 199 items/min)
2017-11-05 23:41:03 [scrapy.extensions.logstats] INFO: Crawled 643818 pages (at 236 pages/min), scraped 566927 items (at 205 items/min)
2017-11-05 23:42:03 [scrapy.extensions.logstats] INFO: Crawled 644055 pages (at 237 pages/min), scraped 567121 items (at 194 items/min)
2017-11-05 23:43:03 [scrapy.extensions.logstats] INFO: Crawled 644293 pages (at 238 pages/min), scraped 567331 items (at 210 items/min)
2017-11-05 23:44:03 [scrapy.extensions.logstats] INFO: Crawled 644531 pages (at 238 pages/min), scraped 567520 items (at 189 items/min)
2017-11-05 23:45:03 [scrapy.extensions.logstats] INFO: Crawled 644767 pages (at 236 pages/min), scraped 567718 items (at 198 items/min)
2017-11-05 23:46:03 [scrapy.extensions.logstats] INFO: Crawled 645012 pages (at 245 pages/min), scraped 567932 items (at 214 items/min)
2017-11-05 23:47:03 [scrapy.extensions.logstats] INFO: Crawled 645251 pages (at 239 pages/min), scraped 568128 items (at 196 items/min)
2017-11-05 23:48:03 [scrapy.extensions.logstats] INFO: Crawled 645489 pages (at 238 pages/min), scraped 568323 items (at 195 items/min)
2017-11-05 23:49:03 [scrapy.extensions.logstats] INFO: Crawled 645737 pages (at 248 pages/min), scraped 568529 items (at 206 items/min)
2017-11-05 23:50:03 [scrapy.extensions.logstats] INFO: Crawled 645979 pages (at 242 pages/min), scraped 568722 items (at 193 items/min)
2017-11-05 23:51:03 [scrapy.extensions.logstats] INFO: Crawled 646227 pages (at 248 pages/min), scraped 568935 items (at 213 items/min)
2017-11-05 23:52:03 [scrapy.extensions.logstats] INFO: Crawled 646475 pages (at 248 pages/min), scraped 569129 items (at 194 items/min)
2017-11-05 23:53:03 [scrapy.extensions.logstats] INFO: Crawled 646719 pages (at 244 pages/min), scraped 569327 items (at 198 items/min)
2017-11-05 23:54:03 [scrapy.extensions.logstats] INFO: Crawled 646963 pages (at 244 pages/min), scraped 569526 items (at 199 items/min)
2017-11-05 23:55:03 [scrapy.extensions.logstats] INFO: Crawled 647209 pages (at 246 pages/min), scraped 569726 items (at 200 items/min)
2017-11-05 23:56:03 [scrapy.extensions.logstats] INFO: Crawled 647456 pages (at 247 pages/min), scraped 569930 items (at 204 items/min)
2017-11-05 23:57:03 [scrapy.extensions.logstats] INFO: Crawled 647704 pages (at 248 pages/min), scraped 570146 items (at 216 items/min)
2017-11-05 23:58:03 [scrapy.extensions.logstats] INFO: Crawled 647949 pages (at 245 pages/min), scraped 570345 items (at 199 items/min)
2017-11-05 23:59:03 [scrapy.extensions.logstats] INFO: Crawled 648191 pages (at 242 pages/min), scraped 570542 items (at 197 items/min)
2017-11-06 00:00:03 [scrapy.extensions.logstats] INFO: Crawled 648437 pages (at 246 pages/min), scraped 570744 items (at 202 items/min)
2017-11-06 00:01:03 [scrapy.extensions.logstats] INFO: Crawled 648682 pages (at 245 pages/min), scraped 570957 items (at 213 items/min)
2017-11-06 00:02:03 [scrapy.extensions.logstats] INFO: Crawled 648927 pages (at 245 pages/min), scraped 571157 items (at 200 items/min)
2017-11-06 00:03:03 [scrapy.extensions.logstats] INFO: Crawled 649172 pages (at 245 pages/min), scraped 571357 items (at 200 items/min)
2017-11-06 00:04:03 [scrapy.extensions.logstats] INFO: Crawled 649417 pages (at 245 pages/min), scraped 571574 items (at 217 items/min)
2017-11-06 00:05:03 [scrapy.extensions.logstats] INFO: Crawled 649659 pages (at 242 pages/min), scraped 571778 items (at 204 items/min)
2017-11-06 00:06:03 [scrapy.extensions.logstats] INFO: Crawled 649901 pages (at 242 pages/min), scraped 571973 items (at 195 items/min)
2017-11-06 00:07:03 [scrapy.extensions.logstats] INFO: Crawled 650149 pages (at 248 pages/min), scraped 572169 items (at 196 items/min)
2017-11-06 00:08:03 [scrapy.extensions.logstats] INFO: Crawled 650393 pages (at 244 pages/min), scraped 572360 items (at 191 items/min)
2017-11-06 00:09:03 [scrapy.extensions.logstats] INFO: Crawled 650637 pages (at 244 pages/min), scraped 572578 items (at 218 items/min)
2017-11-06 00:10:03 [scrapy.extensions.logstats] INFO: Crawled 650882 pages (at 245 pages/min), scraped 572781 items (at 203 items/min)
2017-11-06 00:11:03 [scrapy.extensions.logstats] INFO: Crawled 651123 pages (at 241 pages/min), scraped 572972 items (at 191 items/min)
2017-11-06 00:12:03 [scrapy.extensions.logstats] INFO: Crawled 651369 pages (at 246 pages/min), scraped 573176 items (at 204 items/min)
2017-11-06 00:13:03 [scrapy.extensions.logstats] INFO: Crawled 651621 pages (at 252 pages/min), scraped 573388 items (at 212 items/min)
2017-11-06 00:14:03 [scrapy.extensions.logstats] INFO: Crawled 651860 pages (at 239 pages/min), scraped 573608 items (at 220 items/min)
2017-11-06 00:15:03 [scrapy.extensions.logstats] INFO: Crawled 652106 pages (at 246 pages/min), scraped 573814 items (at 206 items/min)
2017-11-06 00:16:03 [scrapy.extensions.logstats] INFO: Crawled 652354 pages (at 248 pages/min), scraped 574025 items (at 211 items/min)
2017-11-06 00:17:03 [scrapy.extensions.logstats] INFO: Crawled 652600 pages (at 246 pages/min), scraped 574208 items (at 183 items/min)
2017-11-06 00:18:03 [scrapy.extensions.logstats] INFO: Crawled 652840 pages (at 240 pages/min), scraped 574382 items (at 174 items/min)
2017-11-06 00:19:03 [scrapy.extensions.logstats] INFO: Crawled 653082 pages (at 242 pages/min), scraped 574562 items (at 180 items/min)
2017-11-06 00:20:03 [scrapy.extensions.logstats] INFO: Crawled 653331 pages (at 249 pages/min), scraped 574757 items (at 195 items/min)
2017-11-06 00:21:03 [scrapy.extensions.logstats] INFO: Crawled 653580 pages (at 249 pages/min), scraped 574946 items (at 189 items/min)
2017-11-06 00:22:03 [scrapy.extensions.logstats] INFO: Crawled 653827 pages (at 247 pages/min), scraped 575122 items (at 176 items/min)
2017-11-06 00:23:03 [scrapy.extensions.logstats] INFO: Crawled 654074 pages (at 247 pages/min), scraped 575302 items (at 180 items/min)
2017-11-06 00:24:03 [scrapy.extensions.logstats] INFO: Crawled 654315 pages (at 241 pages/min), scraped 575483 items (at 181 items/min)
2017-11-06 00:25:03 [scrapy.extensions.logstats] INFO: Crawled 654560 pages (at 245 pages/min), scraped 575654 items (at 171 items/min)
2017-11-06 00:26:03 [scrapy.extensions.logstats] INFO: Crawled 654807 pages (at 247 pages/min), scraped 575843 items (at 189 items/min)
2017-11-06 00:27:03 [scrapy.extensions.logstats] INFO: Crawled 655051 pages (at 244 pages/min), scraped 576021 items (at 178 items/min)
2017-11-06 00:28:03 [scrapy.extensions.logstats] INFO: Crawled 655295 pages (at 244 pages/min), scraped 576195 items (at 174 items/min)
2017-11-06 00:29:03 [scrapy.extensions.logstats] INFO: Crawled 655539 pages (at 244 pages/min), scraped 576389 items (at 194 items/min)
2017-11-06 00:30:03 [scrapy.extensions.logstats] INFO: Crawled 655782 pages (at 243 pages/min), scraped 576589 items (at 200 items/min)
2017-11-06 00:31:03 [scrapy.extensions.logstats] INFO: Crawled 656028 pages (at 246 pages/min), scraped 576779 items (at 190 items/min)
2017-11-06 00:32:03 [scrapy.extensions.logstats] INFO: Crawled 656269 pages (at 241 pages/min), scraped 576955 items (at 176 items/min)
2017-11-06 00:33:03 [scrapy.extensions.logstats] INFO: Crawled 656512 pages (at 243 pages/min), scraped 577140 items (at 185 items/min)
2017-11-06 00:34:03 [scrapy.extensions.logstats] INFO: Crawled 656759 pages (at 247 pages/min), scraped 577332 items (at 192 items/min)
2017-11-06 00:35:03 [scrapy.extensions.logstats] INFO: Crawled 657002 pages (at 243 pages/min), scraped 577517 items (at 185 items/min)
2017-11-06 00:36:03 [scrapy.extensions.logstats] INFO: Crawled 657249 pages (at 247 pages/min), scraped 577718 items (at 201 items/min)
2017-11-06 00:37:03 [scrapy.extensions.logstats] INFO: Crawled 657492 pages (at 243 pages/min), scraped 577912 items (at 194 items/min)
2017-11-06 00:38:03 [scrapy.extensions.logstats] INFO: Crawled 657734 pages (at 242 pages/min), scraped 578118 items (at 206 items/min)
2017-11-06 00:39:03 [scrapy.extensions.logstats] INFO: Crawled 657979 pages (at 245 pages/min), scraped 578316 items (at 198 items/min)
2017-11-06 00:40:03 [scrapy.extensions.logstats] INFO: Crawled 658222 pages (at 243 pages/min), scraped 578503 items (at 187 items/min)
2017-11-06 00:41:03 [scrapy.extensions.logstats] INFO: Crawled 658467 pages (at 245 pages/min), scraped 578699 items (at 196 items/min)
2017-11-06 00:42:02 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39901122&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"陈琴","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"国泰君安证券股份有限公司","AOI_ID":"1999088","ADI_ID":"44541","ADI_NAME":"财富管理部","PTI_NAME":"证券投资咨询业务(投资顾问)","CER_NUM":"S0880611070027","OBTAIN_DATE":"2011-07-11","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 00:42:03 [scrapy.extensions.logstats] INFO: Crawled 658715 pages (at 248 pages/min), scraped 578901 items (at 202 items/min)
2017-11-06 00:43:03 [scrapy.extensions.logstats] INFO: Crawled 658965 pages (at 250 pages/min), scraped 579106 items (at 205 items/min)
2017-11-06 00:44:03 [scrapy.extensions.logstats] INFO: Crawled 659213 pages (at 248 pages/min), scraped 579308 items (at 202 items/min)
2017-11-06 00:45:03 [scrapy.extensions.logstats] INFO: Crawled 659459 pages (at 246 pages/min), scraped 579500 items (at 192 items/min)
2017-11-06 00:46:03 [scrapy.extensions.logstats] INFO: Crawled 659704 pages (at 245 pages/min), scraped 579689 items (at 189 items/min)
2017-11-06 00:47:04 [scrapy.extensions.logstats] INFO: Crawled 659946 pages (at 242 pages/min), scraped 579861 items (at 172 items/min)
2017-11-06 00:48:03 [scrapy.extensions.logstats] INFO: Crawled 660193 pages (at 247 pages/min), scraped 580048 items (at 187 items/min)
2017-11-06 00:49:03 [scrapy.extensions.logstats] INFO: Crawled 660442 pages (at 249 pages/min), scraped 580230 items (at 182 items/min)
2017-11-06 00:50:03 [scrapy.extensions.logstats] INFO: Crawled 660685 pages (at 243 pages/min), scraped 580413 items (at 183 items/min)
2017-11-06 00:51:03 [scrapy.extensions.logstats] INFO: Crawled 660933 pages (at 248 pages/min), scraped 580595 items (at 182 items/min)
2017-11-06 00:52:03 [scrapy.extensions.logstats] INFO: Crawled 661175 pages (at 242 pages/min), scraped 580782 items (at 187 items/min)
2017-11-06 00:53:03 [scrapy.extensions.logstats] INFO: Crawled 661421 pages (at 246 pages/min), scraped 580966 items (at 184 items/min)
2017-11-06 00:53:33 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29921100&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"盛勇","SCO_NAME":"男","ECO_NAME":"硕士研究生","AOI_NAME":"国泰君安证券股份有限公司","AOI_ID":"1999088","ADI_ID":"55097","ADI_NAME":"固定收益证券部","PTI_NAME":"一般证券业务","CER_NUM":"S0880108113807","OBTAIN_DATE":"2008-11-20","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 00:54:03 [scrapy.extensions.logstats] INFO: Crawled 661663 pages (at 242 pages/min), scraped 581159 items (at 193 items/min)
2017-11-06 00:55:03 [scrapy.extensions.logstats] INFO: Crawled 661907 pages (at 244 pages/min), scraped 581350 items (at 191 items/min)
2017-11-06 00:56:03 [scrapy.extensions.logstats] INFO: Crawled 662148 pages (at 241 pages/min), scraped 581539 items (at 189 items/min)
2017-11-06 00:57:03 [scrapy.extensions.logstats] INFO: Crawled 662394 pages (at 246 pages/min), scraped 581747 items (at 208 items/min)
2017-11-06 00:58:03 [scrapy.extensions.logstats] INFO: Crawled 662642 pages (at 248 pages/min), scraped 581955 items (at 208 items/min)
2017-11-06 00:59:03 [scrapy.extensions.logstats] INFO: Crawled 662886 pages (at 244 pages/min), scraped 582145 items (at 190 items/min)
2017-11-06 01:00:03 [scrapy.extensions.logstats] INFO: Crawled 663123 pages (at 237 pages/min), scraped 582349 items (at 204 items/min)
2017-11-06 01:01:03 [scrapy.extensions.logstats] INFO: Crawled 663375 pages (at 252 pages/min), scraped 582539 items (at 190 items/min)
2017-11-06 01:02:03 [scrapy.extensions.logstats] INFO: Crawled 663626 pages (at 251 pages/min), scraped 582759 items (at 220 items/min)
2017-11-06 01:02:04 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39909833&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"胡双艳","SCO_NAME":"女","ECO_NAME":"大专","AOI_NAME":"国信证券股份有限公司","AOI_ID":"1999098","ADI_ID":"5934","ADI_NAME":"上海北京东路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0980109118508","OBTAIN_DATE":"2009-11-21","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 01:03:03 [scrapy.extensions.logstats] INFO: Crawled 663869 pages (at 243 pages/min), scraped 582962 items (at 203 items/min)
2017-11-06 01:04:03 [scrapy.extensions.logstats] INFO: Crawled 664120 pages (at 251 pages/min), scraped 583169 items (at 207 items/min)
2017-11-06 01:05:03 [scrapy.extensions.logstats] INFO: Crawled 664364 pages (at 244 pages/min), scraped 583359 items (at 190 items/min)
2017-11-06 01:06:02 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39911734&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"傅文荣","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"国信证券股份有限公司","AOI_ID":"1999098","ADI_ID":"22538","ADI_NAME":"石家庄广安大街证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0980109128931","OBTAIN_DATE":"2009-12-28","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 01:06:03 [scrapy.extensions.logstats] INFO: Crawled 664611 pages (at 247 pages/min), scraped 583562 items (at 203 items/min)
2017-11-06 01:06:49 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39907023&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"靳雪飞","SCO_NAME":"女","ECO_NAME":"硕士研究生","AOI_NAME":"国信证券股份有限公司","AOI_ID":"1999098","ADI_ID":"46361","ADI_NAME":"武汉中北路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0980108123495","OBTAIN_DATE":"2008-12-25","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 01:07:03 [scrapy.extensions.logstats] INFO: Crawled 664853 pages (at 242 pages/min), scraped 583764 items (at 202 items/min)
2017-11-06 01:08:03 [scrapy.extensions.logstats] INFO: Crawled 665098 pages (at 245 pages/min), scraped 583958 items (at 194 items/min)
2017-11-06 01:09:03 [scrapy.extensions.logstats] INFO: Crawled 665346 pages (at 248 pages/min), scraped 584170 items (at 212 items/min)
2017-11-06 01:10:03 [scrapy.extensions.logstats] INFO: Crawled 665591 pages (at 245 pages/min), scraped 584366 items (at 196 items/min)
2017-11-06 01:11:03 [scrapy.extensions.logstats] INFO: Crawled 665837 pages (at 246 pages/min), scraped 584558 items (at 192 items/min)
2017-11-06 01:12:03 [scrapy.extensions.logstats] INFO: Crawled 666084 pages (at 247 pages/min), scraped 584749 items (at 191 items/min)
2017-11-06 01:13:03 [scrapy.extensions.logstats] INFO: Crawled 666331 pages (at 247 pages/min), scraped 584974 items (at 225 items/min)
2017-11-06 01:14:03 [scrapy.extensions.logstats] INFO: Crawled 666576 pages (at 245 pages/min), scraped 585169 items (at 195 items/min)
2017-11-06 01:15:03 [scrapy.extensions.logstats] INFO: Crawled 666821 pages (at 245 pages/min), scraped 585360 items (at 191 items/min)
2017-11-06 01:16:03 [scrapy.extensions.logstats] INFO: Crawled 667069 pages (at 248 pages/min), scraped 585561 items (at 201 items/min)
2017-11-06 01:17:03 [scrapy.extensions.logstats] INFO: Crawled 667314 pages (at 245 pages/min), scraped 585775 items (at 214 items/min)
2017-11-06 01:18:03 [scrapy.extensions.logstats] INFO: Crawled 667560 pages (at 246 pages/min), scraped 585970 items (at 195 items/min)
2017-11-06 01:19:03 [scrapy.extensions.logstats] INFO: Crawled 667805 pages (at 245 pages/min), scraped 586171 items (at 201 items/min)
2017-11-06 01:20:03 [scrapy.extensions.logstats] INFO: Crawled 668046 pages (at 241 pages/min), scraped 586378 items (at 207 items/min)
2017-11-06 01:21:03 [scrapy.extensions.logstats] INFO: Crawled 668290 pages (at 244 pages/min), scraped 586584 items (at 206 items/min)
2017-11-06 01:22:03 [scrapy.extensions.logstats] INFO: Crawled 668537 pages (at 247 pages/min), scraped 586773 items (at 189 items/min)
2017-11-06 01:23:03 [scrapy.extensions.logstats] INFO: Crawled 668784 pages (at 247 pages/min), scraped 586979 items (at 206 items/min)
2017-11-06 01:24:03 [scrapy.extensions.logstats] INFO: Crawled 669030 pages (at 246 pages/min), scraped 587168 items (at 189 items/min)
2017-11-06 01:25:03 [scrapy.extensions.logstats] INFO: Crawled 669277 pages (at 247 pages/min), scraped 587365 items (at 197 items/min)
2017-11-06 01:26:03 [scrapy.extensions.logstats] INFO: Crawled 669519 pages (at 242 pages/min), scraped 587539 items (at 174 items/min)
2017-11-06 01:27:03 [scrapy.extensions.logstats] INFO: Crawled 669761 pages (at 242 pages/min), scraped 587746 items (at 207 items/min)
2017-11-06 01:28:03 [scrapy.extensions.logstats] INFO: Crawled 670007 pages (at 246 pages/min), scraped 587937 items (at 191 items/min)
2017-11-06 01:29:03 [scrapy.extensions.logstats] INFO: Crawled 670250 pages (at 243 pages/min), scraped 588139 items (at 202 items/min)
2017-11-06 01:30:03 [scrapy.extensions.logstats] INFO: Crawled 670496 pages (at 246 pages/min), scraped 588326 items (at 187 items/min)
2017-11-06 01:31:03 [scrapy.extensions.logstats] INFO: Crawled 670746 pages (at 250 pages/min), scraped 588519 items (at 193 items/min)
2017-11-06 01:32:03 [scrapy.extensions.logstats] INFO: Crawled 670993 pages (at 247 pages/min), scraped 588714 items (at 195 items/min)
2017-11-06 01:33:03 [scrapy.extensions.logstats] INFO: Crawled 671236 pages (at 243 pages/min), scraped 588890 items (at 176 items/min)
2017-11-06 01:34:03 [scrapy.extensions.logstats] INFO: Crawled 671480 pages (at 244 pages/min), scraped 589085 items (at 195 items/min)
2017-11-06 01:35:03 [scrapy.extensions.logstats] INFO: Crawled 671728 pages (at 248 pages/min), scraped 589273 items (at 188 items/min)
2017-11-06 01:36:03 [scrapy.extensions.logstats] INFO: Crawled 671972 pages (at 244 pages/min), scraped 589476 items (at 203 items/min)
2017-11-06 01:37:03 [scrapy.extensions.logstats] INFO: Crawled 672219 pages (at 247 pages/min), scraped 589665 items (at 189 items/min)
2017-11-06 01:38:03 [scrapy.extensions.logstats] INFO: Crawled 672465 pages (at 246 pages/min), scraped 589879 items (at 214 items/min)
2017-11-06 01:39:03 [scrapy.extensions.logstats] INFO: Crawled 672712 pages (at 247 pages/min), scraped 590084 items (at 205 items/min)
2017-11-06 01:40:03 [scrapy.extensions.logstats] INFO: Crawled 672963 pages (at 251 pages/min), scraped 590355 items (at 271 items/min)
2017-11-06 01:41:03 [scrapy.extensions.logstats] INFO: Crawled 673213 pages (at 250 pages/min), scraped 590586 items (at 231 items/min)
2017-11-06 01:42:03 [scrapy.extensions.logstats] INFO: Crawled 673455 pages (at 242 pages/min), scraped 590811 items (at 225 items/min)
2017-11-06 01:43:03 [scrapy.extensions.logstats] INFO: Crawled 673698 pages (at 243 pages/min), scraped 591035 items (at 224 items/min)
2017-11-06 01:44:03 [scrapy.extensions.logstats] INFO: Crawled 673941 pages (at 243 pages/min), scraped 591256 items (at 221 items/min)
2017-11-06 01:45:03 [scrapy.extensions.logstats] INFO: Crawled 674189 pages (at 248 pages/min), scraped 591476 items (at 220 items/min)
2017-11-06 01:46:03 [scrapy.extensions.logstats] INFO: Crawled 674430 pages (at 241 pages/min), scraped 591691 items (at 215 items/min)
2017-11-06 01:47:03 [scrapy.extensions.logstats] INFO: Crawled 674674 pages (at 244 pages/min), scraped 591916 items (at 225 items/min)
2017-11-06 01:48:03 [scrapy.extensions.logstats] INFO: Crawled 674918 pages (at 244 pages/min), scraped 592129 items (at 213 items/min)
2017-11-06 01:49:03 [scrapy.extensions.logstats] INFO: Crawled 675161 pages (at 243 pages/min), scraped 592330 items (at 201 items/min)
2017-11-06 01:50:03 [scrapy.extensions.logstats] INFO: Crawled 675401 pages (at 240 pages/min), scraped 592539 items (at 209 items/min)
2017-11-06 01:51:03 [scrapy.extensions.logstats] INFO: Crawled 675642 pages (at 241 pages/min), scraped 592737 items (at 198 items/min)
2017-11-06 01:52:03 [scrapy.extensions.logstats] INFO: Crawled 675891 pages (at 249 pages/min), scraped 592936 items (at 199 items/min)
2017-11-06 01:53:03 [scrapy.extensions.logstats] INFO: Crawled 676137 pages (at 246 pages/min), scraped 593145 items (at 209 items/min)
2017-11-06 01:54:03 [scrapy.extensions.logstats] INFO: Crawled 676377 pages (at 240 pages/min), scraped 593333 items (at 188 items/min)
2017-11-06 01:55:03 [scrapy.extensions.logstats] INFO: Crawled 676620 pages (at 243 pages/min), scraped 593533 items (at 200 items/min)
2017-11-06 01:56:03 [scrapy.extensions.logstats] INFO: Crawled 676861 pages (at 241 pages/min), scraped 593724 items (at 191 items/min)
2017-11-06 01:57:03 [scrapy.extensions.logstats] INFO: Crawled 677105 pages (at 244 pages/min), scraped 593917 items (at 193 items/min)
2017-11-06 01:58:03 [scrapy.extensions.logstats] INFO: Crawled 677350 pages (at 245 pages/min), scraped 594124 items (at 207 items/min)
2017-11-06 01:59:03 [scrapy.extensions.logstats] INFO: Crawled 677591 pages (at 241 pages/min), scraped 594312 items (at 188 items/min)
2017-11-06 02:00:03 [scrapy.extensions.logstats] INFO: Crawled 677835 pages (at 244 pages/min), scraped 594487 items (at 175 items/min)
2017-11-06 02:01:03 [scrapy.extensions.logstats] INFO: Crawled 678078 pages (at 243 pages/min), scraped 594684 items (at 197 items/min)
2017-11-06 02:02:03 [scrapy.extensions.logstats] INFO: Crawled 678320 pages (at 242 pages/min), scraped 594883 items (at 199 items/min)
2017-11-06 02:03:03 [scrapy.extensions.logstats] INFO: Crawled 678570 pages (at 250 pages/min), scraped 595082 items (at 199 items/min)
2017-11-06 02:04:03 [scrapy.extensions.logstats] INFO: Crawled 678815 pages (at 245 pages/min), scraped 595279 items (at 197 items/min)
2017-11-06 02:05:03 [scrapy.extensions.logstats] INFO: Crawled 679061 pages (at 246 pages/min), scraped 595489 items (at 210 items/min)
2017-11-06 02:06:03 [scrapy.extensions.logstats] INFO: Crawled 679306 pages (at 245 pages/min), scraped 595700 items (at 211 items/min)
2017-11-06 02:07:03 [scrapy.extensions.logstats] INFO: Crawled 679552 pages (at 246 pages/min), scraped 595896 items (at 196 items/min)
2017-11-06 02:08:03 [scrapy.extensions.logstats] INFO: Crawled 679796 pages (at 244 pages/min), scraped 596106 items (at 210 items/min)
2017-11-06 02:09:03 [scrapy.extensions.logstats] INFO: Crawled 680038 pages (at 242 pages/min), scraped 596323 items (at 217 items/min)
2017-11-06 02:10:03 [scrapy.extensions.logstats] INFO: Crawled 680283 pages (at 245 pages/min), scraped 596525 items (at 202 items/min)
2017-11-06 02:11:03 [scrapy.extensions.logstats] INFO: Crawled 680527 pages (at 244 pages/min), scraped 596730 items (at 205 items/min)
2017-11-06 02:12:03 [scrapy.extensions.logstats] INFO: Crawled 680772 pages (at 245 pages/min), scraped 596945 items (at 215 items/min)
2017-11-06 02:13:03 [scrapy.extensions.logstats] INFO: Crawled 681013 pages (at 241 pages/min), scraped 597150 items (at 205 items/min)
2017-11-06 02:14:03 [scrapy.extensions.logstats] INFO: Crawled 681259 pages (at 246 pages/min), scraped 597357 items (at 207 items/min)
2017-11-06 02:15:03 [scrapy.extensions.logstats] INFO: Crawled 681501 pages (at 242 pages/min), scraped 597559 items (at 202 items/min)
2017-11-06 02:16:03 [scrapy.extensions.logstats] INFO: Crawled 681744 pages (at 243 pages/min), scraped 597769 items (at 210 items/min)
2017-11-06 02:17:03 [scrapy.extensions.logstats] INFO: Crawled 681991 pages (at 247 pages/min), scraped 597989 items (at 220 items/min)
2017-11-06 02:18:03 [scrapy.extensions.logstats] INFO: Crawled 682240 pages (at 249 pages/min), scraped 598208 items (at 219 items/min)
2017-11-06 02:19:03 [scrapy.extensions.logstats] INFO: Crawled 682485 pages (at 245 pages/min), scraped 598460 items (at 252 items/min)
2017-11-06 02:20:03 [scrapy.extensions.logstats] INFO: Crawled 682729 pages (at 244 pages/min), scraped 598693 items (at 233 items/min)
2017-11-06 02:21:03 [scrapy.extensions.logstats] INFO: Crawled 682972 pages (at 243 pages/min), scraped 598908 items (at 215 items/min)
2017-11-06 02:22:03 [scrapy.extensions.logstats] INFO: Crawled 683215 pages (at 243 pages/min), scraped 599166 items (at 258 items/min)
2017-11-06 02:23:03 [scrapy.extensions.logstats] INFO: Crawled 683456 pages (at 241 pages/min), scraped 599379 items (at 213 items/min)
2017-11-06 02:24:03 [scrapy.extensions.logstats] INFO: Crawled 683694 pages (at 238 pages/min), scraped 599631 items (at 252 items/min)
2017-11-06 02:25:03 [scrapy.extensions.logstats] INFO: Crawled 683926 pages (at 232 pages/min), scraped 599821 items (at 190 items/min)
2017-11-06 02:26:03 [scrapy.extensions.logstats] INFO: Crawled 684167 pages (at 241 pages/min), scraped 600025 items (at 204 items/min)
2017-11-06 02:27:03 [scrapy.extensions.logstats] INFO: Crawled 684413 pages (at 246 pages/min), scraped 600212 items (at 187 items/min)
2017-11-06 02:28:03 [scrapy.extensions.logstats] INFO: Crawled 684665 pages (at 252 pages/min), scraped 600427 items (at 215 items/min)
2017-11-06 02:29:03 [scrapy.extensions.logstats] INFO: Crawled 684907 pages (at 242 pages/min), scraped 600622 items (at 195 items/min)
2017-11-06 02:30:03 [scrapy.extensions.logstats] INFO: Crawled 685157 pages (at 250 pages/min), scraped 600846 items (at 224 items/min)
2017-11-06 02:31:03 [scrapy.extensions.logstats] INFO: Crawled 685403 pages (at 246 pages/min), scraped 601058 items (at 212 items/min)
2017-11-06 02:32:03 [scrapy.extensions.logstats] INFO: Crawled 685647 pages (at 244 pages/min), scraped 601267 items (at 209 items/min)
2017-11-06 02:33:03 [scrapy.extensions.logstats] INFO: Crawled 685891 pages (at 244 pages/min), scraped 601476 items (at 209 items/min)
2017-11-06 02:34:03 [scrapy.extensions.logstats] INFO: Crawled 686135 pages (at 244 pages/min), scraped 601687 items (at 211 items/min)
2017-11-06 02:35:03 [scrapy.extensions.logstats] INFO: Crawled 686380 pages (at 245 pages/min), scraped 601890 items (at 203 items/min)
2017-11-06 02:36:03 [scrapy.extensions.logstats] INFO: Crawled 686623 pages (at 243 pages/min), scraped 602109 items (at 219 items/min)
2017-11-06 02:37:03 [scrapy.extensions.logstats] INFO: Crawled 686873 pages (at 250 pages/min), scraped 602343 items (at 234 items/min)
2017-11-06 02:38:03 [scrapy.extensions.logstats] INFO: Crawled 687111 pages (at 238 pages/min), scraped 602555 items (at 212 items/min)
2017-11-06 02:39:03 [scrapy.extensions.logstats] INFO: Crawled 687336 pages (at 225 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:40:03 [scrapy.extensions.logstats] INFO: Crawled 687582 pages (at 246 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:41:03 [scrapy.extensions.logstats] INFO: Crawled 687828 pages (at 246 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:42:03 [scrapy.extensions.logstats] INFO: Crawled 688075 pages (at 247 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:43:03 [scrapy.extensions.logstats] INFO: Crawled 688317 pages (at 242 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:44:03 [scrapy.extensions.logstats] INFO: Crawled 688561 pages (at 244 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:45:03 [scrapy.extensions.logstats] INFO: Crawled 688806 pages (at 245 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:46:03 [scrapy.extensions.logstats] INFO: Crawled 689053 pages (at 247 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:47:03 [scrapy.extensions.logstats] INFO: Crawled 689299 pages (at 246 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:48:03 [scrapy.extensions.logstats] INFO: Crawled 689549 pages (at 250 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:49:03 [scrapy.extensions.logstats] INFO: Crawled 689795 pages (at 246 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:50:03 [scrapy.extensions.logstats] INFO: Crawled 690038 pages (at 243 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:51:03 [scrapy.extensions.logstats] INFO: Crawled 690284 pages (at 246 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:52:03 [scrapy.extensions.logstats] INFO: Crawled 690533 pages (at 249 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:53:03 [scrapy.extensions.logstats] INFO: Crawled 690778 pages (at 245 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:54:03 [scrapy.extensions.logstats] INFO: Crawled 691020 pages (at 242 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:55:03 [scrapy.extensions.logstats] INFO: Crawled 691255 pages (at 235 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:56:03 [scrapy.extensions.logstats] INFO: Crawled 691512 pages (at 257 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:57:03 [scrapy.extensions.logstats] INFO: Crawled 691757 pages (at 245 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:58:03 [scrapy.extensions.logstats] INFO: Crawled 692000 pages (at 243 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 02:59:03 [scrapy.extensions.logstats] INFO: Crawled 692252 pages (at 252 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 03:00:03 [scrapy.extensions.logstats] INFO: Crawled 692495 pages (at 243 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 03:01:03 [scrapy.extensions.logstats] INFO: Crawled 692739 pages (at 244 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 03:02:03 [scrapy.extensions.logstats] INFO: Crawled 692983 pages (at 244 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 03:03:03 [scrapy.extensions.logstats] INFO: Crawled 693233 pages (at 250 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 03:04:03 [scrapy.extensions.logstats] INFO: Crawled 693476 pages (at 243 pages/min), scraped 602555 items (at 0 items/min)
2017-11-06 03:05:03 [scrapy.extensions.logstats] INFO: Crawled 693724 pages (at 248 pages/min), scraped 602609 items (at 54 items/min)
2017-11-06 03:06:03 [scrapy.extensions.logstats] INFO: Crawled 693968 pages (at 244 pages/min), scraped 602837 items (at 228 items/min)
2017-11-06 03:07:03 [scrapy.extensions.logstats] INFO: Crawled 694213 pages (at 245 pages/min), scraped 603050 items (at 213 items/min)
2017-11-06 03:08:03 [scrapy.extensions.logstats] INFO: Crawled 694458 pages (at 245 pages/min), scraped 603271 items (at 221 items/min)
2017-11-06 03:09:03 [scrapy.extensions.logstats] INFO: Crawled 694704 pages (at 246 pages/min), scraped 603471 items (at 200 items/min)
2017-11-06 03:10:03 [scrapy.extensions.logstats] INFO: Crawled 694946 pages (at 242 pages/min), scraped 603672 items (at 201 items/min)
2017-11-06 03:11:03 [scrapy.extensions.logstats] INFO: Crawled 695190 pages (at 244 pages/min), scraped 603884 items (at 212 items/min)
2017-11-06 03:12:03 [scrapy.extensions.logstats] INFO: Crawled 695436 pages (at 246 pages/min), scraped 604095 items (at 211 items/min)
2017-11-06 03:13:03 [scrapy.extensions.logstats] INFO: Crawled 695684 pages (at 248 pages/min), scraped 604303 items (at 208 items/min)
2017-11-06 03:14:03 [scrapy.extensions.logstats] INFO: Crawled 695922 pages (at 238 pages/min), scraped 604512 items (at 209 items/min)
2017-11-06 03:15:03 [scrapy.extensions.logstats] INFO: Crawled 696171 pages (at 249 pages/min), scraped 604727 items (at 215 items/min)
2017-11-06 03:16:03 [scrapy.extensions.logstats] INFO: Crawled 696415 pages (at 244 pages/min), scraped 604932 items (at 205 items/min)
2017-11-06 03:17:03 [scrapy.extensions.logstats] INFO: Crawled 696660 pages (at 245 pages/min), scraped 605133 items (at 201 items/min)
2017-11-06 03:18:03 [scrapy.extensions.logstats] INFO: Crawled 696900 pages (at 240 pages/min), scraped 605359 items (at 226 items/min)
2017-11-06 03:19:03 [scrapy.extensions.logstats] INFO: Crawled 697149 pages (at 249 pages/min), scraped 605562 items (at 203 items/min)
2017-11-06 03:20:03 [scrapy.extensions.logstats] INFO: Crawled 697396 pages (at 247 pages/min), scraped 605776 items (at 214 items/min)
2017-11-06 03:21:03 [scrapy.extensions.logstats] INFO: Crawled 697639 pages (at 243 pages/min), scraped 605988 items (at 212 items/min)
2017-11-06 03:22:03 [scrapy.extensions.logstats] INFO: Crawled 697883 pages (at 244 pages/min), scraped 606207 items (at 219 items/min)
2017-11-06 03:23:03 [scrapy.extensions.logstats] INFO: Crawled 698122 pages (at 239 pages/min), scraped 606406 items (at 199 items/min)
2017-11-06 03:24:03 [scrapy.extensions.logstats] INFO: Crawled 698369 pages (at 247 pages/min), scraped 606624 items (at 218 items/min)
2017-11-06 03:25:03 [scrapy.extensions.logstats] INFO: Crawled 698615 pages (at 246 pages/min), scraped 606841 items (at 217 items/min)
2017-11-06 03:26:03 [scrapy.extensions.logstats] INFO: Crawled 698862 pages (at 247 pages/min), scraped 607055 items (at 214 items/min)
2017-11-06 03:27:03 [scrapy.extensions.logstats] INFO: Crawled 699103 pages (at 241 pages/min), scraped 607274 items (at 219 items/min)
2017-11-06 03:28:03 [scrapy.extensions.logstats] INFO: Crawled 699345 pages (at 242 pages/min), scraped 607489 items (at 215 items/min)
2017-11-06 03:29:03 [scrapy.extensions.logstats] INFO: Crawled 699586 pages (at 241 pages/min), scraped 607700 items (at 211 items/min)
2017-11-06 03:30:03 [scrapy.extensions.logstats] INFO: Crawled 699829 pages (at 243 pages/min), scraped 607897 items (at 197 items/min)
2017-11-06 03:31:03 [scrapy.extensions.logstats] INFO: Crawled 700073 pages (at 244 pages/min), scraped 608119 items (at 222 items/min)
2017-11-06 03:32:03 [scrapy.extensions.logstats] INFO: Crawled 700320 pages (at 247 pages/min), scraped 608309 items (at 190 items/min)
2017-11-06 03:33:03 [scrapy.extensions.logstats] INFO: Crawled 700562 pages (at 242 pages/min), scraped 608501 items (at 192 items/min)
2017-11-06 03:34:03 [scrapy.extensions.logstats] INFO: Crawled 700804 pages (at 242 pages/min), scraped 608684 items (at 183 items/min)
2017-11-06 03:35:03 [scrapy.extensions.logstats] INFO: Crawled 701049 pages (at 245 pages/min), scraped 608877 items (at 193 items/min)
2017-11-06 03:36:03 [scrapy.extensions.logstats] INFO: Crawled 701298 pages (at 249 pages/min), scraped 609052 items (at 175 items/min)
2017-11-06 03:37:03 [scrapy.extensions.logstats] INFO: Crawled 701544 pages (at 246 pages/min), scraped 609247 items (at 195 items/min)
2017-11-06 03:38:03 [scrapy.extensions.logstats] INFO: Crawled 701786 pages (at 242 pages/min), scraped 609455 items (at 208 items/min)
2017-11-06 03:39:03 [scrapy.extensions.logstats] INFO: Crawled 702028 pages (at 242 pages/min), scraped 609639 items (at 184 items/min)
2017-11-06 03:40:03 [scrapy.extensions.logstats] INFO: Crawled 702273 pages (at 245 pages/min), scraped 609830 items (at 191 items/min)
2017-11-06 03:41:03 [scrapy.extensions.logstats] INFO: Crawled 702519 pages (at 246 pages/min), scraped 610066 items (at 236 items/min)
2017-11-06 03:42:03 [scrapy.extensions.logstats] INFO: Crawled 702765 pages (at 246 pages/min), scraped 610271 items (at 205 items/min)
2017-11-06 03:43:03 [scrapy.extensions.logstats] INFO: Crawled 703016 pages (at 251 pages/min), scraped 610478 items (at 207 items/min)
2017-11-06 03:44:03 [scrapy.extensions.logstats] INFO: Crawled 703263 pages (at 247 pages/min), scraped 610722 items (at 244 items/min)
2017-11-06 03:45:03 [scrapy.extensions.logstats] INFO: Crawled 703507 pages (at 244 pages/min), scraped 610932 items (at 210 items/min)
2017-11-06 03:46:03 [scrapy.extensions.logstats] INFO: Crawled 703750 pages (at 243 pages/min), scraped 611139 items (at 207 items/min)
2017-11-06 03:47:03 [scrapy.extensions.logstats] INFO: Crawled 703992 pages (at 242 pages/min), scraped 611365 items (at 226 items/min)
2017-11-06 03:48:03 [scrapy.extensions.logstats] INFO: Crawled 704240 pages (at 248 pages/min), scraped 611623 items (at 258 items/min)
2017-11-06 03:49:03 [scrapy.extensions.logstats] INFO: Crawled 704478 pages (at 238 pages/min), scraped 611856 items (at 233 items/min)
2017-11-06 03:50:03 [scrapy.extensions.logstats] INFO: Crawled 704727 pages (at 249 pages/min), scraped 612094 items (at 238 items/min)
2017-11-06 03:51:03 [scrapy.extensions.logstats] INFO: Crawled 704978 pages (at 251 pages/min), scraped 612336 items (at 242 items/min)
2017-11-06 03:52:03 [scrapy.extensions.logstats] INFO: Crawled 705225 pages (at 247 pages/min), scraped 612582 items (at 246 items/min)
2017-11-06 03:53:03 [scrapy.extensions.logstats] INFO: Crawled 705468 pages (at 243 pages/min), scraped 612822 items (at 240 items/min)
2017-11-06 03:54:03 [scrapy.extensions.logstats] INFO: Crawled 705709 pages (at 241 pages/min), scraped 613065 items (at 243 items/min)
2017-11-06 03:55:03 [scrapy.extensions.logstats] INFO: Crawled 705954 pages (at 245 pages/min), scraped 613330 items (at 265 items/min)
2017-11-06 03:56:03 [scrapy.extensions.logstats] INFO: Crawled 706197 pages (at 243 pages/min), scraped 613602 items (at 272 items/min)
2017-11-06 03:57:03 [scrapy.extensions.logstats] INFO: Crawled 706438 pages (at 241 pages/min), scraped 613831 items (at 229 items/min)
2017-11-06 03:58:03 [scrapy.extensions.logstats] INFO: Crawled 706681 pages (at 243 pages/min), scraped 614060 items (at 229 items/min)
2017-11-06 03:59:03 [scrapy.extensions.logstats] INFO: Crawled 706930 pages (at 249 pages/min), scraped 614271 items (at 211 items/min)
2017-11-06 04:00:03 [scrapy.extensions.logstats] INFO: Crawled 707175 pages (at 245 pages/min), scraped 614451 items (at 180 items/min)
2017-11-06 04:01:03 [scrapy.extensions.logstats] INFO: Crawled 707420 pages (at 245 pages/min), scraped 614631 items (at 180 items/min)
2017-11-06 04:02:03 [scrapy.extensions.logstats] INFO: Crawled 707665 pages (at 245 pages/min), scraped 614831 items (at 200 items/min)
2017-11-06 04:03:03 [scrapy.extensions.logstats] INFO: Crawled 707906 pages (at 241 pages/min), scraped 615009 items (at 178 items/min)
2017-11-06 04:04:03 [scrapy.extensions.logstats] INFO: Crawled 708153 pages (at 247 pages/min), scraped 615190 items (at 181 items/min)
2017-11-06 04:04:54 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=098707&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"周霁","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"国开证券有限责任公司","AOI_ID":"1999138","ADI_ID":"6647","ADI_NAME":"合规法律部","PTI_NAME":"一般证券业务","CER_NUM":"S1380106120176","OBTAIN_DATE":"2007-08-16","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 04:05:03 [scrapy.extensions.logstats] INFO: Crawled 708403 pages (at 250 pages/min), scraped 615394 items (at 204 items/min)
2017-11-06 04:05:22 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=083275&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"姚远","SCO_NAME":"男","ECO_NAME":"大专","AOI_NAME":"国开证券有限责任公司","AOI_ID":"1999138","ADI_ID":"33714","ADI_NAME":"深圳龙华证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S1380100010068","OBTAIN_DATE":"2004-06-09","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 04:06:03 [scrapy.extensions.logstats] INFO: Crawled 708648 pages (at 245 pages/min), scraped 615599 items (at 205 items/min)
2017-11-06 04:07:03 [scrapy.extensions.logstats] INFO: Crawled 708896 pages (at 248 pages/min), scraped 615818 items (at 219 items/min)
2017-11-06 04:08:03 [scrapy.extensions.logstats] INFO: Crawled 709139 pages (at 243 pages/min), scraped 616020 items (at 202 items/min)
2017-11-06 04:09:03 [scrapy.extensions.logstats] INFO: Crawled 709384 pages (at 245 pages/min), scraped 616225 items (at 205 items/min)
2017-11-06 04:10:03 [scrapy.extensions.logstats] INFO: Crawled 709632 pages (at 248 pages/min), scraped 616439 items (at 214 items/min)
2017-11-06 04:11:03 [scrapy.extensions.logstats] INFO: Crawled 709880 pages (at 248 pages/min), scraped 616646 items (at 207 items/min)
2017-11-06 04:12:03 [scrapy.extensions.logstats] INFO: Crawled 710126 pages (at 246 pages/min), scraped 616833 items (at 187 items/min)
2017-11-06 04:13:03 [scrapy.extensions.logstats] INFO: Crawled 710369 pages (at 243 pages/min), scraped 617034 items (at 201 items/min)
2017-11-06 04:14:03 [scrapy.extensions.logstats] INFO: Crawled 710618 pages (at 249 pages/min), scraped 617234 items (at 200 items/min)
2017-11-06 04:15:03 [scrapy.extensions.logstats] INFO: Crawled 710865 pages (at 247 pages/min), scraped 617445 items (at 211 items/min)
2017-11-06 04:16:03 [scrapy.extensions.logstats] INFO: Crawled 711107 pages (at 242 pages/min), scraped 617648 items (at 203 items/min)
2017-11-06 04:17:03 [scrapy.extensions.logstats] INFO: Crawled 711344 pages (at 237 pages/min), scraped 617834 items (at 186 items/min)
2017-11-06 04:18:03 [scrapy.extensions.logstats] INFO: Crawled 711587 pages (at 243 pages/min), scraped 618002 items (at 168 items/min)
2017-11-06 04:19:03 [scrapy.extensions.logstats] INFO: Crawled 711833 pages (at 246 pages/min), scraped 618191 items (at 189 items/min)
2017-11-06 04:20:03 [scrapy.extensions.logstats] INFO: Crawled 712083 pages (at 250 pages/min), scraped 618402 items (at 211 items/min)
2017-11-06 04:21:03 [scrapy.extensions.logstats] INFO: Crawled 712326 pages (at 243 pages/min), scraped 618603 items (at 201 items/min)
2017-11-06 04:22:03 [scrapy.extensions.logstats] INFO: Crawled 712568 pages (at 242 pages/min), scraped 618804 items (at 201 items/min)
2017-11-06 04:23:03 [scrapy.extensions.logstats] INFO: Crawled 712811 pages (at 243 pages/min), scraped 619007 items (at 203 items/min)
2017-11-06 04:24:03 [scrapy.extensions.logstats] INFO: Crawled 713056 pages (at 245 pages/min), scraped 619220 items (at 213 items/min)
2017-11-06 04:25:03 [scrapy.extensions.logstats] INFO: Crawled 713303 pages (at 247 pages/min), scraped 619456 items (at 236 items/min)
2017-11-06 04:26:03 [scrapy.extensions.logstats] INFO: Crawled 713548 pages (at 245 pages/min), scraped 619683 items (at 227 items/min)
2017-11-06 04:27:03 [scrapy.extensions.logstats] INFO: Crawled 713791 pages (at 243 pages/min), scraped 619909 items (at 226 items/min)
2017-11-06 04:28:03 [scrapy.extensions.logstats] INFO: Crawled 714037 pages (at 246 pages/min), scraped 620147 items (at 238 items/min)
2017-11-06 04:29:03 [scrapy.extensions.logstats] INFO: Crawled 714284 pages (at 247 pages/min), scraped 620357 items (at 210 items/min)
2017-11-06 04:30:03 [scrapy.extensions.logstats] INFO: Crawled 714527 pages (at 243 pages/min), scraped 620598 items (at 241 items/min)
2017-11-06 04:31:03 [scrapy.extensions.logstats] INFO: Crawled 714772 pages (at 245 pages/min), scraped 620839 items (at 241 items/min)
2017-11-06 04:32:03 [scrapy.extensions.logstats] INFO: Crawled 715017 pages (at 245 pages/min), scraped 621075 items (at 236 items/min)
2017-11-06 04:33:03 [scrapy.extensions.logstats] INFO: Crawled 715260 pages (at 243 pages/min), scraped 621307 items (at 232 items/min)
2017-11-06 04:34:03 [scrapy.extensions.logstats] INFO: Crawled 715502 pages (at 242 pages/min), scraped 621518 items (at 211 items/min)
2017-11-06 04:35:03 [scrapy.extensions.logstats] INFO: Crawled 715747 pages (at 245 pages/min), scraped 621731 items (at 213 items/min)
2017-11-06 04:36:03 [scrapy.extensions.logstats] INFO: Crawled 715990 pages (at 243 pages/min), scraped 621952 items (at 221 items/min)
2017-11-06 04:37:03 [scrapy.extensions.logstats] INFO: Crawled 716236 pages (at 246 pages/min), scraped 622196 items (at 244 items/min)
2017-11-06 04:38:03 [scrapy.extensions.logstats] INFO: Crawled 716480 pages (at 244 pages/min), scraped 622432 items (at 236 items/min)
2017-11-06 04:39:03 [scrapy.extensions.logstats] INFO: Crawled 716724 pages (at 244 pages/min), scraped 622653 items (at 221 items/min)
2017-11-06 04:40:03 [scrapy.extensions.logstats] INFO: Crawled 716967 pages (at 243 pages/min), scraped 622888 items (at 235 items/min)
2017-11-06 04:41:03 [scrapy.extensions.logstats] INFO: Crawled 717215 pages (at 248 pages/min), scraped 623102 items (at 214 items/min)
2017-11-06 04:42:03 [scrapy.extensions.logstats] INFO: Crawled 717461 pages (at 246 pages/min), scraped 623295 items (at 193 items/min)
2017-11-06 04:43:03 [scrapy.extensions.logstats] INFO: Crawled 717703 pages (at 242 pages/min), scraped 623480 items (at 185 items/min)
2017-11-06 04:44:03 [scrapy.extensions.logstats] INFO: Crawled 717949 pages (at 246 pages/min), scraped 623686 items (at 206 items/min)
2017-11-06 04:45:03 [scrapy.extensions.logstats] INFO: Crawled 718194 pages (at 245 pages/min), scraped 623864 items (at 178 items/min)
2017-11-06 04:46:03 [scrapy.extensions.logstats] INFO: Crawled 718433 pages (at 239 pages/min), scraped 624051 items (at 187 items/min)
2017-11-06 04:47:03 [scrapy.extensions.logstats] INFO: Crawled 718673 pages (at 240 pages/min), scraped 624280 items (at 229 items/min)
2017-11-06 04:48:03 [scrapy.extensions.logstats] INFO: Crawled 718918 pages (at 245 pages/min), scraped 624505 items (at 225 items/min)
2017-11-06 04:49:03 [scrapy.extensions.logstats] INFO: Crawled 719160 pages (at 242 pages/min), scraped 624759 items (at 254 items/min)
2017-11-06 04:50:03 [scrapy.extensions.logstats] INFO: Crawled 719401 pages (at 241 pages/min), scraped 624996 items (at 237 items/min)
2017-11-06 04:51:03 [scrapy.extensions.logstats] INFO: Crawled 719646 pages (at 245 pages/min), scraped 625241 items (at 245 items/min)
2017-11-06 04:52:03 [scrapy.extensions.logstats] INFO: Crawled 719889 pages (at 243 pages/min), scraped 625492 items (at 251 items/min)
2017-11-06 04:53:03 [scrapy.extensions.logstats] INFO: Crawled 720128 pages (at 239 pages/min), scraped 625743 items (at 251 items/min)
2017-11-06 04:54:03 [scrapy.extensions.logstats] INFO: Crawled 720369 pages (at 241 pages/min), scraped 625990 items (at 247 items/min)
2017-11-06 04:55:03 [scrapy.extensions.logstats] INFO: Crawled 720603 pages (at 234 pages/min), scraped 626196 items (at 206 items/min)
2017-11-06 04:56:03 [scrapy.extensions.logstats] INFO: Crawled 720849 pages (at 246 pages/min), scraped 626431 items (at 235 items/min)
2017-11-06 04:57:03 [scrapy.extensions.logstats] INFO: Crawled 721090 pages (at 241 pages/min), scraped 626667 items (at 236 items/min)
2017-11-06 04:58:03 [scrapy.extensions.logstats] INFO: Crawled 721337 pages (at 247 pages/min), scraped 626889 items (at 222 items/min)
2017-11-06 04:59:03 [scrapy.extensions.logstats] INFO: Crawled 721584 pages (at 247 pages/min), scraped 627119 items (at 230 items/min)
2017-11-06 05:00:03 [scrapy.extensions.logstats] INFO: Crawled 721827 pages (at 243 pages/min), scraped 627351 items (at 232 items/min)
2017-11-06 05:01:03 [scrapy.extensions.logstats] INFO: Crawled 722072 pages (at 245 pages/min), scraped 627589 items (at 238 items/min)
2017-11-06 05:02:03 [scrapy.extensions.logstats] INFO: Crawled 722315 pages (at 243 pages/min), scraped 627810 items (at 221 items/min)
2017-11-06 05:03:03 [scrapy.extensions.logstats] INFO: Crawled 722560 pages (at 245 pages/min), scraped 628048 items (at 238 items/min)
2017-11-06 05:04:03 [scrapy.extensions.logstats] INFO: Crawled 722803 pages (at 243 pages/min), scraped 628289 items (at 241 items/min)
2017-11-06 05:05:03 [scrapy.extensions.logstats] INFO: Crawled 723050 pages (at 247 pages/min), scraped 628524 items (at 235 items/min)
2017-11-06 05:06:03 [scrapy.extensions.logstats] INFO: Crawled 723288 pages (at 238 pages/min), scraped 628758 items (at 234 items/min)
2017-11-06 05:07:03 [scrapy.extensions.logstats] INFO: Crawled 723530 pages (at 242 pages/min), scraped 629021 items (at 263 items/min)
2017-11-06 05:08:03 [scrapy.extensions.logstats] INFO: Crawled 723769 pages (at 239 pages/min), scraped 629240 items (at 219 items/min)
2017-11-06 05:09:03 [scrapy.extensions.logstats] INFO: Crawled 724014 pages (at 245 pages/min), scraped 629498 items (at 258 items/min)
2017-11-06 05:10:03 [scrapy.extensions.logstats] INFO: Crawled 724253 pages (at 239 pages/min), scraped 629743 items (at 245 items/min)
2017-11-06 05:11:03 [scrapy.extensions.logstats] INFO: Crawled 724498 pages (at 245 pages/min), scraped 629987 items (at 244 items/min)
2017-11-06 05:12:03 [scrapy.extensions.logstats] INFO: Crawled 724739 pages (at 241 pages/min), scraped 630205 items (at 218 items/min)
2017-11-06 05:13:03 [scrapy.extensions.logstats] INFO: Crawled 724984 pages (at 245 pages/min), scraped 630427 items (at 222 items/min)
2017-11-06 05:14:03 [scrapy.extensions.logstats] INFO: Crawled 725225 pages (at 241 pages/min), scraped 630668 items (at 241 items/min)
2017-11-06 05:15:03 [scrapy.extensions.logstats] INFO: Crawled 725474 pages (at 249 pages/min), scraped 630906 items (at 238 items/min)
2017-11-06 05:16:03 [scrapy.extensions.logstats] INFO: Crawled 725723 pages (at 249 pages/min), scraped 631155 items (at 249 items/min)
2017-11-06 05:17:03 [scrapy.extensions.logstats] INFO: Crawled 725969 pages (at 246 pages/min), scraped 631403 items (at 248 items/min)
2017-11-06 05:18:03 [scrapy.extensions.logstats] INFO: Crawled 726212 pages (at 243 pages/min), scraped 631651 items (at 248 items/min)
2017-11-06 05:19:03 [scrapy.extensions.logstats] INFO: Crawled 726458 pages (at 246 pages/min), scraped 631901 items (at 250 items/min)
2017-11-06 05:20:03 [scrapy.extensions.logstats] INFO: Crawled 726703 pages (at 245 pages/min), scraped 632162 items (at 261 items/min)
2017-11-06 05:21:03 [scrapy.extensions.logstats] INFO: Crawled 726944 pages (at 241 pages/min), scraped 632383 items (at 221 items/min)
2017-11-06 05:22:03 [scrapy.extensions.logstats] INFO: Crawled 727187 pages (at 243 pages/min), scraped 632604 items (at 221 items/min)
2017-11-06 05:23:03 [scrapy.extensions.logstats] INFO: Crawled 727437 pages (at 250 pages/min), scraped 632774 items (at 170 items/min)
2017-11-06 05:24:03 [scrapy.extensions.logstats] INFO: Crawled 727679 pages (at 242 pages/min), scraped 632959 items (at 185 items/min)
2017-11-06 05:25:03 [scrapy.extensions.logstats] INFO: Crawled 727924 pages (at 245 pages/min), scraped 633159 items (at 200 items/min)
2017-11-06 05:26:03 [scrapy.extensions.logstats] INFO: Crawled 728170 pages (at 246 pages/min), scraped 633372 items (at 213 items/min)
2017-11-06 05:27:03 [scrapy.extensions.logstats] INFO: Crawled 728414 pages (at 244 pages/min), scraped 633590 items (at 218 items/min)
2017-11-06 05:28:03 [scrapy.extensions.logstats] INFO: Crawled 728655 pages (at 241 pages/min), scraped 633786 items (at 196 items/min)
2017-11-06 05:29:03 [scrapy.extensions.logstats] INFO: Crawled 728897 pages (at 242 pages/min), scraped 634008 items (at 222 items/min)
2017-11-06 05:30:03 [scrapy.extensions.logstats] INFO: Crawled 729138 pages (at 241 pages/min), scraped 634226 items (at 218 items/min)
2017-11-06 05:31:03 [scrapy.extensions.logstats] INFO: Crawled 729381 pages (at 243 pages/min), scraped 634415 items (at 189 items/min)
2017-11-06 05:32:03 [scrapy.extensions.logstats] INFO: Crawled 729628 pages (at 247 pages/min), scraped 634658 items (at 243 items/min)
2017-11-06 05:33:03 [scrapy.extensions.logstats] INFO: Crawled 729869 pages (at 241 pages/min), scraped 634862 items (at 204 items/min)
2017-11-06 05:34:03 [scrapy.extensions.logstats] INFO: Crawled 730110 pages (at 241 pages/min), scraped 635124 items (at 262 items/min)
2017-11-06 05:34:32 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=022329&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"彭孝港","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"广州证券股份有限公司","AOI_ID":"1999032","ADI_ID":"51569","ADI_NAME":"广州北京路证券营业部","PTI_NAME":"证券投资咨询业务(投资顾问)","CER_NUM":"S0320611070008","OBTAIN_DATE":"2011-07-21","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 05:35:03 [scrapy.extensions.logstats] INFO: Crawled 730356 pages (at 246 pages/min), scraped 635386 items (at 262 items/min)
2017-11-06 05:36:03 [scrapy.extensions.logstats] INFO: Crawled 730598 pages (at 242 pages/min), scraped 635614 items (at 228 items/min)
2017-11-06 05:37:03 [scrapy.extensions.logstats] INFO: Crawled 730850 pages (at 252 pages/min), scraped 635850 items (at 236 items/min)
2017-11-06 05:38:03 [scrapy.extensions.logstats] INFO: Crawled 731095 pages (at 245 pages/min), scraped 636091 items (at 241 items/min)
2017-11-06 05:39:03 [scrapy.extensions.logstats] INFO: Crawled 731330 pages (at 235 pages/min), scraped 636327 items (at 236 items/min)
2017-11-06 05:40:03 [scrapy.extensions.logstats] INFO: Crawled 731576 pages (at 246 pages/min), scraped 636541 items (at 214 items/min)
2017-11-06 05:41:03 [scrapy.extensions.logstats] INFO: Crawled 731817 pages (at 241 pages/min), scraped 636760 items (at 219 items/min)
2017-11-06 05:42:03 [scrapy.extensions.logstats] INFO: Crawled 732062 pages (at 245 pages/min), scraped 636987 items (at 227 items/min)
2017-11-06 05:43:03 [scrapy.extensions.logstats] INFO: Crawled 732307 pages (at 245 pages/min), scraped 637213 items (at 226 items/min)
2017-11-06 05:44:03 [scrapy.extensions.logstats] INFO: Crawled 732556 pages (at 249 pages/min), scraped 637455 items (at 242 items/min)
2017-11-06 05:45:03 [scrapy.extensions.logstats] INFO: Crawled 732801 pages (at 245 pages/min), scraped 637680 items (at 225 items/min)
2017-11-06 05:46:03 [scrapy.extensions.logstats] INFO: Crawled 733049 pages (at 248 pages/min), scraped 637912 items (at 232 items/min)
2017-11-06 05:47:03 [scrapy.extensions.logstats] INFO: Crawled 733293 pages (at 244 pages/min), scraped 638141 items (at 229 items/min)
2017-11-06 05:48:03 [scrapy.extensions.logstats] INFO: Crawled 733537 pages (at 244 pages/min), scraped 638343 items (at 202 items/min)
2017-11-06 05:49:03 [scrapy.extensions.logstats] INFO: Crawled 733784 pages (at 247 pages/min), scraped 638558 items (at 215 items/min)
2017-11-06 05:50:03 [scrapy.extensions.logstats] INFO: Crawled 734027 pages (at 243 pages/min), scraped 638765 items (at 207 items/min)
2017-11-06 05:51:03 [scrapy.extensions.logstats] INFO: Crawled 734277 pages (at 250 pages/min), scraped 638995 items (at 230 items/min)
2017-11-06 05:52:03 [scrapy.extensions.logstats] INFO: Crawled 734518 pages (at 241 pages/min), scraped 639216 items (at 221 items/min)
2017-11-06 05:53:03 [scrapy.extensions.logstats] INFO: Crawled 734767 pages (at 249 pages/min), scraped 639420 items (at 204 items/min)
2017-11-06 05:54:03 [scrapy.extensions.logstats] INFO: Crawled 735011 pages (at 244 pages/min), scraped 639618 items (at 198 items/min)
2017-11-06 05:55:03 [scrapy.extensions.logstats] INFO: Crawled 735254 pages (at 243 pages/min), scraped 639821 items (at 203 items/min)
2017-11-06 05:56:03 [scrapy.extensions.logstats] INFO: Crawled 735496 pages (at 242 pages/min), scraped 640026 items (at 205 items/min)
2017-11-06 05:57:03 [scrapy.extensions.logstats] INFO: Crawled 735737 pages (at 241 pages/min), scraped 640226 items (at 200 items/min)
2017-11-06 05:58:03 [scrapy.extensions.logstats] INFO: Crawled 735983 pages (at 246 pages/min), scraped 640443 items (at 217 items/min)
2017-11-06 05:59:03 [scrapy.extensions.logstats] INFO: Crawled 736228 pages (at 245 pages/min), scraped 640664 items (at 221 items/min)
2017-11-06 06:00:03 [scrapy.extensions.logstats] INFO: Crawled 736473 pages (at 245 pages/min), scraped 640865 items (at 201 items/min)
2017-11-06 06:01:03 [scrapy.extensions.logstats] INFO: Crawled 736715 pages (at 242 pages/min), scraped 641086 items (at 221 items/min)
2017-11-06 06:02:03 [scrapy.extensions.logstats] INFO: Crawled 736959 pages (at 244 pages/min), scraped 641305 items (at 219 items/min)
2017-11-06 06:03:03 [scrapy.extensions.logstats] INFO: Crawled 737205 pages (at 246 pages/min), scraped 641523 items (at 218 items/min)
2017-11-06 06:04:03 [scrapy.extensions.logstats] INFO: Crawled 737452 pages (at 247 pages/min), scraped 641747 items (at 224 items/min)
2017-11-06 06:05:03 [scrapy.extensions.logstats] INFO: Crawled 737693 pages (at 241 pages/min), scraped 641961 items (at 214 items/min)
2017-11-06 06:05:40 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-06 06:05:40 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-06 06:05:41 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-06 06:05:41 [scrapy.core.scraper] ERROR: Error downloading <POST http://person.sac.net.cn/pages/registration/train-line-register!search.action>
Traceback (most recent call last):
  File "f:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "f:\Anaconda3\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "f:\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2017-11-06 06:06:03 [scrapy.extensions.logstats] INFO: Crawled 737867 pages (at 174 pages/min), scraped 642106 items (at 145 items/min)
2017-11-06 06:06:24 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=087804&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"黎子毅","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"国海证券股份有限公司","AOI_ID":"1999035","ADI_ID":"18932","ADI_NAME":"深圳深南大道营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0350100010591","OBTAIN_DATE":"2004-12-02","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 06:07:03 [scrapy.extensions.logstats] INFO: Crawled 738112 pages (at 245 pages/min), scraped 642327 items (at 221 items/min)
2017-11-06 06:08:03 [scrapy.extensions.logstats] INFO: Crawled 738355 pages (at 243 pages/min), scraped 642549 items (at 222 items/min)
2017-11-06 06:09:03 [scrapy.extensions.logstats] INFO: Crawled 738594 pages (at 239 pages/min), scraped 642810 items (at 261 items/min)
2017-11-06 06:10:03 [scrapy.extensions.logstats] INFO: Crawled 738833 pages (at 239 pages/min), scraped 643053 items (at 243 items/min)
2017-11-06 06:11:03 [scrapy.extensions.logstats] INFO: Crawled 739078 pages (at 245 pages/min), scraped 643273 items (at 220 items/min)
2017-11-06 06:12:03 [scrapy.extensions.logstats] INFO: Crawled 739323 pages (at 245 pages/min), scraped 643489 items (at 216 items/min)
2017-11-06 06:13:03 [scrapy.extensions.logstats] INFO: Crawled 739570 pages (at 247 pages/min), scraped 643695 items (at 206 items/min)
2017-11-06 06:14:03 [scrapy.extensions.logstats] INFO: Crawled 739815 pages (at 245 pages/min), scraped 643913 items (at 218 items/min)
2017-11-06 06:15:03 [scrapy.extensions.logstats] INFO: Crawled 740061 pages (at 246 pages/min), scraped 644166 items (at 253 items/min)
2017-11-06 06:16:03 [scrapy.extensions.logstats] INFO: Crawled 740306 pages (at 245 pages/min), scraped 644368 items (at 202 items/min)
2017-11-06 06:17:03 [scrapy.extensions.logstats] INFO: Crawled 740551 pages (at 245 pages/min), scraped 644572 items (at 204 items/min)
2017-11-06 06:18:03 [scrapy.extensions.logstats] INFO: Crawled 740793 pages (at 242 pages/min), scraped 644767 items (at 195 items/min)
2017-11-06 06:19:03 [scrapy.extensions.logstats] INFO: Crawled 741035 pages (at 242 pages/min), scraped 644926 items (at 159 items/min)
2017-11-06 06:20:03 [scrapy.extensions.logstats] INFO: Crawled 741278 pages (at 243 pages/min), scraped 645084 items (at 158 items/min)
2017-11-06 06:21:03 [scrapy.extensions.logstats] INFO: Crawled 741523 pages (at 245 pages/min), scraped 645257 items (at 173 items/min)
2017-11-06 06:22:03 [scrapy.extensions.logstats] INFO: Crawled 741770 pages (at 247 pages/min), scraped 645458 items (at 201 items/min)
2017-11-06 06:23:03 [scrapy.extensions.logstats] INFO: Crawled 742014 pages (at 244 pages/min), scraped 645661 items (at 203 items/min)
2017-11-06 06:24:03 [scrapy.extensions.logstats] INFO: Crawled 742259 pages (at 245 pages/min), scraped 645864 items (at 203 items/min)
2017-11-06 06:25:03 [scrapy.extensions.logstats] INFO: Crawled 742494 pages (at 235 pages/min), scraped 646058 items (at 194 items/min)
2017-11-06 06:26:03 [scrapy.extensions.logstats] INFO: Crawled 742739 pages (at 245 pages/min), scraped 646267 items (at 209 items/min)
2017-11-06 06:27:03 [scrapy.extensions.logstats] INFO: Crawled 742983 pages (at 244 pages/min), scraped 646465 items (at 198 items/min)
2017-11-06 06:28:03 [scrapy.extensions.logstats] INFO: Crawled 743226 pages (at 243 pages/min), scraped 646669 items (at 204 items/min)
2017-11-06 06:29:03 [scrapy.extensions.logstats] INFO: Crawled 743465 pages (at 239 pages/min), scraped 646882 items (at 213 items/min)
2017-11-06 06:30:03 [scrapy.extensions.logstats] INFO: Crawled 743710 pages (at 245 pages/min), scraped 647092 items (at 210 items/min)
2017-11-06 06:31:03 [scrapy.extensions.logstats] INFO: Crawled 743951 pages (at 241 pages/min), scraped 647303 items (at 211 items/min)
2017-11-06 06:32:03 [scrapy.extensions.logstats] INFO: Crawled 744197 pages (at 246 pages/min), scraped 647516 items (at 213 items/min)
2017-11-06 06:33:03 [scrapy.extensions.logstats] INFO: Crawled 744436 pages (at 239 pages/min), scraped 647718 items (at 202 items/min)
2017-11-06 06:34:03 [scrapy.extensions.logstats] INFO: Crawled 744680 pages (at 244 pages/min), scraped 647920 items (at 202 items/min)
2017-11-06 06:35:03 [scrapy.extensions.logstats] INFO: Crawled 744923 pages (at 243 pages/min), scraped 648123 items (at 203 items/min)
2017-11-06 06:36:03 [scrapy.extensions.logstats] INFO: Crawled 745162 pages (at 239 pages/min), scraped 648321 items (at 198 items/min)
2017-11-06 06:37:03 [scrapy.extensions.logstats] INFO: Crawled 745410 pages (at 248 pages/min), scraped 648529 items (at 208 items/min)
2017-11-06 06:38:03 [scrapy.extensions.logstats] INFO: Crawled 745654 pages (at 244 pages/min), scraped 648724 items (at 195 items/min)
2017-11-06 06:39:03 [scrapy.extensions.logstats] INFO: Crawled 745896 pages (at 242 pages/min), scraped 648929 items (at 205 items/min)
2017-11-06 06:40:03 [scrapy.extensions.logstats] INFO: Crawled 746143 pages (at 247 pages/min), scraped 649144 items (at 215 items/min)
2017-11-06 06:41:03 [scrapy.extensions.logstats] INFO: Crawled 746387 pages (at 244 pages/min), scraped 649341 items (at 197 items/min)
2017-11-06 06:42:03 [scrapy.extensions.logstats] INFO: Crawled 746633 pages (at 246 pages/min), scraped 649547 items (at 206 items/min)
2017-11-06 06:43:03 [scrapy.extensions.logstats] INFO: Crawled 746876 pages (at 243 pages/min), scraped 649749 items (at 202 items/min)
2017-11-06 06:44:03 [scrapy.extensions.logstats] INFO: Crawled 747117 pages (at 241 pages/min), scraped 649960 items (at 211 items/min)
2017-11-06 06:45:03 [scrapy.extensions.logstats] INFO: Crawled 747367 pages (at 250 pages/min), scraped 650173 items (at 213 items/min)
2017-11-06 06:46:03 [scrapy.extensions.logstats] INFO: Crawled 747612 pages (at 245 pages/min), scraped 650381 items (at 208 items/min)
2017-11-06 06:47:03 [scrapy.extensions.logstats] INFO: Crawled 747858 pages (at 246 pages/min), scraped 650595 items (at 214 items/min)
2017-11-06 06:48:03 [scrapy.extensions.logstats] INFO: Crawled 748103 pages (at 245 pages/min), scraped 650811 items (at 216 items/min)
2017-11-06 06:49:03 [scrapy.extensions.logstats] INFO: Crawled 748349 pages (at 246 pages/min), scraped 651016 items (at 205 items/min)
2017-11-06 06:50:03 [scrapy.extensions.logstats] INFO: Crawled 748593 pages (at 244 pages/min), scraped 651229 items (at 213 items/min)
2017-11-06 06:51:03 [scrapy.extensions.logstats] INFO: Crawled 748834 pages (at 241 pages/min), scraped 651427 items (at 198 items/min)
2017-11-06 06:52:03 [scrapy.extensions.logstats] INFO: Crawled 749075 pages (at 241 pages/min), scraped 651643 items (at 216 items/min)
2017-11-06 06:53:03 [scrapy.extensions.logstats] INFO: Crawled 749323 pages (at 248 pages/min), scraped 651890 items (at 247 items/min)
2017-11-06 06:54:03 [scrapy.extensions.logstats] INFO: Crawled 749566 pages (at 243 pages/min), scraped 652100 items (at 210 items/min)
2017-11-06 06:55:03 [scrapy.extensions.logstats] INFO: Crawled 749794 pages (at 228 pages/min), scraped 652308 items (at 208 items/min)
2017-11-06 06:56:03 [scrapy.extensions.logstats] INFO: Crawled 750049 pages (at 255 pages/min), scraped 652527 items (at 219 items/min)
2017-11-06 06:57:03 [scrapy.extensions.logstats] INFO: Crawled 750291 pages (at 242 pages/min), scraped 652727 items (at 200 items/min)
2017-11-06 06:58:03 [scrapy.extensions.logstats] INFO: Crawled 750540 pages (at 249 pages/min), scraped 652946 items (at 219 items/min)
2017-11-06 06:59:03 [scrapy.extensions.logstats] INFO: Crawled 750784 pages (at 244 pages/min), scraped 653145 items (at 199 items/min)
2017-11-06 07:00:03 [scrapy.extensions.logstats] INFO: Crawled 751028 pages (at 244 pages/min), scraped 653347 items (at 202 items/min)
2017-11-06 07:01:03 [scrapy.extensions.logstats] INFO: Crawled 751276 pages (at 248 pages/min), scraped 653570 items (at 223 items/min)
2017-11-06 07:02:03 [scrapy.extensions.logstats] INFO: Crawled 751521 pages (at 245 pages/min), scraped 653772 items (at 202 items/min)
2017-11-06 07:03:03 [scrapy.extensions.logstats] INFO: Crawled 751763 pages (at 242 pages/min), scraped 653982 items (at 210 items/min)
2017-11-06 07:04:03 [scrapy.extensions.logstats] INFO: Crawled 752002 pages (at 239 pages/min), scraped 654215 items (at 233 items/min)
2017-11-06 07:05:03 [scrapy.extensions.logstats] INFO: Crawled 752248 pages (at 246 pages/min), scraped 654430 items (at 215 items/min)
2017-11-06 07:06:03 [scrapy.extensions.logstats] INFO: Crawled 752494 pages (at 246 pages/min), scraped 654655 items (at 225 items/min)
2017-11-06 07:07:03 [scrapy.extensions.logstats] INFO: Crawled 752739 pages (at 245 pages/min), scraped 654869 items (at 214 items/min)
2017-11-06 07:08:03 [scrapy.extensions.logstats] INFO: Crawled 752978 pages (at 239 pages/min), scraped 655069 items (at 200 items/min)
2017-11-06 07:09:03 [scrapy.extensions.logstats] INFO: Crawled 753218 pages (at 240 pages/min), scraped 655268 items (at 199 items/min)
2017-11-06 07:10:03 [scrapy.extensions.logstats] INFO: Crawled 753456 pages (at 238 pages/min), scraped 655495 items (at 227 items/min)
2017-11-06 07:11:03 [scrapy.extensions.logstats] INFO: Crawled 753695 pages (at 239 pages/min), scraped 655726 items (at 231 items/min)
2017-11-06 07:12:03 [scrapy.extensions.logstats] INFO: Crawled 753940 pages (at 245 pages/min), scraped 655932 items (at 206 items/min)
2017-11-06 07:13:03 [scrapy.extensions.logstats] INFO: Crawled 754188 pages (at 248 pages/min), scraped 656143 items (at 211 items/min)
2017-11-06 07:14:03 [scrapy.extensions.logstats] INFO: Crawled 754434 pages (at 246 pages/min), scraped 656356 items (at 213 items/min)
2017-11-06 07:15:03 [scrapy.extensions.logstats] INFO: Crawled 754681 pages (at 247 pages/min), scraped 656539 items (at 183 items/min)
2017-11-06 07:16:03 [scrapy.extensions.logstats] INFO: Crawled 754923 pages (at 242 pages/min), scraped 656708 items (at 169 items/min)
2017-11-06 07:17:03 [scrapy.extensions.logstats] INFO: Crawled 755166 pages (at 243 pages/min), scraped 656871 items (at 163 items/min)
2017-11-06 07:18:03 [scrapy.extensions.logstats] INFO: Crawled 755412 pages (at 246 pages/min), scraped 657033 items (at 162 items/min)
2017-11-06 07:19:03 [scrapy.extensions.logstats] INFO: Crawled 755660 pages (at 248 pages/min), scraped 657212 items (at 179 items/min)
2017-11-06 07:20:03 [scrapy.extensions.logstats] INFO: Crawled 755905 pages (at 245 pages/min), scraped 657393 items (at 181 items/min)
2017-11-06 07:21:03 [scrapy.extensions.logstats] INFO: Crawled 756151 pages (at 246 pages/min), scraped 657569 items (at 176 items/min)
2017-11-06 07:22:03 [scrapy.extensions.logstats] INFO: Crawled 756398 pages (at 247 pages/min), scraped 657755 items (at 186 items/min)
2017-11-06 07:23:03 [scrapy.extensions.logstats] INFO: Crawled 756643 pages (at 245 pages/min), scraped 657927 items (at 172 items/min)
2017-11-06 07:24:03 [scrapy.extensions.logstats] INFO: Crawled 756890 pages (at 247 pages/min), scraped 658114 items (at 187 items/min)
2017-11-06 07:25:03 [scrapy.extensions.logstats] INFO: Crawled 757128 pages (at 238 pages/min), scraped 658285 items (at 171 items/min)
2017-11-06 07:26:03 [scrapy.extensions.logstats] INFO: Crawled 757375 pages (at 247 pages/min), scraped 658476 items (at 191 items/min)
2017-11-06 07:27:03 [scrapy.extensions.logstats] INFO: Crawled 757621 pages (at 246 pages/min), scraped 658658 items (at 182 items/min)
2017-11-06 07:27:40 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29993612&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"裴自鑫","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"广发证券股份有限公司","AOI_ID":"1999026","ADI_ID":"46410","ADI_NAME":"廊坊新开路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0260110016876","OBTAIN_DATE":"2010-01-06","ARRIVE_DATE":"2018-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 07:28:03 [scrapy.extensions.logstats] INFO: Crawled 757869 pages (at 248 pages/min), scraped 658853 items (at 195 items/min)
2017-11-06 07:29:03 [scrapy.extensions.logstats] INFO: Crawled 758111 pages (at 242 pages/min), scraped 659050 items (at 197 items/min)
2017-11-06 07:30:03 [scrapy.extensions.logstats] INFO: Crawled 758355 pages (at 244 pages/min), scraped 659234 items (at 184 items/min)
2017-11-06 07:30:15 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29961275&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"卢伟权","SCO_NAME":"男","ECO_NAME":"大专","AOI_NAME":"广发证券股份有限公司","AOI_ID":"1999026","ADI_ID":"46304","ADI_NAME":"东莞虎门证券营业部","PTI_NAME":"证券经纪业务营销","CER_NUM":"S0260309090865","OBTAIN_DATE":"2009-09-17","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 07:31:03 [scrapy.extensions.logstats] INFO: Crawled 758600 pages (at 245 pages/min), scraped 659418 items (at 184 items/min)
2017-11-06 07:32:03 [scrapy.extensions.logstats] INFO: Crawled 758846 pages (at 246 pages/min), scraped 659619 items (at 201 items/min)
2017-11-06 07:33:03 [scrapy.extensions.logstats] INFO: Crawled 759090 pages (at 244 pages/min), scraped 659830 items (at 211 items/min)
2017-11-06 07:34:03 [scrapy.extensions.logstats] INFO: Crawled 759328 pages (at 238 pages/min), scraped 660030 items (at 200 items/min)
2017-11-06 07:35:03 [scrapy.extensions.logstats] INFO: Crawled 759574 pages (at 246 pages/min), scraped 660242 items (at 212 items/min)
2017-11-06 07:36:03 [scrapy.extensions.logstats] INFO: Crawled 759819 pages (at 245 pages/min), scraped 660440 items (at 198 items/min)
2017-11-06 07:37:03 [scrapy.extensions.logstats] INFO: Crawled 760064 pages (at 245 pages/min), scraped 660636 items (at 196 items/min)
2017-11-06 07:38:03 [scrapy.extensions.logstats] INFO: Crawled 760307 pages (at 243 pages/min), scraped 660841 items (at 205 items/min)
2017-11-06 07:39:03 [scrapy.extensions.logstats] INFO: Crawled 760551 pages (at 244 pages/min), scraped 661045 items (at 204 items/min)
2017-11-06 07:40:03 [scrapy.extensions.logstats] INFO: Crawled 760795 pages (at 244 pages/min), scraped 661259 items (at 214 items/min)
2017-11-06 07:41:03 [scrapy.extensions.logstats] INFO: Crawled 761037 pages (at 242 pages/min), scraped 661503 items (at 244 items/min)
2017-11-06 07:42:03 [scrapy.extensions.logstats] INFO: Crawled 761279 pages (at 242 pages/min), scraped 661751 items (at 248 items/min)
2017-11-06 07:43:03 [scrapy.extensions.logstats] INFO: Crawled 761524 pages (at 245 pages/min), scraped 662022 items (at 271 items/min)
2017-11-06 07:44:03 [scrapy.extensions.logstats] INFO: Crawled 761771 pages (at 247 pages/min), scraped 662317 items (at 295 items/min)
2017-11-06 07:45:03 [scrapy.extensions.logstats] INFO: Crawled 762016 pages (at 245 pages/min), scraped 662535 items (at 218 items/min)
2017-11-06 07:46:03 [scrapy.extensions.logstats] INFO: Crawled 762261 pages (at 245 pages/min), scraped 662745 items (at 210 items/min)
2017-11-06 07:47:03 [scrapy.extensions.logstats] INFO: Crawled 762502 pages (at 241 pages/min), scraped 662982 items (at 237 items/min)
2017-11-06 07:48:03 [scrapy.extensions.logstats] INFO: Crawled 762751 pages (at 249 pages/min), scraped 663248 items (at 266 items/min)
2017-11-06 07:49:03 [scrapy.extensions.logstats] INFO: Crawled 762992 pages (at 241 pages/min), scraped 663464 items (at 216 items/min)
2017-11-06 07:50:03 [scrapy.extensions.logstats] INFO: Crawled 763237 pages (at 245 pages/min), scraped 663701 items (at 237 items/min)
2017-11-06 07:51:03 [scrapy.extensions.logstats] INFO: Crawled 763481 pages (at 244 pages/min), scraped 663917 items (at 216 items/min)
2017-11-06 07:52:03 [scrapy.extensions.logstats] INFO: Crawled 763727 pages (at 246 pages/min), scraped 664153 items (at 236 items/min)
2017-11-06 07:53:03 [scrapy.extensions.logstats] INFO: Crawled 763973 pages (at 246 pages/min), scraped 664365 items (at 212 items/min)
2017-11-06 07:54:03 [scrapy.extensions.logstats] INFO: Crawled 764214 pages (at 241 pages/min), scraped 664604 items (at 239 items/min)
2017-11-06 07:55:03 [scrapy.extensions.logstats] INFO: Crawled 764456 pages (at 242 pages/min), scraped 664841 items (at 237 items/min)
2017-11-06 07:56:03 [scrapy.extensions.logstats] INFO: Crawled 764704 pages (at 248 pages/min), scraped 665071 items (at 230 items/min)
2017-11-06 07:57:03 [scrapy.extensions.logstats] INFO: Crawled 764951 pages (at 247 pages/min), scraped 665308 items (at 237 items/min)
2017-11-06 07:58:03 [scrapy.extensions.logstats] INFO: Crawled 765199 pages (at 248 pages/min), scraped 665554 items (at 246 items/min)
2017-11-06 07:59:03 [scrapy.extensions.logstats] INFO: Crawled 765445 pages (at 246 pages/min), scraped 665845 items (at 291 items/min)
2017-11-06 08:00:03 [scrapy.extensions.logstats] INFO: Crawled 765688 pages (at 243 pages/min), scraped 666065 items (at 220 items/min)
2017-11-06 08:01:03 [scrapy.extensions.logstats] INFO: Crawled 765931 pages (at 243 pages/min), scraped 666286 items (at 221 items/min)
2017-11-06 08:02:03 [scrapy.extensions.logstats] INFO: Crawled 766173 pages (at 242 pages/min), scraped 666501 items (at 215 items/min)
2017-11-06 08:03:03 [scrapy.extensions.logstats] INFO: Crawled 766420 pages (at 247 pages/min), scraped 666739 items (at 238 items/min)
2017-11-06 08:04:03 [scrapy.extensions.logstats] INFO: Crawled 766663 pages (at 243 pages/min), scraped 666952 items (at 213 items/min)
2017-11-06 08:05:03 [scrapy.extensions.logstats] INFO: Crawled 766912 pages (at 249 pages/min), scraped 667168 items (at 216 items/min)
2017-11-06 08:06:03 [scrapy.extensions.logstats] INFO: Crawled 767155 pages (at 243 pages/min), scraped 667387 items (at 219 items/min)
2017-11-06 08:07:03 [scrapy.extensions.logstats] INFO: Crawled 767394 pages (at 239 pages/min), scraped 667591 items (at 204 items/min)
2017-11-06 08:08:03 [scrapy.extensions.logstats] INFO: Crawled 767646 pages (at 252 pages/min), scraped 667816 items (at 225 items/min)
2017-11-06 08:09:03 [scrapy.extensions.logstats] INFO: Crawled 767887 pages (at 241 pages/min), scraped 668019 items (at 203 items/min)
2017-11-06 08:10:03 [scrapy.extensions.logstats] INFO: Crawled 768134 pages (at 247 pages/min), scraped 668251 items (at 232 items/min)
2017-11-06 08:11:03 [scrapy.extensions.logstats] INFO: Crawled 768373 pages (at 239 pages/min), scraped 668466 items (at 215 items/min)
2017-11-06 08:12:03 [scrapy.extensions.logstats] INFO: Crawled 768617 pages (at 244 pages/min), scraped 668689 items (at 223 items/min)
2017-11-06 08:13:03 [scrapy.extensions.logstats] INFO: Crawled 768858 pages (at 241 pages/min), scraped 668911 items (at 222 items/min)
2017-11-06 08:14:03 [scrapy.extensions.logstats] INFO: Crawled 769100 pages (at 242 pages/min), scraped 669126 items (at 215 items/min)
2017-11-06 08:15:03 [scrapy.extensions.logstats] INFO: Crawled 769345 pages (at 245 pages/min), scraped 669370 items (at 244 items/min)
2017-11-06 08:16:03 [scrapy.extensions.logstats] INFO: Crawled 769581 pages (at 236 pages/min), scraped 669601 items (at 231 items/min)
2017-11-06 08:17:03 [scrapy.extensions.logstats] INFO: Crawled 769824 pages (at 243 pages/min), scraped 669855 items (at 254 items/min)
2017-11-06 08:18:03 [scrapy.extensions.logstats] INFO: Crawled 770068 pages (at 244 pages/min), scraped 670091 items (at 236 items/min)
2017-11-06 08:19:03 [scrapy.extensions.logstats] INFO: Crawled 770310 pages (at 242 pages/min), scraped 670328 items (at 237 items/min)
2017-11-06 08:20:03 [scrapy.extensions.logstats] INFO: Crawled 770553 pages (at 243 pages/min), scraped 670603 items (at 275 items/min)
2017-11-06 08:21:03 [scrapy.extensions.logstats] INFO: Crawled 770794 pages (at 241 pages/min), scraped 670820 items (at 217 items/min)
2017-11-06 08:22:03 [scrapy.extensions.logstats] INFO: Crawled 771034 pages (at 240 pages/min), scraped 671037 items (at 217 items/min)
2017-11-06 08:23:03 [scrapy.extensions.logstats] INFO: Crawled 771279 pages (at 245 pages/min), scraped 671234 items (at 197 items/min)
2017-11-06 08:23:09 [py.warnings] WARNING: F:\gitwork\pipeline.py:131: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg("sql is:%s/n reason is :%s"%(sql,e))

2017-11-06 08:23:09 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('777','中原证券股份有限公司上海第一分公司','证券经纪；证券投资咨询；与证券交易、证券投资活动有关的财务顾问；证券投资基金代销；为期货公司提供中间介绍业务；融资融券业务；代销金融产品业务；证券承销与保荐（项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）。','95377','上海市市辖区虹口区大连西路261号','沈若蔚','2017-11-06 08:23:09','2017-11-06 08:23:09')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:03 [scrapy.extensions.logstats] INFO: Crawled 771531 pages (at 252 pages/min), scraped 671499 items (at 265 items/min)
2017-11-06 08:24:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('782','中银国际证券有限责任公司武汉分公司','证券经纪；证券投资咨询；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券；证券投资基金代销；代销金融产品。','027-82602808','湖北省武汉市江岸区黄孝河路148号2楼','熊春林','2017-11-06 08:24:25','2017-11-06 08:24:25')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司浙江分公司','证券经纪；证券投资咨询；证券投资基金代销；融资融券；代销金融产品；与证券交易、证券投资活动有关的财务顾问；为期货公司提供中间介绍业务；证券承销与保荐（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）。','95548','浙江省杭州市江干区迪凯银座2201、2202、2203、2204室','李勇进','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司温州分公司','证券经纪；证券投资咨询；证券投资基金代销；融资融券；代销金融产品；与证券交易、证券投资活动有关的财务顾问；为期货公司提供中间介绍业务；证券承销与保荐（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）','95548','浙江省温州市鹿城区车站大道577号财富中心701、702、703室','杨巧武','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司陕西分公司','证券经纪（经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；证券投资咨询（仅限证券投资顾问业务，经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限新三板业务、中小企业私募债、资产证券化业务）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券（客户关系维护、发展客户开展业务等）；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品。','029-88235329','陕西省西安市雁塔区新区科技路27号E阳国际大厦1幢11301室','孙家渝','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司深圳分公司','证券经纪（经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；证券投资咨询（仅限证券投资顾问业务，经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限新三板业务、中小企业私募债、资产证券化业务）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券（客户关系维护、发展客户开展业务等）；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品。','0755-23911600','广东省深圳市福田区中心三路8号中信证券大厦12楼','尹红卫','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份限公司山西分公司','证券经纪（经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；证券投资咨询（仅限证券投资顾问业务，经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限新三板业务、中小企业私募债、资产证券化业务）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券（客户关系维护、发展客户开展业务等）；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品。','03516191968','山西省太原市万柏林区迎泽西大街100号国际能源中心四层','郑文慧','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司东北分公司','证券经纪（经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；证券投资咨询（仅限证券投资顾问业务，经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限新三板业务、中小企业私募债、资产证券化业务）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券（客户关系维护、发展客户开展业务等）；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品（依法须经批准的项目，经相关部门批准后方可开展经营活动）。','024-88598858','辽宁省沈阳市沈河区奉天街335号','许鑫','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司云南分公司','证券经纪；证券投资咨询的投资顾问；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐的项目承揽、项目信息传递与推介、客户关系维护等辅助工作；证券资产管理的项目承揽、项目信息传递与推介、客户关系维护等辅助工作；融资融券；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品。','0871-68178677','云南省昆明市西山区环城西路弥勒寺新村华海新境界商务大厦2幢11层（1101、1102房）','张蕊','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司安徽分公司','证券经纪；证券投资咨询；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品。','0551-65662907','安徽省合肥市庐阳区濉溪路287号金鼎广场A座1-商101,1-701-708室','吴剑峰','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:24:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司湖北分公司','"证券经纪（经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；证券投资咨询（仅限证券投资顾问业务，经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限新三板业务、中小企业私募债、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券（客户关系维护、发展客户开展业务等）；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品；管理所辖地区的证券营业部。（经营期限与许可证核定的期限一直）（国家有专项规定的项目经审批后或凭许可证在核定的期限内方可经营"','027-85621877','湖北省武汉市江汉区建设大道737号广发银行大厦51层','石想荣','2017-11-06 08:24:27','2017-11-06 08:24:27')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 08:25:03 [scrapy.extensions.logstats] INFO: Crawled 771799 pages (at 268 pages/min), scraped 671919 items (at 420 items/min)
2017-11-06 08:26:03 [scrapy.extensions.logstats] INFO: Crawled 772043 pages (at 244 pages/min), scraped 672139 items (at 220 items/min)
2017-11-06 08:27:03 [scrapy.extensions.logstats] INFO: Crawled 772285 pages (at 242 pages/min), scraped 672358 items (at 219 items/min)
2017-11-06 08:28:03 [scrapy.extensions.logstats] INFO: Crawled 772531 pages (at 246 pages/min), scraped 672592 items (at 234 items/min)
2017-11-06 08:29:03 [scrapy.extensions.logstats] INFO: Crawled 772770 pages (at 239 pages/min), scraped 672814 items (at 222 items/min)
2017-11-06 08:30:03 [scrapy.extensions.logstats] INFO: Crawled 773018 pages (at 248 pages/min), scraped 673039 items (at 225 items/min)
2017-11-06 08:31:03 [scrapy.extensions.logstats] INFO: Crawled 773260 pages (at 242 pages/min), scraped 673275 items (at 236 items/min)
2017-11-06 08:32:03 [scrapy.extensions.logstats] INFO: Crawled 773504 pages (at 244 pages/min), scraped 673518 items (at 243 items/min)
2017-11-06 08:33:03 [scrapy.extensions.logstats] INFO: Crawled 773751 pages (at 247 pages/min), scraped 673747 items (at 229 items/min)
2017-11-06 08:34:03 [scrapy.extensions.logstats] INFO: Crawled 773992 pages (at 241 pages/min), scraped 673972 items (at 225 items/min)
2017-11-06 08:35:03 [scrapy.extensions.logstats] INFO: Crawled 774232 pages (at 240 pages/min), scraped 674202 items (at 230 items/min)
2017-11-06 08:36:03 [scrapy.extensions.logstats] INFO: Crawled 774469 pages (at 237 pages/min), scraped 674426 items (at 224 items/min)
2017-11-06 08:37:03 [scrapy.extensions.logstats] INFO: Crawled 774710 pages (at 241 pages/min), scraped 674646 items (at 220 items/min)
2017-11-06 08:38:03 [scrapy.extensions.logstats] INFO: Crawled 774959 pages (at 249 pages/min), scraped 674884 items (at 238 items/min)
2017-11-06 08:39:03 [scrapy.extensions.logstats] INFO: Crawled 775202 pages (at 243 pages/min), scraped 675117 items (at 233 items/min)
2017-11-06 08:40:03 [scrapy.extensions.logstats] INFO: Crawled 775443 pages (at 241 pages/min), scraped 675357 items (at 240 items/min)
2017-11-06 08:41:03 [scrapy.extensions.logstats] INFO: Crawled 775687 pages (at 244 pages/min), scraped 675575 items (at 218 items/min)
2017-11-06 08:42:03 [scrapy.extensions.logstats] INFO: Crawled 775934 pages (at 247 pages/min), scraped 675836 items (at 261 items/min)
2017-11-06 08:43:03 [scrapy.extensions.logstats] INFO: Crawled 776176 pages (at 242 pages/min), scraped 676082 items (at 246 items/min)
2017-11-06 08:44:03 [scrapy.extensions.logstats] INFO: Crawled 776412 pages (at 236 pages/min), scraped 676287 items (at 205 items/min)
2017-11-06 08:45:03 [scrapy.extensions.logstats] INFO: Crawled 776605 pages (at 193 pages/min), scraped 676459 items (at 172 items/min)
2017-11-06 08:46:03 [scrapy.extensions.logstats] INFO: Crawled 776808 pages (at 203 pages/min), scraped 676640 items (at 181 items/min)
2017-11-06 08:47:03 [scrapy.extensions.logstats] INFO: Crawled 777020 pages (at 212 pages/min), scraped 676845 items (at 205 items/min)
2017-11-06 08:48:04 [scrapy.extensions.logstats] INFO: Crawled 777201 pages (at 181 pages/min), scraped 677020 items (at 175 items/min)
2017-11-06 08:49:03 [scrapy.extensions.logstats] INFO: Crawled 777397 pages (at 196 pages/min), scraped 677233 items (at 213 items/min)
2017-11-06 08:50:05 [scrapy.extensions.logstats] INFO: Crawled 777608 pages (at 211 pages/min), scraped 677441 items (at 208 items/min)
2017-11-06 08:51:03 [scrapy.extensions.logstats] INFO: Crawled 777735 pages (at 127 pages/min), scraped 677557 items (at 116 items/min)
2017-11-06 08:52:04 [scrapy.extensions.logstats] INFO: Crawled 777970 pages (at 235 pages/min), scraped 677784 items (at 227 items/min)
2017-11-06 08:53:03 [scrapy.extensions.logstats] INFO: Crawled 778178 pages (at 208 pages/min), scraped 677973 items (at 189 items/min)
2017-11-06 08:54:03 [scrapy.extensions.logstats] INFO: Crawled 778384 pages (at 206 pages/min), scraped 678167 items (at 194 items/min)
2017-11-06 08:55:03 [scrapy.extensions.logstats] INFO: Crawled 778600 pages (at 216 pages/min), scraped 678365 items (at 198 items/min)
2017-11-06 08:56:03 [scrapy.extensions.logstats] INFO: Crawled 778812 pages (at 212 pages/min), scraped 678558 items (at 193 items/min)
2017-11-06 08:57:03 [scrapy.extensions.logstats] INFO: Crawled 779035 pages (at 223 pages/min), scraped 678768 items (at 210 items/min)
2017-11-06 08:58:03 [scrapy.extensions.logstats] INFO: Crawled 779257 pages (at 222 pages/min), scraped 678994 items (at 226 items/min)
2017-11-06 08:59:03 [scrapy.extensions.logstats] INFO: Crawled 779461 pages (at 204 pages/min), scraped 679189 items (at 195 items/min)
2017-11-06 09:00:03 [scrapy.extensions.logstats] INFO: Crawled 779693 pages (at 232 pages/min), scraped 679411 items (at 222 items/min)
2017-11-06 09:01:05 [scrapy.extensions.logstats] INFO: Crawled 779915 pages (at 222 pages/min), scraped 679608 items (at 197 items/min)
2017-11-06 09:02:03 [scrapy.extensions.logstats] INFO: Crawled 780143 pages (at 228 pages/min), scraped 679813 items (at 205 items/min)
2017-11-06 09:03:03 [scrapy.extensions.logstats] INFO: Crawled 780352 pages (at 209 pages/min), scraped 680008 items (at 195 items/min)
2017-11-06 09:04:04 [scrapy.extensions.logstats] INFO: Crawled 780422 pages (at 70 pages/min), scraped 680071 items (at 63 items/min)
2017-11-06 09:05:04 [scrapy.extensions.logstats] INFO: Crawled 780525 pages (at 103 pages/min), scraped 680171 items (at 100 items/min)
2017-11-06 09:06:03 [scrapy.extensions.logstats] INFO: Crawled 780584 pages (at 59 pages/min), scraped 680231 items (at 60 items/min)
2017-11-06 09:07:06 [scrapy.extensions.logstats] INFO: Crawled 780670 pages (at 86 pages/min), scraped 680312 items (at 81 items/min)
2017-11-06 09:08:03 [scrapy.extensions.logstats] INFO: Crawled 780866 pages (at 196 pages/min), scraped 680498 items (at 186 items/min)
2017-11-06 09:09:03 [scrapy.extensions.logstats] INFO: Crawled 781077 pages (at 211 pages/min), scraped 680661 items (at 163 items/min)
2017-11-06 09:10:03 [scrapy.extensions.logstats] INFO: Crawled 781210 pages (at 133 pages/min), scraped 680767 items (at 106 items/min)
2017-11-06 09:11:06 [scrapy.extensions.logstats] INFO: Crawled 781282 pages (at 72 pages/min), scraped 680827 items (at 60 items/min)
2017-11-06 09:12:03 [scrapy.extensions.logstats] INFO: Crawled 781380 pages (at 98 pages/min), scraped 680902 items (at 75 items/min)
2017-11-06 09:13:23 [scrapy.extensions.logstats] INFO: Crawled 781421 pages (at 41 pages/min), scraped 680945 items (at 43 items/min)
2017-11-06 09:14:03 [scrapy.extensions.logstats] INFO: Crawled 781523 pages (at 102 pages/min), scraped 681023 items (at 78 items/min)
2017-11-06 09:15:03 [scrapy.extensions.logstats] INFO: Crawled 781721 pages (at 198 pages/min), scraped 681216 items (at 193 items/min)
2017-11-06 09:16:09 [scrapy.extensions.logstats] INFO: Crawled 781747 pages (at 26 pages/min), scraped 681233 items (at 17 items/min)
2017-11-06 09:17:03 [scrapy.extensions.logstats] INFO: Crawled 781837 pages (at 90 pages/min), scraped 681315 items (at 82 items/min)
2017-11-06 09:18:03 [scrapy.extensions.logstats] INFO: Crawled 782051 pages (at 214 pages/min), scraped 681488 items (at 173 items/min)
2017-11-06 09:19:03 [scrapy.extensions.logstats] INFO: Crawled 782265 pages (at 214 pages/min), scraped 681672 items (at 184 items/min)
2017-11-06 09:20:03 [scrapy.extensions.logstats] INFO: Crawled 782479 pages (at 214 pages/min), scraped 681852 items (at 180 items/min)
2017-11-06 09:21:03 [scrapy.extensions.logstats] INFO: Crawled 782686 pages (at 207 pages/min), scraped 682031 items (at 179 items/min)
2017-11-06 09:22:05 [scrapy.extensions.logstats] INFO: Crawled 782915 pages (at 229 pages/min), scraped 682218 items (at 187 items/min)
2017-11-06 09:23:03 [scrapy.extensions.logstats] INFO: Crawled 783142 pages (at 227 pages/min), scraped 682416 items (at 198 items/min)
2017-11-06 09:24:03 [scrapy.extensions.logstats] INFO: Crawled 783360 pages (at 218 pages/min), scraped 682609 items (at 193 items/min)
2017-11-06 09:25:03 [scrapy.extensions.logstats] INFO: Crawled 783569 pages (at 209 pages/min), scraped 682799 items (at 190 items/min)
2017-11-06 09:26:03 [scrapy.extensions.logstats] INFO: Crawled 783786 pages (at 217 pages/min), scraped 683012 items (at 213 items/min)
2017-11-06 09:26:38 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=39901573&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"诸鸣","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"光大证券股份有限公司","AOI_ID":"1999093","ADI_ID":"10450","ADI_NAME":"上海宝山牡丹江路证券营业部","PTI_NAME":"一般证券业务","CER_NUM":"S0930107111991","OBTAIN_DATE":"2007-11-20","ARRIVE_DATE":"2019-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 09:27:03 [scrapy.extensions.logstats] INFO: Crawled 783998 pages (at 212 pages/min), scraped 683217 items (at 205 items/min)
2017-11-06 09:28:03 [scrapy.extensions.logstats] INFO: Crawled 784195 pages (at 197 pages/min), scraped 683396 items (at 179 items/min)
2017-11-06 09:29:03 [scrapy.extensions.logstats] INFO: Crawled 784414 pages (at 219 pages/min), scraped 683606 items (at 210 items/min)
2017-11-06 09:30:03 [scrapy.extensions.logstats] INFO: Crawled 784631 pages (at 217 pages/min), scraped 683816 items (at 210 items/min)
2017-11-06 09:31:03 [scrapy.extensions.logstats] INFO: Crawled 784846 pages (at 215 pages/min), scraped 684023 items (at 207 items/min)
2017-11-06 09:32:04 [scrapy.extensions.logstats] INFO: Crawled 785059 pages (at 213 pages/min), scraped 684226 items (at 203 items/min)
2017-11-06 09:33:03 [scrapy.extensions.logstats] INFO: Crawled 785303 pages (at 244 pages/min), scraped 684451 items (at 225 items/min)
2017-11-06 09:34:03 [scrapy.extensions.logstats] INFO: Crawled 785530 pages (at 227 pages/min), scraped 684676 items (at 225 items/min)
2017-11-06 09:35:03 [scrapy.extensions.logstats] INFO: Crawled 785735 pages (at 205 pages/min), scraped 684899 items (at 223 items/min)
2017-11-06 09:36:03 [scrapy.extensions.logstats] INFO: Crawled 785938 pages (at 203 pages/min), scraped 685101 items (at 202 items/min)
2017-11-06 09:37:03 [scrapy.extensions.logstats] INFO: Crawled 786142 pages (at 204 pages/min), scraped 685290 items (at 189 items/min)
2017-11-06 09:38:03 [scrapy.extensions.logstats] INFO: Crawled 786349 pages (at 207 pages/min), scraped 685489 items (at 199 items/min)
2017-11-06 09:39:03 [scrapy.extensions.logstats] INFO: Crawled 786565 pages (at 216 pages/min), scraped 685685 items (at 196 items/min)
2017-11-06 09:40:03 [scrapy.extensions.logstats] INFO: Crawled 786769 pages (at 204 pages/min), scraped 685866 items (at 181 items/min)
2017-11-06 09:41:03 [scrapy.extensions.logstats] INFO: Crawled 786981 pages (at 212 pages/min), scraped 686068 items (at 202 items/min)
2017-11-06 09:42:04 [scrapy.extensions.logstats] INFO: Crawled 787199 pages (at 218 pages/min), scraped 686278 items (at 210 items/min)
2017-11-06 09:43:03 [scrapy.extensions.logstats] INFO: Crawled 787427 pages (at 228 pages/min), scraped 686513 items (at 235 items/min)
2017-11-06 09:44:03 [scrapy.extensions.logstats] INFO: Crawled 787639 pages (at 212 pages/min), scraped 686729 items (at 216 items/min)
2017-11-06 09:45:03 [scrapy.extensions.logstats] INFO: Crawled 787854 pages (at 215 pages/min), scraped 686929 items (at 200 items/min)
2017-11-06 09:46:03 [scrapy.extensions.logstats] INFO: Crawled 788064 pages (at 210 pages/min), scraped 687123 items (at 194 items/min)
2017-11-06 09:47:03 [scrapy.extensions.logstats] INFO: Crawled 788287 pages (at 223 pages/min), scraped 687358 items (at 235 items/min)
2017-11-06 09:48:03 [scrapy.extensions.logstats] INFO: Crawled 788491 pages (at 204 pages/min), scraped 687570 items (at 212 items/min)
2017-11-06 09:49:03 [scrapy.extensions.logstats] INFO: Crawled 788708 pages (at 217 pages/min), scraped 687796 items (at 226 items/min)
2017-11-06 09:50:03 [scrapy.extensions.logstats] INFO: Crawled 788915 pages (at 207 pages/min), scraped 687997 items (at 201 items/min)
2017-11-06 09:51:03 [scrapy.extensions.logstats] INFO: Crawled 789117 pages (at 202 pages/min), scraped 688203 items (at 206 items/min)
2017-11-06 09:52:04 [scrapy.extensions.logstats] INFO: Crawled 789336 pages (at 219 pages/min), scraped 688435 items (at 232 items/min)
2017-11-06 09:53:11 [scrapy.extensions.logstats] INFO: Crawled 789571 pages (at 235 pages/min), scraped 688667 items (at 232 items/min)
2017-11-06 09:54:03 [scrapy.extensions.logstats] INFO: Crawled 789768 pages (at 197 pages/min), scraped 688859 items (at 192 items/min)
2017-11-06 09:55:03 [scrapy.extensions.logstats] INFO: Crawled 789981 pages (at 213 pages/min), scraped 689068 items (at 209 items/min)
2017-11-06 09:56:03 [scrapy.extensions.logstats] INFO: Crawled 790184 pages (at 203 pages/min), scraped 689273 items (at 205 items/min)
2017-11-06 09:57:03 [scrapy.extensions.logstats] INFO: Crawled 790412 pages (at 228 pages/min), scraped 689505 items (at 232 items/min)
2017-11-06 09:58:03 [scrapy.extensions.logstats] INFO: Crawled 790626 pages (at 214 pages/min), scraped 689723 items (at 218 items/min)
2017-11-06 09:59:03 [scrapy.extensions.logstats] INFO: Crawled 790855 pages (at 229 pages/min), scraped 689937 items (at 214 items/min)
2017-11-06 10:00:03 [scrapy.extensions.logstats] INFO: Crawled 791068 pages (at 213 pages/min), scraped 690119 items (at 182 items/min)
2017-11-06 10:01:03 [scrapy.extensions.logstats] INFO: Crawled 791299 pages (at 231 pages/min), scraped 690345 items (at 226 items/min)
2017-11-06 10:02:03 [scrapy.extensions.logstats] INFO: Crawled 791532 pages (at 233 pages/min), scraped 690579 items (at 234 items/min)
2017-11-06 10:03:08 [scrapy.extensions.logstats] INFO: Crawled 791767 pages (at 235 pages/min), scraped 690834 items (at 255 items/min)
2017-11-06 10:04:03 [scrapy.extensions.logstats] INFO: Crawled 791974 pages (at 207 pages/min), scraped 691048 items (at 214 items/min)
2017-11-06 10:05:03 [scrapy.extensions.logstats] INFO: Crawled 792184 pages (at 210 pages/min), scraped 691271 items (at 223 items/min)
2017-11-06 10:06:03 [scrapy.extensions.logstats] INFO: Crawled 792398 pages (at 214 pages/min), scraped 691476 items (at 205 items/min)
2017-11-06 10:07:03 [scrapy.extensions.logstats] INFO: Crawled 792609 pages (at 211 pages/min), scraped 691689 items (at 213 items/min)
2017-11-06 10:07:08 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29980136&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"王骁","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"光大证券股份有限公司","AOI_ID":"1999093","ADI_ID":"26111","ADI_NAME":"武汉新华路证券营业部","PTI_NAME":"证券经纪人","CER_NUM":"S0930412120103","OBTAIN_DATE":"2012-12-12","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 10:07:14 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29981289&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"刘玉峰","SCO_NAME":"男","ECO_NAME":"本科","AOI_NAME":"光大证券股份有限公司","AOI_ID":"1999093","ADI_ID":"26111","ADI_NAME":"武汉新华路证券营业部","PTI_NAME":"证券经纪人","CER_NUM":"S0930412120107","OBTAIN_DATE":"2012-12-12","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 10:08:03 [scrapy.extensions.logstats] INFO: Crawled 792824 pages (at 215 pages/min), scraped 691934 items (at 245 items/min)
2017-11-06 10:09:03 [scrapy.extensions.logstats] INFO: Crawled 793024 pages (at 200 pages/min), scraped 692177 items (at 243 items/min)
2017-11-06 10:09:34 [scrapy.log] INFO: http://person.sac.net.cn/pages/registration/train-line-register!search.action?filter_EQS_RPI_ID=29971985&sqlkey=registration&sqlval=SELECT_PERSON_INFO[{"RPI_PHOTO_PATH":null,"RPI_NAME":"顾天怡","SCO_NAME":"女","ECO_NAME":"本科","AOI_NAME":"高盛高华证券有限责任公司","AOI_ID":"1999143","ADI_ID":"15468","ADI_NAME":"投资银行部","PTI_NAME":"一般证券业务","CER_NUM":"S1430110100001","OBTAIN_DATE":"2010-10-21","ARRIVE_DATE":"2017-12-31","CERTC_ID":"00","CERTC_NAME":null}]
2017-11-06 10:10:03 [scrapy.extensions.logstats] INFO: Crawled 793257 pages (at 233 pages/min), scraped 692399 items (at 222 items/min)
2017-11-06 10:11:03 [scrapy.extensions.logstats] INFO: Crawled 793454 pages (at 197 pages/min), scraped 692603 items (at 204 items/min)
2017-11-06 10:12:03 [scrapy.extensions.logstats] INFO: Crawled 793658 pages (at 204 pages/min), scraped 692881 items (at 278 items/min)
2017-11-06 10:12:10 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司北京分公司','证券经纪（经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；证券投资咨询（仅限证券投资顾问业务，经营业务区域与中信证券股份有限公司《经营证券业务许可证》一致）；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限新三板业务、中小企业私募债、资产证券化业务）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；融资融券（客户关系维护、发展客户开展业务等）；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品；管理北京的证券营业部','010-65648685','北京市市辖区东城区建国门北大街5号4层401室','毛克勤','2017-11-06 10:12:10','2017-11-06 10:12:10')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:12:10 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司湖南分公司','证券经纪；证券投资咨询；证券投资基金代销；为期货公司提供中间介绍业务；融资融券；与证券交易、证券投资活动有关的财务顾问；代销金融产品；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券承销与保荐（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）','0731-85362597','湖南省长沙市芙蓉区芙蓉中路二段198号新世纪大厦二楼','陈可可','2017-11-06 10:12:10','2017-11-06 10:12:10')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:12:10 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('736','中信证券股份有限公司上海分公司','证券经纪（限山东省、河南省、浙江省天台县、浙江省苍南县以外区域）；证券投资咨询；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（限承揽）；证券资产管理（限承揽）；融资融券；证券投资基金代销；为期货公司提供中间介绍业务；代销金融产品。【依法须经批准的项目，经相关部门批准后方可开展经营活动】','021-61768635','上海市市辖区浦东新区世纪大道1568号8层（实际楼层7层）01、06、07单元），10层（实际楼层9层）01-03A、07单元','汪丽华','2017-11-06 10:12:10','2017-11-06 10:12:10')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:12:15 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('737','中信建投证券股份有限公司沈阳分公司','证券经纪；证券投资咨询；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券投资基金代销；为期货公司提供中间介绍业务；融资融券业务；代销金融产品业务。','024-24850036','辽宁省沈阳市沈河区北站路61号12层1号','张昕','2017-11-06 10:12:15','2017-11-06 10:12:15')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:12:16 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('737','中信建投证券股份有限公司天津分公司','证券经纪；证券投资咨询；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券投资基金代销；为期货公司提供中间介绍业务；融资融券业务；代销金融产品业务。','022-23660571','天津市市辖区南开区育梁道26号天津理工大学国际交流中心国交中心南楼201室','李志山','2017-11-06 10:12:16','2017-11-06 10:12:16')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:12:16 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('737','中信建投证券股份有限公司湖北分公司','证券经纪；证券投资咨询；与证券交易、证券投资活动有关的财务顾问；证券承销与保荐（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；证券投资基金代销；为期货公司提供中间介绍业务；融资融券业务；代销金融产品业务。','027-87314886','湖北省武汉市武昌区中北路24号龙源大厦A座3层','梁峻','2017-11-06 10:12:16','2017-11-06 10:12:16')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:12:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('751','中泰证券股份有限公司青岛分公司','证券经纪，证券投资咨询，与证券交易、证券投资活动有关的财务顾问，证券承销与保荐，融资融券，证券投资基金代销，代销金融产品（以上须依据证监会的核发的许可证开展经营活动，以上未经金融监管部门批准，不得从事吸收存款、融资担保、代客理财等金融业务）。（依法须经批准的项目，经相关部门批准后方可开展经营活动）','0532-88915770','山东省青岛市崂山区香港东路195号5号楼一层101单元','陈庆之','2017-11-06 10:12:26','2017-11-06 10:12:26')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:13:03 [scrapy.extensions.logstats] INFO: Crawled 793939 pages (at 281 pages/min), scraped 694532 items (at 1651 items/min)
2017-11-06 10:13:13 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('808','中国国际金融股份有限公司上海分公司','管理华东地区（山东省、江苏省、安徽省、浙江省、福建省、江西省、上海市）的证券营业部;经营华东地区（山东省、江苏省、安徽省、浙江省、福建省、江西省、上海市）、华中地区（湖北省、湖南省、河南省）、华南地区（广东省【深圳市除外】、广西壮族自治区、海南省、四川省、云南省、贵州省和重庆市）的证券承销与保荐业务。','021-58796226','上海市市辖区浦东新区陆家嘴环路1233号汇亚大厦32层、29层2901-2903室、2904B室','沈黎','2017-11-06 10:13:13','2017-11-06 10:13:13')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:13:13 [scrapy.log] INFO: sql is:insert into dbo.SAC_BRANCH_Org (orgid,BRANCH_FULL_NAME,BUSINESS_SCOPE,CS_TEL,OFF_ADDRESS,PERSON_IN_CHARGE,AddTime,Checktime) values ('808','中国国际金融股份有限公司上海自贸试验区分公司','人民币特种股票、人民币普通股票、境外发行股票，境内外政府债券、公司债券和企业债券的经纪业务；证券投资基金代销；为期货公司提供中间介绍业务；融资融券业务；代销金融产品业务；投资顾问及其他顾问业务；客户资产管理（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；人民币普通股票、人民币特种股票、境外发行股票，境内外政府债券、公司债券和企业债券的承销业务（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；企业重组、收购与合并顾问（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；项目融资顾问（仅限项目承揽、项目信息传递与推荐、客户关系维护等辅助工作）；基金的发起和管理；同业拆借；外汇买卖','02158796226','上海市市辖区浦东新区中国（上海）自由贸易试验区陆家嘴环路1233号汇亚大厦31层3104A单元','方斌寅','2017-11-06 10:13:13','2017-11-06 10:13:13')/n reason is :(8152, b'String or binary data would be truncated.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n')
2017-11-06 10:14:03 [scrapy.extensions.logstats] INFO: Crawled 794220 pages (at 281 pages/min), scraped 696727 items (at 2195 items/min)
2017-11-06 10:15:03 [scrapy.extensions.logstats] INFO: Crawled 794464 pages (at 244 pages/min), scraped 697163 items (at 436 items/min)
2017-11-06 10:16:03 [scrapy.extensions.logstats] INFO: Crawled 794667 pages (at 203 pages/min), scraped 697371 items (at 208 items/min)
2017-11-06 10:17:03 [scrapy.extensions.logstats] INFO: Crawled 794881 pages (at 214 pages/min), scraped 697581 items (at 210 items/min)
2017-11-06 10:18:03 [scrapy.extensions.logstats] INFO: Crawled 795087 pages (at 206 pages/min), scraped 697771 items (at 190 items/min)
2017-11-06 10:19:03 [scrapy.extensions.logstats] INFO: Crawled 795298 pages (at 211 pages/min), scraped 697966 items (at 195 items/min)
2017-11-06 10:20:04 [scrapy.extensions.logstats] INFO: Crawled 795508 pages (at 210 pages/min), scraped 698154 items (at 188 items/min)
2017-11-06 10:21:04 [scrapy.extensions.logstats] INFO: Crawled 795568 pages (at 60 pages/min), scraped 698209 items (at 55 items/min)
2017-11-06 10:22:03 [scrapy.extensions.logstats] INFO: Crawled 795630 pages (at 62 pages/min), scraped 698274 items (at 65 items/min)
2017-11-06 10:23:05 [scrapy.extensions.logstats] INFO: Crawled 795846 pages (at 216 pages/min), scraped 698489 items (at 215 items/min)
2017-11-06 10:24:03 [scrapy.extensions.logstats] INFO: Crawled 796074 pages (at 228 pages/min), scraped 698707 items (at 218 items/min)
2017-11-06 10:25:03 [scrapy.extensions.logstats] INFO: Crawled 796280 pages (at 206 pages/min), scraped 698902 items (at 195 items/min)
2017-11-06 10:26:03 [scrapy.extensions.logstats] INFO: Crawled 796482 pages (at 202 pages/min), scraped 699097 items (at 195 items/min)
2017-11-06 10:27:03 [scrapy.extensions.logstats] INFO: Crawled 796693 pages (at 211 pages/min), scraped 699304 items (at 207 items/min)
2017-11-06 10:28:03 [scrapy.extensions.logstats] INFO: Crawled 796901 pages (at 208 pages/min), scraped 699502 items (at 198 items/min)
2017-11-06 10:29:03 [scrapy.extensions.logstats] INFO: Crawled 797118 pages (at 217 pages/min), scraped 699704 items (at 202 items/min)
2017-11-06 10:30:03 [scrapy.extensions.logstats] INFO: Crawled 797349 pages (at 231 pages/min), scraped 699913 items (at 209 items/min)
2017-11-06 10:31:03 [scrapy.extensions.logstats] INFO: Crawled 797560 pages (at 211 pages/min), scraped 700101 items (at 188 items/min)
2017-11-06 10:32:03 [scrapy.extensions.logstats] INFO: Crawled 797773 pages (at 213 pages/min), scraped 700311 items (at 210 items/min)
2017-11-06 10:33:03 [scrapy.extensions.logstats] INFO: Crawled 797990 pages (at 217 pages/min), scraped 700528 items (at 217 items/min)
2017-11-06 10:34:04 [scrapy.extensions.logstats] INFO: Crawled 798223 pages (at 233 pages/min), scraped 700755 items (at 227 items/min)
2017-11-06 10:35:03 [scrapy.extensions.logstats] INFO: Crawled 798452 pages (at 229 pages/min), scraped 700972 items (at 217 items/min)
2017-11-06 10:36:03 [scrapy.extensions.logstats] INFO: Crawled 798671 pages (at 219 pages/min), scraped 701189 items (at 217 items/min)
2017-11-06 10:37:03 [scrapy.extensions.logstats] INFO: Crawled 798894 pages (at 223 pages/min), scraped 701401 items (at 212 items/min)
2017-11-06 10:38:03 [scrapy.extensions.logstats] INFO: Crawled 799118 pages (at 224 pages/min), scraped 701603 items (at 202 items/min)
2017-11-06 10:39:03 [scrapy.extensions.logstats] INFO: Crawled 799344 pages (at 226 pages/min), scraped 701808 items (at 205 items/min)
2017-11-06 10:40:03 [scrapy.extensions.logstats] INFO: Crawled 799558 pages (at 214 pages/min), scraped 701993 items (at 185 items/min)
2017-11-06 10:41:03 [scrapy.extensions.logstats] INFO: Crawled 799774 pages (at 216 pages/min), scraped 702198 items (at 205 items/min)
2017-11-06 10:42:03 [scrapy.extensions.logstats] INFO: Crawled 799996 pages (at 222 pages/min), scraped 702402 items (at 204 items/min)
2017-11-06 10:43:03 [scrapy.extensions.logstats] INFO: Crawled 800199 pages (at 203 pages/min), scraped 702583 items (at 181 items/min)
2017-11-06 10:44:04 [scrapy.extensions.logstats] INFO: Crawled 800418 pages (at 219 pages/min), scraped 702769 items (at 186 items/min)
2017-11-06 10:45:03 [scrapy.extensions.logstats] INFO: Crawled 800613 pages (at 195 pages/min), scraped 702941 items (at 172 items/min)
2017-11-06 10:46:05 [scrapy.extensions.logstats] INFO: Crawled 800718 pages (at 105 pages/min), scraped 703043 items (at 102 items/min)
2017-11-06 10:47:03 [scrapy.extensions.logstats] INFO: Crawled 800832 pages (at 114 pages/min), scraped 703135 items (at 92 items/min)
2017-11-06 10:48:03 [scrapy.extensions.logstats] INFO: Crawled 801049 pages (at 217 pages/min), scraped 703330 items (at 195 items/min)
2017-11-06 10:49:05 [scrapy.extensions.logstats] INFO: Crawled 801182 pages (at 133 pages/min), scraped 703435 items (at 105 items/min)
2017-11-06 10:50:06 [scrapy.extensions.logstats] INFO: Crawled 801218 pages (at 36 pages/min), scraped 703465 items (at 30 items/min)
2017-11-06 10:51:23 [scrapy.extensions.logstats] INFO: Crawled 801227 pages (at 9 pages/min), scraped 703480 items (at 15 items/min)
2017-11-06 10:52:05 [scrapy.extensions.logstats] INFO: Crawled 801233 pages (at 6 pages/min), scraped 703485 items (at 5 items/min)
2017-11-06 10:53:06 [scrapy.extensions.logstats] INFO: Crawled 801326 pages (at 93 pages/min), scraped 703557 items (at 72 items/min)
2017-11-06 10:54:05 [scrapy.extensions.logstats] INFO: Crawled 801361 pages (at 35 pages/min), scraped 703584 items (at 27 items/min)
2017-11-06 10:55:05 [scrapy.extensions.logstats] INFO: Crawled 801378 pages (at 17 pages/min), scraped 703593 items (at 9 items/min)
2017-11-06 10:56:09 [scrapy.extensions.logstats] INFO: Crawled 801383 pages (at 5 pages/min), scraped 703599 items (at 6 items/min)
2017-11-06 10:57:06 [scrapy.extensions.logstats] INFO: Crawled 801387 pages (at 4 pages/min), scraped 703604 items (at 5 items/min)
2017-11-06 10:58:03 [scrapy.extensions.logstats] INFO: Crawled 801509 pages (at 122 pages/min), scraped 703712 items (at 108 items/min)
2017-11-06 10:59:18 [scrapy.extensions.logstats] INFO: Crawled 801572 pages (at 63 pages/min), scraped 703760 items (at 48 items/min)
2017-11-06 11:00:18 [scrapy.extensions.logstats] INFO: Crawled 801578 pages (at 6 pages/min), scraped 703766 items (at 6 items/min)
2017-11-06 11:01:05 [scrapy.extensions.logstats] INFO: Crawled 801581 pages (at 3 pages/min), scraped 703770 items (at 4 items/min)
2017-11-06 11:02:07 [scrapy.extensions.logstats] INFO: Crawled 801590 pages (at 9 pages/min), scraped 703775 items (at 5 items/min)
2017-11-06 11:03:07 [scrapy.extensions.logstats] INFO: Crawled 801621 pages (at 31 pages/min), scraped 703801 items (at 26 items/min)
2017-11-06 11:04:06 [scrapy.extensions.logstats] INFO: Crawled 801651 pages (at 30 pages/min), scraped 703837 items (at 36 items/min)
2017-11-06 11:05:14 [scrapy.extensions.logstats] INFO: Crawled 801657 pages (at 6 pages/min), scraped 703842 items (at 5 items/min)
2017-11-06 11:06:03 [scrapy.extensions.logstats] INFO: Crawled 801670 pages (at 13 pages/min), scraped 703847 items (at 5 items/min)
2017-11-06 11:07:07 [scrapy.extensions.logstats] INFO: Crawled 801675 pages (at 5 pages/min), scraped 703853 items (at 6 items/min)
2017-11-06 11:08:10 [scrapy.extensions.logstats] INFO: Crawled 801703 pages (at 28 pages/min), scraped 703883 items (at 30 items/min)
2017-11-06 11:09:10 [scrapy.extensions.logstats] INFO: Crawled 801731 pages (at 28 pages/min), scraped 703910 items (at 27 items/min)
2017-11-06 11:10:04 [scrapy.extensions.logstats] INFO: Crawled 801762 pages (at 31 pages/min), scraped 703937 items (at 27 items/min)
2017-11-06 11:11:12 [scrapy.extensions.logstats] INFO: Crawled 801769 pages (at 7 pages/min), scraped 703945 items (at 8 items/min)
2017-11-06 11:12:06 [scrapy.extensions.logstats] INFO: Crawled 801780 pages (at 11 pages/min), scraped 703950 items (at 5 items/min)
2017-11-06 11:13:04 [scrapy.extensions.logstats] INFO: Crawled 801872 pages (at 92 pages/min), scraped 704030 items (at 80 items/min)
2017-11-06 11:14:03 [scrapy.extensions.logstats] INFO: Crawled 801978 pages (at 106 pages/min), scraped 704114 items (at 84 items/min)
2017-11-06 11:15:04 [scrapy.extensions.logstats] INFO: Crawled 802057 pages (at 79 pages/min), scraped 704185 items (at 71 items/min)
2017-11-06 11:16:04 [scrapy.extensions.logstats] INFO: Crawled 802115 pages (at 58 pages/min), scraped 704229 items (at 44 items/min)
2017-11-06 11:17:05 [scrapy.extensions.logstats] INFO: Crawled 802176 pages (at 61 pages/min), scraped 704288 items (at 59 items/min)
2017-11-06 11:18:03 [scrapy.extensions.logstats] INFO: Crawled 802317 pages (at 141 pages/min), scraped 704417 items (at 129 items/min)
2017-11-06 11:19:05 [scrapy.extensions.logstats] INFO: Crawled 802397 pages (at 80 pages/min), scraped 704478 items (at 61 items/min)
2017-11-06 11:20:03 [scrapy.extensions.logstats] INFO: Crawled 802419 pages (at 22 pages/min), scraped 704497 items (at 19 items/min)
2017-11-06 11:21:09 [scrapy.extensions.logstats] INFO: Crawled 802422 pages (at 3 pages/min), scraped 704503 items (at 6 items/min)
2017-11-06 11:22:05 [scrapy.extensions.logstats] INFO: Crawled 802434 pages (at 12 pages/min), scraped 704510 items (at 7 items/min)
2017-11-06 11:23:03 [scrapy.extensions.logstats] INFO: Crawled 802543 pages (at 109 pages/min), scraped 704592 items (at 82 items/min)
2017-11-06 11:24:03 [scrapy.extensions.logstats] INFO: Crawled 802643 pages (at 100 pages/min), scraped 704688 items (at 96 items/min)
2017-11-06 11:25:04 [scrapy.extensions.logstats] INFO: Crawled 802721 pages (at 78 pages/min), scraped 704757 items (at 69 items/min)
2017-11-06 11:26:04 [scrapy.extensions.logstats] INFO: Crawled 802819 pages (at 98 pages/min), scraped 704849 items (at 92 items/min)
2017-11-06 11:27:04 [scrapy.extensions.logstats] INFO: Crawled 802892 pages (at 73 pages/min), scraped 704918 items (at 69 items/min)
2017-11-06 11:28:03 [scrapy.extensions.logstats] INFO: Crawled 803018 pages (at 126 pages/min), scraped 705014 items (at 96 items/min)
2017-11-06 11:29:03 [scrapy.extensions.logstats] INFO: Crawled 803164 pages (at 146 pages/min), scraped 705160 items (at 146 items/min)
2017-11-06 11:30:03 [scrapy.extensions.logstats] INFO: Crawled 803338 pages (at 174 pages/min), scraped 705303 items (at 143 items/min)
2017-11-06 11:31:05 [scrapy.extensions.logstats] INFO: Crawled 803446 pages (at 108 pages/min), scraped 705390 items (at 87 items/min)
2017-11-06 11:32:03 [scrapy.extensions.logstats] INFO: Crawled 803508 pages (at 62 pages/min), scraped 705452 items (at 62 items/min)
2017-11-06 11:33:03 [scrapy.extensions.logstats] INFO: Crawled 803678 pages (at 170 pages/min), scraped 705602 items (at 150 items/min)
2017-11-06 11:34:03 [scrapy.extensions.logstats] INFO: Crawled 803891 pages (at 213 pages/min), scraped 705789 items (at 187 items/min)
2017-11-06 11:35:09 [scrapy.extensions.logstats] INFO: Crawled 803967 pages (at 76 pages/min), scraped 705857 items (at 68 items/min)
2017-11-06 11:36:13 [scrapy.extensions.logstats] INFO: Crawled 803985 pages (at 18 pages/min), scraped 705869 items (at 12 items/min)
2017-11-06 11:37:04 [scrapy.extensions.logstats] INFO: Crawled 804010 pages (at 25 pages/min), scraped 705890 items (at 21 items/min)
2017-11-06 11:38:03 [scrapy.extensions.logstats] INFO: Crawled 804080 pages (at 70 pages/min), scraped 705966 items (at 76 items/min)
2017-11-06 11:39:04 [scrapy.extensions.logstats] INFO: Crawled 804180 pages (at 100 pages/min), scraped 706045 items (at 79 items/min)
2017-11-06 11:40:03 [scrapy.extensions.logstats] INFO: Crawled 804261 pages (at 81 pages/min), scraped 706120 items (at 75 items/min)
2017-11-06 11:41:06 [scrapy.extensions.logstats] INFO: Crawled 804334 pages (at 73 pages/min), scraped 706176 items (at 56 items/min)
2017-11-06 11:42:04 [scrapy.extensions.logstats] INFO: Crawled 804418 pages (at 84 pages/min), scraped 706248 items (at 72 items/min)
2017-11-06 11:43:03 [scrapy.extensions.logstats] INFO: Crawled 804539 pages (at 121 pages/min), scraped 706359 items (at 111 items/min)
2017-11-06 11:44:04 [scrapy.extensions.logstats] INFO: Crawled 804581 pages (at 42 pages/min), scraped 706393 items (at 34 items/min)
2017-11-06 11:45:03 [scrapy.extensions.logstats] INFO: Crawled 804598 pages (at 17 pages/min), scraped 706416 items (at 23 items/min)
2017-11-06 11:46:06 [scrapy.extensions.logstats] INFO: Crawled 804620 pages (at 22 pages/min), scraped 706432 items (at 16 items/min)
2017-11-06 11:47:06 [scrapy.extensions.logstats] INFO: Crawled 804635 pages (at 15 pages/min), scraped 706448 items (at 16 items/min)
2017-11-06 11:48:05 [scrapy.extensions.logstats] INFO: Crawled 804719 pages (at 84 pages/min), scraped 706526 items (at 78 items/min)
2017-11-06 11:49:04 [scrapy.extensions.logstats] INFO: Crawled 804807 pages (at 88 pages/min), scraped 706607 items (at 81 items/min)
2017-11-06 11:50:03 [scrapy.extensions.logstats] INFO: Crawled 804873 pages (at 66 pages/min), scraped 706683 items (at 76 items/min)
2017-11-06 11:51:03 [scrapy.extensions.logstats] INFO: Crawled 804989 pages (at 116 pages/min), scraped 706782 items (at 99 items/min)
2017-11-06 11:52:05 [scrapy.extensions.logstats] INFO: Crawled 805067 pages (at 78 pages/min), scraped 706854 items (at 72 items/min)
2017-11-06 11:53:03 [scrapy.extensions.logstats] INFO: Crawled 805181 pages (at 114 pages/min), scraped 706951 items (at 97 items/min)
2017-11-06 11:54:04 [scrapy.extensions.logstats] INFO: Crawled 805284 pages (at 103 pages/min), scraped 707033 items (at 82 items/min)
2017-11-06 11:55:03 [scrapy.extensions.logstats] INFO: Crawled 805385 pages (at 101 pages/min), scraped 707124 items (at 91 items/min)
2017-11-06 11:56:03 [scrapy.extensions.logstats] INFO: Crawled 805464 pages (at 79 pages/min), scraped 707197 items (at 73 items/min)
2017-11-06 11:57:04 [scrapy.extensions.logstats] INFO: Crawled 805557 pages (at 93 pages/min), scraped 707292 items (at 95 items/min)
2017-11-06 11:58:03 [scrapy.extensions.logstats] INFO: Crawled 805699 pages (at 142 pages/min), scraped 707433 items (at 141 items/min)
2017-11-06 11:59:05 [scrapy.extensions.logstats] INFO: Crawled 805933 pages (at 234 pages/min), scraped 707668 items (at 235 items/min)
2017-11-06 12:00:03 [scrapy.extensions.logstats] INFO: Crawled 806069 pages (at 136 pages/min), scraped 707800 items (at 132 items/min)
2017-11-06 12:01:04 [scrapy.extensions.logstats] INFO: Crawled 806205 pages (at 136 pages/min), scraped 707927 items (at 127 items/min)
2017-11-06 12:02:04 [scrapy.extensions.logstats] INFO: Crawled 806262 pages (at 57 pages/min), scraped 707981 items (at 54 items/min)
2017-11-06 12:03:03 [scrapy.extensions.logstats] INFO: Crawled 806399 pages (at 137 pages/min), scraped 708100 items (at 119 items/min)
2017-11-06 12:04:04 [scrapy.extensions.logstats] INFO: Crawled 806519 pages (at 120 pages/min), scraped 708182 items (at 82 items/min)
2017-11-06 12:05:03 [scrapy.extensions.logstats] INFO: Crawled 806620 pages (at 101 pages/min), scraped 708247 items (at 65 items/min)
2017-11-06 12:06:04 [scrapy.extensions.logstats] INFO: Crawled 806725 pages (at 105 pages/min), scraped 708315 items (at 68 items/min)
2017-11-06 12:07:03 [scrapy.extensions.logstats] INFO: Crawled 806803 pages (at 78 pages/min), scraped 708372 items (at 57 items/min)
2017-11-06 12:08:03 [scrapy.extensions.logstats] INFO: Crawled 806937 pages (at 134 pages/min), scraped 708465 items (at 93 items/min)
2017-11-06 12:09:03 [scrapy.extensions.logstats] INFO: Crawled 807150 pages (at 213 pages/min), scraped 708615 items (at 150 items/min)
2017-11-06 12:10:03 [scrapy.extensions.logstats] INFO: Crawled 807386 pages (at 236 pages/min), scraped 708773 items (at 158 items/min)
2017-11-06 12:11:03 [scrapy.extensions.logstats] INFO: Crawled 807601 pages (at 215 pages/min), scraped 708929 items (at 156 items/min)
2017-11-06 12:12:03 [scrapy.extensions.logstats] INFO: Crawled 807795 pages (at 194 pages/min), scraped 709075 items (at 146 items/min)
2017-11-06 12:13:03 [scrapy.extensions.logstats] INFO: Crawled 808027 pages (at 232 pages/min), scraped 709233 items (at 158 items/min)
2017-11-06 12:14:03 [scrapy.extensions.logstats] INFO: Crawled 808257 pages (at 230 pages/min), scraped 709382 items (at 149 items/min)
2017-11-06 12:15:03 [scrapy.extensions.logstats] INFO: Crawled 808483 pages (at 226 pages/min), scraped 709557 items (at 175 items/min)
2017-11-06 12:16:03 [scrapy.extensions.logstats] INFO: Crawled 808632 pages (at 149 pages/min), scraped 709665 items (at 108 items/min)
2017-11-06 12:17:03 [scrapy.extensions.logstats] INFO: Crawled 808847 pages (at 215 pages/min), scraped 709828 items (at 163 items/min)
2017-11-06 12:18:06 [scrapy.extensions.logstats] INFO: Crawled 808946 pages (at 99 pages/min), scraped 709897 items (at 69 items/min)
2017-11-06 12:19:08 [scrapy.extensions.logstats] INFO: Crawled 809003 pages (at 57 pages/min), scraped 709934 items (at 37 items/min)
2017-11-06 12:20:03 [scrapy.extensions.logstats] INFO: Crawled 809120 pages (at 117 pages/min), scraped 710014 items (at 80 items/min)
2017-11-06 12:21:03 [scrapy.extensions.logstats] INFO: Crawled 809326 pages (at 206 pages/min), scraped 710167 items (at 153 items/min)
2017-11-06 12:22:03 [scrapy.extensions.logstats] INFO: Crawled 809525 pages (at 199 pages/min), scraped 710327 items (at 160 items/min)
2017-11-06 12:23:03 [scrapy.extensions.logstats] INFO: Crawled 809715 pages (at 190 pages/min), scraped 710522 items (at 195 items/min)
2017-11-06 12:24:03 [scrapy.extensions.logstats] INFO: Crawled 809927 pages (at 212 pages/min), scraped 710754 items (at 232 items/min)
2017-11-06 12:25:03 [scrapy.extensions.logstats] INFO: Crawled 810136 pages (at 209 pages/min), scraped 710946 items (at 192 items/min)
2017-11-06 12:26:03 [scrapy.extensions.logstats] INFO: Crawled 810349 pages (at 213 pages/min), scraped 711160 items (at 214 items/min)
2017-11-06 12:27:03 [scrapy.extensions.logstats] INFO: Crawled 810582 pages (at 233 pages/min), scraped 711375 items (at 215 items/min)
2017-11-06 12:28:08 [scrapy.extensions.logstats] INFO: Crawled 810814 pages (at 232 pages/min), scraped 711581 items (at 206 items/min)
2017-11-06 12:29:03 [scrapy.extensions.logstats] INFO: Crawled 811036 pages (at 222 pages/min), scraped 711782 items (at 201 items/min)
2017-11-06 12:30:03 [scrapy.extensions.logstats] INFO: Crawled 811260 pages (at 224 pages/min), scraped 711992 items (at 210 items/min)
2017-11-06 12:31:03 [scrapy.extensions.logstats] INFO: Crawled 811465 pages (at 205 pages/min), scraped 712179 items (at 187 items/min)
2017-11-06 12:32:03 [scrapy.extensions.logstats] INFO: Crawled 811689 pages (at 224 pages/min), scraped 712374 items (at 195 items/min)
2017-11-06 12:33:03 [scrapy.extensions.logstats] INFO: Crawled 811891 pages (at 202 pages/min), scraped 712572 items (at 198 items/min)
2017-11-06 12:34:03 [scrapy.extensions.logstats] INFO: Crawled 812105 pages (at 214 pages/min), scraped 712744 items (at 172 items/min)
2017-11-06 12:35:03 [scrapy.extensions.logstats] INFO: Crawled 812310 pages (at 205 pages/min), scraped 712903 items (at 159 items/min)
2017-11-06 12:36:03 [scrapy.extensions.logstats] INFO: Crawled 812536 pages (at 226 pages/min), scraped 713096 items (at 193 items/min)
2017-11-06 12:37:03 [scrapy.extensions.logstats] INFO: Crawled 812749 pages (at 213 pages/min), scraped 713281 items (at 185 items/min)
2017-11-06 12:38:08 [scrapy.extensions.logstats] INFO: Crawled 812981 pages (at 232 pages/min), scraped 713459 items (at 178 items/min)
2017-11-06 12:39:03 [scrapy.extensions.logstats] INFO: Crawled 813196 pages (at 215 pages/min), scraped 713630 items (at 171 items/min)
2017-11-06 12:40:03 [scrapy.extensions.logstats] INFO: Crawled 813412 pages (at 216 pages/min), scraped 713811 items (at 181 items/min)
2017-11-06 12:41:03 [scrapy.extensions.logstats] INFO: Crawled 813625 pages (at 213 pages/min), scraped 713992 items (at 181 items/min)
2017-11-06 12:42:03 [scrapy.extensions.logstats] INFO: Crawled 813866 pages (at 241 pages/min), scraped 714194 items (at 202 items/min)
2017-11-06 12:43:03 [scrapy.extensions.logstats] INFO: Crawled 814083 pages (at 217 pages/min), scraped 714364 items (at 170 items/min)
2017-11-06 12:44:03 [scrapy.extensions.logstats] INFO: Crawled 814289 pages (at 206 pages/min), scraped 714523 items (at 159 items/min)
2017-11-06 12:45:03 [scrapy.extensions.logstats] INFO: Crawled 814520 pages (at 231 pages/min), scraped 714723 items (at 200 items/min)
2017-11-06 12:46:03 [scrapy.extensions.logstats] INFO: Crawled 814729 pages (at 209 pages/min), scraped 714881 items (at 158 items/min)
2017-11-06 12:47:03 [scrapy.extensions.logstats] INFO: Crawled 814944 pages (at 215 pages/min), scraped 715050 items (at 169 items/min)
2017-11-06 12:48:05 [scrapy.extensions.logstats] INFO: Crawled 815182 pages (at 238 pages/min), scraped 715252 items (at 202 items/min)
2018-03-08 10:06:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: Sac)
2018-03-08 10:06:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Windows-10-10.0.16299-SP0
2018-03-08 10:06:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: Sac)
2018-03-08 10:06:37 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Windows-10-10.0.16299-SP0
2018-03-08 10:06:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'Sac', 'CONCURRENT_REQUESTS': 8, 'DEPTH_PRIORITY': -1, 'DOWNLOAD_DELAY': 0.2, 'LOG_FILE': 'sac.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Sac.spiders', 'SPIDER_MODULES': ['Sac.spiders']}
2018-03-08 10:06:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-03-08 10:06:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-03-08 10:06:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-03-08 10:06:38 [py.warnings] WARNING: F:\gitwork\pipeline.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2018-03-08 10:06:38 [scrapy.middleware] INFO: Enabled item pipelines:
['Sac.pipelines.SacPipeline']
2018-03-08 10:06:38 [scrapy.core.engine] INFO: Spider opened
2018-03-08 10:06:38 [pipeline] INFO: START DB SERVER >>> host:10.1.18.35 on database Haifeng.CrawlerData
2018-03-08 10:06:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-03-08 10:06:39 [py.warnings] WARNING: F:\gitwork\pipeline.py:135: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg(repr(e), level=log.ERROR)

2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [py.warnings] WARNING: F:\gitwork\pipeline.py:155: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg("sql is:%s/n reason is :%s" % (sql, e), level=log.ERROR)

2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999082'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [py.warnings] WARNING: F:\gitwork\pipeline.py:203: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg("sql is:%s/n reason is :%s" % (sql, e))

2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999082','爱建证券有限责任公司','1339','774','0','3','483','5','56','7','11','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199040'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199040','安徽大时代证券投资咨询有限公司','218','193','0','0','0','0','25','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199039'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199039','安徽华安新兴证券投资咨询有限责任公司','17','3','0','0','0','0','14','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999145'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999145','安信证券股份有限公司','9123','6421','0','206','1499','71','817','97','12','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199070'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199070','北部资产经营股份有限公司','8','0','0','0','0','0','8','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199050'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199050','北京博星证券投资顾问有限公司','67','42','0','0','0','0','25','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999142'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999142','北京高华证券有限责任公司','127','89','0','0','0','16','22','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199002'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199002','北京股商投资有限公司','116','89','0','0','0','0','27','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199085'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199085','北京海问咨询有限公司','5','0','0','0','0','0','5','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199087'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199087','北京和众汇富科技股份有限公司','102','65','0','0','0','0','37','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199016'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199016','北京金美林投资顾问有限公司','9','1','0','0','0','0','8','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199022'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199022','北京盛世创富证券投资顾问有限公司','196','149','0','0','0','0','47','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199005'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199005','北京首证投资顾问有限公司','137','104','0','0','0','0','33','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '611'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('611','北京天相财富管理顾问有限公司','24','0','0','0','0','1','23','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199017'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199017','北京指南针科技发展股份有限公司','31','13','0','0','0','0','18','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199013'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199013','北京中方信富投资管理咨询有限公司','63','1','0','0','0','0','62','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199001','北京中富金石咨询有限公司','103','82','0','0','0','0','21','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199015'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199015','北京中和应泰财务顾问有限公司','20','10','0','0','0','0','10','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199086'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199086','北京中资北方投资顾问有限公司','198','144','0','0','0','0','54','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '609'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('609','渤海汇金证券资产管理有限公司','126','102','0','0','0','0','0','0','24','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999115'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999115','渤海证券股份有限公司','1819','1221','0','34','394','18','142','10','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999040'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999040','财达证券股份有限公司','2209','1596','0','14','421','21','135','6','16','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999053'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999053','财富证券有限责任公司','2719','1396','0','25','942','17','316','6','17','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999016'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999016','财通证券股份有限公司','3637','2262','0','2','873','28','436','36','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '602'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('602','财通证券资产管理有限公司','180','144','0','0','0','0','0','0','36','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999020'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999020','长城国瑞证券有限公司','769','584','0','6','125','3','26','11','14','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999107'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999107','长城证券股份有限公司','4175','2288','0','3','1423','24','346','56','35','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '605'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('605','长江证券（上海）资产管理有限公司','255','228','0','0','0','0','0','0','27','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999137'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999137','长江证券承销保荐有限公司','368','307','0','0','0','0','0','61','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999049'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999049','长江证券股份有限公司','8787','4493','0','135','2851','64','1243','0','1','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199128'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199128','成都汇阳投资顾问有限公司','49','20','0','0','0','0','29','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999110'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999110','川财证券有限责任公司','421','308','0','0','68','10','24','5','6','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1899002'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1899002','大公国际资信评估有限公司','59','0','59','0','0','0','0','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199095'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199095','大连华讯投资股份有限公司','231','151','0','0','0','0','80','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999017'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999017','大通证券股份有限公司','1365','655','0','15','564','3','115','6','7','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999077'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999077','大同证券有限责任公司','1752','816','0','0','602','2','318','5','9','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999012'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999012','德邦证券股份有限公司','1094','926','0','1','51','6','67','22','21','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999156'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999156','第一创业证券承销保荐有限责任公司','118','98','0','0','0','0','0','20','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999108'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999108','第一创业证券股份有限公司','3634','1126','0','13','2282','1','191','0','21','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199117'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199117','鼎信汇金(北京)投资管理有限公司','10','1','0','0','0','0','9','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999055'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999055','东北证券股份有限公司','3971','2264','0','0','1040','44','578','44','1','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999159'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999159','东方花旗证券有限公司','413','341','0','0','0','0','0','72','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1899008'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1899008','东方金诚国际信用评估有限公司','47','0','47','0','0','0','0','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999086'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999086','东方证券股份有限公司','4305','2840','0','19','921','53','472','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999063'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999063','东海证券股份有限公司','2522','1510','0','0','793','24','159','15','21','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999060'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999060','东吴证券股份有限公司','3396','1921','0','8','1040','44','304','60','19','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999148'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999148','东兴证券股份有限公司','2919','2207','0','6','207','25','385','65','24','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '619'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('619','东亚前海证券有限责任公司','45','45','0','0','0','0','0','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '606'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('606','东证融汇证券资产管理有限公司','121','93','0','0','0','0','0','0','28','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999034'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999034','东莞证券股份有限公司','3759','2169','0','18','1181','13','337','25','16','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999122'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999122','方正证券股份有限公司','8973','5170','0','40','2759','69','904','0','31','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199083'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199083','福建天信投资咨询顾问股份有限公司','32','8','0','0','0','0','24','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199069'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199069','福建中讯证券研究有限责任公司','19','10','0','0','0','0','9','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999143'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999143','高盛高华证券有限责任公司','66','55','0','0','0','0','0','11','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999093'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999093','光大证券股份有限公司','7143','3397','0','3','2859','74','724','86','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199060'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199060','广东博众证券投资咨询有限公司','104','82','0','0','0','0','22','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199056'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199056','广东科德投资顾问有限公司','37','11','0','0','0','0','26','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999026'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999026','广发证券股份有限公司','11678','6865','0','103','1858','99','2572','180','1','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '592'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('592','广发证券资产管理（广东）有限公司','202','152','0','0','0','0','0','0','50','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199131'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199131','广州广证恒生证券研究所有限公司','45','35','0','0','0','10','0','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199007','广州汇正财经顾问有限公司','70','61','0','0','0','0','9','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199112'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199112','广州经传多赢投资咨询有限公司','348','248','0','0','0','0','100','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:39 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199058'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199058','广州市万隆证券咨询顾问有限公司','24','5','0','0','0','0','19','0','0','2018-03-08 10:06:39','2018-03-08 10:06:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199059'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199059','广州越声理财咨询有限公司','21','9','0','0','0','0','12','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999032'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999032','广州证券股份有限公司','3297','2576','0','25','497','0','161','17','21','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999094'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999094','国都证券股份有限公司','1474','784','0','2','468','7','195','9','9','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999035'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999035','国海证券股份有限公司','3238','1540','0','0','1306','23','320','29','20','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999113'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999113','国金证券股份有限公司','2974','2232','0','0','200','64','309','144','25','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999138'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999138','国开证券股份有限公司','707','592','0','0','48','12','36','9','10','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999059'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999059','国联证券股份有限公司','1828','1128','0','0','410','27','249','0','14','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999007','国融证券股份有限公司','2144','1313','0','6','665','8','122','13','17','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999068'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999068','国盛证券有限责任公司','3024','1589','0','0','1368','14','44','7','2','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '607'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('607','国盛证券资产管理有限公司','60','50','0','0','0','0','0','0','10','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999088'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999088','国泰君安证券股份有限公司','11223','6787','0','1','2492','118','1717','108','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999098'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999098','国信证券股份有限公司','8453','6638','0','13','96','57','1456','167','26','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999002'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999002','国元证券股份有限公司','4278','2409','0','57','1329','26','364','62','31','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199062'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199062','海南港澳资讯产业股份有限公司','248','149','0','0','0','0','99','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199073'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199073','海顺证券投资咨询有限公司','231','173','0','0','0','0','58','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999085'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999085','海通证券股份有限公司','11617','4308','0','0','6053','115','1014','127','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199038'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199038','杭州顶点财经网络传媒有限公司','26','17','0','0','0','0','9','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199003','和讯信息科技有限公司','15','1','0','0','0','0','14','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199019'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199019','河北源达证券投资顾问股份有限公司','67','20','0','0','0','0','47','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199047'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199047','河南和信证券投资顾问股份有限公司','59','46','0','0','0','3','10','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199021'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199021','黑龙江省容维证券数据程序化有限公司','52','18','0','0','0','0','34','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999056'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999056','恒泰长财证券有限责任公司','138','126','0','0','0','0','0','12','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999067'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999067','恒泰证券股份有限公司','3387','1668','0','48','1260','6','396','0','9','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999133'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999133','宏信证券有限责任公司','1421','943','0','14','277','3','149','17','18','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999120'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999120','红塔证券股份有限公司','994','589','0','2','256','27','101','12','7','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199052'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199052','湖南金证投资咨询顾问有限公司','38','29','0','0','0','1','8','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199008'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199008','湖南巨景证券投资顾问有限公司','451','390','0','0','0','0','61','0','0','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999001','华安证券股份有限公司','3398','1976','0','12','1000','13','365','17','15','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999089'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999089','华宝证券有限责任公司','727','515','0','0','139','12','35','0','26','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999036'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999036','华创证券有限责任公司','2416','1592','0','8','391','50','318','30','27','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999021'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999021','华福证券有限责任公司','3487','2652','0','15','415','9','373','13','10','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999091'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999091','华金证券股份有限公司','940','610','0','0','254','13','44','10','9','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999128'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999128','华林证券股份有限公司','2879','1474','0','77','1137','0','147','38','6','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999023'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999023','华龙证券股份有限公司','1902','1257','0','0','138','7','465','19','16','2018-03-08 10:06:40','2018-03-08 10:06:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999149'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999149','华融证券股份有限公司','2723','1688','0','1','790','20','169','21','34','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999100'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999100','华泰联合证券有限责任公司','564','439','0','0','0','0','0','125','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '600'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('600','华泰证券（上海）资产管理有限公司','197','139','0','0','0','0','0','0','58','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999057'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999057','华泰证券股份有限公司','6911','3574','0','17','1422','68','1830','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999112'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999112','华西证券股份有限公司','2939','2438','0','0','39','6','409','33','14','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999154'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999154','华英证券有限责任公司','196','173','0','0','0','0','0','23','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '610'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('610','华菁证券有限公司','181','153','0','0','0','4','4','9','11','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999105'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999105','华鑫证券有限责任公司','1690','975','0','4','536','11','152','0','12','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '618'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('618','汇丰前海证券有限责任公司','76','65','0','0','0','8','3','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999141'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999141','江海证券有限公司','2744','1214','0','0','1245','3','251','12','19','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199084'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199084','江苏百瑞赢证券咨询有限公司','542','499','0','0','0','0','43','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199121'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199121','江苏金百临投资咨询股份有限公司','24','10','0','0','0','0','14','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199115'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199115','江苏天鼎证券投资咨询有限公司','154','113','0','0','0','0','41','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '612'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('612','金通证券有限责任公司','9','9','0','0','0','0','0','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999037'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999037','金元证券股份有限公司','1836','1069','0','15','635','2','85','19','11','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999135'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999135','九州证券股份有限公司','4573','1170','0','0','3269','1','90','17','26','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999079'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999079','开源证券股份有限公司','2162','1698','0','2','289','7','124','12','30','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999132'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999132','联储证券有限责任公司','1736','1106','0','0','495','2','107','4','22','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1899004'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1899004','联合信用评级有限公司','76','0','76','0','0','0','0','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199018'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199018','联合信用投资咨询有限公司','20','8','0','0','0','0','12','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999030'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999030','联讯证券股份有限公司','1879','1047','0','23','513','14','266','7','9','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199082'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199082','辽宁弘历投资咨询有限公司','12','3','0','0','0','0','9','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999010'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999010','民生证券股份有限公司','2966','1832','0','0','581','35','400','100','18','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999155'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999155','摩根士丹利华鑫证券有限责任公司','155','144','0','0','0','0','0','11','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999062'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999062','南京证券股份有限公司','2050','1151','0','2','529','12','334','12','10','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1899003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1899003','鹏元资信评估有限公司','71','0','71','0','0','0','0','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999106'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999106','平安证券股份有限公司','3688','3098','0','26','255','38','220','41','10','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199072'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199072','青岛大摩证券投资有限公司','16','0','0','0','0','7','9','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999151'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999151','瑞信方正证券有限责任公司','160','139','0','0','0','0','0','21','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999146'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999146','瑞银证券有限责任公司','346','264','0','0','0','36','19','24','3','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199046'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199046','山东点掌资本管理有限公司','18','9','0','0','0','0','9','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199043'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199043','山东神光咨询服务有限责任公司','27','0','0','0','0','0','27','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999076'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999076','山西证券股份有限公司','2428','1106','0','1','840','16','443','0','22','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199068'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199068','陕西巨丰投资资讯有限责任公司','173','123','0','0','0','0','50','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199097'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199097','上海朝阳永续理财顾问有限公司','9','0','0','0','0','0','9','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199032'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199032','上海东方财富证券研究所有限公司','33','0','0','0','0','0','33','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999153'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999153','上海东方证券资产管理有限公司','186','161','0','0','0','0','0','0','25','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '584'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('584','上海光大证券资产管理有限公司','143','107','0','0','0','0','0','0','36','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999160'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999160','上海国泰君安证券资产管理有限公司','189','139','0','0','0','0','0','0','50','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199037'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:41 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199037','上海海能证券投资顾问有限公司','26','14','0','0','0','0','12','0','0','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:41 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999158'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999158','上海海通证券资产管理有限公司','154','120','0','0','0','0','0','0','34','2018-03-08 10:06:41','2018-03-08 10:06:41')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999015'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999015','上海华信证券有限责任公司','647','564','0','0','53','6','7','8','9','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199063'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199063','上海凯石证券投资咨询有限公司','6','0','0','0','0','0','6','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199071'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199071','上海迈步投资管理有限公司','6','0','0','0','0','0','6','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199127'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199127','上海荣正投资咨询有限公司','19','0','0','0','0','0','19','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199130'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199130','上海森洋投资咨询有限公司','13','1','0','0','0','0','12','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199023'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199023','上海申银万国证券研究所有限公司','241','128','0','0','0','110','3','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199025'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199025','上海世基投资顾问有限公司','10','4','0','0','0','0','6','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199035'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199035','上海新兰德证券投资咨询顾问有限公司','76','29','0','0','0','0','47','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1899007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1899007','上海新世纪资信评估投资服务有限公司','77','0','77','0','0','0','0','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199024'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199024','上海亚商投资顾问有限公司','8','4','0','0','0','0','4','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199088'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199088','上海益盟软件技术股份有限公司','134','22','0','0','0','0','112','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199122'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199122','上海益学投资咨询有限公司','41','22','0','0','0','0','19','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '593'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('593','上海远东资信评估有限公司','26','0','26','0','0','0','0','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199033'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199033','上海证券通投资资讯科技有限公司','141','84','0','0','0','0','57','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999087'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999087','上海证券有限责任公司','1781','1049','0','3','505','23','191','0','10','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199030'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199030','上海证券之星综合研究有限公司','66','31','0','0','0','0','35','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '616'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('616','上海资信有限公司','7','0','7','0','0','0','0','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '608'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('608','申港证券股份有限公司','461','402','0','0','36','0','0','14','9','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999118'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999118','申万宏源西部证券有限公司','1131','631','0','1','163','1','335','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '601'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('601','申万宏源证券承销保荐有限责任公司','386','293','0','0','0','0','0','93','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999090'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999090','申万宏源证券有限公司','10541','4926','0','6','4086','0','1437','0','86','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199105'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199105','深圳大德汇富咨询顾问有限公司','6','0','0','0','0','0','6','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199080'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199080','深圳怀新企业投资顾问股份有限公司','190','163','0','0','0','0','27','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199077'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199077','深圳君银证券投资咨询顾问有限公司','179','124','0','0','0','0','55','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199129'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199129','深圳市国诚投资咨询有限公司','61','34','0','0','0','0','27','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199113'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199113','深圳市启富证券投资顾问有限公司','6','0','0','0','0','0','6','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199078'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199078','深圳市新兰德证券投资咨询有限公司','127','77','0','0','0','0','50','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199034'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199034','深圳市优品投资顾问有限公司','58','19','0','0','0','0','39','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199026'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199026','深圳市中广资本管理有限公司','8','1','0','0','0','0','7','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199081'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199081','深圳市中证投资资讯有限公司','16','0','0','0','0','0','16','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199076'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199076','深圳市尊悦证券资讯有限公司','8','0','0','0','0','8','0','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199079'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199079','深圳市珞珈投资咨询有限公司','6','0','0','0','0','0','6','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199094'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199094','沈阳麟龙投资顾问有限公司','23','8','0','0','0','0','15','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999103'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999103','世纪证券有限责任公司','1447','895','0','67','413','11','43','5','13','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999011'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999011','首创证券有限责任公司','1650','890','0','12','587','5','141','8','7','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199114'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199114','四川大决策证券投资顾问有限公司','181','156','0','0','0','0','25','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199066'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199066','四川省钱坤证券投资咨询有限公司','165','113','0','0','0','0','52','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999119'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999119','太平洋证券股份有限公司','2771','1626','0','0','811','47','236','19','32','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999111'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999111','天风证券股份有限公司','3632','2504','0','7','813','79','152','34','43','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199012'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199012','天一星辰（北京）科技有限公司','19','12','0','0','0','0','7','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999038'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999038','万和证券股份有限公司','1295','625','0','2','588','4','66','3','7','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999027'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999027','万联证券股份有限公司','2537','1602','0','36','657','6','214','8','14','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999065'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999065','网信证券有限责任公司','750','500','0','0','173','5','58','4','10','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199093'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199093','武汉中证通投资咨询有限公司','196','166','0','0','0','0','30','0','0','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:42 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999095'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:42 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999095','五矿证券有限公司','1545','725','0','1','752','1','48','5','13','2018-03-08 10:06:42','2018-03-08 10:06:42')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999080'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999080','西部证券股份有限公司','3038','2054','0','7','522','17','394','20','24','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999116'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999116','西藏东方财富证券股份有限公司','3621','1154','0','2','2354','10','79','4','18','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999125'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999125','西南证券股份有限公司','3644','1833','0','22','1183','48','470','49','39','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199091'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199091','厦门高能投资咨询有限公司','5','0','0','0','0','0','5','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199074'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199074','厦门市新汇通投资咨询有限公司','12','0','0','0','0','0','12','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199075'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199075','厦门市鑫鼎盛控股有限公司','8','0','0','0','0','0','8','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999050'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999050','湘财证券股份有限公司','1939','1155','0','0','482','3','285','7','7','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999028'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999028','新时代证券股份有限公司','2295','1244','0','11','800','22','200','6','12','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999150'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999150','信达证券股份有限公司','3093','1694','0','14','731','41','568','24','21','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999019'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999019','兴业证券股份有限公司','5859','3286','0','0','1333','98','1041','94','7','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '594'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('594','兴证证券资产管理有限公司','107','85','0','0','0','0','0','0','22','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '604'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('604','银河金汇证券资产管理有限公司','82','51','0','0','0','0','0','0','31','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999147'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999147','银泰证券有限责任公司','1539','502','0','1','966','1','63','0','6','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999099'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999099','英大证券有限责任公司','1274','545','0','7','661','6','27','14','14','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199067'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199067','云南产业投资管理有限公司','60','34','0','0','0','0','26','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999109'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999109','招商证券股份有限公司','9570','5207','0','46','3233','91','872','121','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '603'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('603','招商证券资产管理有限公司','108','75','0','0','0','0','0','0','33','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1099005'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1099005','浙江同花顺基金销售有限公司','1','1','0','0','0','0','0','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199104'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199104','浙江同花顺云软件有限公司','51','40','0','0','0','0','11','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '585'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('585','浙江浙商证券资产管理有限公司','161','122','0','0','0','0','0','0','39','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999123'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999123','浙商证券股份有限公司','3546','2397','0','14','857','31','207','40','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1899001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1899001','中诚信证券评估有限公司','29','0','29','0','0','0','0','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999152'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999152','中德证券有限责任公司','241','195','0','0','0','0','0','46','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '2699003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('2699003','中国长城资产管理公司','219','219','0','0','0','0','0','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999008'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999008','中国国际金融股份有限公司','2269','1903','0','0','0','93','144','92','37','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999005'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999005','中国民族证券有限责任公司','1850','1177','0','9','315','5','323','21','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999013'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999013','中国银河证券股份有限公司','9805','6455','0','0','1188','36','2084','41','1','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999096'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999096','中国中投证券有限责任公司','4535','2565','0','8','1224','16','687','10','25','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999064'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999064','中航证券有限公司','2424','1080','0','1','1184','20','109','20','10','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999029'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999029','中山证券有限责任公司','1667','957','0','7','590','4','61','9','39','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '599'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('599','中泰证券（上海）资产管理有限公司','125','90','0','0','0','0','0','0','35','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '40016',
            'ADI_NAME': '北京分公司',
            'ChangeInformationCount': '4',
            'CorpFullName': '爱建证券有限责任公司',
            'CreditTip': None,
            'CropRowID': '1999082',
            'Education': '大专',
            'EmpFullName': '丁旭',
            'EmpHashID': '66D74208C027B1CCE053D651A8C0B157',
            'EmpID': '29974756',
            'Gender': '男',
            'QualificationEndDate': '2018-03-31',
            'QualificationName': '证券经纪人证书',
            'QualificationNo': 'S0820416030003',
            'QualificationStartDate': '2016-03-05',
            'QualificationType': '证券经纪人',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-02-23/registrationRpInfo/145621281939314562128193930.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999074'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999074','中泰证券股份有限公司','8613','5197','0','40','1981','45','1292','58','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999140'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999140','中天国富证券有限公司','632','588','0','0','0','0','0','44','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999139'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999139','中天证券股份有限公司','917','634','0','0','165','7','103','0','8','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999144'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999144','中信建投证券股份有限公司','11301','6733','0','0','2307','43','1994','186','38','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999075'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999075','中信证券（山东）有限责任公司','2251','1816','0','0','87','0','348','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999101'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999101','中信证券股份有限公司','9299','6847','0','6','387','91','1775','144','49','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999130'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999130','中银国际证券股份有限公司','4016','2151','0','64','1381','51','304','33','32','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999134'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999134','中邮证券有限责任公司','806','571','0','4','158','3','48','5','17','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '1999073'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('1999073','中原证券股份有限公司','2798','1804','0','1','380','11','561','16','25','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:43 [scrapy.log] ERROR: sql is:select CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor from dbo.SAC_ProfessionalQualificationCrop where CropRowID = '199125'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:43 [scrapy.log] INFO: sql is:insert into dbo.SAC_ProfessionalQualificationCrop (CropRowID,CorpFullName,QualificationCount,GeneralSecurities,InvestmentConsulting,BusinessMarketing,SecuritiesBroker,analyst,InvestmentAdviser,SponsorRepresentative,InvestmentSponsor,AddTime,Checktime) values ('199125','重庆东金投资顾问有限公司','166','108','0','0','0','0','58','0','0','2018-03-08 10:06:43','2018-03-08 10:06:43')/n reason is :(208, b"Invalid object name 'dbo.SAC_ProfessionalQualificationCrop'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:44 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '57576',
            'ADI_NAME': '烟台只楚路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '爱建证券有限责任公司',
            'CreditTip': None,
            'CropRowID': '1999082',
            'Education': '中专',
            'EmpFullName': '张国海',
            'EmpHashID': '66D7420A56BDB1CCE053D651A8C0B157',
            'EmpID': '242993',
            'Gender': '男',
            'QualificationEndDate': '2018-07-31',
            'QualificationName': '证券经纪人证书',
            'QualificationNo': 'S0820417070011',
            'QualificationStartDate': '2017-07-31',
            'QualificationType': '证券经纪人',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-07-26/registrationRpInfo/150105122172815010512217280.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:44 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '52869',
            'ADI_NAME': '长沙中山路证券营业部',
            'ChangeInformationCount': '6',
            'CorpFullName': '爱建证券有限责任公司',
            'CreditTip': None,
            'CropRowID': '1999082',
            'Education': '本科',
            'EmpFullName': '陈姣',
            'EmpHashID': '66D7420993AEB1CCE053D651A8C0B157',
            'EmpID': '39907788',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S0820117090019',
            'QualificationStartDate': '2017-09-19',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-09-14/registrationRpInfo/150537221030215053722103020.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:44 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '54926',
            'ADI_NAME': '无锡清扬路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '爱建证券有限责任公司',
            'CreditTip': None,
            'CropRowID': '1999082',
            'Education': '本科',
            'EmpFullName': '许玉鸣',
            'EmpHashID': '66D74209B6D3B1CCE053D651A8C0B157',
            'EmpID': '179449',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S0820116090027',
            'QualificationStartDate': '2016-09-28',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-09-19/registrationRpInfo/147426907120014742690712000.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:44 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:44 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0820116090027'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:44 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('爱建证券有限责任公司','正常','S0820116090027','2016-09-28','一般证券业务','179449','2018-03-08 10:06:44','2018-03-08 10:06:44')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:45 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '33100',
            'ADI_NAME': '市场部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安徽华安新兴证券投资咨询有限责任公司',
            'CreditTip': None,
            'CropRowID': '199039',
            'Education': '本科',
            'EmpFullName': '高云',
            'EmpHashID': '66D7420786B2B1CCE053D651A8C0B157',
            'EmpID': '090922',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'A0390114050003',
            'QualificationStartDate': '2014-05-31',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080102/registrationRpInfo/136386340160680698.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:45 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '58755',
            'ADI_NAME': '宁波分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '中专',
            'EmpFullName': '兰海燕',
            'EmpHashID': '66D742079761B1CCE053D651A8C0B157',
            'EmpID': '70616',
            'Gender': '女',
            'QualificationEndDate': '2018-08-31',
            'QualificationName': '证券经纪人证书',
            'QualificationNo': 'S1450415080015',
            'QualificationStartDate': '2015-08-17',
            'QualificationType': '证券经纪人',
            'image': 'http://photo.sac.net.cn/sacmp/images/2015-05-15/registrationRpInfo/143168000067114316800006710.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450115060041'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450115060041','2015-06-13','一般证券业务','70616','2018-03-08 10:06:45','2018-03-08 10:06:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450415080015'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450415080015','2015-08-17','证券经纪人','70616','2018-03-08 10:06:45','2018-03-08 10:06:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:45 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47684',
            'ADI_NAME': '深圳沙头角营业部',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '周海文',
            'EmpHashID': '66D74207CD28B1CCE053D651A8C0B157',
            'EmpID': '19925322',
            'Gender': '女',
            'QualificationEndDate': '2018-11-30',
            'QualificationName': '证券经纪人证书',
            'QualificationNo': 'S1450412050127',
            'QualificationStartDate': '2012-05-17',
            'QualificationType': '证券经纪人',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080104/registrationRpInfo/136386914788116170.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450410110001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','离职','S1450410110001','2010-11-22','证券经纪人','19925322','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450412050127'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450412050127','2012-05-17','证券经纪人','19925322','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450412110014'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','离职','S1450412110014','2012-11-01','证券经纪人','19925322','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0010100010721'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('华安证券股份有限公司','离职','S0010100010721','2005-01-25','一般证券业务','090922','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'A0390114050003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安徽华安新兴证券投资咨询有限责任公司','正常','A0390114050003','2014-05-31','一般证券业务','090922','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47682',
            'ADI_NAME': '深圳红荔西路证券营业部',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '张际平',
            'EmpHashID': '66D742066F61B1CCE053D651A8C0B157',
            'EmpID': '19925908',
            'Gender': '女',
            'QualificationEndDate': '2018-05-31',
            'QualificationName': '证券经纪人证书',
            'QualificationNo': 'S1450412120030',
            'QualificationStartDate': '2012-12-31',
            'QualificationType': '证券经纪人',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080102/registrationRpInfo/136386115347429801.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450410120015'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','离职','S1450410120015','2010-12-30','证券经纪人','19925908','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450412050167'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','离职','S1450412050167','2012-05-18','证券经纪人','19925908','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450412120030'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450412120030','2012-12-31','证券经纪人','19925908','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0980109087356'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国信证券股份有限公司','离职','S0980109087356','2009-08-12','一般证券业务','39907788','2018-03-08 10:06:46','2018-03-08 10:06:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190110020014'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','离职','S0190110020014','2010-02-21','一般证券业务','39907788','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1130111070007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国金证券股份有限公司','离职','S1130111070007','2011-07-04','一般证券业务','39907788','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190112060006'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','离职','S0190112060006','2012-06-04','一般证券业务','39907788','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190613010021'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','离职','S0190613010021','2013-01-30','证券投资咨询业务(投资顾问)','39907788','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0820117090019'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('爱建证券有限责任公司','正常','S0820117090019','2017-09-19','一般证券业务','39907788','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0820417070011'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('爱建证券有限责任公司','正常','S0820417070011','2017-07-31','证券经纪人','242993','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1480309120143'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('东兴证券股份有限公司','离职','S1480309120143','2009-12-07','证券经纪业务营销','29974756','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0820110080008'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('爱建证券有限责任公司','离职','S0820110080008','2010-08-13','一般证券业务','29974756','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0490112010002'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('长江证券股份有限公司','离职','S0490112010002','2012-01-04','一般证券业务','29974756','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0820416030003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('爱建证券有限责任公司','正常','S0820416030003','2016-03-05','证券经纪人','29974756','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '11262',
            'ADI_NAME': '上海安国路证券营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '爱建证券有限责任公司',
            'CreditTip': None,
            'CropRowID': '1999082',
            'Education': '大专',
            'EmpFullName': '张文斌',
            'EmpHashID': '66D742084FB3B1CCE053D651A8C0B157',
            'EmpID': '59900954',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '证券经纪人证书',
            'QualificationNo': 'S0820414080003',
            'QualificationStartDate': '2014-08-12',
            'QualificationType': '证券经纪人',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080101/registrationRpInfo/136385979795295382.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0820310020102'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('爱建证券有限责任公司','机构内变更','S0820310020102','2010-02-24','证券经纪业务营销','59900954','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:47 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0820414080003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:47 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('爱建证券有限责任公司','正常','S0820414080003','2014-08-12','证券经纪人','59900954','2018-03-08 10:06:47','2018-03-08 10:06:47')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:50 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '50041',
            'ADI_NAME': '厦门湖里大道营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '李蔓菱',
            'EmpHashID': '66D74208C924B1CCE053D651A8C0B157',
            'EmpID': '202951',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117030038',
            'QualificationStartDate': '2017-03-13',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-01-17/registrationRpInfo/148463729317414846372931740.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:50 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47685',
            'ADI_NAME': '深圳耀华创建大厦营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '罗小岑',
            'EmpHashID': '66D7420916EEB1CCE053D651A8C0B157',
            'EmpID': '225458',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117080311',
            'QualificationStartDate': '2017-08-14',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-05-23/registrationRpInfo/149552281871614955228187160.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:50 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55698',
            'ADI_NAME': '西安长乐中路证券营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '王斌',
            'EmpHashID': '66D742092A1EB1CCE053D651A8C0B157',
            'EmpID': '40335',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450116070146',
            'QualificationStartDate': '2016-07-23',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2014-08-06/registrationRpInfo/140730031977314073003197730.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:51 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '50788',
            'ADI_NAME': '江苏分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '沈梦婷',
            'EmpHashID': '66D7420962F5B1CCE053D651A8C0B157',
            'EmpID': '98190',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117040131',
            'QualificationStartDate': '2017-04-17',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2015-08-18/registrationRpInfo/143989347243014398934724300.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:51 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47679',
            'ADI_NAME': '深圳宝安海秀路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '王津津',
            'EmpHashID': '66D7420984AFB1CCE053D651A8C0B157',
            'EmpID': '255716',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117100016',
            'QualificationStartDate': '2017-10-04',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-09-22/registrationRpInfo/150604269317715060426931770.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:51 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '49269',
            'ADI_NAME': '河源紫金香江中路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '高中',
            'EmpFullName': '施小红',
            'EmpHashID': '66D74209AE60B1CCE053D651A8C0B157',
            'EmpID': '220382',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117050240',
            'QualificationStartDate': '2017-05-17',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-04-28/registrationRpInfo/149336217162514933621716250.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:51 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47679',
            'ADI_NAME': '深圳宝安海秀路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '郑惠满',
            'EmpHashID': '66D74209DA0CB1CCE053D651A8C0B157',
            'EmpID': '161573',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450116080093',
            'QualificationStartDate': '2016-08-03',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-07-15/registrationRpInfo/146856468375714685646837570.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:52 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47651',
            'ADI_NAME': '南昌胜利路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '中专',
            'EmpFullName': '董晶',
            'EmpHashID': '66D7420A0F5FB1CCE053D651A8C0B157',
            'EmpID': '179066',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450116110141',
            'QualificationStartDate': '2016-11-19',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-09-20/registrationRpInfo/147442216064714744221606470.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450116110141'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450116110141','2016-11-19','一般证券业务','179066','2018-03-08 10:06:52','2018-03-08 10:06:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:52 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '57319',
            'ADI_NAME': '西安南关正街证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '董明智',
            'EmpHashID': '66D7420A628DB1CCE053D651A8C0B157',
            'EmpID': '250448',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117090175',
            'QualificationStartDate': '2017-09-16',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-08-25/registrationRpInfo/150362376102715036237610270.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117090175'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117090175','2017-09-16','一般证券业务','250448','2018-03-08 10:06:52','2018-03-08 10:06:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450116080093'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450116080093','2016-08-03','一般证券业务','161573','2018-03-08 10:06:52','2018-03-08 10:06:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117050240'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117050240','2017-05-17','一般证券业务','220382','2018-03-08 10:06:53','2018-03-08 10:06:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117100016'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117100016','2017-10-04','一般证券业务','255716','2018-03-08 10:06:53','2018-03-08 10:06:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0570415080165'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('华泰证券股份有限公司','离职','S0570415080165','2015-08-29','证券经纪人','98190','2018-03-08 10:06:53','2018-03-08 10:06:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117040131'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117040131','2017-04-17','一般证券业务','98190','2018-03-08 10:06:53','2018-03-08 10:06:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0790114080014'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('开源证券股份有限公司','离职','S0790114080014','2014-08-12','一般证券业务','40335','2018-03-08 10:06:53','2018-03-08 10:06:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450116070146'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450116070146','2016-07-23','一般证券业务','40335','2018-03-08 10:06:53','2018-03-08 10:06:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:54 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:54 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260117060042'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:54 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260117060042','2017-06-05','一般证券业务','225458','2018-03-08 10:06:54','2018-03-08 10:06:54')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:54 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:54 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117080311'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:54 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117080311','2017-08-14','一般证券业务','225458','2018-03-08 10:06:54','2018-03-08 10:06:54')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:54 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:54 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117030038'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:54 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117030038','2017-03-13','一般证券业务','202951','2018-03-08 10:06:54','2018-03-08 10:06:54')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:56 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47994',
            'ADI_NAME': '佛山分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '傅丽桑',
            'EmpHashID': '66D7420B266FB1CCE053D651A8C0B157',
            'EmpID': '272600',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010117',
            'QualificationStartDate': '2018-01-14',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-02/registrationRpInfo/151487135666115148713566610.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:57 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:57 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010117'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:57 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010117','2018-01-14','一般证券业务','272600','2018-03-08 10:06:57','2018-03-08 10:06:57')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55417',
            'ADI_NAME': '株洲庐山路证券营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '晏菁',
            'EmpHashID': '66D7420B24F4B1CCE053D651A8C0B157',
            'EmpID': '29941175',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010181',
            'QualificationStartDate': '2018-01-21',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080103/registrationRpInfo/136386822569892658.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '52279',
            'ADI_NAME': '辽宁分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '王芷睿',
            'EmpHashID': '66D7420B251CB1CCE053D651A8C0B157',
            'EmpID': '268203',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117120108',
            'QualificationStartDate': '2017-12-21',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-08/registrationRpInfo/151269534880615126953488060.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47655',
            'ADI_NAME': '青岛东海西路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '于洁',
            'EmpHashID': '66D7420B2A2AB1CCE053D651A8C0B157',
            'EmpID': '276590',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020051',
            'QualificationStartDate': '2018-02-11',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-25/registrationRpInfo/151686677470215168667747020.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:58 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55320',
            'ADI_NAME': '湖南分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '邱思',
            'EmpHashID': '66D7420B261EB1CCE053D651A8C0B157',
            'EmpID': '272014',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010153',
            'QualificationStartDate': '2018-01-17',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-27/registrationRpInfo/151436385407815143638540780.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:58 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47684',
            'ADI_NAME': '深圳沙头角营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '郑博文',
            'EmpHashID': '66D7420B25FFB1CCE053D651A8C0B157',
            'EmpID': '176289',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020001',
            'QualificationStartDate': '2018-02-03',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-09-01/registrationRpInfo/147269862838714726986283870.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:58 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59148',
            'ADI_NAME': '江西分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '高中',
            'EmpFullName': '谢培生',
            'EmpHashID': '66D7420B29E5B1CCE053D651A8C0B157',
            'EmpID': '269847',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010078',
            'QualificationStartDate': '2018-01-09',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-15/registrationRpInfo/151331503761315133150376130.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:58 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47673',
            'ADI_NAME': '上海杨高南路证券营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '朱政杰',
            'EmpHashID': '66D7420B29D2B1CCE053D651A8C0B157',
            'EmpID': '198702',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020035',
            'QualificationStartDate': '2018-02-07',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-12-21/registrationRpInfo/148237249219214823724921920.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:06:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117010052'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','离职','S1450117010052','2017-01-14','一般证券业务','198702','2018-03-08 10:06:59','2018-03-08 10:06:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020035'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020035','2018-02-07','一般证券业务','198702','2018-03-08 10:06:59','2018-03-08 10:06:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010078'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010078','2018-01-09','一般证券业务','269847','2018-03-08 10:06:59','2018-03-08 10:06:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1090416090122'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('招商证券股份有限公司','离职','S1090416090122','2016-09-25','证券经纪人','176289','2018-03-08 10:06:59','2018-03-08 10:06:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:06:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:06:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020001','2018-02-03','一般证券业务','176289','2018-03-08 10:06:59','2018-03-08 10:06:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020051'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:00 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020051','2018-02-11','一般证券业务','276590','2018-03-08 10:07:00','2018-03-08 10:07:00')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010153'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:00 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010153','2018-01-17','一般证券业务','272014','2018-03-08 10:07:00','2018-03-08 10:07:00')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1490109061264'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:00 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('华融证券股份有限公司','离职','S1490109061264','2009-06-30','一般证券业务','29941175','2018-03-08 10:07:00','2018-03-08 10:07:00')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010181'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:00 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010181','2018-01-21','一般证券业务','29941175','2018-03-08 10:07:00','2018-03-08 10:07:00')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117120108'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:00 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117120108','2017-12-21','一般证券业务','268203','2018-03-08 10:07:00','2018-03-08 10:07:00')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55320',
            'ADI_NAME': '湖南分公司',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '何家兴',
            'EmpHashID': '66D7420B264EB1CCE053D651A8C0B157',
            'EmpID': '137493',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020014',
            'QualificationStartDate': '2018-02-04',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-03-17/registrationRpInfo/145826448210414582644821040.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:00 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:00 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1220116050050'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:00 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('方正证券股份有限公司','机构内变更','S1220116050050','2016-05-09','一般证券业务','137493','2018-03-08 10:07:00','2018-03-08 10:07:00')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:01 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:01 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0880417030020'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:01 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国泰君安证券股份有限公司','离职','S0880417030020','2017-03-21','证券经纪人','137493','2018-03-08 10:07:01','2018-03-08 10:07:01')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:01 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:01 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020014'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:01 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020014','2018-02-04','一般证券业务','137493','2018-03-08 10:07:01','2018-03-08 10:07:01')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:03 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:03 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010187'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:03 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010187','2018-01-22','一般证券业务','274415','2018-03-08 10:07:03','2018-03-08 10:07:03')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:03 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47590',
            'ADI_NAME': '北京阜成门营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '杨海燕',
            'EmpHashID': '66D7420B29B7B1CCE053D651A8C0B157',
            'EmpID': '273346',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020038',
            'QualificationStartDate': '2018-02-07',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-04/registrationRpInfo/151505532143815150553214380.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:03 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '51254',
            'ADI_NAME': '山东分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '陈露',
            'EmpHashID': '66D7420B29AFB1CCE053D651A8C0B157',
            'EmpID': '270571',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010077',
            'QualificationStartDate': '2018-01-09',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-20/registrationRpInfo/151373196915415137319691540.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:04 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '17060',
            'ADI_NAME': '合规法务部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '王娴',
            'EmpHashID': '66D7420B2456B1CCE053D651A8C0B157',
            'EmpID': '276306',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020060',
            'QualificationStartDate': '2018-02-12',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-23/registrationRpInfo/151671021636215167102163620.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:04 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59078',
            'ADI_NAME': '深圳前海分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '李宇平',
            'EmpHashID': '66D7420B2429B1CCE053D651A8C0B157',
            'EmpID': '251299',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020008',
            'QualificationStartDate': '2018-02-03',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-08-30/registrationRpInfo/150407443162615040744316260.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:04 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '54909',
            'ADI_NAME': '河南分公司',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '张帅帅',
            'EmpHashID': '66D7420B2985B1CCE053D651A8C0B157',
            'EmpID': '214826',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020050',
            'QualificationStartDate': '2018-02-11',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-04-06/registrationRpInfo/149145549338814914554933880.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:04 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:04 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0020117040028'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:04 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国元证券股份有限公司','离职','S0020117040028','2017-04-22','一般证券业务','214826','2018-03-08 10:07:04','2018-03-08 10:07:04')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:04 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:04 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0210117080084'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:04 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('华福证券有限责任公司','离职','S0210117080084','2017-08-08','一般证券业务','214826','2018-03-08 10:07:04','2018-03-08 10:07:04')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:04 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:04 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020050'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:04 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020050','2018-02-11','一般证券业务','214826','2018-03-08 10:07:04','2018-03-08 10:07:04')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47694',
            'ADI_NAME': '武汉胜利街营业部',
            'ChangeInformationCount': '4',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '袁诚',
            'EmpHashID': '66D7420B2977B1CCE053D651A8C0B157',
            'EmpID': '59920350',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450618010001',
            'QualificationStartDate': '2018-01-16',
            'QualificationType': '证券投资咨询业务(投资顾问)',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-11-28/registrationRpInfo/151184184474215118418447420.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:05 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47640',
            'ADI_NAME': '茂名人民南路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '李嘉铭',
            'EmpHashID': '66D7420B295EB1CCE053D651A8C0B157',
            'EmpID': '268213',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117120190',
            'QualificationStartDate': '2017-12-30',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-08/registrationRpInfo/151269720125315126972012530.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:05 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117120190'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:05 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117120190','2017-12-30','一般证券业务','268213','2018-03-08 10:07:05','2018-03-08 10:07:05')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0490110040261'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:05 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('长江证券股份有限公司','离职','S0490110040261','2010-04-07','一般证券业务','59920350','2018-03-08 10:07:05','2018-03-08 10:07:05')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0640612030002'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:05 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('中航证券有限公司','离职','S0640612030002','2012-03-03','证券投资咨询业务(投资顾问)','59920350','2018-03-08 10:07:05','2018-03-08 10:07:05')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117120104'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:05 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450117120104','2017-12-18','一般证券业务','59920350','2018-03-08 10:07:05','2018-03-08 10:07:05')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:05 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450618010001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:05 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450618010001','2018-01-16','证券投资咨询业务(投资顾问)','59920350','2018-03-08 10:07:05','2018-03-08 10:07:05')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0130117090123'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:06 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('中国银河证券股份有限公司','离职','S0130117090123','2017-09-12','一般证券业务','251299','2018-03-08 10:07:06','2018-03-08 10:07:06')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020008'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:06 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020008','2018-02-03','一般证券业务','251299','2018-03-08 10:07:06','2018-03-08 10:07:06')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020060'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:06 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020060','2018-02-12','一般证券业务','276306','2018-03-08 10:07:06','2018-03-08 10:07:06')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:06 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010077'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:06 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010077','2018-01-09','一般证券业务','270571','2018-03-08 10:07:06','2018-03-08 10:07:06')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:07 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:07 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020038'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:07 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020038','2018-02-07','一般证券业务','273346','2018-03-08 10:07:07','2018-03-08 10:07:07')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:07 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55982',
            'ADI_NAME': '天津围堤道证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '中专',
            'EmpFullName': '苏娜',
            'EmpHashID': '66D7420B2476B1CCE053D651A8C0B157',
            'EmpID': '273643',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010241',
            'QualificationStartDate': '2018-01-28',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-09/registrationRpInfo/151546130347115154613034710.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:07 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:07 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010241'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:07 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010241','2018-01-28','一般证券业务','273643','2018-03-08 10:07:07','2018-03-08 10:07:07')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:10 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59078',
            'ADI_NAME': '深圳前海分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '丘华纯',
            'EmpHashID': '66D7420B2D0BB1CCE053D651A8C0B157',
            'EmpID': '276975',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020055',
            'QualificationStartDate': '2018-02-12',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-29/registrationRpInfo/151721428347815172142834780.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:10 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47693',
            'ADI_NAME': '陕西分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '宋扬刚',
            'EmpHashID': '66D7420B2CFDB1CCE053D651A8C0B157',
            'EmpID': '264086',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020052',
            'QualificationStartDate': '2018-02-12',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-29/registrationRpInfo/151721739488615172173948860.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:10 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '50412',
            'ADI_NAME': '山西分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '刘秀斌',
            'EmpHashID': '66D7420B2935B1CCE053D651A8C0B157',
            'EmpID': '273173',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010265',
            'QualificationStartDate': '2018-01-30',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-05/registrationRpInfo/151511420103115151142010310.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:11 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55758',
            'ADI_NAME': '烟台胜利路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '王庆丰',
            'EmpHashID': '66D7420B2CD2B1CCE053D651A8C0B157',
            'EmpID': '274414',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010219',
            'QualificationStartDate': '2018-01-27',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-10/registrationRpInfo/151557332142615155733214260.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:11 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '52279',
            'ADI_NAME': '辽宁分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '杨朗',
            'EmpHashID': '66D7420B292CB1CCE053D651A8C0B157',
            'EmpID': '271178',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010054',
            'QualificationStartDate': '2018-01-09',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-25/registrationRpInfo/151417215294815141721529480.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:11 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47693',
            'ADI_NAME': '陕西分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '焦晨',
            'EmpHashID': '66D7420B2CC0B1CCE053D651A8C0B157',
            'EmpID': '274502',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010243',
            'QualificationStartDate': '2018-01-30',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-11/registrationRpInfo/151563983949815156398394980.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:11 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:11 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010243'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:11 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010243','2018-01-30','一般证券业务','274502','2018-03-08 10:07:11','2018-03-08 10:07:11')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:11 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '56990',
            'ADI_NAME': '邯郸人民路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '冯龙',
            'EmpHashID': '66D7420B28D3B1CCE053D651A8C0B157',
            'EmpID': '271386',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010033',
            'QualificationStartDate': '2018-01-08',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-25/registrationRpInfo/151419283049815141928304980.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:11 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:11 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010033'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:11 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010033','2018-01-08','一般证券业务','271386','2018-03-08 10:07:11','2018-03-08 10:07:11')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:12 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47707',
            'ADI_NAME': '中山兴政路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '高嘉俊',
            'EmpHashID': '66D7420B28C8B1CCE053D651A8C0B157',
            'EmpID': '274401',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010186',
            'QualificationStartDate': '2018-01-22',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-10/registrationRpInfo/151557106137615155710613760.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:12 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:12 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010186'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:12 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010186','2018-01-22','一般证券业务','274401','2018-03-08 10:07:12','2018-03-08 10:07:12')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:12 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:12 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020064'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:12 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020064','2018-02-14','一般证券业务','276605','2018-03-08 10:07:12','2018-03-08 10:07:12')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010219'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:13 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010219','2018-01-27','一般证券业务','274414','2018-03-08 10:07:13','2018-03-08 10:07:13')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010054'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:13 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010054','2018-01-09','一般证券业务','271178','2018-03-08 10:07:13','2018-03-08 10:07:13')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010265'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:13 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010265','2018-01-30','一般证券业务','273173','2018-03-08 10:07:13','2018-03-08 10:07:13')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0340417120041'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:13 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('东莞证券股份有限公司','离职','S0340417120041','2017-12-17','证券经纪人','264086','2018-03-08 10:07:13','2018-03-08 10:07:13')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:13 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020052'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:13 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020052','2018-02-12','一般证券业务','264086','2018-03-08 10:07:13','2018-03-08 10:07:13')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:14 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:14 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020055'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:14 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020055','2018-02-12','一般证券业务','276975','2018-03-08 10:07:14','2018-03-08 10:07:14')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:16 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '50788',
            'ADI_NAME': '江苏分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '陆婷婷',
            'EmpHashID': '66D7420B2883B1CCE053D651A8C0B157',
            'EmpID': '274996',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010222',
            'QualificationStartDate': '2018-01-27',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-16/registrationRpInfo/151608300759315160830075930.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:16 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55758',
            'ADI_NAME': '烟台胜利路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '于佳伟',
            'EmpHashID': '66D7420B2C2AB1CCE053D651A8C0B157',
            'EmpID': '274385',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010218',
            'QualificationStartDate': '2018-01-27',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-10/registrationRpInfo/151558046473615155804647360.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:16 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '51254',
            'ADI_NAME': '山东分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '秦健',
            'EmpHashID': '66D7420B286CB1CCE053D651A8C0B157',
            'EmpID': '271236',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010036',
            'QualificationStartDate': '2018-01-08',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-25/registrationRpInfo/151418633375115141863337510.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:17 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47685',
            'ADI_NAME': '深圳耀华创建大厦营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '王子天',
            'EmpHashID': '66D7420B2868B1CCE053D651A8C0B157',
            'EmpID': '270315',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010076',
            'QualificationStartDate': '2018-01-09',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-19/registrationRpInfo/151367489431015136748943100.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:17 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '57653',
            'ADI_NAME': '南宁民族大道证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '张烨华',
            'EmpHashID': '66D7420B2857B1CCE053D651A8C0B157',
            'EmpID': '275767',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010268',
            'QualificationStartDate': '2018-01-31',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-19/registrationRpInfo/151632963025815163296302580.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:17 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '52481',
            'ADI_NAME': '南昌红谷中大道营业部',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '肖磊鑫',
            'EmpHashID': '66D7420B2851B1CCE053D651A8C0B157',
            'EmpID': '54133',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020019',
            'QualificationStartDate': '2018-02-04',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2014-12-22/registrationRpInfo/141921454800614192145480060.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:17 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '57494',
            'ADI_NAME': '延吉长白山路证券营业部',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '金银',
            'EmpHashID': '66D7420B2844B1CCE053D651A8C0B157',
            'EmpID': '215563',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010206',
            'QualificationStartDate': '2018-01-24',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-04-10/registrationRpInfo/149179269298214917926929820.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:18 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47649',
            'ADI_NAME': '绵阳涪城路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '中专',
            'EmpFullName': '罗敏',
            'EmpHashID': '66D7420B2C16B1CCE053D651A8C0B157',
            'EmpID': '276651',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020030',
            'QualificationStartDate': '2018-02-06',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-25/registrationRpInfo/151688939091915168893909190.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:18 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '54146',
            'ADI_NAME': '福建分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '张俊雄',
            'EmpHashID': '66D7420B27FCB1CCE053D651A8C0B157',
            'EmpID': '274842',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010245',
            'QualificationStartDate': '2018-01-30',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-12/registrationRpInfo/151574488121015157448812100.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:18 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:18 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010245'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:18 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010245','2018-01-30','一般证券业务','274842','2018-03-08 10:07:18','2018-03-08 10:07:18')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020030'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:19 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020030','2018-02-06','一般证券业务','276651','2018-03-08 10:07:19','2018-03-08 10:07:19')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0980115010008'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:19 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国信证券股份有限公司','离职','S0980115010008','2015-01-03','一般证券业务','54133','2018-03-08 10:07:19','2018-03-08 10:07:19')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450417110016'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:19 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450417110016','2017-11-11','证券经纪人','54133','2018-03-08 10:07:19','2018-03-08 10:07:19')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020019'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:19 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020019','2018-02-04','一般证券业务','54133','2018-03-08 10:07:19','2018-03-08 10:07:19')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010268'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:19 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010268','2018-01-31','一般证券业务','275767','2018-03-08 10:07:19','2018-03-08 10:07:19')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:19 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010076'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:19 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010076','2018-01-09','一般证券业务','270315','2018-03-08 10:07:19','2018-03-08 10:07:19')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010036'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:20 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010036','2018-01-08','一般证券业务','271236','2018-03-08 10:07:20','2018-03-08 10:07:20')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010218'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:20 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010218','2018-01-27','一般证券业务','274385','2018-03-08 10:07:20','2018-03-08 10:07:20')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0930417050109'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:20 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('光大证券股份有限公司','离职','S0930417050109','2017-05-20','证券经纪人','215563','2018-03-08 10:07:20','2018-03-08 10:07:20')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0930417080058'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:20 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('光大证券股份有限公司','离职','S0930417080058','2017-08-27','证券经纪人','215563','2018-03-08 10:07:20','2018-03-08 10:07:20')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010206'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:20 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010206','2018-01-24','一般证券业务','215563','2018-03-08 10:07:20','2018-03-08 10:07:20')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:20 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010222'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:20 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010222','2018-01-27','一般证券业务','274996','2018-03-08 10:07:20','2018-03-08 10:07:20')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:22 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '57337',
            'ADI_NAME': '安徽分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '张强',
            'EmpHashID': '66D7420B27C5B1CCE053D651A8C0B157',
            'EmpID': '276423',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020067',
            'QualificationStartDate': '2018-02-17',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-24/registrationRpInfo/151677639554715167763955470.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:23 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47661',
            'ADI_NAME': '汕头红领巾路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '郑晓琳',
            'EmpHashID': '66D7420B2B31B1CCE053D651A8C0B157',
            'EmpID': '276467',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020078',
            'QualificationStartDate': '2018-02-18',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-02-01/registrationRpInfo/151746684569215174668456920.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:23 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '51246',
            'ADI_NAME': '厦门鹭江道营业部',
            'ChangeInformationCount': '4',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '林武娟',
            'EmpHashID': '66D7420B2766B1CCE053D651A8C0B157',
            'EmpID': '69948650',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020059',
            'QualificationStartDate': '2018-02-12',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080102/registrationRpInfo/136386400976794208.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:23 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47693',
            'ADI_NAME': '陕西分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '李丹丹',
            'EmpHashID': '66D7420B2765B1CCE053D651A8C0B157',
            'EmpID': '276899',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020056',
            'QualificationStartDate': '2018-02-12',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-29/registrationRpInfo/151720408791115172040879110.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:24 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59203',
            'ADI_NAME': '新疆分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '魏建伟',
            'EmpHashID': '66D7420B274BB1CCE053D651A8C0B157',
            'EmpID': '273481',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010159',
            'QualificationStartDate': '2018-01-20',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-08/registrationRpInfo/151537468820815153746882080.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:24 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:24 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010159'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:24 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010159','2018-01-20','一般证券业务','273481','2018-03-08 10:07:24','2018-03-08 10:07:24')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:24 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47693',
            'ADI_NAME': '陕西分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '黄雪婷',
            'EmpHashID': '66D7420B2B0CB1CCE053D651A8C0B157',
            'EmpID': '275571',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020047',
            'QualificationStartDate': '2018-02-11',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-18/registrationRpInfo/151624096065915162409606590.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:24 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47693',
            'ADI_NAME': '陕西分公司',
            'ChangeInformationCount': '4',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '李峰',
            'EmpHashID': '66D7420B2B0BB1CCE053D651A8C0B157',
            'EmpID': '29919497',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010249',
            'QualificationStartDate': '2018-01-30',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080105/registrationRpInfo/13638728232993511.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:24 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47624',
            'ADI_NAME': '黑龙江分公司',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '李晶',
            'EmpHashID': '66D7420B2AFDB1CCE053D651A8C0B157',
            'EmpID': '042630',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450618020010',
            'QualificationStartDate': '2018-02-27',
            'QualificationType': '证券投资咨询业务(投资顾问)',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080101/registrationRpInfo/136385895016674926.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0470100010105'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴安证券有限责任公司','离职','S0470100010105','2004-08-02','一般证券业务','042630','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450107111204'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450107111204','2007-11-22','一般证券业务','042630','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450618020010'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450618020010','2018-02-27','证券投资咨询业务(投资顾问)','042630','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0500108121192'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('湘财证券股份有限公司','离职','S0500108121192','2008-12-01','一般证券业务','29919497','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1300110100053'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('中银国际证券股份有限公司','机构内变更','S1300110100053','2010-10-29','一般证券业务','29919497','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1300415010002'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('中银国际证券股份有限公司','离职','S1300415010002','2015-01-06','证券经纪人','29919497','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010249'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010249','2018-01-30','一般证券业务','29919497','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020047'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:25 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020047','2018-02-11','一般证券业务','275571','2018-03-08 10:07:25','2018-03-08 10:07:25')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:25 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47693',
            'ADI_NAME': '陕西分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '冯盈盈',
            'EmpHashID': '66D7420B2DBDB1CCE053D651A8C0B157',
            'EmpID': '267168',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020053',
            'QualificationStartDate': '2018-02-12',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-29/registrationRpInfo/151721788326315172178832630.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:26 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0340418010103'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('东莞证券股份有限公司','离职','S0340418010103','2018-01-09','证券经纪人','267168','2018-03-08 10:07:26','2018-03-08 10:07:26')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020053'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020053','2018-02-12','一般证券业务','267168','2018-03-08 10:07:26','2018-03-08 10:07:26')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020056'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020056','2018-02-12','一般证券业务','276899','2018-03-08 10:07:26','2018-03-08 10:07:26')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0020111030064'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国元证券股份有限公司','离职','S0020111030064','2011-03-30','一般证券业务','69948650','2018-03-08 10:07:26','2018-03-08 10:07:26')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450114060042'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450114060042','2014-06-24','一般证券业务','69948650','2018-03-08 10:07:26','2018-03-08 10:07:26')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450614100001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450614100001','2014-10-01','证券投资咨询业务(投资顾问)','69948650','2018-03-08 10:07:26','2018-03-08 10:07:26')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:26 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020059'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:26 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020059','2018-02-12','一般证券业务','69948650','2018-03-08 10:07:26','2018-03-08 10:07:26')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:27 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:27 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020078'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020078','2018-02-18','一般证券业务','276467','2018-03-08 10:07:27','2018-03-08 10:07:27')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:27 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:27 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020067'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:27 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020067','2018-02-17','一般证券业务','276423','2018-03-08 10:07:27','2018-03-08 10:07:27')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:29 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59078',
            'ADI_NAME': '深圳前海分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '黄伟民',
            'EmpHashID': '66D7420B2725B1CCE053D651A8C0B157',
            'EmpID': '277442',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020082',
            'QualificationStartDate': '2018-02-18',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-02-01/registrationRpInfo/151746717755315174671775530.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:30 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47696',
            'ADI_NAME': '阳江安宁路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '利显富',
            'EmpHashID': '66D7420B2D91B1CCE053D651A8C0B157',
            'EmpID': '277750',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020083',
            'QualificationStartDate': '2018-02-18',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-02-05/registrationRpInfo/151780904274315178090427430.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:30 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47624',
            'ADI_NAME': '黑龙江分公司',
            'ChangeInformationCount': '4',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '韩菲',
            'EmpHashID': '66D7420B2D72B1CCE053D651A8C0B157',
            'EmpID': '093308',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450618020009',
            'QualificationStartDate': '2018-02-27',
            'QualificationType': '证券投资咨询业务(投资顾问)',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080101/registrationRpInfo/136385907181477729.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:30 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55320',
            'ADI_NAME': '湖南分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '高中',
            'EmpFullName': '文霞梅',
            'EmpHashID': '66D7420B2ABFB1CCE053D651A8C0B157',
            'EmpID': '275361',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020073',
            'QualificationStartDate': '2018-02-17',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-17/registrationRpInfo/151615432928815161543292880.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:30 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47653',
            'ADI_NAME': '广西分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '邓志娟',
            'EmpHashID': '66D7420B2AA8B1CCE053D651A8C0B157',
            'EmpID': '275481',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010278',
            'QualificationStartDate': '2018-01-31',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-17/registrationRpInfo/151617432206415161743220640.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:31 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47593',
            'ADI_NAME': '北京远大路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '高中',
            'EmpFullName': '邢泽荻',
            'EmpHashID': '66D7420B26BCB1CCE053D651A8C0B157',
            'EmpID': '271739',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010100',
            'QualificationStartDate': '2018-01-13',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-26/registrationRpInfo/151428460280115142846028010.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:31 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47649',
            'ADI_NAME': '绵阳涪城路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '陈鹏',
            'EmpHashID': '66D7420B2D3DB1CCE053D651A8C0B157',
            'EmpID': '276648',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020029',
            'QualificationStartDate': '2018-02-06',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-25/registrationRpInfo/151688570394615168857039460.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:31 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '36837',
            'ADI_NAME': '投资银行业务委员会',
            'ChangeInformationCount': '5',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '硕士研究生',
            'EmpFullName': '董德喜',
            'EmpHashID': '66D7420B2D2BB1CCE053D651A8C0B157',
            'EmpID': '29970247',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010275',
            'QualificationStartDate': '2018-01-31',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080103/registrationRpInfo/136386499090518540.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:31 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0930109102844'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:31 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('光大证券股份有限公司','离职','S0930109102844','2009-10-22','一般证券业务','29970247','2018-03-08 10:07:31','2018-03-08 10:07:31')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0350112040022'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:31 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国海证券股份有限公司','离职','S0350112040022','2012-04-23','一般证券业务','29970247','2018-03-08 10:07:31','2018-03-08 10:07:31')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0880113070055'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:31 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国泰君安证券股份有限公司','离职','S0880113070055','2013-07-29','一般证券业务','29970247','2018-03-08 10:07:31','2018-03-08 10:07:31')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0960116030018'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:31 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('中国中投证券有限责任公司','离职','S0960116030018','2016-03-19','一般证券业务','29970247','2018-03-08 10:07:31','2018-03-08 10:07:31')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:31 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010275'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:31 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010275','2018-01-31','一般证券业务','29970247','2018-03-08 10:07:31','2018-03-08 10:07:31')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:32 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47653',
            'ADI_NAME': '广西分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '张日炜',
            'EmpHashID': '66D7420B2A67B1CCE053D651A8C0B157',
            'EmpID': '276414',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020027',
            'QualificationStartDate': '2018-02-06',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-24/registrationRpInfo/151677513502915167751350290.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:32 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:32 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020027'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:32 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020027','2018-02-06','一般证券业务','276414','2018-03-08 10:07:32','2018-03-08 10:07:32')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:32 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:32 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020029'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:32 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020029','2018-02-06','一般证券业务','276648','2018-03-08 10:07:32','2018-03-08 10:07:32')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:32 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:32 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010100'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:32 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010100','2018-01-13','一般证券业务','271739','2018-03-08 10:07:32','2018-03-08 10:07:32')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010278'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010278','2018-01-31','一般证券业务','275481','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020073'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020073','2018-02-17','一般证券业务','275361','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1410105070009'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('江海证券有限公司','离职','S1410105070009','2005-07-11','一般证券业务','093308','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1410611070010'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('江海证券有限公司','离职','S1410611070010','2011-07-27','证券投资咨询业务(投资顾问)','093308','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117020066'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450117020066','2017-02-17','一般证券业务','093308','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450618020009'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450618020009','2018-02-27','证券投资咨询业务(投资顾问)','093308','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020083'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020083','2018-02-18','一般证券业务','277750','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:33 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020082'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:33 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020082','2018-02-18','一般证券业务','277442','2018-03-08 10:07:33','2018-03-08 10:07:33')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:36 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '52336',
            'ADI_NAME': '威海新威路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '马冠宇',
            'EmpHashID': '66D7420B2A50B1CCE053D651A8C0B157',
            'EmpID': '277582',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118030009',
            'QualificationStartDate': '2018-03-05',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-02-02/registrationRpInfo/151755129852815175512985280.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:36 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:36 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118030009'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:36 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118030009','2018-03-05','一般证券业务','277582','2018-03-08 10:07:36','2018-03-08 10:07:36')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:36 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47685',
            'ADI_NAME': '深圳耀华创建大厦营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '陆顺姣',
            'EmpHashID': '66D7420B269FB1CCE053D651A8C0B157',
            'EmpID': '251129',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010204',
            'QualificationStartDate': '2018-01-24',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-08-29/registrationRpInfo/150400379598515040037959850.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:36 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '51246',
            'ADI_NAME': '厦门鹭江道营业部',
            'ChangeInformationCount': '4',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '田迪',
            'EmpHashID': '66D7420B2686B1CCE053D651A8C0B157',
            'EmpID': '39953120',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450618010006',
            'QualificationStartDate': '2018-01-16',
            'QualificationType': '证券投资咨询业务(投资顾问)',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080103/registrationRpInfo/136386547256929690.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:37 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:37 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0880100010443'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:37 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国泰君安证券股份有限公司','离职','S0880100010443','2004-07-19','一般证券业务','054358','2018-03-08 10:07:37','2018-03-08 10:07:37')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:37 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:37 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118030007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:37 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118030007','2018-03-04','一般证券业务','054358','2018-03-08 10:07:37','2018-03-08 10:07:37')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:37 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '57337',
            'ADI_NAME': '安徽分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '苏建军',
            'EmpHashID': '66D7420B255DB1CCE053D651A8C0B157',
            'EmpID': '272466',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010048',
            'QualificationStartDate': '2018-01-09',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-29/registrationRpInfo/151452955549915145295554990.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:38 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47673',
            'ADI_NAME': '上海杨高南路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '查玮晶',
            'EmpHashID': '66D7420B1D02B1CCE053D651A8C0B157',
            'EmpID': '272178',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010126',
            'QualificationStartDate': '2018-01-15',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-28/registrationRpInfo/151443545138115144354513810.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:38 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:38 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010126'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:38 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010126','2018-01-15','一般证券业务','272178','2018-03-08 10:07:38','2018-03-08 10:07:38')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:38 [scrapy.extensions.logstats] INFO: Crawled 245 pages (at 245 pages/min), scraped 350 items (at 350 items/min)
2018-03-08 10:07:38 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:38 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010090'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:38 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010090','2018-01-09','一般证券业务','271402','2018-03-08 10:07:38','2018-03-08 10:07:38')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010048'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010048','2018-01-09','一般证券业务','272466','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47592',
            'ADI_NAME': '北京复兴门外大街营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '张棣堃',
            'EmpHashID': '66D7420B2673B1CCE053D651A8C0B157',
            'EmpID': '273334',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010254',
            'QualificationStartDate': '2018-01-30',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-04/registrationRpInfo/151504747578515150474757850.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010254'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010254','2018-01-30','一般证券业务','273334','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0130111110125'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('中国银河证券股份有限公司','离职','S0130111110125','2011-11-04','一般证券业务','39953120','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190112040007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','机构内变更','S0190112040007','2012-04-13','一般证券业务','39953120','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190615010005'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','离职','S0190615010005','2015-01-21','证券投资咨询业务(投资顾问)','39953120','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450618010006'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450618010006','2018-01-16','证券投资咨询业务(投资顾问)','39953120','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0900417090053'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('申万宏源证券有限公司','离职','S0900417090053','2017-09-10','证券经纪人','251129','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:39 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010204'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:39 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010204','2018-01-24','一般证券业务','251129','2018-03-08 10:07:39','2018-03-08 10:07:39')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:40 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47589',
            'ADI_NAME': '保山保岫东路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '杨竑玥',
            'EmpHashID': '66D7420B26A7B1CCE053D651A8C0B157',
            'EmpID': '276353',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020024',
            'QualificationStartDate': '2018-02-06',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-24/registrationRpInfo/151676519071715167651907170.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:40 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:40 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020024'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:40 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020024','2018-02-06','一般证券业务','276353','2018-03-08 10:07:40','2018-03-08 10:07:40')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:43 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '56391',
            'ADI_NAME': '浙江分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '张宇烜',
            'EmpHashID': '66D7420B18E0B1CCE053D651A8C0B157',
            'EmpID': '271073',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010118',
            'QualificationStartDate': '2018-01-15',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-04/registrationRpInfo/151504354246015150435424600.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:43 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55407',
            'ADI_NAME': '清远分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '曾炘鹏',
            'EmpHashID': '66D7420B14B8B1CCE053D651A8C0B157',
            'EmpID': '79903223',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010094',
            'QualificationStartDate': '2018-01-09',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080104/registrationRpInfo/136387054138448800.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:43 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '51246',
            'ADI_NAME': '厦门鹭江道营业部',
            'ChangeInformationCount': '4',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '李宏平',
            'EmpHashID': '66D7420B211AB1CCE053D651A8C0B157',
            'EmpID': '058094',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450618010007',
            'QualificationStartDate': '2018-01-16',
            'QualificationType': '证券投资咨询业务(投资顾问)',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080102/registrationRpInfo/136386395137793026.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:43 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47649',
            'ADI_NAME': '绵阳涪城路证券营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '陈攀',
            'EmpHashID': '66D7420B18B1B1CCE053D651A8C0B157',
            'EmpID': '269406',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010020',
            'QualificationStartDate': '2018-01-07',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-13/registrationRpInfo/151315037615315131503761530.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:43 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59591',
            'ADI_NAME': '工会办公室',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '博士研究生',
            'EmpFullName': '于海莲',
            'EmpHashID': '66D7420B18ADB1CCE053D651A8C0B157',
            'EmpID': '79948334',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010208',
            'QualificationStartDate': '2018-01-27',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080101/registrationRpInfo/13638561318668674.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:44 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '53387',
            'ADI_NAME': '重庆分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '硕士研究生',
            'EmpFullName': '唐秋兰',
            'EmpHashID': '66D7420B18A9B1CCE053D651A8C0B157',
            'EmpID': '93310',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010095',
            'QualificationStartDate': '2018-01-10',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2015-08-04/registrationRpInfo/143864567344314386456734430.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:44 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59203',
            'ADI_NAME': '新疆分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '樊志宇',
            'EmpHashID': '66D7420B14A8B1CCE053D651A8C0B157',
            'EmpID': '270469',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010113',
            'QualificationStartDate': '2018-01-13',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-19/registrationRpInfo/151366441069915136644106990.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:44 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47592',
            'ADI_NAME': '北京复兴门外大街营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '高中',
            'EmpFullName': '何庆涛',
            'EmpHashID': '66D7420B1C83B1CCE053D651A8C0B157',
            'EmpID': '273021',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010130',
            'QualificationStartDate': '2018-01-15',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2018-01-03/registrationRpInfo/151496277417915149627741790.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:44 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:44 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010130'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:44 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010130','2018-01-15','一般证券业务','273021','2018-03-08 10:07:44','2018-03-08 10:07:44')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:44 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '53387',
            'ADI_NAME': '重庆分公司',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '中专',
            'EmpFullName': '李斌',
            'EmpHashID': '66D7420B146AB1CCE053D651A8C0B157',
            'EmpID': '39917309',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010210',
            'QualificationStartDate': '2018-01-27',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080104/registrationRpInfo/136387183219578612.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450310090006'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450310090006','2010-09-01','证券经纪业务营销','39917309','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450413070001'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450413070001','2013-07-01','证券经纪人','39917309','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010210'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010210','2018-01-27','一般证券业务','39917309','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010113'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010113','2018-01-13','一般证券业务','270469','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1250115080089'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('西南证券股份有限公司','离职','S1250115080089','2015-08-17','一般证券业务','93310','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010095'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010095','2018-01-10','一般证券业务','93310','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'F0690112080003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信基金管理有限责任公司','离职','F0690112080003','2012-08-31','一般证券业务','79948334','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:45 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010208'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:45 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010208','2018-01-27','一般证券业务','79948334','2018-03-08 10:07:45','2018-03-08 10:07:45')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010020'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010020','2018-01-07','一般证券业务','269406','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190100010668'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','离职','S0190100010668','2004-04-20','一般证券业务','058094','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190109031668'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','离职','S0190109031668','2009-03-31','一般证券业务','058094','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0190611040058'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('兴业证券股份有限公司','离职','S0190611040058','2011-04-08','证券投资咨询业务(投资顾问)','058094','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450618010007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450618010007','2018-01-16','证券投资咨询业务(投资顾问)','058094','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0340111100060'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('东莞证券股份有限公司','离职','S0340111100060','2011-10-14','一般证券业务','79903223','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010094'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010094','2018-01-09','一般证券业务','79903223','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:46 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010118'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:46 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010118','2018-01-15','一般证券业务','271073','2018-03-08 10:07:46','2018-03-08 10:07:46')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:49 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '55407',
            'ADI_NAME': '清远分公司',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '李莉',
            'EmpHashID': '66D7420B1840B1CCE053D651A8C0B157',
            'EmpID': '59963571',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010240',
            'QualificationStartDate': '2018-01-28',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080104/registrationRpInfo/136387055300749060.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:49 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47631',
            'ADI_NAME': '江门建设二路营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '胡小华',
            'EmpHashID': '66D7420B1414B1CCE053D651A8C0B157',
            'EmpID': '270678',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010107',
            'QualificationStartDate': '2018-01-13',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-20/registrationRpInfo/151374654993615137465499360.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:50 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:50 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010107'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:50 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010107','2018-01-13','一般证券业务','270678','2018-03-08 10:07:50','2018-03-08 10:07:50')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:50 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59203',
            'ADI_NAME': '新疆分公司',
            'ChangeInformationCount': '4',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '王雪娇',
            'EmpHashID': '66D7420B1413B1CCE053D651A8C0B157',
            'EmpID': '69933243',
            'Gender': '女',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010112',
            'QualificationStartDate': '2018-01-13',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080105/registrationRpInfo/136387357427721661.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:50 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59203',
            'ADI_NAME': '新疆分公司',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '郎超',
            'EmpHashID': '66D7420B1410B1CCE053D651A8C0B157',
            'EmpID': '69965838',
            'Gender': '男',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010110',
            'QualificationStartDate': '2018-01-13',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080105/registrationRpInfo/136387354505420878.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:50 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59203',
            'ADI_NAME': '新疆分公司',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '孙佳',
            'EmpHashID': '66D7420B1400B1CCE053D651A8C0B157',
            'EmpID': '243691',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010161',
            'QualificationStartDate': '2018-01-20',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-07-28/registrationRpInfo/150120974003215012097400320.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:51 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0210117080151'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:51 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('华福证券有限责任公司','离职','S0210117080151','2017-08-16','一般证券业务','243691','2018-03-08 10:07:51','2018-03-08 10:07:51')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010161'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:51 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010161','2018-01-20','一般证券业务','243691','2018-03-08 10:07:51','2018-03-08 10:07:51')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59088',
            'ADI_NAME': '武汉关山大道证券营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '高中',
            'EmpFullName': '汪贤坤',
            'EmpHashID': '66D7420B2051B1CCE053D651A8C0B157',
            'EmpID': '185531',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010125',
            'QualificationStartDate': '2018-01-15',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2016-10-28/registrationRpInfo/147764833918914776483391890.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:51 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1350416110283'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:51 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('九州证券股份有限公司','离职','S1350416110283','2016-11-19','证券经纪人','185531','2018-03-08 10:07:51','2018-03-08 10:07:51')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010125'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:51 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010125','2018-01-15','一般证券业务','185531','2018-03-08 10:07:51','2018-03-08 10:07:51')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:51 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010232'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:51 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010232','2018-01-28','一般证券业务','275445','2018-03-08 10:07:51','2018-03-08 10:07:51')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260111050349'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260111050349','2011-05-19','一般证券业务','69965838','2018-03-08 10:07:52','2018-03-08 10:07:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0680117080007'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('国盛证券有限责任公司','离职','S0680117080007','2017-08-05','一般证券业务','69965838','2018-03-08 10:07:52','2018-03-08 10:07:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010110'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010110','2018-01-13','一般证券业务','69965838','2018-03-08 10:07:52','2018-03-08 10:07:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260111010539'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260111010539','2011-01-30','一般证券业务','69933243','2018-03-08 10:07:52','2018-03-08 10:07:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260113060066'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','机构内变更','S0260113060066','2013-06-18','一般证券业务','69933243','2018-03-08 10:07:52','2018-03-08 10:07:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260616020041'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260616020041','2016-02-20','证券投资咨询业务(投资顾问)','69933243','2018-03-08 10:07:52','2018-03-08 10:07:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010112'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:52 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010112','2018-01-13','一般证券业务','69933243','2018-03-08 10:07:52','2018-03-08 10:07:52')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:52 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '36837',
            'ADI_NAME': '投资银行业务委员会',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '博士研究生',
            'EmpFullName': '马辉',
            'EmpHashID': '66D7420B1828B1CCE053D651A8C0B157',
            'EmpID': '29912928',
            'Gender': '男',
            'QualificationEndDate': '2018-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450718010003',
            'QualificationStartDate': '2018-01-10',
            'QualificationType': '保荐代表人',
            'image': 'http://photo.sac.net.cn/sacmp/images/20080101/registrationRpInfo/136385920957380985.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0550108111215'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('东北证券股份有限公司','离职','S0550108111215','2008-11-10','一般证券业务','29912928','2018-03-08 10:07:53','2018-03-08 10:07:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450111050004'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450111050004','2011-05-05','一般证券业务','29912928','2018-03-08 10:07:53','2018-03-08 10:07:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450718010003'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450718010003','2018-01-10','保荐代表人','29912928','2018-03-08 10:07:53','2018-03-08 10:07:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260110071019'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260110071019','2010-07-23','一般证券业务','59963571','2018-03-08 10:07:53','2018-03-08 10:07:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260417040068'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260417040068','2017-04-24','证券经纪人','59963571','2018-03-08 10:07:53','2018-03-08 10:07:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010240'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010240','2018-01-28','一般证券业务','59963571','2018-03-08 10:07:53','2018-03-08 10:07:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:53 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010211'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:53 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010211','2018-01-27','一般证券业务','274609','2018-03-08 10:07:53','2018-03-08 10:07:53')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:56 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '51254',
            'ADI_NAME': '山东分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '杨洁',
            'EmpHashID': '66D7420B1C1FB1CCE053D651A8C0B157',
            'EmpID': '269525',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010053',
            'QualificationStartDate': '2018-01-09',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-18/registrationRpInfo/151356232405015135623240500.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:56 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '47684',
            'ADI_NAME': '深圳沙头角营业部',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '刘颖冰',
            'EmpHashID': '66D7420B17F5B1CCE053D651A8C0B157',
            'EmpID': '270930',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010026',
            'QualificationStartDate': '2018-01-08',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-25/registrationRpInfo/151417135339715141713533970.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:56 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '53387',
            'ADI_NAME': '重庆分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '傅少川',
            'EmpHashID': '66D7420B17DFB1CCE053D651A8C0B157',
            'EmpID': '271630',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010039',
            'QualificationStartDate': '2018-01-08',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-26/registrationRpInfo/151427065033015142706503300.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:56 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '56990',
            'ADI_NAME': '邯郸人民路证券营业部',
            'ChangeInformationCount': '2',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '彭月',
            'EmpHashID': '66D7420B13CAB1CCE053D651A8C0B157',
            'EmpID': '253817',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020016',
            'QualificationStartDate': '2018-02-04',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-09-13/registrationRpInfo/150528209704715052820970470.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '51254',
            'ADI_NAME': '山东分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '曹金香',
            'EmpHashID': '66D7420B13ADB1CCE053D651A8C0B157',
            'EmpID': '271522',
            'Gender': '女',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118010122',
            'QualificationStartDate': '2018-01-15',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-26/registrationRpInfo/151425821821615142582182160.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '59149',
            'ADI_NAME': '韶关分公司',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '大专',
            'EmpFullName': '邓辉燕',
            'EmpHashID': '66D7420B2042B1CCE053D651A8C0B157',
            'EmpID': '267525',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450117120180',
            'QualificationStartDate': '2017-12-30',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-05/registrationRpInfo/151246655164715124665516470.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '56391',
            'ADI_NAME': '浙江分公司',
            'ChangeInformationCount': '3',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '赵娇珂',
            'EmpHashID': '66D7420B2022B1CCE053D651A8C0B157',
            'EmpID': '79355',
            'Gender': '女',
            'QualificationEndDate': '2019-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450618020002',
            'QualificationStartDate': '2018-02-06',
            'QualificationType': '证券投资咨询业务(投资顾问)',
            'image': 'http://photo.sac.net.cn/sacmp/images/2015-06-30/registrationRpInfo/143564135058014356413505800.jpg'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:57 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:57 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260115070080'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:57 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260115070080','2015-07-12','一般证券业务','79355','2018-03-08 10:07:57','2018-03-08 10:07:57')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:57 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:57 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117040041'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:57 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','机构内变更','S1450117040041','2017-04-04','一般证券业务','79355','2018-03-08 10:07:57','2018-03-08 10:07:57')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:57 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:57 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450618020002'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:57 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450618020002','2018-02-06','证券投资咨询业务(投资顾问)','79355','2018-03-08 10:07:57','2018-03-08 10:07:57')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:57 [scrapy.core.scraper] ERROR: Error processing {'db': 'dbo.SAC_ProfessionalQualificationPerson',
 'keys': ['EMPID'],
 'result': {'ADI_ID': '8480',
            'ADI_NAME': '信息技术中心',
            'ChangeInformationCount': '1',
            'CorpFullName': '安信证券股份有限公司',
            'CreditTip': None,
            'CropRowID': '1999145',
            'Education': '本科',
            'EmpFullName': '刘洁',
            'EmpHashID': '66D7420B1BD3B1CCE053D651A8C0B157',
            'EmpID': '269727',
            'Gender': '男',
            'QualificationEndDate': '2020-12-31',
            'QualificationName': '执业证书',
            'QualificationNo': 'S1450118020022',
            'QualificationStartDate': '2018-02-06',
            'QualificationType': '一般证券业务',
            'image': 'http://photo.sac.net.cn/sacmp/images/2017-12-14/registrationRpInfo/151324673708215132467370820.JPG'}}
Traceback (most recent call last):
  File "f:\envs\work\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\gitwork\pipeline.py", line 461, in process_item
    main(item)
  File "F:\gitwork\pipeline.py", line 449, in main
    self.tableName)
  File "F:\gitwork\pipeline.py", line 345, in sqlquery
    item, keys, wherekeys, tb, isfetchall=isfetchall)
  File "F:\gitwork\pipeline.py", line 102, in foo
    result = func(self, *args, **kwargs)
  File "F:\gitwork\pipeline.py", line 118, in getQueryResult
    wherekv[i] = items[i]
KeyError: 'EMPID'
2018-03-08 10:07:58 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:58 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020022'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:58 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020022','2018-02-06','一般证券业务','269727','2018-03-08 10:07:58','2018-03-08 10:07:58')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:58 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:58 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450117120180'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:58 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450117120180','2017-12-30','一般证券业务','267525','2018-03-08 10:07:58','2018-03-08 10:07:58')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:58 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:58 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010122'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:58 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010122','2018-01-15','一般证券业务','271522','2018-03-08 10:07:58','2018-03-08 10:07:58')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S0260117100026'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('广发证券股份有限公司','离职','S0260117100026','2017-10-05','一般证券业务','253817','2018-03-08 10:07:59','2018-03-08 10:07:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118020016'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118020016','2018-02-04','一般证券业务','253817','2018-03-08 10:07:59','2018-03-08 10:07:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010039'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010039','2018-01-08','一般证券业务','271630','2018-03-08 10:07:59','2018-03-08 10:07:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010026'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010026','2018-01-08','一般证券业务','270930','2018-03-08 10:07:59','2018-03-08 10:07:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-03-08 10:07:59 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-03-08 10:07:59 [scrapy.log] ERROR: ProgrammingError(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:07:59 [scrapy.log] ERROR: sql is:select CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID from dbo.SAC_Employee_Change where QualificationNo = 'S1450118010053'/n reason is :Statement not executed or executed statement has no resultset
2018-03-08 10:07:59 [scrapy.log] INFO: sql is:insert into dbo.SAC_Employee_Change (CorpFullName,QualificationStatus,QualificationNo,QualificationStartDate,QualificationType,EmpID,AddTime,Checktime) values ('安信证券股份有限公司','正常','S1450118010053','2018-01-09','一般证券业务','269525','2018-03-08 10:07:59','2018-03-08 10:07:59')/n reason is :(208, b"Invalid object name 'dbo.SAC_Employee_Change'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n")
2018-03-08 10:08:00 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
